{
    "links": [
        "https://helmholtz.software/software/2x2-3x3-and-nxn-space-filling-curves",
        "https://helmholtz.software/software/ai4hpc",
        "https://helmholtz.software/software/aiida-kkr",
        "https://helmholtz.software/software/aiida-spirit",
        "https://helmholtz.software/software/album",
        "https://helmholtz.software/software/alice2modelica",
        "https://helmholtz.software/software/allpix-squared",
        "https://helmholtz.software/software/alpaca",
        "https://helmholtz.software/software/alpaka",
        "https://helmholtz.software/software/amiris",
        "https://helmholtz.software/software/anndata",
        "https://helmholtz.software/software/ansible-collection-toolkit",
        "https://helmholtz.software/software/anvio",
        "https://helmholtz.software/software/arbor",
        "https://helmholtz.software/software/ardoco",
        "https://helmholtz.software/software/arosics",
        "https://helmholtz.software/software/atomec",
        "https://helmholtz.software/software/autogaita",
        "https://helmholtz.software/software/autopq",
        "https://helmholtz.software/software/autopv",
        "https://helmholtz.software/software/autowp",
        "https://helmholtz.software/software/aviator",
        "https://helmholtz.software/software/awi-gpt",
        "https://helmholtz.software/software/awi-pangaea-ai-hub",
        "https://helmholtz.software/software/base-repo",
        "https://helmholtz.software/software/basic",
        "https://helmholtz.software/software/basicpy",
        "https://helmholtz.software/software/beluga",
        "https://helmholtz.software/software/bending-stiffness",
        "https://helmholtz.software/software/beos",
        "https://helmholtz.software/software/bifurcations-discrete-maps",
        "https://helmholtz.software/software/bioautoml",
        "https://helmholtz.software/software/blenderproc",
        "https://helmholtz.software/software/boxbeam",
        "https://helmholtz.software/software/brainprint",
        "https://helmholtz.software/software/cadet",
        "https://helmholtz.software/software/calibr8",
        "https://helmholtz.software/software/cat4kit",
        "https://helmholtz.software/software/catena",
        "https://helmholtz.software/software/celldetection",
        "https://helmholtz.software/software/cellrank",
        "https://helmholtz.software/software/chase",
        "https://helmholtz.software/software/cheetah",
        "https://helmholtz.software/software/chemotion-eln",
        "https://helmholtz.software/software/climate-index-collection",
        "https://helmholtz.software/software/cimpredict",
        "https://helmholtz.software/software/circlize",
        "https://helmholtz.software/software/citation-file-format",
        "https://helmholtz.software/software/citychem",
        "https://helmholtz.software/software/climsight",
        "https://helmholtz.software/software/cnpypp",
        "https://helmholtz.software/software/cola",
        "https://helmholtz.software/software/collector-app",
        "https://helmholtz.software/software/comando",
        "https://helmholtz.software/software/comola",
        "https://helmholtz.software/software/complexheatmap",
        "https://helmholtz.software/software/cipm",
        "https://helmholtz.software/software/copy-paste-imputation",
        "https://helmholtz.software/software/corc",
        "https://helmholtz.software/software/corsika",
        "https://helmholtz.software/software/cosmoscout-vr",
        "https://helmholtz.software/software/cp2k",
        "https://helmholtz.software/software/cryogrid",
        "https://helmholtz.software/software/crystfel",
        "https://helmholtz.software/software/cuas-mpi",
        "https://helmholtz.software/software/cubegui",
        "https://helmholtz.software/software/cubelib",
        "https://helmholtz.software/software/cubew",
        "https://helmholtz.software/software/cudamemtest",
        "https://helmholtz.software/software/cupla",
        "https://helmholtz.software/software/damnit",
        "https://helmholtz.software/software/dasf-messaging-python",
        "https://helmholtz.software/software/datadesc",
        "https://helmholtz.software/software/datalad",
        "https://helmholtz.software/software/datalad-container-extension",
        "https://helmholtz.software/software/datalad-next-extension",
        "https://helmholtz.software/software/datasail",
        "https://helmholtz.software/software/dcache",
        "https://helmholtz.software/software/deeploki",
        "https://helmholtz.software/software/deploy2zenodo",
        "https://helmholtz.software/software/deus",
        "https://helmholtz.software/software/digital-earth-viewer",
        "https://helmholtz.software/software/dirschema",
        "https://helmholtz.software/software/displam",
        "https://helmholtz.software/software/dl4pude",
        "https://helmholtz.software/software/earth-system-model-evaluation-tool-esmvaltool",
        "https://helmholtz.software/software/easywave",
        "https://helmholtz.software/software/egsim",
        "https://helmholtz.software/software/ehrapy",
        "https://helmholtz.software/software/electrode",
        "https://helmholtz.software/software/elephant",
        "https://helmholtz.software/software/emipy",
        "https://helmholtz.software/software/enpt",
        "https://helmholtz.software/software/enrichedheatmap",
        "https://helmholtz.software/software/esm-tools",
        "https://helmholtz.software/software/esmvalcore",
        "https://helmholtz.software/software/ethosfine-framework-for-integrated-energy-system-assessment",
        "https://helmholtz.software/software/hisim",
        "https://helmholtz.software/software/ethospenalps",
        "https://helmholtz.software/software/ethosreflow",
        "https://helmholtz.software/software/ethoszoomin",
        "https://helmholtz.software/software/elias",
        "https://helmholtz.software/software/beta-faircore4eosc",
        "https://helmholtz.software/software/fairmq",
        "https://helmholtz.software/software/fame",
        "https://helmholtz.software/software/fastscape-toolbox",
        "https://helmholtz.software/software/fastsurfer",
        "https://helmholtz.software/software/fatsegnet",
        "https://helmholtz.software/software/fesom",
        "https://helmholtz.software/software/fishinspector",
        "https://helmholtz.software/software/fiware-deployment-kit",
        "https://helmholtz.software/software/fleur",
        "https://helmholtz.software/software/formatfuzzer",
        "https://helmholtz.software/software/fracspy",
        "https://helmholtz.software/software/fsqc",
        "https://helmholtz.software/software/gaia",
        "https://helmholtz.software/software/gasnetsim",
        "https://helmholtz.software/software/geomultisens",
        "https://helmholtz.software/software/gfzrnx",
        "https://helmholtz.software/software/ginkgo",
        "https://helmholtz.software/software/gipptools",
        "https://helmholtz.software/software/glaes",
        "https://helmholtz.software/software/global-benchmark-database-gbd",
        "https://helmholtz.software/software/gmgpolar",
        "https://helmholtz.software/software/goac",
        "https://helmholtz.software/software/golem",
        "https://helmholtz.software/software/gravis",
        "https://helmholtz.software/software/gr-framework",
        "https://helmholtz.software/software/gstools",
        "https://helmholtz.software/software/habitat-sampler",
        "https://helmholtz.software/software/hcocena",
        "https://helmholtz.software/software/heat",
        "https://helmholtz.software/software/heatnetsim",
        "https://helmholtz.software/software/heliport",
        "https://helmholtz.software/software/hifis-rsd",
        "https://helmholtz.software/software/higgs-dataset-training",
        "https://helmholtz.software/software/hilbertcurve",
        "https://helmholtz.software/software/hipsta",
        "https://helmholtz.software/software/holowizard",
        "https://helmholtz.software/software/hybridmt",
        "https://helmholtz.software/software/icgem",
        "https://helmholtz.software/software/ideal-equilibrium-oxygen-membrane-reactor",
        "https://helmholtz.software/software/igmas",
        "https://helmholtz.software/software/interactivecomplexheatmap",
        "https://helmholtz.software/software/interactivevis",
        "https://helmholtz.software/software/ioproc",
        "https://helmholtz.software/software/iqtools",
        "https://helmholtz.software/software/isaac",
        "https://helmholtz.software/software/jards",
        "https://helmholtz.software/software/jcuber",
        "https://helmholtz.software/software/jemris",
        "https://helmholtz.software/software/jplag",
        "https://helmholtz.software/software/jtrack",
        "https://helmholtz.software/software/jube",
        "https://helmholtz.software/software/jukkr",
        "https://helmholtz.software/software/julearn",
        "https://helmholtz.software/software/jumpdiff",
        "https://helmholtz.software/software/jumper",
        "https://helmholtz.software/software/jupedsim",
        "https://helmholtz.software/software/jupyterhub-outpost",
        "https://helmholtz.software/software/jupyterhub-outpostspawner",
        "https://helmholtz.software/software/jurassic",
        "https://helmholtz.software/software/juri",
        "https://helmholtz.software/software/kaapana",
        "https://helmholtz.software/software/kadi4mat",
        "https://helmholtz.software/software/kagen-communication-free-massively-distributed-graph-generators",
        "https://helmholtz.software/software/kahypar",
        "https://helmholtz.software/software/kaminpar",
        "https://helmholtz.software/software/kamping-karlsruhe-mpi-next-generation",
        "https://helmholtz.software/software/karri",
        "https://helmholtz.software/software/kd-tree-python",
        "https://helmholtz.software/software/key",
        "https://helmholtz.software/software/keymaera-x",
        "https://helmholtz.software/software/kinfit",
        "https://helmholtz.software/software/kramersmoyal",
        "https://helmholtz.software/software/lapy",
        "https://helmholtz.software/software/libertem",
        "https://helmholtz.software/software/lightning-uq-box",
        "https://helmholtz.software/software/linmog",
        "https://helmholtz.software/software/llama",
        "https://helmholtz.software/software/llview",
        "https://helmholtz.software/software/lynx",
        "https://helmholtz.software/software/maftools",
        "https://helmholtz.software/software/mainzelliste",
        "https://helmholtz.software/software/mallob",
        "https://helmholtz.software/software/mallocmc",
        "https://helmholtz.software/software/mapman",
        "https://helmholtz.software/software/massbank",
        "https://helmholtz.software/software/materials-learning-algorithms",
        "https://helmholtz.software/software/matrad",
        "https://helmholtz.software/software/mcodac",
        "https://helmholtz.software/software/me-compute",
        "https://helmholtz.software/software/mitk",
        "https://helmholtz.software/software/membrain-v2",
        "https://helmholtz.software/software/mercy",
        "https://helmholtz.software/software/merkle-dag-matlab",
        "https://helmholtz.software/software/meshit",
        "https://helmholtz.software/software/messy",
        "https://helmholtz.software/software/metabolator",
        "https://helmholtz.software/software/methylkit",
        "https://helmholtz.software/software/metrics-reloaded",
        "https://helmholtz.software/software/mfdfa",
        "https://helmholtz.software/software/mhm",
        "https://helmholtz.software/software/mibianto",
        "https://helmholtz.software/software/micromechanics-indentationgui",
        "https://helmholtz.software/software/millepede-ii",
        "https://helmholtz.software/software/minterpy",
        "https://helmholtz.software/software/mirp",
        "https://helmholtz.software/software/mlair",
        "https://helmholtz.software/software/mmpxrt",
        "https://helmholtz.software/software/mdis",
        "https://helmholtz.software/software/mode-behave",
        "https://helmholtz.software/software/moovie",
        "https://helmholtz.software/software/mptrac",
        "https://helmholtz.software/software/mss",
        "https://helmholtz.software/software/mtress",
        "https://helmholtz.software/software/multiphase-code-repository-by-hzdr",
        "https://helmholtz.software/software/nest",
        "https://helmholtz.software/software/nest-ml",
        "https://helmholtz.software/software/nuclear-nexus",
        "https://helmholtz.software/software/nnu-net",
        "https://helmholtz.software/software/nodejs-tcp-server-client",
        "https://helmholtz.software/software/nodejs-tls-server-client",
        "https://helmholtz.software/software/novosparc",
        "https://helmholtz.software/software/o3as",
        "https://helmholtz.software/software/odm2sms",
        "https://helmholtz.software/software/odv",
        "https://helmholtz.software/software/oemof-solph",
        "https://helmholtz.software/software/opencarp",
        "https://helmholtz.software/software/openfuelcell2",
        "https://helmholtz.software/software/opengeosys",
        "https://helmholtz.software/software/openpmd-api",
        "https://helmholtz.software/software/osadcp-toolbox",
        "https://helmholtz.software/software/otter",
        "https://helmholtz.software/software/palladio",
        "https://helmholtz.software/software/training-catalogue-for-photon-neutron",
        "https://helmholtz.software/software/pasta-bit-vector",
        "https://helmholtz.software/software/pdaf",
        "https://helmholtz.software/software/peakperformance",
        "https://helmholtz.software/software/pecon",
        "https://helmholtz.software/software/pedpy",
        "https://helmholtz.software/software/pepc",
        "https://helmholtz.software/software/perihub",
        "https://helmholtz.software/software/perilab",
        "https://helmholtz.software/software/perun",
        "https://helmholtz.software/software/petrack",
        "https://helmholtz.software/software/php-codemeta-crosswalk",
        "https://helmholtz.software/software/picongpu",
        "https://helmholtz.software/software/pigx",
        "https://helmholtz.software/software/pkgndep",
        "https://helmholtz.software/software/pointneighborsjl",
        "https://helmholtz.software/software/postwrf",
        "https://helmholtz.software/software/potsdam-open-source-radio-interferometry-tool",
        "https://helmholtz.software/software/profasi",
        "https://helmholtz.software/software/propulate",
        "https://helmholtz.software/software/pia",
        "https://helmholtz.software/software/ptylab",
        "https://helmholtz.software/software/pyapi-rts",
        "https://helmholtz.software/software/pycomlink",
        "https://helmholtz.software/software/pygms",
        "https://helmholtz.software/software/pyquickmaps",
        "https://helmholtz.software/software/pysdc",
        "https://helmholtz.software/software/python-icat",
        "https://helmholtz.software/software/pyxmake",
        "https://helmholtz.software/software/quast",
        "https://helmholtz.software/software/radiative-forcing-of-hypersonic-aircraft-trajectories",
        "https://helmholtz.software/software/radplanbio",
        "https://helmholtz.software/software/rafcon",
        "https://helmholtz.software/software/random-simplex",
        "https://helmholtz.software/software/rankings-reloaded",
        "https://helmholtz.software/software/rayx",
        "https://helmholtz.software/software/rce",
        "https://helmholtz.software/software/reflectorch",
        "https://helmholtz.software/software/remix",
        "https://helmholtz.software/software/restore",
        "https://helmholtz.software/software/rgreat",
        "https://helmholtz.software/software/ribodetector",
        "https://helmholtz.software/software/rtlola-frontend",
        "https://helmholtz.software/software/rtlola-interpreter",
        "https://helmholtz.software/software/s2downloader",
        "https://helmholtz.software/software/sampledb",
        "https://helmholtz.software/software/saqc",
        "https://helmholtz.software/software/scalasca",
        "https://helmholtz.software/software/scanpy",
        "https://helmholtz.software/software/scits",
        "https://helmholtz.software/software/score-p",
        "https://helmholtz.software/software/sdaas",
        "https://helmholtz.software/software/seisbench",
        "https://helmholtz.software/software/seiscomp",
        "https://helmholtz.software/software/sensor-management-system",
        "https://helmholtz.software/software/serghei",
        "https://helmholtz.software/software/sfctools",
        "https://helmholtz.software/software/shepard",
        "https://helmholtz.software/software/shockhash",
        "https://helmholtz.software/software/sichash",
        "https://helmholtz.software/software/signal-processor",
        "https://helmholtz.software/software/simcats",
        "https://helmholtz.software/software/simona",
        "https://helmholtz.software/software/simpa",
        "https://helmholtz.software/software/simplifyenrichment",
        "https://helmholtz.software/software/smash",
        "https://helmholtz.software/software/smg2s",
        "https://helmholtz.software/software/somesy",
        "https://helmholtz.software/software/spatialdata-framework",
        "https://helmholtz.software/software/spatialio",
        "https://helmholtz.software/software/spechomo",
        "https://helmholtz.software/software/spex",
        "https://helmholtz.software/software/spiralize",
        "https://helmholtz.software/software/spirit",
        "https://helmholtz.software/software/stable-baselines3",
        "https://helmholtz.software/software/stmlab",
        "https://helmholtz.software/software/stream2segment",
        "https://helmholtz.software/software/sumo",
        "https://helmholtz.software/software/supervillain",
        "https://helmholtz.software/software/swh-client",
        "https://helmholtz.software/software/t8code",
        "https://helmholtz.software/software/tamarin-prover",
        "https://helmholtz.software/software/tbt-segmentation",
        "https://helmholtz.software/software/tereno-doi",
        "https://helmholtz.software/software/tetrax",
        "https://helmholtz.software/software/tigl",
        "https://helmholtz.software/software/tigramite",
        "https://helmholtz.software/software/timeio",
        "https://helmholtz.software/software/timeseries-management",
        "https://helmholtz.software/software/tixi",
        "https://helmholtz.software/software/tomato-tools",
        "https://helmholtz.software/software/tomobear",
        "https://helmholtz.software/software/treams",
        "https://helmholtz.software/software/tridec-cloud",
        "https://helmholtz.software/software/trimmomatic",
        "https://helmholtz.software/software/trixiparticlesjl",
        "https://helmholtz.software/software/tsmp",
        "https://helmholtz.software/software/ukis-csmask",
        "https://helmholtz.software/software/ultimodel",
        "https://helmholtz.software/software/ultramassexplorer-ume",
        "https://helmholtz.software/software/unicore",
        "https://helmholtz.software/software/uqtestfuns",
        "https://helmholtz.software/software/urbem-urban-emission-downscaling-for-air-quality-modeling",
        "https://helmholtz.software/software/urmoac",
        "https://helmholtz.software/software/utile-oxy",
        "https://helmholtz.software/software/varfish",
        "https://helmholtz.software/software/vasca",
        "https://helmholtz.software/software/velocityconversion",
        "https://helmholtz.software/software/vencopy",
        "https://helmholtz.software/software/vinos",
        "https://helmholtz.software/software/vitess",
        "https://helmholtz.software/software/vitruvius",
        "https://helmholtz.software/software/voltron",
        "https://helmholtz.software/software/weskit",
        "https://helmholtz.software/software/wombat",
        "https://helmholtz.software/software/wps-command-line-tool-repository",
        "https://helmholtz.software/software/wrainfo",
        "https://helmholtz.software/software/xcascade",
        "https://helmholtz.software/software/xdibias",
        "https://helmholtz.software/software/xraypac"
    ],
    "final_links": [
        {
            "software_organization": "https://helmholtz.software/software/2x2-3x3-and-nxn-space-filling-curves",
            "repo_link": "https://github.com/jokergoo/sfcurve",
            "readme": "# sfcurve: 2x2, 3x3 and nxn Space-Filling Curves\n\n[![CRAN](https://www.r-pkg.org/badges/version/sfcurve)](https://cran.r-project.org/web/packages/sfcurve/index.html)\n[![CRAN](https://cranlogs.r-pkg.org/badges/grand-total/sfcurve)](https://cran.r-project.org/web/packages/sfcurve/index.html)\n\n\n![](https://github.com/user-attachments/assets/7e0e14e7-1300-421f-8ffe-113b80caee97)\n\n\nThis package provides a way to encode all possible forms of 2x2 and 3x3\nspace-filling curves. For example, the following eight forms correspond to the\n2x2 curve on level 3 and with `R(0)` (bottom-in right-out base pattern with rotation\nof 0 degree) as the seed.\n\n<img src=\"https://github.com/user-attachments/assets/82b56013-8e9e-45f6-b77a-0875769c6369\" width=700 />\n\nIt also supports nxn curves expanded from any valid level-1 unit.\n\n## Install\n\n```r\ninstall.packages(\"sfcurve\")\n```\n\nor the devel version:\n\n```r\ndevtools::install_github(\"jokergoo/sfcurve\")\n```\n\n## Usage\n\nHilbert curve (2x2):\n\n```\n> sfc_2x2(\"I\", \"111\")\nAn sfc_2x2 object.\n  Increase mode: 2 x 2\n  Level: 3\n  Expansion rule: 2x2\n\nA sequence of 64 base patterns.\n  R(0)L(270)L(0)R(90)     I(0)R(0)R(270)L(180)\n  L(270)R(0)R(270)I(180)  R(180)L(90)L(180)I(270)\n  .... other 4 lines ....\n  I(90)L(90)L(180)R(270)  I(180)R(180)R(90)L(0)\n  L(90)R(180)R(90)I(0)    R(0)L(270)L(0)R(90)\n\nSeed: A sequence of 1 base pattern.\n  I(0)\n```\n\nPeano curve (3x3):\n\n```\n> sfc_3x3_peano(\"I\", \"111\")\nAn sfc_3x3_peano object.\n  Increase mode: 3 x 3\n  Level: 3\n  Expansion rule: 3x3 Peano\n\nA sequence of 729 base patterns.\n  I(0)J(0)R(0)R(270)  I(180)L(180)L(270)J(0)\n  I(0)J(0)I(0)L(0)    L(90)J(180)R(180)R(90)\n  .... other 88 lines ....\n  I(0)J(0)R(0)R(270)  I(180)L(180)L(270)J(0)\n  I(0)\n\nSeed: A sequence of 1 base pattern.\n  I(0)\n```\n\nMeander curve (3x3):\n\n```\n> sfc_3x3_meander(\"I\", \"111\")\nAn sfc_3x3_meander object.\n  Increase mode: 3 x 3\n  Level: 3\n  Expansion rule: 3x3 Meander\n\nA sequence of 729 base patterns.\n  R(0)I(270)L(270)I(0)  L(0)L(90)R(180)R(90)\n  I(0)R(0)I(270)L(270)  I(0)L(0)L(90)R(180)\n  .... other 88 lines ....\n  R(0)I(270)L(270)I(0)  L(0)L(90)R(180)R(90)\n  I(0)\n\nSeed: A sequence of 1 base pattern.\n  I(0)\n```\n\nIt also allows using a sequence as the seed:\n\n\n```\np = sfc_seed(\"LLLILILIILIILIIILIIILIIII\")\np2 = sfc_2x2(p, \"1111\")\nplot(p2)\n```\n\n<img src=\"https://github.com/user-attachments/assets/f1144f7f-282f-4988-aafd-9f712dd3ed2d\" width=500 />\n\nFor more comprehensive introduction of the theory and the package, please refer to the vignettes.\n\n## License\n\nMIT @ Zuguang Gu\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ai4hpc",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/CoE-RAISE/FZJ/ai4hpc/ai4hpc",
            "readme": "# AI4HPC\n\n[**AI4HPC**](https://ai4hpc.readthedocs.io), part of [CoE RAISE](https://www.coe-raise.eu/), is an open-source library to train AI models with CFD datasets on HPC systems. \n\nIn CoE RAISE, innovative AI methods on heterogeneous HPC architectures capable of scaling towards Exascale are developed and generalized for selected representative simulation codes and data-driven workflows.\n\n**AI4HPC** consists of data manipulation routines tuned to handle CFD datasets, ML models useful for CFD analyses, and optimizations for HPC systems. **AI4HPC** also includes a benchmarking suite to test the limits of any system with CPUs and GPUs towards Exascale and a HyperParameter Optimization (HPO) suite for scalable HPO tasks.\n\nThe documentation is available at https://ai4hpc.readthedocs.io.\n\n![](./docs/images/ai4hpc.png)\n\n#### Acknowledgement:\nThe development leading to these results has received funding from the European Union’s Horizon 2020 – Research and Innovation Framework Programme H2020–INFRAEDI–2019–1 under grant agreement no. 951733.\n\n![](./docs/images/eu_logo.png)\n\n#### Contact:\nDo not hesitate to contact EI for any comments and/or questions!\\\nEI - e.inanc@fz-juelich.de\n\n\n",
            "project_id": "4370"
        },
        {
            "software_organization": "https://helmholtz.software/software/aiida-kkr",
            "repo_link": "https://github.com/JuDFTteam/aiida-kkr",
            "readme": "[![aiida-core](https://img.shields.io/badge/AiiDA->=v2.0.0,<3.0.0-1f425f.svg?logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAACMAAAAhCAYAAABTERJSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAFhgAABYYBG6Yz4AAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAAUbSURBVFiFzZhrbFRVEMd%2Fc%2B5uu6UUbIFC%2FUAUVEQCLbQJBIiBDyiImJiIhmohYNCkqJAQxASLF8tDgYRHBLXRhIcKNtFEhVDgAxBJqgmVh4JEKg3EIn2QYqBlt917xg%2BFss%2ByaDHOtzsz5z%2B%2FuZl7ztmF%2F5HJvxVQN6cPYX8%2FPLnOmsvNAvqfwuib%2FbNIk9cQeQnLcKRL5xLIV%2Fic9eJeunjPYbRs4FjQSpTB3aS1IpRKeeOOewajy%2FKKEO8Q0DuVdKy8IqsbPulxGHUfCBBu%2BwUYGuFuBTK7wQnht6PEbf4tlRomVRjCbXNjQEB0AyrFQOL5ENIJm7dTLZE6DPJCnEtFZVXDLny%2B4Sjv0PmmYu1ZdUek9RiMgoDmJ8V0L7XJqsZ3UW8YsBOwEeHeeFce7jEYXBy0m9m4BbXqSj2%2Bxnkg26MCVrN6DEZcwggtd8pTFx%2Fh3B9B50YLaFOPwXQKUt0tBLegtSomfBlfY13PwijbEnhztGzgJsK5h9W9qeWwBqjvyhB2iBs1Qz0AU974DciRGO8CVN8AJhAeMAdA3KbrKEtvxhsI%2B9emWiJlGBEU680Cfk%2BSsVqXZvcFYGXjF8ABVJ%2BTNfVXehyms1zzn1gmIOxLEB6E31%2FWBe5rnCarmo7elf7dJEeaLh80GasliI5F6Q9cAz1GY1OJVNDxTzQTw7iY%2FHEZRQY7xqJ9RU2LFe%2FYqakdP911ha0XhjjiTVAkDwgatWfCGeYocx8M3glG8g8EXhSrLrHnEFJ5Ymow%2FkhIYv6ttYUW1iFmEqqxdVoUs9FmsDYSqmtmJh3Cl1%2BVtl2s7owDUdocR5bceiyoSivGTT5vzpbzL1uoBpmcAAQgW7ArnKD9ng9rc%2BNgrobSNwpSkkhcRN%2BvmXLjIsDovYHHEfmsYFygPAnIDEQrQPzJYCOaLHLUfIt7Oq0LJn9fxkSgNCb1qEIQ5UKgT%2Fs6gJmVOOroJhQBXVqw118QtWLdyUxEP45sUpSzqP7RDdFYMyB9UReMiF1MzPwoUqHt8hjGFFeP5wZAbZ%2F0%2BcAtAAcji6LeSq%2FMYiAvSsdw3GtrfVSVFUBbIhwRWYR7yOcr%2FBi%2FB1MSJZ16JlgH1AGM3EO2QnmMyrSbTSiACgFBv4yCUapZkt9qwWVL7aeOyHvArJjm8%2Fz9BhdI4XcZgz2%2FvRALosjsk1ODOyMcJn9%2FYI6IrkS5vxMGdUwou2YKfyVqJpn5t9aNs3gbQMbdbkxnGdsr4bTHm2AxWo9yNZK4PXR3uzhAh%2BM0AZejnCrGdy0UvJxl0oMKgWSLR%2B1LH2aE9ViejiFs%2BXn6bTjng3MlIhJ1I1TkuLdg6OcAbD7Xx%2Bc3y9TrWAiSHqVkbZ2v9ilCo6s4AjwZCzFyD9mOL305nV9aonvsQeT2L0gVk4OwOJqXXVRW7naaxswDKVdlYLyMXAnntteYmws2xcVVZzq%2BtHPAooQggmJkc6TLSusOiL4RKgwzzYU1iFQgiUBA1H7E8yPau%2BZl9P7AblVNebtHqTgxLfRqrNvZWjsHZFuqMqKcDWdlFjF7UGvX8Jn24DyEAykJwNcdg0OvJ4p5pQ9tV6SMlP4A0PNh8aYze1ArROyUNTNouy8tNF3Rt0CSXb6bRFl4%2FIfQzNMjaE9WwpYOWQnOdEF%2BTdJNO0iFh7%2BI0kfORzQZb6P2kymS9oTxzBiM9rUqLWr1WE5G6ODhycQd%2FUnNVeMbcH68hYkGycNoUNWc8fxaxfwhDbHpfwM5oeTY7rUX8QAAAABJRU5ErkJggg%3D%3D)](https://www.aiida.net/)\n[![Documentation Status](https://readthedocs.org/projects/aiida-kkr/badge/?version=latest)](https://aiida-kkr.readthedocs.io/en/latest/?badge=latest)\n[![Build status](https://github.com/JuDFTteam/aiida-kkr/actions/workflows/ci.yml/badge.svg)](https://github.com/JuDFTteam/aiida-kkr/actions)\n[![codecov](https://codecov.io/gh/JuDFTteam/aiida-kkr/branch/develop/graph/badge.svg)](https://codecov.io/gh/JuDFTteam/aiida-kkr)\n[![MIT license](http://img.shields.io/badge/license-MIT-brightgreen.svg)](http://opensource.org/licenses/MIT)\n[![GitHub version](https://badge.fury.io/gh/JuDFTteam%2Faiida-kkr.svg)](https://badge.fury.io/gh/JuDFTteam%2Faiida-kkr)\n[![PyPI version](https://badge.fury.io/py/aiida-kkr.svg)](https://badge.fury.io/py/aiida-kkr)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3628250.svg)](https://doi.org/10.5281/zenodo.3628250)\n\n\n\n# aiida-kkr\n\n[AiiDA](https://aiida.net) plugin for the [Jülich KKR codes](https://jukkr.fz-juelich.de) plus workflows and utility.\n\n## Features\n\n* KKR calculations for bulk and interfaces\n* treatment of alloys using VCA or CPA\n* self-consistency, DOS and bandstructure calculations\n* extraction of magnetic exchange coupling parameters (*J_ij*, *D_ij*)\n* impurity embedding solving the Dyson equation\n\n\n## How to cite\n\nIf you use this plugin please cite:\n> [Rüßmann, P., Bertoldo, F. & Blügel, S. The AiiDA-KKR plugin and its application to high-throughput impurity embedding into a topological insulator. *npj Comput Mater* **7**, 13 (2021). https://doi.org/10.1038/s41524-020-00482-5](https://doi.org/10.1038/s41524-020-00482-5)\n\nThe ArXiv preprint can be found here:\n> [Philipp Rüßmann, Fabian Bertoldo and Stefan Blügel, *The AiiDA-KKR plugin and its application to high-throughput impurity embedding into a topological insulator*, arXiv:2003.08315 [cond-mat.mtrl-sci] (2020)](https://arxiv.org/abs/2003.08315)\n\n\n# Installation\n\n```shell\n$ pip install aiida-kkr  # install latest version of aiida-kkr (published on pypi.org)\n$ reentry scan -r aiida  # update entry points, needed in order to find kkr.* entrypoints in aiida\n\n# setupt aiida if this was not done already:\n$ verdi quicksetup  # better to set up a new profile\n$ verdi calculation plugins  # should now show kkr.* entrypoints\n```\n\nTo install the developer version download the repository and install the downloaded version (see `setup.json` for a list of optional packages that are installed with the extras given in `[]`)\n\n```shell\n$ git clone https://github.com/JuDFTteam/aiida-kkr.git\n$ pip install -e aiida-kkr[testing,devtools,docs]\n$ reentry scan -r aiida\n```\n\n## Remarks about dependencies and extras\n\n- The `aiida-kkr` plugin uses the `ase` and `pymatgen` packages for structure conversions.\n- For `aiida-core>=1.5,<1.6` make sure to use the requirements specified in `requirements_aiida-core_1.5.txt` (use `pip install -r requirements_aiida-core_1.5.txt aiida-kkr` for the installation to overwrite the aiida-core dependency).\n- Other extras that can be optionally installed with `aiida-kkr` are\n  * `pre-commit` which installes the pre-commit hooks that allow style (`yapf`) and static code checking (`pylint`)\n  * `testing` which installs `pytest` and all extension used in the tests\n  * `docs` which installs `Sphinx` to build the documentation\n  * `devtools` which installs tools that might be helpful during development\n\n\n# Usage and Documentation\n\n* see http://aiida-kkr.readthedocs.io for user's and developer's guides and API reference\n* check out http://judft.de and https://jukkr.fz-juelich.de for information of the KKR codes used by the plugin\n\n# Contributing\n\nThank you for your interest in contributing to aiida-kkr.\nCheck out our [contributing guide](CONTRIBUTING.md) for some information.\n\n# Releasing new versions\n\nTo create a new release follow these steps:\n- finish your development and merge it into the `develop` branch\n- update documentation\n- update / fix tests\n- bump version numbers (in files `aiida_kkr/__init__.py`, `pyproject.toml`, `.bumpversion.cfg`)\n- merge changes from `develop` back into `master` and create a tag for the new version number (this triggers publication to pypi)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/aiida-spirit",
            "repo_link": "https://github.com/JuDFTteam/aiida-spirit",
            "readme": "[![Build Status](https://github.com/JuDFTteam/aiida-spirit/workflows/ci/badge.svg?branch=master)](https://github.com/JuDFTteam/aiida-spirit/actions)\n[![Coverage Status](https://codecov.io/gh/JuDFTteam/aiida-spirit/branch/main/graph/badge.svg?token=F7ISM4558S)](https://codecov.io/gh/JuDFTteam/aiida-spirit)\n[![Docs status](https://readthedocs.org/projects/aiida-spirit/badge)](http://aiida-spirit.readthedocs.io/)\n[![PyPI version](https://badge.fury.io/py/aiida-spirit.svg)](https://badge.fury.io/py/aiida-spirit)\n[![DOI](https://zenodo.org/badge/364820045.svg)](https://zenodo.org/badge/latestdoi/364820045)\n\n# aiida-spirit\n\nAiiDA plugin for the [spirit code](http://spirit-code.github.io/)\n\n\n## Installation\n\n```shell\npip install aiida-spirit # install aiida-spirit from pypi\nverdi quicksetup  # better to set up a new profile\nverdi plugin list aiida.calculations  # should now show your calclulation plugins\n```\n\n\n## Usage\n\nHere goes a complete example of how to submit a test calculation using this plugin.\n\nA quick demo of how to submit a calculation (the spirit python API needs to be installed for this to work: `pip install spirit`):\n```shell\nverdi daemon start     # make sure the daemon is running\ncd examples\n./example_LLG.py       # run test calculation\nverdi process list -a  # check record of calculation\n```\n\n## Development\n\n```shell\ngit clone https://github.com/JuDFTteam/aiida-spirit .\ncd aiida-spirit\npip install -e .[pre-commit,testing]  # install extra dependencies\npre-commit install  # install pre-commit hooks\npytest -v  # discover and run all tests\n```\n\nNote that `pytest -v` will create a test database and profile which requires to find the `pg_ctl` command.\nIf `pg_ctl` is not found you need to nake sure that postgres is installed and then add the localtion of\n`pg_ctl` to the `PATH`:\n```\n# add postgres path for pg_ctl to PATH\n# this is an example for Postgres 9.6 installed on a mac\nPATH=\"/Applications/Postgres.app/Contents/Versions/9.6/bin/:$PATH\"\nexport PATH\n```\n\n## Citation\n\nIf you use AiiDA-Spirit please cite the method paper\n - P. Rüßmann, J. Ribas Sobreviela, M. Sallermann, M. Hoffmann, F. Rhiem, and S. Blügel, *The AiiDA-Spirit Plugin for Automated Spin-Dynamics Simulations and Multi-Scale Modeling Based on First-Principles Calculations*, Front. Mater. **9**, 825043 (2022). [doi: 10.3389/fmats.2022.825043](https://doi.org/10.3389/fmats.2022.825043),\n\n and the latest code release\n - P. Rüßmann, J. Ribas Sobreviela, M. Sallermann, M. Hoffmann, F. Rhiem, and S. Blügel. JuDFTteam/aiida-spirit. Zenodo. [doi: 10.5281/zenodo.8070770](https://doi.org/10.5281/zenodo.8070770).\n\n## License\n\nThe AiiDA-Spirit code is under the [MIT license](LICENSE).\n\n## Contact\n\np.ruessmann@fz-juelich.de\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/album",
            "repo_link": "https://gitlab.com/album-app/album",
            "readme": "# album\n\nIntroduction: [https://album.solutions/](https://album.solutions/)\n\nDocumentation: [https://docs.album.solutions/](https://docs.album.solutions/)\n\n## Citation\n\nAlbrecht, J.P.\\*, Schmidt, D.\\*, and Harrington, K., 2021. Album: a\nframework for scientific data processing with software solutions of\nheterogeneous tools. arXiv preprint arXiv:2110.00601.  \nhttps://arxiv.org/abs/2110.00601\n\n## Developers\n\n- Kyle Harrington, Max Delbrueck Center for Molecular Medicine in the\nHelmholtz Association\n- Jan Philipp Albrecht, Max Delbrueck Center for Molecular Medicine in\n  the Helmholtz Association\n- Deborah Schmidt, Max Delbrueck Center for Molecular Medicine in\n  the Helmholtz Association\n",
            "project_id": "24064427"
        },
        {
            "software_organization": "https://helmholtz.software/software/alice2modelica",
            "repo_link": "https://jugit.fz-juelich.de/iek-10/public/tools/alice2modelica",
            "readme": "# ALICE2Modelica\n\n\n\n\n\n## Description\nALICE2Modelica enables the automated and scalable generation of building models for use in Modelica-based building control and simulation. The toolchain is builds upon the developed mini-language ALICE, which constitutes a straightforward approach to describe geometrical information of the envelope of rooms. Based on ALICE files, floor plans in SVG format, and parametrizable Modelica room\ntemplates, the toolchain automatically generates Modelica room and building models including Heating, Ventilation and Air\nConditioning (HVAC) systems.\n\n\n## Input files\n<ul>\n  <li>ALICE files for every room: human-oriented mini-language as well as a webbased tool for generating geometrical diagrams of building\nspaces and their internal components</li>\n  <li>SVG files for every floor of the building</li>\n  <li>Modelica templates based on the Modelica library [AixLib](https://github.com/RWTH-EBC/AixLib) forming the base for creating the room models </li>\n</ul> \n\n\n## Work flow\n![Figure](https://jugit.fz-juelich.de/iek-10/public/tools/alice2modelica/-/blob/main/Input%20files/DataFlowALICE2Modelica_PaperV8.png)\n\n<ul>\n  <li>ALICE parser: extracts for every wall, window and door, the ALICE-specific wall index  + the dimensions of these components\nand potential radiators </li>\n<li> SVG parser: extracts for every ALICE wall index of every room\nthe corresponding orientation + additional\ndictionary (for every room contains the\ncoupled neighbor rooms, respective coupling orientation and\ncoupling form (wall/door)) +  which walls are internal/ external  </li>\n<li> Output files: \n<ul>\n   <li>Room simulation models </li>\n   <li> Room optimization models (for decentralized and distributed\nMPC and parameter estimation)</li>\n   <li> Building (=coupled rooms) simulation model </li>\n   <li> Building (=coupled rooms) optimization model (for centralized\nMPC and parameter estimation) </li>\n</ul> \n<li> Steps\n<ul>\n   <li>Creation of Modelica simulation models for the individual\nrooms (and corridors) based on the room\ntemplates + orientation and dimension information\nextracted from the ALICE and SVG files </li>\n   <li> Creation of optimization models for a local, decentralized room\nMPC by making use of the Optimica .mop-file\nextension, which allows for simulation and optimization in the\nJModelica.org framework</li>\n   <li> Creation of local controller models for use in a distributed MPC and parameter estimation </li>\n   <li> Creation of the overall Modelica building model\nconsisting of all coupled rooms </li>\n</ul> \n<li> Possible interfacing modules that ALICE2Modelica is compatible with:\n<ul>\n<li> Calibration developed in [Mork2023](https://www.sciencedirect.com/science/article/pii/S2352710223017990)\n</ul> \n</ul> \n\n\n\n\n\n\n## Authors and acknowledgment\nFirst author: Maximilian Mork (IEK-10)\n\nCo-authors: \n<ul>\n  <li>Eziama Ubachukwu (IEK-10 - FZJ)</li>\n  <li>Jakob Benz (IEK-10 - FZJ)</li>\n  <li>Philipp Althau (IEK-10 - FZJ)</li>\n  <li>André Xhonneux (IEK-10 - FZJ) </li>\n  <li>Dirk Müller (IEK-10 - FZJ, EBC - RWTH) </li>\n</ul> \n\n\n## License\nCC BY 4.0\n\n\n## References\n<ul>\n  <li>[AixLib Github](https://github.com/RWTH-EBC/AixLib)</li>\n  <li>[JModelica](https://www.sciencedirect.com/science/article/pii/S009813540900283X)</li>\n\n</ul> \n",
            "project_id": "10927"
        },
        {
            "software_organization": "https://helmholtz.software/software/allpix-squared",
            "repo_link": "https://gitlab.cern.ch/allpix-squared/allpix-squared",
            "readme": "",
            "project_id": "14102"
        },
        {
            "software_organization": "https://helmholtz.software/software/alpaca",
            "repo_link": "https://github.com/INM-6/alpaca",
            "readme": "# alpaca\n\n## Automated Lightweight Provenance Capture\n\n[![tests](https://github.com/INM-6/alpaca/actions/workflows/CI.yml/badge.svg)](https://github.com/INM-6/alpaca/actions/workflows/CI.yml)\n[![Documentation Status](https://readthedocs.org/projects/alpaca-prov/badge/?version=latest)](https://alpaca-prov.readthedocs.io/en/latest/?badge=latest)\n\nAlpaca is a Python package for the capture of provenance information during the\nexecution of Python scripts that process data.\n\nAlpaca provides a simple API for recording the details of the functions being\nexecuted, the data flow, and a description of parameters used.\nThis is accomplished with minimal code instrumentation and user intervention.\n\nProvenance information is structured and serialized according to a model\nbased on the [W3C PROV format](https://www.w3.org/TR/prov-overview).\n\n\n## Table of contents\n  - [Prerequisites](#prerequisites)\n  - [Installation](#installation)\n  - [Documentation](#documentation)\n  - [How to run](#how-to-run)\n  - [Collaborators](#collaborators)\n  - [How to contribute](#how-to-contribute)\n  - [Get support](#get-support)\n  - [Acknowledgments](#acknowledgments)\n  - [License](#license)\n  - [Copyright](#copyright)\n\n\n## Prerequisites\n\n### Requirements\n\nAlpaca requires Python 3.8 or higher and the packages specified in \n[requirements.txt](requirements/requirements.txt).\n\n\n## Installation\n\nUse the package manager [pip](https://pip.pypa.io/en/stable/) to install Alpaca.\n\nPackage on [pypi](https://pypi.org/)\n```bash\npip install alpaca-prov\n```\n\nMore detailed instructions on how to setup conda environments and additional\ninstall options can be checked in the [Installation](doc/install.rst) page.\n\n\n## Documentation\n\nSee [https://alpaca-prov.readthedocs.io/en/latest/](https://alpaca-prov.readthedocs.io/en/latest/).\n\n\n## How to run\n\nExamples showing how to use Alpaca can be found in the [examples](examples/)\nfolder. Detailed instructions on how to set up and run are \n[here](doc/examples.rst).\n\n\n## Colaborators\n\nAll the contributors to the development of Alpaca can be found in the \n[Authors and contributors](doc/authors.rst) page.\n\n\n## How to contribute\n\nIf you want to suggest new features, changes, or make a contribution, please\nfirst open an issue on the [project page on GitHub](https://github.com/INM-6/alpaca/issues)\nto discuss your idea.\n\nPull requests are welcome. Any contribution should also\nbe covered by appropriate unit tests in the [tests](alpaca/test) folder.\n\n\n## Get support\n\nIf you experience any issue or wish to report a bug, please open an issue on\nthe [project page on GitHub](https://github.com/INM-6/alpaca/issues).\n\n\n## Acknowledgments\n\nSee [acknowledgments](doc/acknowledgments.rst).\n\n\n## License\n \nBSD 3-Clause License, see [LICENSE.txt](LICENSE.txt) for details.\n\n\n## Copyright\n\n:copyright: 2022-2023, Forschungszentrum Jülich GmbH, INM-6, IAS-6. All rights reserved."
        },
        {
            "software_organization": "https://helmholtz.software/software/alpaka",
            "repo_link": "https://github.com/alpaka-group/alpaka",
            "readme": "**alpaka** - Abstraction Library for Parallel Kernel Acceleration\n=================================================================\n\n\n[![Continuous Integration](https://github.com/alpaka-group/alpaka/workflows/Continuous%20Integration/badge.svg)](https://github.com/alpaka-group/alpaka/actions?query=workflow%3A%22Continuous+Integration%22)\n[![Documentation Status](https://readthedocs.org/projects/alpaka/badge/?version=latest)](https://alpaka.readthedocs.io)\n[![Doxygen](https://img.shields.io/badge/API-Doxygen-blue.svg)](https://alpaka-group.github.io/alpaka)\n[![Language](https://img.shields.io/badge/language-C%2B%2B17-orange.svg)](https://isocpp.org/)\n[![Platforms](https://img.shields.io/badge/platform-linux%20%7C%20windows%20%7C%20mac-lightgrey.svg)](https://github.com/alpaka-group/alpaka)\n[![License](https://img.shields.io/badge/license-MPL--2.0-blue.svg)](https://www.mozilla.org/en-US/MPL/2.0/)\n\n![alpaka](docs/logo/alpaka_401x135.png)\n\nThe **alpaka** library is a header-only C++20 abstraction library for accelerator development.\n\nIts aim is to provide performance portability across accelerators through the abstraction (not hiding!) of the underlying levels of parallelism.\n\nIt is platform independent and supports the concurrent and cooperative use of multiple devices such as the hosts CPU (x86, ARM, RISC-V and Power 8+) and  GPU accelerators from different vendors (NVIDIA, AMD and Intel).\nA multitude of accelerator back-end variants using CUDA, HIP, SYCL, OpenMP 2.0+, std::thread and also serial execution is provided and can be selected depending on the device.\nOnly one implementation of the user kernel is required by representing them as function objects with a special interface.\nThere is no need to write special CUDA, HIP, SYCL, OpenMP or custom threading code.\nAccelerator back-ends can be mixed and synchronized via compute device queue.\nThe decision which accelerator back-end executes which kernel can be made at runtime.\n\nThe abstraction used is very similar to the CUDA grid-blocks-threads domain decomposition strategy.\nAlgorithms that should be parallelized have to be divided into a multi-dimensional grid consisting of small uniform work items.\nThese functions are called kernels and are executed in parallel threads.\nThe threads in the grid are organized in blocks.\nAll threads in a block are executed in parallel and can interact via fast shared memory and low level synchronization methods.\nBlocks are executed independently and can not interact in any way.\nThe block execution order is unspecified and depends on the accelerator in use.\nBy using this abstraction the execution can be optimally adapted to the available hardware.\n\n\nSoftware License\n----------------\n\n**alpaka** is licensed under **MPL-2.0**.\n\n\nDocumentation\n-------------\n\nThe alpaka documentation can be found in the [online manual](https://alpaka.readthedocs.io).\nThe documentation files in [`.rst` (reStructuredText)](https://www.sphinx-doc.org/en/stable/rest.html) format are located in the `docs` subfolder of this repository.\nThe [source code documentation](https://alpaka-group.github.io/alpaka/) is generated with [doxygen](http://www.doxygen.org).\n\n\nAccelerator Back-ends\n---------------------\n\n| Accelerator Back-end   | Lib/API                                                 | Devices                    | Execution strategy grid-blocks     | Execution strategy block-threads     |\n|------------------------|---------------------------------------------------------|----------------------------|------------------------------------|--------------------------------------|\n| Serial                 | n/a                                                     | Host CPU (single core)     | sequential                         | sequential (only 1 thread per block) |\n| OpenMP 2.0+ blocks     | OpenMP 2.0+                                             | Host CPU (multi core)      | parallel (preemptive multitasking) | sequential (only 1 thread per block) |\n| OpenMP 2.0+ threads    | OpenMP 2.0+                                             | Host CPU (multi core)      | sequential                         | parallel (preemptive multitasking)   |\n| std::thread            | std::thread                                             | Host CPU (multi core)      | sequential                         | parallel (preemptive multitasking)   |\n| TBB                    | TBB 2.2+                                                | Host CPU (multi core)      | parallel (preemptive multitasking) | sequential (only 1 thread per block) |\n| CUDA                   | CUDA 12.0+                                              | NVIDIA GPUs                | parallel (undefined)               | parallel (lock-step within warps)    |\n| HIP(clang)             | [HIP 6.0+](https://github.com/ROCm-Developer-Tools/HIP) | AMD GPUs                   | parallel (undefined)               | parallel (lock-step within warps)    |\n| SYCL(oneAPI)           | oneAPI 2024.2+                                          | CPUs, Intel GPUs and FPGAs | parallel (undefined)               | parallel (lock-step within warps)    |\n\n\nSupported Compilers\n-------------------\n\nThis library uses C++20 (or newer when available).\n\n| Accelerator Back-end | gcc 10.4 / 11.1 (Linux)        | gcc 12.3 (Linux)                      | gcc 13.1 (Linux)                      | clang 10/11 (Linux)            | clang 12 (Linux)               | clang 13 (Linux)               | clang 14 (Linux)               | clang 15 (Linux)               | clang 16 (Linux)               | clang 17 (Linux)                      | clang 18 (Linux)                      | clang 19 (Linux)   | icpx 2025.0 (Linux)     | Xcode 15.4 / 16.1 (macOS) | Visual Studio 2022 (Windows) |\n|----------------------|--------------------------------|---------------------------------------|---------------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|---------------------------------------|---------------------------------------|--------------------|-------------------------|---------------------------|------------------------------|\n| Serial               | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark: | :white_check_mark:      | :white_check_mark:        | :white_check_mark:           |\n| OpenMP 2.0+ blocks   | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark: | :white_check_mark: [^1] | :white_check_mark:        | :white_check_mark:           |\n| OpenMP 2.0+ threads  | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark: | :white_check_mark: [^1] | :white_check_mark:        | :white_check_mark:           |\n| std::thread          | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark: | :white_check_mark:      | :white_check_mark:        | :white_check_mark:           |\n| TBB                  | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:             | :white_check_mark:                    | :white_check_mark:                    | :white_check_mark: | :white_check_mark:      | :white_check_mark:        | :white_check_mark:           |\n| CUDA (nvcc)          | :white_check_mark: (CUDA 12.0) | :white_check_mark: (CUDA 12.0 - 12.5) | :white_check_mark: (CUDA 12.4 - 12.5) | :white_check_mark: (CUDA 12.0) | :white_check_mark: (CUDA 12.0) | :white_check_mark: (CUDA 12.0) | :white_check_mark: (CUDA 12.0) | :white_check_mark: (CUDA 12.2) | :white_check_mark: (CUDA 12.3) | :white_check_mark: (CUDA 12.4 - 12.5) | :white_check_mark: (CUDA 12.4 - 12.5) | :x:                | :x:                     | -                         | :x:                          |\n| CUDA (clang)         | -                              | -                                     | -                                     | :x:                            | :x:                            | :x:                            | :x:                            | :x:                            | :x:                            | :x:                                   | :x:                                   | :x:                | :x:                     | -                         | -                            |\n| HIP (clang)          | -                              | -                                     | -                                     | :x:                            | :x:                            | :x:                            | :x:                            | :x:                            | :x:                            | :white_check_mark: (HIP 6.0 - 6.1)    | :white_check_mark: (HIP 6.2)          | :x:                | :x:                     | -                         | -                            |\n| SYCL                 | :x:                            | :x:                                   | :x:                                   | :x:                            | :x:                            | :x:                            | :x:                            | :x:                            | :x:                            | :x:                                   | :x:                                   | :x:                | :white_check_mark: [^2] | -                         | :x:                          |\n\nOther compilers or combinations marked with :x: in the table above may work but are not tested in CI and are therefore not explicitly supported.\n\n[^1]: Due to an [LLVM bug](https://github.com/llvm/llvm-project/issues/58491) in debug mode only release builds are supported.\n[^2]: Currently, the unit tests are compiled but not executed.\n\nDependencies\n------------\n\n[Boost](https://boost.org/) 1.74.0+ is the only mandatory external dependency.\nThe **alpaka** library itself just requires header-only libraries.\nHowever some of the accelerator back-end implementations require different boost libraries to be built.\n\nWhen an accelerator back-end using *CUDA* is enabled, version *11.2* (with nvcc as CUDA compiler) or version *11.2* (with clang as CUDA compiler) of the *CUDA SDK* is the minimum requirement.\n*NOTE*: When using clang as a native *CUDA* compiler, the *CUDA accelerator back-end* can not be enabled together with any *OpenMP accelerator back-end* because this combination is currently unsupported.\n*NOTE*: Separable compilation is disabled by default and can be enabled via the CMake flag `CMAKE_CUDA_SEPARABLE_COMPILATION`.\n\nWhen an accelerator back-end using *OpenMP* is enabled, the compiler and the platform have to support the corresponding minimum *OpenMP* version.\n\nWhen an accelerator back-end using *TBB* is enabled, the compiler and the platform have to support the corresponding minimum *TBB* version.\n\n\nUsage\n-----\n\nThe library is header only so nothing has to be built.\nCMake 3.22+ is required to provide the correct defines and include paths.\nJust call `alpaka_add_executable` instead of `add_executable` and the difficulties of the CUDA nvcc compiler in handling `.cu` and `.cpp` files are automatically taken care of.\nSource files do not need any special file ending.\nExamples of how to utilize alpaka within CMake can be found in the `example` folder.\n\nThe whole alpaka library can be included with: `#include <alpaka/alpaka.hpp>`\nCode that is not intended to be utilized by the user is hidden in the `detail` namespace.\n\nFurthermore, for a CUDA-like experience when adopting alpaka we provide the library [*cupla*](https://github.com/alpaka-group/cupla).\nIt enables a simple and straightforward way of porting existing CUDA applications to alpaka and thus to a variety of accelerators.\n\n### Single header\n\nThe CI creates a single-header version of alpaka on each commit,\nwhich you can find on the [single-header branch](https://github.com/alpaka-group/alpaka/tree/single-header).\n\nThis is especially useful, if you would like to play with alpaka on [Compiler explorer](https://godbolt.org/z/hzPnhnna9).\nJust include alpaka like\n```c++\n#include <https://raw.githubusercontent.com/alpaka-group/alpaka/single-header/include/alpaka/alpaka.hpp>\n```\nand enable the desired backend on the compiler's command line using the corresponding macro, e.g. via `-DALPAKA_ACC_CPU_B_SEQ_T_SEQ_ENABLED`.\n\nIntroduction\n------------\n\nFor a quick introduction, feel free to playback the recording of our presentation at\n[GTC 2016](https://www.nvidia.com/gtc/):\n\n - E. Zenker, R. Widera, G. Juckeland et al.,\n   *Porting the Plasma Simulation PIConGPU to Heterogeneous Architectures with Alpaka*,\n   [video link (39 min)](http://on-demand.gputechconf.com/gtc/2016/video/S6298.html),\n   [slides (PDF)](https://on-demand.gputechconf.com/gtc/2016/presentation/s6298-erik-zenker-porting-the-plasma.pdf),\n   [DOI:10.5281/zenodo.6336086](https://doi.org/10.5281/zenodo.6336086)\n\n\nCiting alpaka\n-------------\n\nCurrently all authors of **alpaka** are scientists or connected with\nresearch. For us to justify the importance and impact of our work, please\nconsider citing us accordingly in your derived work and publications:\n\n```latex\n% Peer-Reviewed Publication %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%\n% Peer reviewed and accepted publication in\n%   \"2nd International Workshop on Performance Portable\n%    Programming Models for Accelerators (P^3MA)\"\n% colocated with the\n%   \"2017 ISC High Performance Conference\"\n%   in Frankfurt, Germany\n@inproceedings{MathesP3MA2017,\n  author    = {{Matthes}, A. and {Widera}, R. and {Zenker}, E. and {Worpitz}, B. and\n               {Huebl}, A. and {Bussmann}, M.},\n  title     = {Tuning and optimization for a variety of many-core architectures without changing a single line of implementation code\n               using the Alpaka library},\n  archivePrefix = \"arXiv\",\n  eprint    = {1706.10086},\n  keywords  = {Computer Science - Distributed, Parallel, and Cluster Computing},\n  day       = {30},\n  month     = {Jun},\n  year      = {2017},\n  url       = {https://arxiv.org/abs/1706.10086},\n}\n\n% Peer-Reviewed Publication %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%\n% Peer reviewed and accepted publication in\n%   \"The Sixth International Workshop on\n%    Accelerators and Hybrid Exascale Systems (AsHES)\"\n% at the\n%   \"30th IEEE International Parallel and Distributed\n%    Processing Symposium\" in Chicago, IL, USA\n@inproceedings{ZenkerAsHES2016,\n  author    = {Erik Zenker and Benjamin Worpitz and Ren{\\'{e}} Widera\n               and Axel Huebl and Guido Juckeland and\n               Andreas Kn{\\\"{u}}pfer and Wolfgang E. Nagel and Michael Bussmann},\n  title     = {Alpaka - An Abstraction Library for Parallel Kernel Acceleration},\n  archivePrefix = \"arXiv\",\n  eprint    = {1602.08477},\n  keywords  = {Computer science;CUDA;Mathematical Software;nVidia;OpenMP;Package;\n               performance portability;Portability;Tesla K20;Tesla K80},\n  day       = {23},\n  month     = {May},\n  year      = {2016},\n  publisher = {IEEE Computer Society},\n  url       = {http://arxiv.org/abs/1602.08477},\n}\n\n\n% Original Work: Benjamin Worpitz' Master Thesis %%%%%%%%%%\n%\n@MasterThesis{Worpitz2015,\n  author = {Benjamin Worpitz},\n  title  = {Investigating performance portability of a highly scalable\n            particle-in-cell simulation code on various multi-core\n            architectures},\n  school = {{Technische Universit{\\\"{a}}t Dresden}},\n  month  = {Sep},\n  year   = {2015},\n  type   = {Master Thesis},\n  doi    = {10.5281/zenodo.49768},\n  url    = {http://dx.doi.org/10.5281/zenodo.49768}\n}\n```\n\nContributing\n------------\n\nRules for contributions can be found in [CONTRIBUTING.md](CONTRIBUTING.md).\nAny pull request will be reviewed by a [maintainer](https://github.com/orgs/alpaka-group/teams/alpaka-maintainers).\n\nThanks to all [active and former contributors](.zenodo.json).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/amiris",
            "repo_link": "https://gitlab.com/dlr-ve/esy/amiris/amiris",
            "readme": "<!-- SPDX-FileCopyrightText: 2023 German Aerospace Center <amiris@dlr.de>\n\nSPDX-License-Identifier: Apache-2.0 -->\n# AMIRIS\nAMIRIS is the **A**gent-based **M**arket model for the **I**nvestigation of **R**enewable and **I**ntegrated energy **S**ystems.\n\n## Statement of need\nAMIRIS is an agent-based simulation of electricity markets and their actors.\nIt enables researchers to analyse and evaluate energy policy instruments and their impact on the actors involved in the simulation context.\nDifferent prototypical agents on the electricity market interact with each other, each employing complex decision strategies. \nAMIRIS allows calculating the impact of policy instruments on economic performance of power plant operators and marketers.\nIt is based on [FAME](https://gitlab.com/fame-framework), the open Framework for distributed Agent-based Modelling of Energy systems.\nAMIRIS follows an explorative approach.\nThus, it does not optimise the energy system like other tools, e.g. [REMix](https://gitlab.com/dlr-ve/esy/remix/framework), but explores emerging effects created by energy system actors and their interactions under a given set of assumptions.\n\n## Further information\nPlease have a look at the [AMIRIS-Wiki](https://gitlab.com/dlr-ve/esy/amiris/amiris/-/wikis/home) for further information.\nDo not hesitate to ask questions about AMIRIS at the [openMod-Forum](https://forum.openmod.org/tag/amiris).\n\n## Recommended Skills\nAMIRIS is a *JAVA* application configured via *Python* scripts.\nTo configure and run AMIRIS applications, no programming skills are strictly necessary, but experience with energy system modelling and Python is helpful.\nDevelopers, who want to modify the functionality or enhance the capabilities of AMIRIS, however, should have at least basic understanding of Java.\nIn addition, a basic understanding of [(FAME)](https://gitlab.com/fame-framework) is required in order to design new agents and their interactions.\n\n## Get Started\n### System Requirements\nAMIRIS is based on [FAME](https://gitlab.com/fame-framework), the open Framework for distributed Agent-based Modelling of Energy systems.\nTo run AMIRIS, Python 3.9 or higher and Java Development Kit (JDK) 11 or higher are required.\nIn case you want to modify the AMIRIS code, additional tools might be required.\nSee our [Wiki](https://gitlab.com/dlr-ve/esy/amiris/amiris/-/wikis/GetStarted/Getting-started) for additional instructions.\n\n#### Java\nAMIRIS requires JDK version 11 or higher and has been tested to work with versions 11, 17, and 21.\nYou can test if you have a JDK by using the command `java --version` (or `java -version` on some systems).\nThis should show your Java version if Java was found.\nIf you get a command not found error, or if Java version is less than 11 please download and install a recent JDK from e.g. [here](https://adoptium.net/).\n\n#### Python\nYou will need a Python-enabled shell with Python 3.9 or higher and pip.\nYou can test if you have Python available by using the command `python --version`.\nThis should show your Python version if the Python command was found.\nNote that if you use a Python environment manager you can have several Python versions on your system side by side.\nIf you do not have Python installed on your system, you may use e.g. [conda](https://docs.conda.io/en/latest/miniconda.html) or [mamba](https://github.com/conda-forge/miniforge#mambaforge) or [Poetry](https://python-poetry.org/).\n\n### Set up Python Environment\nIn case you do not have any experience with creating a Python environment, we recommend to use [anaconda](https://www.anaconda.com/).\nInstall anaconda, start the anaconda prompt or powershell and enter:\n\n1. `conda create -n amirisEnv python=3.9`\n2. `conda activate amirisEnv`\n\nIn case you are using mamba, simple replace \"conda\" in the first command with \"mamba\" (but not in the second).\n\n### Install AMIRIS-Py\nWe recommend to use [AMIRIS-Py](https://gitlab.com/dlr-ve/esy/amiris/amiris-py/-/blob/main/README.md).\nAMIRIS-Py provides \"one-command\" installation and execution scripts, but you may also run AMIRIS using FAME scripts (see [here](https://gitlab.com/dlr-ve/esy/amiris/amiris/-/wikis/GetStarted/Getting-started)).\nIn your AMIRIS Python environment (called \"amirisEnv\" above), run\n\n```\npip install amirispy\n```\n\n### Download AMIRIS\n1. Create a new folder on your disk called, e.g., \"AMIRIS\": `mkdir <AMIRIS>`\n2. Open your Python-enabled shell and navigate to this newly created folder: `cd <AMIRIS>` \n3. If not done yet, activate your Python environment with amiris-py: `conda activate <amirisEnv>`\n4. To download the latest AMIRIS build use: `amiris install`. This downloads the latest [AMIRIS model](https://gitlab.com/dlr-ve/esy/amiris/amiris/-/jobs/artifacts/main/download?job=deploy:jdk11) and the latest version of [AMIRIS examples](https://gitlab.com/dlr-ve/esy/amiris/examples) into the current folder.\n\nYour \"AMIRIS\" folder should now look like this:\n\n```\nAMIRIS\n├─── examples\n│    ├─── Austria2019/\n│    ├─── Germany2019/\n│    ├─── ...\n│    ├─── Simple/\n│    └─── README.md\n├─── amiris-core_X.y.z-with-dependencies.jar\n└─── fameSetup.yaml\n```\n\nYou are now ready to execute AMIRIS.\n\n## Run AMIRIS with AMIRIS-Py\nUse amiris-py again to run AMIRIS:\n\n```\namiris run -j ./amiris-core_3.1.0-jar-with-dependencies.jar -s ./examples/Simple/scenario.yaml -o simple\n```\n\nThis runs the packaged AMIRIS Java archive (Jar) file specified after the `-j` option and simulates the scenario specified after the `-s` option.\nThe AMIRIS outputs are stored in a folder as designated after the `-o` option. \nCheck out the files in the AMIRIS folder - use the version code of the jar file you downloaded.\n\n## Results \nOpen the created output folder called e.g. \"simple\".\nEach type of agent has its own output file in CSV format.\nOpen the files in your favourite CSV editor.\nThe files take the following general structure:\n\n| AgentId | TimeStep | Col1 | Col2 | Col3 | ... |\n|---------|----------|------|------|------|-----|\n\nwhere:\n* `AgentId` refers to the unique ID of that agent - as specified in the input scenario.yaml \n* `TimeStep` refers to the time step at which the output was created; the number refers to the passed seconds since January 1st 2000, 00:00h (ignoring leap years). To convert to a human-readable time stamp best use the python function `fameio.source.time.FameTime.convert_fame_time_step_to_datetime`\n* `Col1` refers to the agent-type specific first output column\n* `Col2` refers to the agent-type specific second output column\n* `...` there can be arbitrarily many output columns - depending on the type of the agent \n\nHere, `AgentId` and `TimeStep` form a 2-column multiindex.\nThus, each agent can only write one value per column and simulation time.\nFor example, open the \"EnergyExchange.csv\". \nThe Agent with ID 1 is the only one of type EnergyExchange - so this column is kind of uninteresting in this file.\nThe fourth column is named \"ElectricityPriceInEURperMWH\" and contains the market-clearing day-ahead electricity prices.\n\nAlthough in this file, all columns are filled in every time step, this is not the case for all types of agents.\nSome agents write their column entries at slightly different time steps.\nThis is caused by the simulation, which saves output data at the time step the action is performed.\n\nSome types of agents need to write out more than one output per time step.\nE.g., the conventional plant operators writes out the dispatched power for every power plant of each agent and each time step.\nSuch output will be assigned an extra CSV file named \"AgentType_MultiindexColumn\".\nThese files can feature an N-dimensional-multiindex with a single \"value\" column like so:\n\n| AgentId | TimeStep | 3rd index | 4th index | ... | Value |\n|---------|----------|-----------|-----------|-----|-------|\n\nIn this example of \"ConventionalPlantOperator_DispatchedPowerInMWHperPlant.csv\", `AgentId`, `TimeStep` and `ID` of the power plant form a 3D-multiindex.\nEach index is assigned a single value for \"DispatchedPowerInMWHperPlant\".\n\n## Next Steps\nCongratulations, you have now successfully run AMIRIS. \nYou want to see which inputs led to those results? See the input scenario at \"./examples/Simple/scenario.yaml\".\nOr do you want to create your own simulation configuration or how to modify AMIRIS?\nCheck out the [AMIRIS-Wiki](https://gitlab.com/dlr-ve/esy/amiris/amiris/-/wikis/GetStarted/Getting-started).\nPlease also refer to the [FAME-Wiki](https://gitlab.com/fame-framework/wiki/-/wikis) when applying more advanced adaptations to your scenario, such as changing the [simulation duration](https://gitlab.com/fame-framework/wiki/-/wikis/GetStarted/core/Contracts). \n\n\n## Available Support\nThis is a purely scientific project by (at the moment) one research group. \nThus, there is no paid technical support available.\nHowever, we will give our best to answer your questions and provide support.\n\nIf you experience any trouble with AMIRIS, you may contact the developers at the [openMod-Forum](https://forum.openmod.org/tag/amiris) or via [amiris@dlr.de](mailto:amiris@dlr.de).\nPlease report bugs and make feature requests by filing issues following the provided templates (see also [CONTRIBUTING](CONTRIBUTING.md)).\nFor substantial enhancements, we recommend that you contact us via [amiris@dlr.de](mailto:amiris@dlr.de) for working together on the code in joint projects or towards common publications in order to further develop AMIRIS.\n\n## Citing AMIRIS\nIf you use AMIRIS in your scientific work please cite:\n\nChristoph Schimeczek, Kristina Nienhaus, Ulrich Frey, Evelyn Sperber, Seyedfarzad Sarfarazi, Felix Nitsch, Johannes Kochems & A. Achraf El Ghazi (2023).\nAMIRIS: Agent-based Market model for the Investigation of Renewable and Integrated energy Systems.\nJournal of Open Source Software. [doi: 10.21105/joss.05041](https://doi.org/10.21105/joss.05041)\n\n## Acknowledgements\nDevelopment of AMIRIS was funded by the German Aerospace Center, the German Federal Ministry for Economic Affairs and Climate Action, the German Federal Ministry of Education and Research, and the German Federal for the Environment, Nature Conservation and Nuclear Safety. \nIt received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 864276.\nWe express our gratitude to all [contributors](CONTRIBUTING.md#list-of-contributors).\n\n",
            "project_id": "31597451"
        },
        {
            "software_organization": "https://helmholtz.software/software/anndata",
            "repo_link": "https://github.com/scverse/anndata",
            "readme": "[![Build Status](https://dev.azure.com/scverse/anndata/_apis/build/status/scverse.anndata?branchName=main)](https://dev.azure.com/scverse/anndata/_build)\n[![Conda](https://img.shields.io/conda/vn/conda-forge/anndata.svg)](https://anaconda.org/conda-forge/anndata)\n[![Coverage](https://codecov.io/gh/scverse/anndata/branch/main/graph/badge.svg?token=IN1mJN1Wi8)](https://codecov.io/gh/scverse/anndata)\n[![Docs](https://readthedocs.com/projects/icb-anndata/badge/?version=latest)](https://anndata.readthedocs.io)\n[![PyPI](https://img.shields.io/pypi/v/anndata.svg)](https://pypi.org/project/anndata)\n[![Downloads](https://static.pepy.tech/badge/anndata/month)](https://pepy.tech/project/anndata)\n[![Downloads](https://static.pepy.tech/badge/anndata)](https://pepy.tech/project/anndata)\n[![Stars](https://img.shields.io/github/stars/scverse/anndata?style=flat&logo=github&color=yellow)](https://github.com/scverse/anndata/stargazers)\n[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](http://numfocus.org)\n\n<img\n  src=\"https://raw.githubusercontent.com/scverse/anndata/main/docs/_static/img/anndata_schema.svg\"\n  class=\"dark-light\" align=\"right\" width=\"350\" alt=\"image\"\n/>\n\n# anndata - Annotated data\n\nanndata is a Python package for handling annotated data matrices in memory and on disk, positioned between pandas and xarray. anndata offers a broad range of computationally efficient features including, among others, sparse data support, lazy operations, and a PyTorch interface.\n\n- Discuss development on [GitHub](https://github.com/scverse/anndata).\n- Read the [documentation](https://anndata.readthedocs.io).\n- Ask questions on the [scverse Discourse](https://discourse.scverse.org).\n- Install via `pip install anndata` or `conda install anndata -c conda-forge`.\n- See [Scanpy's documentation](https://scanpy.readthedocs.io/) for usage related to single cell data. anndata was initially built for Scanpy.\n\n[//]: # (numfocus-fiscal-sponsor-attribution)\n\nanndata is part of the scverse project ([website](https://scverse.org), [governance](https://scverse.org/about/roles)) and is fiscally sponsored by [NumFOCUS](https://numfocus.org/).\nPlease consider making a tax-deductible [donation](https://numfocus.org/donate-to-scverse) to help the project pay for developer time, professional services, travel, workshops, and a variety of other needs.\n\n\n<a href=\"https://numfocus.org/project/scverse\">\n  <img\n    src=\"https://raw.githubusercontent.com/numfocus/templates/master/images/numfocus-logo.png\"\n    width=\"200\"\n  >\n</a>\n\n## Public API\n\nOur public API is documented in the [API section][] of these docs.\nWe cannot guarantee the stability of our internal APIs, whether it's the location of a function, its arguments, or something else.\nIn other words, we do not officially support (or encourage users to do) something like `from anndata._core import AnnData` as `_core` is both not documented and contains a [leading underscore][].\nHowever, we are aware that [many users do use these internal APIs][] and thus encourage them to [open an issue][] or migrate to the public API.\nThat is, if something is missing from our public API as documented, for example a feature you wish to be exported publicly, please open an issue.\n\n[api section]: https://anndata.readthedocs.io/en/stable/api.html\n[leading underscore]: https://peps.python.org/pep-0008/#public-and-internal-interfaces\n[many users do use these internal APIs]: https://github.com/search?q=%22anndata._io%22&type=code\n[open an issue]: https://github.com/scverse/anndata/issues/new/choose\n\n\n## Citation\n\nIf you use `anndata` in your work, please cite the `anndata` publication as follows:\n\n> **anndata: Annotated data**\n>\n> Isaac Virshup, Sergei Rybakov, Fabian J. Theis, Philipp Angerer, F. Alexander Wolf\n>\n> _JOSS_ 2024 Sep 16. doi: [10.21105/joss.04371](https://doi.org/10.21105/joss.04371).\n\nYou can cite the scverse publication as follows:\n\n> **The scverse project provides a computational ecosystem for single-cell omics data analysis**\n>\n> Isaac Virshup, Danila Bredikhin, Lukas Heumos, Giovanni Palla, Gregor Sturm, Adam Gayoso, Ilia Kats, Mikaela Koutrouli, Scverse Community, Bonnie Berger, Dana Pe’er, Aviv Regev, Sarah A. Teichmann, Francesca Finotello, F. Alexander Wolf, Nir Yosef, Oliver Stegle & Fabian J. Theis\n>\n> _Nat Biotechnol._ 2023 Apr 10. doi: [10.1038/s41587-023-01733-8](https://doi.org/10.1038/s41587-023-01733-8).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ansible-collection-toolkit",
            "repo_link": "https://github.com/hifis-net/ansible-collection-toolkit",
            "readme": "<!--\nSPDX-FileCopyrightText: Helmholtz Centre for Environmental Research (UFZ)\nSPDX-FileCopyrightText: Helmholtz-Zentrum Dresden-Rossendorf (HZDR)\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# Ansible Collection - hifis.toolkit\n\n[![Latest release](https://img.shields.io/github/v/release/hifis-net/ansible-collection-toolkit)](https://github.com/hifis-net/ansible-collection-toolkit/releases)\n[![hifis.gitlab_runner](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/gitlab_runner.yml/badge.svg)](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/gitlab_runner.yml)\n[![hifis.gitlab](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/gitlab.yml/badge.svg)](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/gitlab.yml)\n[![hifis.haproxy](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/haproxy.yml/badge.svg)](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/haproxy.yml)\n[![hifis.keepalived](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/keepalived.yml/badge.svg)](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/keepalived.yml)\n[![hifis.netplan](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/netplan.yml/badge.svg)](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/netplan.yml)\n[![hifis.redis](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/redis.yml/badge.svg)](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/redis.yml)\n[![hifis.ssh_keys](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/ssh_keys.yml/badge.svg)](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/ssh_keys.yml)\n[![hifis.unattended_upgrades](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/unattended_upgrades.yml/badge.svg)](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/unattended_upgrades.yml)\n[![hifis.zammad](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/zammad.yml/badge.svg)](https://github.com/hifis-net/ansible-collection-toolkit/actions/workflows/zammad.yml)\n[![DOI](https://zenodo.org/badge/495697576.svg)](https://zenodo.org/doi/10.5281/zenodo.11147483)\n\nThis collection provides production-ready Ansible roles used for providing services used in research and by research\nsoftware engineers, but not exclusively. The following use cases are supported:\n\n* **DevOps platform:**\n    * [GitLab](roles/gitlab)\n    * deploy [GitLab-Runner](roles/gitlab_runner) with a focus, but not limited, on Openstack autoscaling\n    * [Redis](roles/redis)\n* **Help desk:**\n    * [Zammad](roles/zammad)\n* **High Availability (HA) / Load Balancing:**\n    * [HAProxy](roles/haproxy)\n    * [Keepalived](roles/keepalived)\n* **OS-related:**\n    * [unattended-upgrades](roles/unattended_upgrades)\n    * [netplan](roles/netplan)\n    * distribute authorized [SSH keys](roles/ssh_keys) to users\n\n## Looking for the unattended_upgrades role?\n\nYou can now find it under [roles/unattended_upgrades](roles/unattended_upgrades).\n\nWe moved our existing Ansible roles into a single collection to deduplicate code and have a common test suite for all roles.\nWe decided to reuse the unattended_upgrades repository as a collection repo as it is our most popular role.\n\n## Minimum required Ansible-version\n\n* Ansible >= 2.16\n\n## Installation\n\nInstall the collection via ansible-galaxy:\n\n```shell\nansible-galaxy collection install hifis.toolkit\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## License\n\nApache-2.0\n\n## Author\n\nThis collection is maintained by [HIFIS Software Services](https://hifis.net/).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/anvio",
            "repo_link": "https://github.com/merenlab/anvio",
            "readme": "<p align=\"center\"><img src=\"https://github.com/merenlab/anvio/raw/master/anvio/data/interactive/images/logo-fancy.png\" height=\"256\" /></p>\n\n[![Daily Component Tests and Migrations](https://github.com/merenlab/anvio/actions/workflows/daily-component-tests-and-migrations.yaml/badge.svg)](https://github.com/merenlab/anvio/actions/workflows/daily-component-tests-and-migrations.yaml)\n\n### Releases\n\nGithub [releases page](https://github.com/merenlab/anvio/releases) lists all the stable releases of anvi'o.\n\n### Installation and tutorials\n\nThe [anvi'o project page](https://anvio.org) gives access to installation manuals, user tutorials, and other sweets.\n\n### Help on anvi'o programs and artifacts\n\n[The anvi'o help pages](https://anvio.org/help) describe individual anvi'o programs as well as artifacts they consume or produce.\n\n### Coding style considerations\n\nPlease see [relevant discussions](https://github.com/merenlab/anvio/issues?q=label%3A%22coding+style%22+).\n\n### Community chat\n\nClick [this link](https://discord.gg/C6He6mSNY4) to join the anvi'o Discord channel.\n\n### Others on anvi'o\n\nRead our [user testimonials](http://merenlab.org/2017/07/12/testimonials/).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/arbor",
            "repo_link": "https://github.com/arbor-sim/arbor/",
            "readme": "[![ci](https://github.com/arbor-sim/arbor/actions/workflows/test-matrix.yml/badge.svg)](https://github.com/arbor-sim/arbor/actions/workflows/test-matrix.yml)\n[![spack](https://github.com/arbor-sim/arbor/actions/workflows/test-spack.yml/badge.svg)](https://github.com/arbor-sim/arbor/actions/workflows/test-spack.yml)\n[![pip](https://github.com/arbor-sim/arbor/actions/workflows/test-pip.yml/badge.svg)](https://github.com/arbor-sim/arbor/actions/workflows/test-pip.yml)\n[![pythonwheels](https://github.com/arbor-sim/arbor/actions/workflows/build-pip-wheels.yml/badge.svg)](https://github.com/arbor-sim/arbor/actions/workflows/build-pip-wheels.yml)\n[![gitpod](https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod)](https://gitpod.io/#https://github.com/arbor-sim/arbor)\n[![docs](https://readthedocs.org/projects/arbor/badge/?version=latest)](https://docs.arbor-sim.org/en/latest/)\n[![gitter](https://badges.gitter.im/arbor-sim/community.svg)](https://gitter.im/arbor-sim/community)\n[![CodeQL](https://github.com/arbor-sim/arbor/actions/workflows/codeql.yml/badge.svg?branch=master)](https://github.com/arbor-sim/arbor/actions/workflows/codeql.yml)\n\n# Arbor Library\n\n[Arbor](https://arbor-sim.org) is a library for implementing performance portable network simulations of multi-compartment neuron models.\n\nAn installation guide and library documentation are available online at [docs.arbor-sim.org](http://docs.arbor-sim.org).\n\n[Submit a ticket](https://github.com/arbor-sim/arbor/issues) or [join Gitter](https://gitter.im/arbor-sim/community) or [Matrix](https://matrix.to/#/#arbor-sim_community:gitter.im) if you have any questions or need help.\n\n### Citing Arbor\n\nThe Arbor introductory paper and entry on Zenodo can be cited, see [CITATION.bib](CITATION.bib). Please refer to [our documentation](https://docs.arbor-sim.org/en/latest/index.html#citing-arbor) for more information.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ardoco",
            "repo_link": "https://github.com/ArDoCo/Core",
            "readme": "# ArDoCo Core\n\n[![Maven Verify](https://github.com/ArDoCo/Core/actions/workflows/verify.yml/badge.svg)](https://github.com/ArDoCo/Core/actions/workflows/verify.yml)\n[![Maven Central](https://maven-badges.herokuapp.com/maven-central/io.github.ardoco.core/parent/badge.svg)](https://maven-badges.herokuapp.com/maven-central/io.github.ardoco.core/parent)\n[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=ArDoCo_Core&metric=alert_status)](https://sonarcloud.io/dashboard?id=ArDoCo_Core)\n[![Latest Release](https://img.shields.io/github/release/ArDoCo/Core.svg)](https://github.com/ArDoCo/Core/releases/latest)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7274034.svg)](https://doi.org/10.5281/zenodo.7274034)\n\nThe goal of the ArDoCo project is to connect architecture documentation and models with Traceability Link Recovery (TLR) while identifying missing or deviating elements (inconsistencies).\nAn element can be any representable item of the model, like a component or a relation.\nTo do so, we first create trace links and then make use of them and other information to identify inconsistencies.\n\nArDoCo is actively developed by researchers of the _[Modelling for Continuous Software Engineering (MCSE) group](https://mcse.kastel.kit.edu)_ of _[KASTEL - Institute of Information Security and Dependability](https://kastel.kit.edu)_ at the [KIT](https://www.kit.edu).\n\nThis **Core** repository contains the framework and core definitions for the other approaches.\nAs such, there is the definition of our pipeline and the data handling as well as the definitions for the various pipeline steps, inputs, outputs, etc.\n\nFor more information about the setup, the project structure, or the architecture, please have a look at the [Wiki](https://github.com/ArDoCo/Core/wiki).\n\n## Maven\n\n```xml\n\n<dependencies>\n\t<dependency>\n\t\t<groupId>io.github.ardoco.core</groupId>\n\t\t<artifactId>framework</artifactId> <!-- or any other subproject -->\n\t\t<version>VERSION</version>\n\t</dependency>\n</dependencies>\n```\n\nFor snapshot releases, make sure to add the following repository\n\n```xml\n\n<repositories>\n\t<repository>\n\t\t<releases>\n\t\t\t<enabled>false</enabled>\n\t\t</releases>\n\t\t<snapshots>\n\t\t\t<enabled>true</enabled>\n\t\t</snapshots>\n\t\t<id>mavenSnapshot</id>\n\t\t<url>https://s01.oss.sonatype.org/content/repositories/snapshots</url>\n\t</repository>\n</repositories>\n```\n\n## Relevant repositories\nThe following is an excerpt of repositories that use this framework and implement the different approaches and pipelines of ArDoCo:\n* [ArDoCo/TLR](https://github.com/ArDoCo/TLR): implementing different traceability link recovery approaches\n* [ArDoCo/InconsistencyDetection](https://github.com/ArDoCo/InconsistencyDetection): implementing inconsistency detection approaches\n* [ArDoCo/LiSSA](https://github.com/ArDoCo/LiSSA): implementing processing of sketches and diagrams for, e.g., TLR"
        },
        {
            "software_organization": "https://helmholtz.software/software/arosics",
            "repo_link": "https://git.gfz-potsdam.de/danschef/arosics",
            "readme": ".. figure:: https://danschef.git-pages.gfz-potsdam.de/arosics/images/arosics_logo.png\n    :target: https://git.gfz-potsdam.de/danschef/arosics\n    :align: center\n\n==================================================================================================\nAn Automated and Robust Open-Source Image Co-Registration Software for Multi-Sensor Satellite Data\n==================================================================================================\n\n* Free software: Apache 2.0\n* **Documentation:** https://danschef.git-pages.gfz-potsdam.de/arosics/doc/\n* The (open-access) **paper** corresponding to this software repository can be found here:\n  `Scheffler et al. 2017 <https://www.mdpi.com/2072-4292/9/7/676>`__\n  (cite as: Scheffler D, Hollstein A, Diedrich H, Segl K, Hostert P. AROSICS: An Automated and Robust Open-Source\n  Image Co-Registration Software for Multi-Sensor Satellite Data. Remote Sensing. 2017; 9(7):676).\n* Information on how to **cite the AROSICS Python package** can be found in the\n  `CITATION <https://git.gfz-potsdam.de/danschef/arosics/-/blob/main/CITATION>`__ file.\n* Submit feedback by filing an issue `here <https://git.gfz-potsdam.de/danschef/arosics/issues>`__\n  or join our chat here: |Gitter|\n\n.. |Gitter| image:: https://badges.gitter.im/Join%20Chat.svg\n    :target: https://gitter.im/arosics/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link\n    :alt: https://gitter.im/arosics/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link\n\nStatus\n------\n\n.. image:: https://git.gfz-potsdam.de/danschef/arosics/badges/main/pipeline.svg\n        :target: https://git.gfz-potsdam.de/danschef/arosics/commits/main\n.. image:: https://git.gfz-potsdam.de/danschef/arosics/badges/main/coverage.svg\n        :target: https://danschef.git-pages.gfz-potsdam.de/arosics/coverage/\n.. image:: https://img.shields.io/pypi/v/arosics.svg\n        :target: https://pypi.python.org/pypi/arosics\n.. image:: https://img.shields.io/conda/vn/conda-forge/arosics.svg\n        :target: https://anaconda.org/conda-forge/arosics\n.. image:: https://img.shields.io/pypi/l/arosics.svg\n        :target: https://git.gfz-potsdam.de/danschef/arosics/blob/main/LICENSE\n.. image:: https://img.shields.io/pypi/pyversions/arosics.svg\n        :target: https://img.shields.io/pypi/pyversions/arosics.svg\n.. image:: https://img.shields.io/pypi/dm/arosics.svg\n        :target: https://pypi.python.org/pypi/arosics\n.. image:: https://zenodo.org/badge/253474603.svg\n        :target: https://zenodo.org/badge/latestdoi/253474603\n\nSee also the latest coverage_ report and the pytest_ HTML report.\n\nFeature overview\n----------------\n\nAROSICS is a python package to perform **automatic subpixel co-registration** of two satellite image datasets\nbased on an image matching approach working in the frequency domain, combined with a multistage workflow for\neffective detection of false-positives.\n\nIt detects and corrects **local as well as global misregistrations** between two input images in the subpixel scale,\nthat are often present in satellite imagery. The algorithm is robust against the typical difficulties of\nmulti-sensoral/multi-temporal images. Clouds are automatically handled by the implemented outlier detection algorithms.\nThe user may provide user-defined masks to exclude certain image areas from tie point creation. The image overlap area\nis automatically detected. AROSICS supports a wide range of input data formats and can be used from the command\nline (without any Python experience) or as a normal Python package.\n\n\nGlobal co-registration - fast but only for static X/Y-shifts\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nOnly a global X/Y translation is computed within a small subset of the input images (window position is adjustable).\nThis allows very fast co-registration but only corrects for translational (global) X/Y shifts.\nThe calculated subpixel-shifts are (by default) applied to the geocoding information of the output image.\nNo spatial resampling is done automatically as long as both input images have the same projection. However, AROSICS\nalso allows to align the output image to the reference image coordinate grid if needed.\n\nHere is an example of a Landsat-8 / Sentinel-2 image pair before and after co-registration using AROSICS:\n\n.. image:: https://git.gfz-potsdam.de/danschef/arosics/raw/main/docs/images/animation_testcase1_zoom_L8_S2_global_coreg_before_after_900x456.gif\n\n\nLocal co-registration - for spatially variable shifts but a bit slower\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nA dense grid of tie points is automatically computed, whereas tie points are subsequently validated using a\nmultistage workflow. Only those tie points not marked as false-positives are used to compute the parameters of an\naffine transformation. Warping of the target image is done using an appropriate resampling technique\n(cubic by default).\n\nHere is an example of the computed shift vectors after filtering false-positives\n(mainly due to clouds in the target image):\n\n.. image:: https://git.gfz-potsdam.de/danschef/arosics/raw/main/docs/images/shift_vectors_testcase1__900x824.gif\n\n\nFor further details check out the `documentation <https://danschef.git-pages.gfz-potsdam.de/arosics/doc/>`__!\n\n\nHistory / Changelog\n-------------------\n\nYou can find the protocol of recent changes in the AROSICS package\n`here <https://git.gfz-potsdam.de/danschef/arosics/-/blob/main/HISTORY.rst>`__.\n\n\nCredits\n-------\n\nAROSICS was developed by Daniel Scheffler (German Research Centre of Geosciences) within the context of the\n`GeoMultiSens <http://www.geomultisens.gfz-potsdam.de/>`__ project funded by the German Federal Ministry of Education and Research\n(project grant code: 01 IS 14 010 A-C).\n\nThis package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.\nThe test data represent modified Copernicus Sentinel-2 data (ESA 2016). The input data for the figures in the\ndocumentation have been provided by NASA (Landsat-8) and ESA (Sentinel-2).\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage\n.. _coverage: https://danschef.git-pages.gfz-potsdam.de/arosics/coverage/\n.. _pytest: https://danschef.git-pages.gfz-potsdam.de/arosics/test_reports/report.html\n.. _conda: https://docs.conda.io/\n\n",
            "project_id": "163"
        },
        {
            "software_organization": "https://helmholtz.software/software/atomec",
            "repo_link": "https://github.com/atomec-project/atoMEC",
            "readme": "![image](https://github.com/atomec-project/atoMEC/blob/develop/docs/source/img/logos/atoMEC_horizontal2.png)\n\n# atoMEC: Average-Atom Code for Matter under Extreme Conditions\n\n[![docs](https://github.com/atomec-project/atoMEC/actions/workflows/gh-pages.yml/badge.svg)](https://github.com/atomec-project/atoMEC/actions/workflows/gh-pages.yml)\n[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/release/python-3100/)\n[![image](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)\n[![codecov](https://codecov.io/gh/atomec-project/atoMEC/branch/develop/graph/badge.svg?token=V66CJJ3KPI)](https://codecov.io/gh/atomec-project/atoMEC)\n[![CodeFactor](https://www.codefactor.io/repository/github/atomec-project/atomec/badge)](https://www.codefactor.io/repository/github/atomec-project/atomec)\n\natoMEC is a python-based average-atom code for simulations of high energy density phenomena such as in warm dense matter.\nIt is designed as an open-source and modular python package.\n\natoMEC uses Kohn-Sham density functional theory, in combination with an average-atom approximation,\nto solve the electronic structure problem for single-element materials at finite temperature.\n\nMore information on the average-atom methodology and Kohn-Sham density functional theory can be found (for example) in this [paper](https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.4.023055) and references therein.\n\nThis repository is structured as follows:\n```\n├── atoMEC : source code\n├── docs : sphinx documentation\n├── examples : simple examples to get you started with the package\n└── tests : CI tests\n```\n\n\n## Installation\n\nThe latest stable release of `atoMEC` can be installed via `pip`. It is first necessary to install the `libxc` package from a tarball source, because it currently has no official wheels distribution on PyPI. This step takes some time.\n\n```sh\n$ pip install https://gitlab.com/libxc/libxc/-/archive/6.2.2/libxc-6.2.2.tar.gz\n$ pip install atoMEC\n```\n\nNote that atoMEC does not (yet) support Windows installation (please see the section below on supported operating systems).\n\nRead on for instructions on how to install `atoMEC` from source, using the recommended `pipenv` installation route.\n\n### Installation via `pipenv`\n\nFirst, clone the atoMEC repository and ``cd`` into the main directory.\n\n* It is recommended to install atoMEC inside a virtual environment. Below, we detail how to achive this with [pipenv](https://pypi.org/project/pipenv/).\n\n  This route is recommended because `pipenv` automatically creates a virtual environment and manages dependencies. Note that `pyblibxc` is automatically installed in this case, so there is no need to install it separately.\n\n  1. First, install `pipenv` if it is not already installed, for example via `pip install pipenv` (or see [pipenv](https://pypi.org/project/pipenv/) for installation instructions)\n  2. Next, install `atoMEC`'s dependencies with `pipenv install` (use `--dev` option to install the test dependencies in the same environment)\n  3. Use `pipenv shell` to activate the virtual environment\n  4. Install atoMEC with `pip install atoMEC` (for developers: `pip install -e .`)\n  5. Now run scripts from inside the `atoMEC` virtual environment, e.g. `python examples/simple.py`\n\n* Run the tests (see Testing section below) and report any failures (for example by raising an issue).\n\n### Supported operating systems\n\n* **Linux and macOS**: atoMEC has been installed on various linux distributions and macOS, and is expected to work for most distributions and versions\n* **Windows**: atoMEC does **not** support Windows installation. This is due to the dependency on `pylibxc` which currently lacks Windows support. We are looking into ways to make the dependency on `pylibxc` optional, in order to allow installation on Windows. However, this is not currently a priority.\n\n\n### Supported Python versions\n\n* atoMEC has been tested and is expected to work for all Python versions >= 3.8 and <= 3.12\n* atoMEC does not work for Python <= 3.7\n* Until 09.10.2023 (release 1.4.0), all development and CI testing was done with Python 3.8. As of this date, development and CI testing is done with Python 3.12.\n* Python 3.12 is therefore the recommended version for atoMEC >= 1.4.0, since this is used for the current testing and development environment\n\n\n## Running\nYou can familiarize yourself with the usage of this package by running the example scripts in `examples/`.\n\n## Contributing to atoMEC\nWe welcome your contributions, please adhere to the following guidelines when contributing to the code:\n* In general, contributors should develop on branches based off of `develop` and merge requests should be to `develop`\n* Please choose a descriptive branch name\n* Merges from `develop` to `master` will be done after prior consultation of the core development team\n* Merges from `develop` to `master` are only done for code releases. This way we always have a clean `master` that reflects the current release\n* Code should be formatted using [black](https://pypi.org/project/black/) style\n\n## Testing\n* First, install the test requirements (if not already installed in the virtual env with `pipenv install --dev`):\n```sh\n# activate environment first (optional)\n$ pipenv shell\n\n# install atoMEC as editable project in current directory (for developers)\n$ pip install -e .[tests]\n\n# alternatively install package from PyPI with test dependencies\n$ pip install atoMEC[tests]\n```\n\n* To run the tests:\n```sh\n$ pytest --cov=atoMEC --random-order tests/\n```\n\n### Build documentation locally (for developers)\n\nInstall the prerequisites:\n```sh\n$ pip install -r docs/requirements.txt\n```\n\n1. Change into `docs/` folder.\n2. Run `make apidocs`.\n3. Run `make html`. This creates a `_build` folder inside `docs`. You may also want to use `make html SPHINXOPTS=\"-W\"` sometimes. This treats warnings as errors and stops the output at first occurrence of an error (useful for debugging rST syntax).\n4. Open `docs/_build/html/index.html`.\n5. `make clean` if required (e.g. after fixing errors) and building again.\n\n## Developers\n### Scientific Supervision\n- Attila Cangi ([Center for Advanced Systems Understanding](https://www.casus.science/))\n- Eli Kraisler ([Hebrew University of Jerusalem](https://en.huji.ac.il/en))\n\n### Core Developers and Maintainers\n- Tim Callow ([Center for Advanced Systems Understanding](https://www.casus.science/))\n- Daniel Kotik ([Center for Advanced Systems Understanding](https://www.casus.science/))\n\n### Contributions (alphabetical)\n- Nathan Rahat ([Hebrew University of Jerusalem](https://en.huji.ac.il/en))\n- Ekaterina Tsvetoslavova Stankulova ([Center for Advanced Systems Understanding](https://www.casus.science/))\n\n## Citing atoMEC\nIf you use code from this repository in a published work, please cite\n\n1. T. J. Callow, D. Kotik, E. Kraisler, and A. Cangi, \"atoMEC: An open-source average-atom Python code\", _Proceedings of the 21st Python in Science Conference_, edited by Meghann Agarwal, Chris Calloway, Dillon Niederhut, and David Shupe (2022), pp. 31 – 39\n2. The DOI corresponding to the specific version of atoMEC that you used (DOIs are listed at [Zenodo.org](https://doi.org/10.5281/zenodo.5205718))\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/autogaita",
            "repo_link": "https://github.com/mahan-hosseini/AutoGaitA",
            "readme": "![AutoGaitA](https://github.com/mahan-hosseini/AutoGaitA/blob/main/autogaita/resources/logo.png?raw=true)\n![Repository Active](https://www.repostatus.org/badges/latest/active.svg)\n[![Test AutoGaitA](https://github.com/mahan-hosseini/AutoGaitA/actions/workflows/autogaita_test_and_black.yml/badge.svg)](https://github.com/mahan-hosseini/AutoGaitA/actions/workflows/autogaita_test_and_black.yml)\n![Python](https://img.shields.io/badge/python-v3.10+-blue.svg)\n[![PyPI - Version](https://img.shields.io/pypi/v/autogaita)](https://pypi.org/project/autogaita/)\n![license: GPL v3](https://img.shields.io/badge/license-GPLv3-blue.svg)\n[![paper: biorxiv](https://img.shields.io/badge/paper-biorxiv-blue)](https://doi.org/10.1101/2024.04.14.589409) \n\n![Black](https://img.shields.io/badge/code%20style-black-000000.svg)\n[![X URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2Fautogaita&style=social&label=updates)](https://x.com/autogaita)\n\n# Automated Gait Analysis in Python 🐸\n\n- AutoGaitA simplifies, accelerates, and standardises gait analyses after body posture tracking with [DeepLabCut](https://github.com/DeepLabCut/DeepLabCut) or 3D tracking methods such as [Simi Motion](http://www.simi.com/en/products/movement-analysis/simi-motion-2d3d.html?type=rss%2F). \n- AutoGaitA's first-level tools provide a wide range of automated kinematic analyses for each input video and AutoGaitA Group allows the comparison of up to six groups. \n- AutoGaitA enables comparisons to be made across experimental conditions, species, disease states or genotypes. \n- Despite being developed with gait data, AutoGaitA can be utilised for the analysis of any motor behaviour.\n\n## Getting Started\n\n***Note!** [Our documentation](https://docs.google.com/document/d/1iQxSwqBW3VdIXHm-AtV4TGlgpJPDldogVx6qzscsGxA/edit?usp=sharing) provides step-by-step walkthroughs of how to install autogaita for **[Windows](https://docs.google.com/document/d/1iQxSwqBW3VdIXHm-AtV4TGlgpJPDldogVx6qzscsGxA/edit?tab=t.0#heading=h.28j6wu2vamre)** and **[Mac](https://docs.google.com/document/d/1iQxSwqBW3VdIXHm-AtV4TGlgpJPDldogVx6qzscsGxA/edit?tab=t.0#heading=h.ljmdh7hfayyx)***\n\nIt is strongly recommended that a separate virtual environment for AutoGaitA is created (note that the approach below creates the virtual environment to your current directory):\n\n- Create the virtual environment:\n    - `python -m venv env_gaita`\n\n- After creation, activate the virtual environment via:\n    - *Windows:* `env_gaita\\Scripts\\activate`\n    - *Mac:* `source env_gaita/bin/activate`\n\n- Once activated, install AutoGaitA in the virtual environment via pip: `pip install autogaita`.\n\n- Access the main user interface via: `python -m autogaita`.\n\n- To update to the latest release (see the *Releases* panel on the right for the latest release) activate the virtual environment and: `pip install autogaita -U`. \n\n## Demo Video\n*Check out the video below for a demonstration of AutoGaitA's main workflow!*\n<p><a href=\"https://youtu.be/_HIZVuUzpzk?feature=shared\">\n<img src=\"https://github.com/mahan-hosseini/AutoGaitA/blob/main/autogaita/resources/pic_to_demo_for_repo.png\" width=\"550\">\n\n## Tutorials & Examples\n\n### Walkthrough Tutorial Videos  \n\n**[The AutoGaitA YouTube Channel](https://youtube.com/playlist?list=PLCn5T7K_H8K56NIcEsfDK664OP7cN_Bad&si=mV5p2--nYvbofkPh) provides tutorials for file preparation and instructions on how to use AutoGaitA. This includes in-depth explanations of all details, (main & advanced) configurations, possibilities, and outputs.**\n\n*Please note that tutorial videos might not always reflect the most up-to-date version of our toolbox, especially in the beginning when things are regularly changing. We will make sure to record new videos whenever there are major changes though. Last tutorial-update was with v0.4.0. (August 2024).*\n\n### Example Data\nWe provide an example dataset in the **example data** folder of this repository, with a set of mice walking over differently wide beams and both the beam as well as body coordinates being tracked with DLC. Note that this dataset was used in our tutorial videos introducing *AutoGaitA DLC*, *AutoGaitA Group* and in our video explaining file preparation for *AutoGaitA DLC*.  We further provide a **group** folder there that can be used alongside the *AutoGaitA Group* tutorial to confirm that users generate the same set of results following our instructions.\n\n### Annotation Table Examples and Templates\nAnnotation Table example and template files for *AutoGaitA DLC* and *AutoGaitA Universal 3D* can be found in the [**annotation tables**](https://github.com/mahan-hosseini/AutoGaitA/tree/main/annotation%20tables) folder of this repository.\n\nUsers are advised to read the **General Recommendations** section of that folder, use the template to enter their data's timestamp information and to then compare the resulting table with our example to check formatting. Users working with ImageJ/FIJI are encouraged to check out the [AnnotationTable-Plugin](https://github.com/luca-flemming/AnnotationTable-Plugin) developed by our contributor Luca Flemming.\n\n## Documentation\n\n**[The AutoGaitA Documentation](https://docs.google.com/document/d/1iQxSwqBW3VdIXHm-AtV4TGlgpJPDldogVx6qzscsGxA/edit?usp=sharing) provides complete guidelines on installation, file preparation, AutoGaitA GUIs, using AutoGaitA via the command line, installing FFmpeg for rotating 3D PCA videos, lists known issues and FAQ.**  \n\n## Two important options\n\n### Custom joints & angles\n**We strongly advise** users to pay attention to the *custom joints and angles* windows of AutoGaitA's first level toolboxes. Please see the relevant links below. These windows allow users to customise which columns of their data should be analysed and how angles should be computed. \n\nBy default, *AutoGaitA DLC* and *AutoGaitA Universal 3D* implement standard values for mouse and human locomotion, respectively. If your analysis deviates from these standards (e.g. by focussing on another behaviour or a different species) **you must change these values!** \n\n**Find out more about *AutoGaitA's custom joints and angles:***\n- [YouTube - AutoGaitA DLC Advanced Configuration](https://youtu.be/MP9g9kXRE_Q?feature=shared) \n- [YouTube - AutoGaitA Universal 3D (prev. called Simi)](https://youtu.be/rTG-Fc9XI9g?feature=shared) \n- [Documentation - AutoGaitA DLC](https://docs.google.com/document/d/1iQxSwqBW3VdIXHm-AtV4TGlgpJPDldogVx6qzscsGxA/edit?tab=t.0#heading=h.20bg7b7ymt0b)\n- [Documentation - AutoGaitA Universal 3D](https://docs.google.com/document/d/1iQxSwqBW3VdIXHm-AtV4TGlgpJPDldogVx6qzscsGxA/edit?tab=t.0#heading=h.uz61bpmua7qz)\n\n### Bin number of step cycle normalisation\nAn important step in AutoGaitA is normalising step cycles (or instances of other behaviours) to a uniform length before calculating the video-level average. This uniform length is called *bin number*, must be set by users and defaults to a value of 25.\n\nStep cycles are normalised via averaging temporally adjacent data points if their original length was larger than the bin number and repeating values if they were shorter originally. Examples are provided here: \n- [Documentation/AutoGaitA DLC/Main Configuration/Option #6](https://docs.google.com/document/d/1iQxSwqBW3VdIXHm-AtV4TGlgpJPDldogVx6qzscsGxA/edit?tab=t.0#heading=h.bboivsfqr2lz).\n\n**We strongly advise** users to think carefully about an appropriate bin number for their datasets. The correct value varies and depends strongly on the studied species, behaviour and the frame rate of cameras.\n\n## Analysing other behaviours - AutoCyclA 🚴\nEven though AutoGaitA's main focus is to automate and standardise gait analyses, our toolbox can be used to automate the analyses of any rhythmic behaviour of interest. For a proof-of-principle demonstration and an introduction of the general workflow of such analyses, see **[AutoCyclA - Automated Cycling Analysis with AutoGaitA.](https://github.com/mahan-hosseini/AutoGaitA/tree/main/autocycla)**\n\n## Updating AutoGaitA\nIt is strongly recommended that AutoGaitA is kept up to date since new features and important bugfixes are provided regularly. \n\nAutoGaitA's cfg files and dictionaries sometimes change as a result, which means that previously generated first-level *Results* folders cannot always be analysed with AutoGaitA Group after an update. In such cases, it is recommended to re-run first-level analyses. \n\nWe document each version's cfg-changes in [AutoGaitA Releases](https://github.com/mahan-hosseini/AutoGaitA/releases), which is particularly relevant for users wrapping custom scripts around AutoGaitA's functions.\n\n## Reference\nIf you use this code or data please [cite our preprint](https://www.biorxiv.org/content/10.1101/2024.04.14.589409v1).\n\n## License\nAutoGaitA is licensed under [GPL v3.0](https://github.com/mahan-hosseini/AutoGaitA/blob/main/LICENSE) and Forschungszentrum Jülich GmbH holds all copyrights. \n\nThe AutoGaitA software is provided without warranty of any kind, express or implied, including, but not limited to, the implied warranty of fitness for a particular purpose.\n\n## Authors\n[Mahan Hosseini](https://github.com/mahan-hosseini)\n\n## Contributors\n[Luca Flemming](https://github.com/luca-flemming) - Undergraduate Student\n\n[Nicholas del Grosso](https://github.com/nickdelgrosso) - RSE Advisor\n\n## Contributing\nIf you would like to contribute to the AutoGaitA toolbox, feel free to open a pull request or contact us at autogaita@fz-juelich.de! \n\nWe are looking forward to your input and ideas 😊\n\n## Archive\nWe have archived the resources of outdated AutoGaitA versions here:\n\n- v0.4.1 - [Documentation](https://docs.google.com/document/d/1Y4wrrsjs0ybLDKPzE2LAatqPDq9jtwjIuk4M0jRZ3wE/edit?usp=sharing)\n- v0.3.1 - [YouTube Tutorials](https://youtube.com/playlist?list=PLCn5T7K_H8K776DLuXKoPsUpI6Yb0NU33&si=7ZAAvcrPxR7WsB8a) & [Documentation](https://docs.google.com/document/d/11mJd7jUHk7joQ0BdZT98CJRrIANdyosMQMJGFtp6yR4/edit?usp=sharing)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/autopq",
            "repo_link": "https://github.com/SMEISEN/AutoPQ",
            "readme": "# AutoPQ: Automated point forecast-based quantile forecasts\n\nAutoPQ addresses three challenges:\n- Many state-of-the-art forecasting methods are still point forecasts and remain unused for probabilistic forecasts\n- According to the no-free-lunch theorem, no forecasting method exists that excels in all forecasting tasks\n- Smart grid applications typically require forecasts with customized probabilistic characteristics\n\n## Methodology\n\nThe underlying idea of AutoPQ is to generate a probabilistic forecast based on an arbitrary point forecast using a conditional Invertible Neural Network (cINN) and to make corresponding design decisions automatically, aiming to increase the probabilistic performance. To account for different computing systems and performance requirements, two variants are available: AutoPQ-default suitable for standard computing systems achieving competitive forecasting performance, and AutoPQ-advanced requiring High-Performance Computing (HPC) systems to further increase forecasting performance for smart grid applications with high decision costs.\n\n![concept_pipeline_github](https://github.com/SMEISEN/AutoPQ/assets/33990691/40344260-77ee-4515-9964-16875b9383d7)\n\n## Installation\n\nTo install this project, perform the following steps.\n1) Clone the project\n2) Open a terminal of the virtual environment where you want to use the project\n3) cd AutoPQ\n4) pip install . or pip install -e . if you want to install the project editable.\n\n## How to use\n\nExemplary evaluations using AutoPQ are given in the examples folder.\n\n### Hyperparameter optimization\n\n- The default configuration optimizes the sampling hyperparameter $\\lambda_\\text{q}$ for generating samples in the latent space of the cINN.\n- The advanced configuration simultaneously optimizes the point forecasting method's hyperparameters $\\boldsymbol{\\lambda_\\text{p}}$ and the sampling hyperparameter $\\lambda_\\text{q}$.\n\n### Evaluation types\n\nThe evaluation trains the models using the training data sub-set, optimizes hyperparameters based on the validation data sub-set, and makes probabilistic forecasts for the test data sub-set.\n\n## Citation\n\nIf you use this method please cite the corresponding papers:\n> Kaleb Phipps, Stefan Meisenbacher, Benedikt Heidrich, Marian Turowski, Ralf Mikut, and Veit Hagenmeyer. 2023. Loss-customised probabilistic energy time series forecasts using automated hyperparameter optimisation. In Proceedings of the 14th ACM International Conference on Future Energy Systems (e-Energy ’23), Association for Computing Machinery, New York, NY, USA, 271–286. [https://doi.org/10.1145/3575813.3595204](https://doi.org/10.1145/3575813.3595204)\n\n> Stefan Meisenbacher et al. 2024. AutoPQ: Automated point forecast-based quantile forecasts. In preparation.\n\n## Funding\n\nThis project is funded by the Helmholtz Association under the Program “Energy System Design” and the Helmholtz Association's Initiative and Networking Fund through Helmholtz AI.\n\n## References\n\nThe cINN is based on:\n> B. Heidrich, M. Turowski, K. Phipps, K. Schmieder, W. Süß, R. Mikut, and V. Hagenmeyer, “Controlling non-stationarity and periodicities in time series generation using conditional invertible neural networks”, Applied Intelligence, vol. 53, no. 8, pp. 8826–8843, 2023.\n\nGenerating probabilistic forecasts by sampling in the cINN's latent space is based on:\n> K. Phipps, B. Heidrich, M. Turowski, M. Wittig, R. Mikut, and V. Hagenmeyer, “Generating probabilistic forecasts from arbitrary point forecasts using a conditional invertible neural network”, Applied Intelligence, 2024.\n\nOptimization of the sampling hyperparameter is performed using [Hyperopt](https://github.com/hyperopt/hyperopt)\n> J. Bergstra, D. Yamins, and D. Cox, “Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures”, in Proceedings of the 30th International Conference on Machine Learning, ser. ICML ’13, Proceedings of Machine Learning Research, PMLR, 2013, pp. 115–123.\n\nOptimization of the point forecasting method's hyperparameters is performed using [Propulate](https://github.com/Helmholtz-AI-Energy/propulate)\n> O. Taubert, M. Weiel, D. Coquelin, A. Farshian, C. Debus, A. Schug, A. Streit, and M. Götz, “Massively parallel genetic optimization through asynchronous propagation of populations”, in High Performance Computing, A. Bhatele, J. Hammond, M. Baboulin, and C. Kruse, Eds., Cham, Switzerland: Springer Nature, 2023, pp. 106–124.\n\nThe Load-BW data is taken from the Open Power System Data (OPSD) portal:\n> F. Wiese et al., “Open Power System Data: Frictionless data for electricity system modelling”, Applied Energy, vol. 236, pp. 401–409, 2019.\n\nThe Load-GCP data set is taken from the UCI Machine Learning Repository:\n> A. Trindade, Electricity load diagrams 2011-2014, UCI Machine Learning Repository, 2015.\n\nThe Mobility data set is taken from the UCI Machine Learning Repository:\n> H. Fanaee-T, Bike sharing dataset, UCI Machine Learning Repository, 2013.\n\nThe Price, PV, and WP data are from the price, solar power, and wind power forecasting tracks of the Global Energy Forecasting Competition (GEFCom) 2014:\n> T. Hong, P. Pinson, S. Fan, H. Zareipour, A. Troccoli, and R. J. Hyndman, “Probabilistic energy forecasting: Global energy forecasting competition 2014 and beyond”, International Journal of Forecasting, vol. 32, no. 3, pp. 896–913, 2016.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/autopv",
            "repo_link": "https://github.com/SMEISEN/AutoPV",
            "readme": "# AutoPV: Automated photovoltaic forecasts with limited information using an ensemble of pre-trained models\nAutoPV addresses three challenges:\n- Missing information about the PV mounting configuration (tilt and azimuth angles, mixed-oriented configurations)\n- Missing or limited training data for PV model design (cold-start problem)\n- Adaption to drifting PV power generation capabilities during operation (e.g. age-related degradation, soiling, maintenance)\n\n## Methodology\n\nThe underlying idea of AutoPV is to describe the arbitrary mounting configuration of a new PV plant as a convex linear combination of outputs from a sufficiently diverse ensemble pool of PV models of the same region. AutoPV incorporates three steps: i) create the ensemble model pool, ii) form the ensemble output by an optimally weighted sum of the scaled model outputs in the pool, and iii) rescale the ensemble output with the new PV plant’s peak power rating.\n\n![pipeline](https://github.com/SMEISEN/AutoPV/assets/33990691/56363d4b-5418-427b-b723-bf14255804ce)\n\n\n## Installation\n\nTo install this project, perform the following steps.\n1) Clone the project\n2) Open a terminal of the virtual environment where you want to use the project\n3) cd AuroPV\n4) pip install . or pip install -e . if you want to install the project editable.\n\n## How to use\n\nExemplary evaluations using AutoPV are given in the examples folder.\n\n### Model pools\n- The default model pool is based on physical-inspired modeling and uses 12 models (tilt: 15°, 45°, 75°, azimuth: 0°, 90°, 180°, 270°). The default model pool is suitable for situations where no data of nearby PV plants are available.\n- The nearby plants model pool uses machine learning-based modeling to create the models using data from nearby PV plants. The nearby plants model pool can represent shading if it is present in the nearby PV plants.\n\n### Evaluation types\n- The offline evaluation optimizes the ensemble weights using the entire training data and does not adapt the weights over time.\n- The online evaluation cyclically adapts the weights based on the testing data (cold-start) and does not require training data.\n\n## Citation\n\nIf you use this method please cite the corresponding paper:\n> Stefan Meisenbacher, Benedikt Heidrich, Tim Martin, Ralf Mikut, and Veit Hagenmeyer. 2023. AutoPV: Automated photovoltaic forecasts with limited information using an ensemble of pre-trained models. In Proceedings of the Fourteenth ACM International Conference on Future Energy Systems (e-Energy ’23). Association for Computing Machinery, New York, NY, USA, 386–414. https://doi.org/10.1145/3575813.3597348\n\n## Funding\nThis project is funded by the Helmholtz Association under the Program “Energy System Design” and the Helmholtz Association’s Initiative and Networking Fund through Helmholtz AI.\n\n## References\n\nThe example data includes weather measurements from DWD:\n> Deutscher Wetterdienst. 2023. Historical 10-minute station observations of solar incoming radiation, longwave downward radiation, pressure, air temperature, and mean wind speed for Germany. https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/autowp",
            "repo_link": "https://github.com/SMEISEN/AutoWP",
            "readme": "# AutoWP: Automated wind power forecasts with limited computing resources using an ensemble of diverse wind power curves\n\nAutoWP addresses two challenges:\n- Achieving good accuracy in Wind Power (WP) forecasting with low computational effort\n- Handling regular or irregular interventions in the WP generation capabilities\n\n## Methodology\n\nThe underlying idea of AutoWP is to represent a new WP turbine as a convex linear combination of WP curves from a sufficiently diverse ensemble. The method consists of three steps: i) create the ensemble of normalized WP curves, ii) form the normalized ensemble WP curve by the optimally weighted sum of the WP curves in the ensemble, and iii) re-scale the ensemble WP curve with the new WP turbine’s peak power rating.\n\n![autowp_pipeline](https://github.com/SMEISEN/AutoWP/assets/33990691/46b4f23c-4a8f-423e-8e20-a24e2b02ff5d)\n\n## Installation\n\nTo install this project, perform the following steps.\n1) Clone the project\n2) Open a terminal of the virtual environment where you want to use the project\n3) cd AutoWP\n4) pip install . or pip install -e . if you want to install the project editable.\n\n## How to use\n\nExemplary evaluations using AutoWP are given in the examples folder.\n\n### Model pool\n\nThe model pool is based on a selection of 10 WP curves from the [windpowerlib](https://github.com/wind-python/windpowerlib). The selection reduces redundancy and preserves diversity. Since these WP curves provided by turbine Original Equipment Manufacturers (OEMs) have the hub height as reference height, height correction of the wind speed forecast based on the wind profile power law is used. \n\n### Evaluation types\n\nThe offline evaluation optimizes the ensemble weights using the entire training data and does not adapt the weights over time.\n\n## Citation\n\nIf you use this method please cite the corresponding paper:\n> S. Meisenbacher et al, “AutoWP: Automated wind power forecasts with limited computing resources using an ensemble of diverse wind power curves”, 2024, in preparation.\n\n## Funding\n\nThis project is funded by the Helmholtz Association under the Program “Energy System Design” and the Helmholtz Association?s Initiative and Networking Fund through Helmholtz AI.\n\n## References\n\nThe example data is from the wind power forecasting track of the Global Energy Forecasting Competition (GEFCom) 2014:\n> T. Hong, P. Pinson, S. Fan, H. Zareipour, A. Troccoli, and R. J. Hyndman, “Probabilistic energy forecasting: Global energy forecasting competition 2014 and beyond”, International Journal of Forecasting, vol. 32, no. 3, pp. 896–913, 2016.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/aviator",
            "repo_link": "https://github.com/CCB-SB/Aviator",
            "readme": "# Aviator\n\n### [https://ccb-compute2.cs.uni-saarland.de/aviator](https://ccb-compute2.cs.uni-saarland.de/aviator)\n\nAviator is a web-server monitoring the availability of other published web-servers.\nIt allows researchers to monitor their own tools or to asses if a tool they would like to\naccess is temporarily or permanently offline.\n\nAviator is composed of two modules:\n\n### - [Tool List](https://ccb-compute2.cs.uni-saarland.de/aviator/tools): web-servers collected automatically from literature\n### - [Aviator-enabled](https://ccb-compute2.cs.uni-saarland.de/aviator/aviator-enabled): web-servers manually added by their authors\n\nThe web-server URL or an API endpoint provided by the authors are queried twice per day. In addition to providing an availability overview we provide the possibility for authors to be notified if their webserver is offline for an unexpected period of time. \n\nTo add your published web-server to Aviator a simple [API endpoint](https://ccb-compute2.cs.uni-saarland.de/aviator/aviator-enable) and a [registration](https://ccb-compute2.cs.uni-saarland.de/aviator/register) is needed. \n\n## License\n\n[MIT © CCB-SB](/LICENSE)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/awi-gpt",
            "repo_link": "https://github.com/CliDyn",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/awi-pangaea-ai-hub",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/base-repo",
            "repo_link": "https://github.com/kit-data-manager/base-repo",
            "readme": "# KIT Data Manager - Base Repository Service\n\n[![Build Status](https://github.com/kit-data-manager/base-repo/actions/workflows/gradle.yml/badge.svg)](https://github.com/kit-data-manager/base-repo/actions/workflows/gradle.yml)\n[![Codecov](https://codecov.io/gh/kit-data-manager/base-repo/branch/master/graph/badge.svg)](https://codecov.io/gh/kit-data-manager/base-repo)\n![License](https://img.shields.io/github/license/kit-data-manager/base-repo.svg)\n[![SQAaaS badge shields.io](https://img.shields.io/badge/Docker-white?logo=docker)](https://github.com/kit-data-manager/base-repo/pkgs/container/base-repo)\n[![SQAaaS badge shields.io](https://img.shields.io/badge/sqaaas%20software-silver-lightgrey)](https://api.eu.badgr.io/public/assertions/onNKx_lhTn68bPKnMAg-eQ \"SQAaaS silver badge achieved\")\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7660036.svg)](https://doi.org/10.5281/zenodo.7660036)\n\nThis project contains the repository service microservice for the KIT DM infrastructure. The service provides\ndata resource management, e.g. register DataCite-oriented metadata and upload/download content to data resources.\n\n## How to build\n\nIn order to build this microservice you'll need:\n\n* Java SE Development Kit 17 or higher\n\nAfter obtaining the sources change to the folder where the sources are located perform the following steps:\n\n```bash\nuser@localhost:/home/user/base-repo$ ./gradlew -Dprofile=minimal build\nRunning gradle version: 7.4.2\nBuilding base-repo version: 1.5.5\nJDK version: 11\nUsing minimal profile for building base-repoo\n<-------------> 0% EXECUTING [0s]\n[...]\nuser@localhost:/home/user/base-repo$\n```\n\nThe Gradle wrapper will now take care of downloading the configured version of Gradle, checking out all required libraries, build these\nlibraries and finally build the base-repo microservice itself. As a result, a fat jar containing the entire service is created at 'build/libs/base-repo.jar'.\n\n## How to start\n\n### Prerequisites\n\n* PostgreSQL 9.1 or higher\n* RabbitMQ 3.7.3 or higher (in case you want to use the messaging feature, which is recommended)\n* Elastic 8.X or higher (in case you want to use the search feature)\n\n### Setup\n\nBefore you are able to start the repository microservice, you have provide a configuration file according to your local setup.\nTherefor, copy the file 'config/application-default.properties' to your project folder, rename it to 'application.properties' and customize it as required. Special attentioned should be payed to the datasource url as well as to the repository base path. Also, the property 'repo.messaging.enabled' should be changed to 'true' in case you want to use the messaging feature of the repository.\n\nAs soon as you finished modifying 'application.properties', you may start the repository microservice by executing the following command inside the project folder,\ne.g. where the service has been built before:\n\n```bash\nuser@localhost:/home/user/base-repo$ ./build/libs/base-repo.jar\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::        (v2.7.5)\n[...]\n1970-01-01 00:00:00.000  INFO 56918 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''\n\n```\n\nIf your 'application.properties' is not located inside the project folder you can provide it using the command line argument --spring.config.location=<PATH_TO_APPLICATION.PROPERTIES>\n\nAs soon as the microservice is started, you can browse to\n\n<http://localhost:8090/swagger-ui.html>\n\nin order to see available RESTful endpoints and their documentation.\n\n### Enhanced Startup\n\nAt certain points, base-repo offers and will offer extension points allowing to add custom features that are not part of the default distribution, e.g. custom message handlers. If you are familiar with software development, it might be no big deal to include an additional dependency to 'build.gradle' of base-repo. However, in some cases this might not be desirable or possible. Therefor, base-repo allows to place additional libraries required at runtime in a separate folder which is then loaded as soon as the microservice starts and made available using the dependency injection feature of Spring Boot.\n\nIn order to tell Spring Boot where to look for additional libraries, you have to define an environment variable JAVA_OPTS looking as follows:\n\n```bash\nexport JAVA_OPTS=\"-cp .:./config:./base-repo.jar -Dloader.path=./base-repo.jar,./lib/,.\"\n```\n\nThe first part '-cp' has to contain three elements divided by ':':\n\n1. The configuration folder where your application.properties is located (this element can be omitted, if application.properties\nis located in the current folder),\n2. the current folder,\n3. and the microservice jar file.\n\nThe second part '-Dloader.path' basically contains the same information as '-cp' but with the difference, that the config folder is not required, whereas the folder\ncontaining all additional libraries has to be provided, in our case it's './lib'.\n\nPlease keep in mind that all arguments shown in the example assume, that you are in the same folder where your microservice jar file is located and that you start the service\nby calling './base-repo.jar'. If your microservice jar is located elsewhere, you should consider to provide absolute paths for all arguments above.\nIn case you want to choose a different folder for placing your additional libraries, you have to rename it in JAVA_OPTS accordingly.\n\nWhat you now have to do before you start the microservice is to place additional jar files (and required dependencies!) in the 'lib' folder. At the next startup, the new functionality should be available.\n\n## More Information\n\n* [Getting Started & Documentation](https://kit-data-manager.github.io/webpage/base-repo/index.html)\n* [API documentation](https://kit-data-manager.github.io/webpage/base-repo/documentation/api-docs.html)\n* [Docker container](https://github.com/kit-data-manager/base-repo/pkgs/container/base-repo%2Fbase-repo)\n* [Information about the DataCite metadata schema](https://schema.datacite.org/)\n\n## License\n\nThe KIT Data Manager is licensed under the Apache License, Version 2.0.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/basic",
            "repo_link": "https://github.com/marrlab/BaSiC",
            "readme": "# BaSiC\n\nMatlab code accompanying \n\n**A BaSiC Tool for Background and Shading Correction of Optical Microscopy Images**\n\nby Tingying Peng, Kurt Thorn, Timm Schroeder, Lichao Wang, Fabian J Theis, Carsten Marr\\*, Nassir Navab\\*, Nature Communication 8:14836 (2017). [doi: 10.1038/ncomms14836](http://www.nature.com/articles/ncomms14836).\n\nBaSiC is licensed under \n\n[Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Public License](https://creativecommons.org/licenses/by-nc-nd/4.0/legalcode)\n\nIt is free for academic use and please contact us for any commercial use.\n\n## Usage\n![BaSiC corrects both spatial uneven illumination of microscopy images and temporal background bleaching for time-lapse movies.](images/usage.png)\n\n\n## Demo\n\nDownload demo data examples from [Dropbox](https://www.dropbox.com/s/plznvzdjglrse3h/Demoexamples.zip?dl=0) and run matlab files under example folder.\n\n## ImageJ/Fiji Plugin\nBaSiC is also available as a ImageJ/Fiji Plugin.\n\n\n### Installation instruction\n\nNote: If you do not have Fiji installed on your computer, you can download it from [Fiji website](http://fiji.sc/).\n\n\n### Install via Fiji Updater\n\n1. Start Fiji and run the updater (\"Help->Update Fiji\")\n2. Select the \"Manage Update Sites\" button at the bottom-left of the updater window\n3. Scroll the list of available update sites to find \"BaSiC\" (Note: If you cannot find \"BaSiC\" in the list, select \"Add Update Sites\", Change the name field from default \"New\" to \"BaSiC\", set the URL field to http://sites.imagej.net/BaSiC/)\n4. Check the box at the left of \"BaSiC\"\n5. Select \"Close\" \n6. Select \"Apply Changes\" \n7. Restart Fiji. BaSiC should appear in the Plugins menu.\n\nFrom now on, running the Fiji updater will also check for BaSiC updates, and install them if they are available.\n\n\n### Install manually\n\nPlease download [BaSiC Plugin](https://github.com/QSCD/BaSiC/blob/master/BaSiCPlugin.zip) from this repository. \n\n1. Copy “BaSiC_.jar” to the “$FIJIROOT/plugins” folder of your Fiji/ImageJ installation.\n2. Copy all dependent jar files in the \"Dependent\" folder to your Fiji/ImageJ \"$FIJIROOT/jars\" directory.\n\n\n### Troubleshooting\n\nIf you get the error message \n\n\"java.lang.NoSuchMethodError: edu.emory.mathcs.utils.ConcurrencyUtils.submit\"\n\nmake sure that in your Fiji/ImageJ \"$FIJIROOT/jars\" directory, there is only one version of each jar from the \"Dependent\" folder. Particularly, delete jtransforms-2.4.jar and replace it with our jtransform.jar.\n\n## Issues\nIf you have any issues concerning BaSiC, please report them in the [Issues](https://github.com/QSCD/BaSiC/issues) section of this GitHub repository and we will try to find a solution.\n\n\n## BaSiCPy\nPython version of BaSiC implementation (https://github.com/peng-lab/BaSiCPy)\n\n\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/basicpy",
            "repo_link": "https://github.com/peng-lab/BaSiCPy",
            "readme": "# BaSiCPy\nA python package for background and shading correction of optical microscopy images\n\n[![PyPI](https://img.shields.io/pypi/v/basicpy.svg)](https://pypi.org/project/basicpy)\n[![Status](https://img.shields.io/pypi/status/basicpy.svg)](https://pypi.org/project/basicpy/)\n[![Python Version](https://img.shields.io/pypi/pyversions/basicpy.svg)](https://python.org)\n[![License](https://img.shields.io/pypi/l/basicpy)](https://github.com/peng-lab/BaSiCPy/blob/main/LICENSE)\n[![Tests](https://github.com/peng-lab/basicpy/workflows/CI/badge.svg)](https://github.com/peng-lab/basicpy/actions?workflow=CI)\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)\n[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Read the Docs](https://img.shields.io/readthedocs/basicpy/latest.svg?label=Read%20the%20Docs)](https://basicpy.readthedocs.io/)\n<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->\n[![All Contributors](https://img.shields.io/badge/all_contributors-5-orange.svg?style=flat-square)](#contributors-)\n<!-- ALL-CONTRIBUTORS-BADGE:END -->\n\nBaSiCPy is a python package for background and shading correction of optical microscopy images.\nIt is developed based on the Matlab version of [BaSiC](https://github.com/marrlab/BaSiC) tool with major improvements in the algorithm.\n\nReference:\n- BaSiCPy: A robust and scalable shadow correction tool for optical microscopy images (in prep.)\n- A BaSiC Tool for Background and Shading Correction of Optical Microscopy Images\n  by Tingying Peng, Kurt Thorn, Timm Schroeder, Lichao Wang, Fabian J Theis, Carsten Marr\\*, Nassir Navab\\*, Nature Communication 8:14836 (2017). [doi: 10.1038/ncomms14836](http://www.nature.com/articles/ncomms14836).\n\n\n## Simple examples\n\n|Notebook|Description|Colab Link|\n| :------------------------: |:---------------:| :---------------------------------------------------: |\n| [timelapse_brightfield](https://github.com/peng-lab/BaSiCPy/tree/dev/docs/notebooks/timelapse_brightfield.ipynb)| 100 continuous brightfield frames of a time-lapse movie of differentiating mouse hematopoietic stem cells. | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/peng-lab/BaSiCPy/blob/dev/docs/notebooks/timelapse_brightfield.ipynb) |\n| [timelapse_nanog](https://github.com/peng-lab/BaSiCPy/tree/dev/docs/notebooks/timelapse_nanog.ipynb)| 189 continuous fluorescence frames of a time-lapse movie of differentiating mouse embryonic stem cells, which move much more slower compared to the fast moving hematopoietic stem cells, resulting in a much larger correlation between frames. Note that in this challenging case, the automatic parameters are no longer optimal, so we use the manual parameter setting (larger smooth regularization on both flat-field and dark-field) to improve BaSiC’s performance. | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/peng-lab/BaSiCPy/blob/dev/docs/notebooks/timelapse_nanog.ipynb) |\n| [WSI_brain](https://github.com/peng-lab/BaSiCPy/tree/dev/docs/notebooks/WSI_brain.ipynb)| you can stitch image tiles together to view the effect of shading correction | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/peng-lab/BaSiCPy/blob/dev/docs/notebooks/WSI_brain.ipynb) |\n\nYou can also find examples of running the package at [notebooks folder](https://github.com/peng-lab/BaSiCPy/tree/dev/docs/notebooks). Data used in the examples and a description can be downloaded from [Zenodo](https://doi.org/10.5281/zenodo.6334809).\n\n---\n## Usage\n\nSee [Read the Docs](https://basicpy.readthedocs.io/en/latest/) for the detailed usage.\n\n## Installation\n\n### For Mac (Intel chip), Linux or WSL2 users\n\n Install from PyPI\n\n```console\npip install basicpy\n```\n\nor install the latest development version\n\n```console\ngit clone https://github.com/peng-lab/BaSiCPy.git\ncd BaSiCPy\npip install .\n```\n\n### For Mac users with M1 / M2 chip\n\nBaSiCPy requires [`jax`](https://github.com/google/jax/),\nwhich has potential build issue with M1 chips.\nOne easiest solution is using [Miniforge](https://github.com/conda-forge/miniforge)\nas explained [here](https://github.com/google/jax/issues/5501).\nIn the Miniforge environment, please try the following:\n```bash\nconda install -c conda-forge jax jaxlib\npip install basicpy\n```\n\n### For Windows users\n\nBaSiCPy requires [`jax`](https://github.com/google/jax/) which does not support Windows officially.\nHowever, thanks to [cloudhan/jax-windows-builder](https://github.com/cloudhan/jax-windows-builder), we can install BaSiCPy as follows:\n\n```bash\npip install \"jax[cpu]==0.4.11\" -f https://whls.blob.core.windows.net/unstable/index.html --use-deprecated legacy-resolver\npip install ml-dtypes==0.2.0\npip install basicpy\n```\n\nOne may need to add\n```python\nimport jax\njax.config.update('jax_platform_name', 'cpu')\n```\nat the top of the script to ensure that JAX uses CPU.\n\nFor details and latest updates, see [this issue](https://github.com/google/jax/issues/438).\n\n### Install with dev dependencies\n\n```console\ngit clone https://github.com/peng-lab/BaSiCPy.git\ncd BaSiCPy\npython -m venv venv\nsource venv/bin/activate\npip install -e '.[dev]'\n```\n\n## Development\n\n### bump2version\n\nThis repository uses [bump2version](https://github.com/c4urself/bump2version) to manage dependencies. New releases are pushed to PyPi in the CI pipeline when a new version is committed with a version tag and pushed to the repo.\n\nThe development flow should use the following process:\n1. New features and bug fixes should be pushed to `dev`\n2. When tests have passed a new development version is ready to be release, use `bump2version major|minor|patch`. This will commit and create a new version tag with the `-dev` suffix.\n3. Additional fixes/features can be added to the current development release by using `bump2version build`.\n4. Once the new bugs/features have been tested and a main release is ready, use `bump2version release` to remove the `-dev` suffix.\n\nAfter creating a new tagged version, push to Github and the version will be built and pushed to PyPi.\n\n### All-contributors\n\nThis repository uses [All Contributors](https://allcontributors.org/) to manage the contributor list. Please execute the following to add/update contributors.\n\n```bash\nyarn\nyarn all-contributors add username contribution\nyarn all-contributors generate # to reflect the changes to README.md\n```\n\nFor the possible contribution types, see the [All Contributors documentation](https://allcontributors.org/docs/en/emoji-key).\n\n## Contributors\n\n### Current version\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/Nicholas-Schaub\"><img src=\"https://avatars.githubusercontent.com/u/15925882?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Nicholas-Schaub</b></sub></a><br /><a href=\"#projectManagement-Nicholas-Schaub\" title=\"Project Management\">📆</a> <a href=\"https://github.com/peng-lab/BaSiCPy/pulls?q=is%3Apr+reviewed-by%3ANicholas-Schaub\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"#infra-Nicholas-Schaub\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">🚇</a> <a href=\"https://github.com/peng-lab/BaSiCPy/commits?author=Nicholas-Schaub\" title=\"Tests\">⚠️</a> <a href=\"https://github.com/peng-lab/BaSiCPy/commits?author=Nicholas-Schaub\" title=\"Code\">💻</a> <a href=\"#ideas-Nicholas-Schaub\" title=\"Ideas, Planning, & Feedback\">🤔</a></td>\n    <td align=\"center\"><a href=\"https://github.com/tdmorello\"><img src=\"https://avatars.githubusercontent.com/u/34800427?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tim Morello</b></sub></a><br /><a href=\"https://github.com/peng-lab/BaSiCPy/commits?author=tdmorello\" title=\"Code\">💻</a> <a href=\"https://github.com/peng-lab/BaSiCPy/commits?author=tdmorello\" title=\"Documentation\">📖</a> <a href=\"https://github.com/peng-lab/BaSiCPy/pulls?q=is%3Apr+reviewed-by%3Atdmorello\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"https://github.com/peng-lab/BaSiCPy/commits?author=tdmorello\" title=\"Tests\">⚠️</a> <a href=\"#ideas-tdmorello\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#infra-tdmorello\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">🚇</a></td>\n    <td align=\"center\"><a href=\"https://github.com/tying84\"><img src=\"https://avatars.githubusercontent.com/u/11461947?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Tingying Peng</b></sub></a><br /><a href=\"#data-tying84\" title=\"Data\">🔣</a> <a href=\"#financial-tying84\" title=\"Financial\">💵</a> <a href=\"#projectManagement-tying84\" title=\"Project Management\">📆</a> <a href=\"#talk-tying84\" title=\"Talks\">📢</a> <a href=\"https://github.com/peng-lab/BaSiCPy/commits?author=tying84\" title=\"Code\">💻</a></td>\n    <td align=\"center\"><a href=\"https://github.com/yfukai\"><img src=\"https://avatars.githubusercontent.com/u/5919272?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>Yohsuke T. Fukai</b></sub></a><br /><a href=\"#research-yfukai\" title=\"Research\">🔬</a> <a href=\"https://github.com/peng-lab/BaSiCPy/commits?author=yfukai\" title=\"Code\">💻</a> <a href=\"#ideas-yfukai\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"https://github.com/peng-lab/BaSiCPy/pulls?q=is%3Apr+reviewed-by%3Ayfukai\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"https://github.com/peng-lab/BaSiCPy/commits?author=yfukai\" title=\"Tests\">⚠️</a> <a href=\"#question-yfukai\" title=\"Answering Questions\">💬</a> <a href=\"#infra-yfukai\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">🚇</a></td>\n    <td align=\"center\"><a href=\"https://github.com/YuLiu-web\"><img src=\"https://avatars.githubusercontent.com/u/70626217?v=4?s=100\" width=\"100px;\" alt=\"\"/><br /><sub><b>YuLiu-web</b></sub></a><br /><a href=\"https://github.com/peng-lab/BaSiCPy/commits?author=YuLiu-web\" title=\"Documentation\">📖</a> <a href=\"#userTesting-YuLiu-web\" title=\"User Testing\">📓</a></td>\n  </tr>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\nFor details on the contribution roles, see the [documentation](https://basicpy.readthedocs.io/en/latest/contributors.html).\n\n\n### Old version (`f3fcf19`), used as the reference implementation to check the approximate algorithm\n- Lorenz Lamm (@LorenzLamm)\n- Mohammad Mirkazemi (@Mirkazemi)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/beluga",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/bending-stiffness",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/Bending-Stiffness",
            "readme": "![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=plastic&logo=openjdk&logoColor=white) ![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/bendingStiffness?style=plastic)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12808969.svg)](https://doi.org/10.5281/zenodo.12808969) [![SWH](https://archive.softwareheritage.org/badge/swh:1:dir:65f4716d51672926f9ae328ea314d969e37534c6/)](https://archive.softwareheritage.org/swh:1:dir:65f4716d51672926f9ae328ea314d969e37534c6;origin=https://github.com/Ramy-Badr-Ahmed/bendingStiffness;visit=swh:1:snp:cf3a5710e567c74b08a7144be79796fb78e9743c;anchor=swh:1:rev:ae6455bbac2db3f8838eb0d69b5ba09e5f50d06e) \n\n### Summary\n\nA java code analysing the Bending Stiffness of Actin Filament Experiment.\n\n- Reads coordinates from `snake.txt` of a measured filament (an example is in the `images` directory)\n- Calculates the mean squared displacement (MSD) and contour length from data\n- Error calculation in persistence length and contour length are saved in `mathematica` directory.\n- (optional) Modify `config.properties` as needed.\n\n### Running the Demo\n\n1. Place your `snake.txt` and `elongation.txt` files in the `data` directory (an example exists).\n2. Compile and run the `Snake` class.\n\n```sh\njavac -d out src/Snake.java\njava -cp out Snake\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/beos",
            "repo_link": "https://gitlab.com/dlr-sy/beos",
            "readme": "[![PyPi](https://img.shields.io/pypi/v/beos?label=PyPi)](https://pypi.org/project/beos/)\n[![doi](https://img.shields.io/badge/DOI-10.5281%2Fzenodo.13175694-red.svg)](https://zenodo.org/records/13175694)\n[![pipeline status](https://gitlab.com/dlr-sy/boxbeam/badges/master/pipeline.svg)]()\n\n# BEOS\nBEOS is a legacy Fortran-based buckling tool. It is compiled for Python using [f2py](https://numpy.org/doc/stable/f2py).\n> Installation from source requires an active Fortran compiler (ifort, gfortran). \n## Downloading\nUse GIT to get the latest code base. From the command line, use\n```\ngit clone https://gitlab.dlr.de/fa_sw/beos beos\n```\nIf you check out the repository for the first time, you have to initialize all submodule dependencies first. Execute the following from within the repository. \n```\ngit submodule update --init --recursive\n```\nTo update all refererenced submodules to the latest production level, use\n```\ngit submodule foreach --recursive 'git pull origin $(git config -f $toplevel/.gitmodules submodule.$name.branch || echo master)'\n```\n## Installation\nBEOS can be installed from source using [poetry](https://python-poetry.org). If you don't have [poetry](https://python-poetry.org) installed, run\n```\npip install poetry --pre --upgrade\n```\nto install the latest version of [poetry](https://python-poetry.org) within your python environment. Use\n```\npoetry update\n```\nto update all dependencies in the lock file or directly execute\n```\npoetry install\n```\nto install all dependencies from the lock file. Last, you should be able to import BEOS as a python package.\n```python\nimport beos\n```\n## Example\nPlease refer to the linked [repository](https://gitlab.com/dlr-sy/beos) for specific application examples.\n## Contact\n* [Marc Garbade](mailto:marc.garbade@dlr.de)\n## Support\n* [List of Contributors](CONTRIBUTING.md)\n",
            "project_id": "60534780"
        },
        {
            "software_organization": "https://helmholtz.software/software/bifurcations-discrete-maps",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/Bifurcations-Discrete-Maps",
            "readme": "![Python](https://img.shields.io/badge/Python-3670A0?style=plastic&logo=python&logoColor=ffdd54) ![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/Bifurcations?style=plastic)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.13276873.svg)](https://doi.org/10.5281/zenodo.13276873)\n\n# Bifurcation Diagrams for Discrete-Time Maps\n\nThis repository provides Python implementations for generating interactive bifurcation diagrams and analysing chaotic behavior in discrete-time dynamical systems. \n\nThe following maps are currently included:\n\n- Logistic Map\n- Tent Map\n- Sine Map\n\n### Overview\n\nEach map is implemented to analyse its bifurcation diagram and Lyapunov exponent, which are key to understanding the dynamics and chaos within these systems.\n\n### Installation\n\n1) Create and source virtual environment:\n```shell\npython -m venv env\nsource env/bin/activate  # On Windows use `env\\Scripts\\activate`\n```\n2) Install the dependencies:\n```shell\npip install -r requirements.txt\n```\n\n### Example Usage\n\nTo analyse a specific map, run the corresponding script in the Maps directory. You can tweak the map parameters as needed.\n\nInteractive plots will be generated and saved as offline HTML files within each map's directory.\n\n>[!Note]\n> Some plots have been uploaded to the `Maps` directories for reference.\n\n##### Scripts\n```shell\npython Maps/LogisticMap/main.py\n\npython Maps/TentMap/main.py\n\npython Maps/SineMap/main.py\n```\n##### Example (Logistic Map):\n```python\nfrom logistic import LogisticMap\nfrom utils.plotting import saveInteractivePlot\nimport datetime\n\n# Parameters for logistic map\nparams = {\n    'paramMin': 3.57,  # bifurcation parameter\n    'paramMax': 4.0,   \n    'stepSize': 1e-3,\n    'numTransient': 300,\n    'numPlotPoints': 300,\n    'numIterationsLyapunov': 200\n}\n\nlogisticMap = LogisticMap(**params)\n\n# Generate and save bifurcation diagram\nrhoValues, xValues, hoverText = logisticMap.generateBifurcationData()\n\ntimestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n\nplotParams = {\n    'title': 'Logistic Map Bifurcation Diagram',\n    'xAxisTitle': 'Bifurcation Parameter (rho)',\n    'yAxisTitle': 'System States x(n)',\n    'fileName': f'logisticMap_bifurcation_{timestamp}.html',\n    'markerSize': 0.05,\n    'opacity': 0.6,\n}\n\nsaveInteractivePlot(rhoValues, xValues, hoverText, **plotParams)\n\n# Generate and save Lyapunov exponent plot\nrhoValuesLyapunov, lyapunovExponents, lyapunovHoverText = logisticMap.generateLyapunovData()\n\nplotParams = {\n    'title': 'Logistic Map Lyapunov Exponent',\n    'xAxisTitle': 'Bifurcation Parameter (rho)',\n    'yAxisTitle': 'Lyapunov Exponent',\n    'fileName': f'logisticMap_lyapunov_exponent_{timestamp}.html',\n    'mode': 'lines'\n}\n\nsaveInteractivePlot(rhoValuesLyapunov, lyapunovExponents, lyapunovHoverText, **plotParams)\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/bioautoml",
            "repo_link": "https://github.com/Bonidia/BioAutoML",
            "readme": "![Python](https://img.shields.io/badge/python-v3.7-blue)\n![Dependencies](https://img.shields.io/badge/dependencies-up%20to%20date-brightgreen.svg)\n![Contributions welcome](https://img.shields.io/badge/contributions-welcome-orange.svg)\n![Status](https://img.shields.io/badge/status-up-brightgreen)\n\n<h1 align=\"center\">\n  <img src=\"https://github.com/Bonidia/BioAutoML/blob/main/img/BioAutoML.png\" alt=\"BioAutoML\" width=\"400\">\n</h1>\n\n<h4 align=\"center\">BioAutoML: Automated Feature Engineering and Metalearning for Classification of Biological Sequences</h4>\n\n<h4 align=\"center\">Democratizing Machine Learning in Life Sciences</h4>\n\n<p align=\"center\">\n  <a href=\"https://github.com/Bonidia/BioAutoML/\">Home</a> •\n  <a href=\"https://bonidia.github.io/BioAutoML/\">Documentation</a> •\n  <a href=\"#installing-dependencies-and-package\">Installing</a> •\n  <a href=\"#how-to-use\">How To Use</a> •\n  <a href=\"#citation\">Citation</a> \n</p>\n\n<h1 align=\"center\"></h1>\n\n\n## Update news!!!\n\n**New Website: [[https://bonidia.github.io/BioAutoML-WP/](https://bonidia.github.io/BioAutoML-WP/)]** \n\n**New Version - Protein:** BioAutoML + iFeature[[Ref](https://github.com/Superzchen/iFeature)]- Access on [[https://bonidia.github.io/BioAutoML/](https://bonidia.github.io/BioAutoML/)]\n\n**New Version - Protein:** Access on [[https://bonidia.github.io/BioAutoML/](https://bonidia.github.io/BioAutoML/)]\n\n**Published Paper:** Access on [[https://doi.org/10.1093/bib/bbac218](https://doi.org/10.1093/bib/bbac218)]\n\n\n## Awards\n\n⭐ Latin America Research Awards (LARA), Google, 2021. Project: BioAutoML: Automated Feature Engineering for Classification of Biological Sequences (24 awarded projects, from a base of 700 submissions). Elected by LARA-Google among the 24 most promising ideas in Latin America - 2021 - [[Link](https://blog.google/intl/pt-br/novidades/iniciativas/conheca-os-vencedores-do-premio-lara-2021-o-programa-de-bolsas-de-pesquisa-do-google/)] [[Link](http://www.saocarlos.usp.br/programa-de-bolsas-do-google-premia-trabalhos-orientados-pelo-cemeai/)].\n\n⭐ Finalist Project (Top 15 of 82), Falling Walls Lab Brazil 2022, DWIH São Paulo, Falling Walls Foundation, DAAD The German Center for Science and Innovation [[Link](https://www.youtube.com/watch?v=H5C_UIgVeQM)].\n\n⭐ Helmholtz Visiting Researcher Grant/Award - Helmholtz Information & Data Science Academy (HIDA), 2023. Project Title: BioAutoML-Fast: End-to-End Multi-Threaded Machine Learning Package for Life Sciences [[Link](https://bonidia.github.io/website/Certificate%20HVRG_Bonidia-1.pdf)].\n\n⭐ FEMS Research & Training Grant/Award - Federation of European Microbiological Societies (FEMS), 2023 (€: 5.000,00) [[Link](https://ibbsonline.org/wp-content/uploads/2023/10/IBBS-NL_Sep-2023-Issue.pdf)].\n\n⭐ BioAutoML - Top 10 Finalist - Santander X Brazil Award - Selected among the top 10 university projects (from over 200 entries) in Brazil in the national innovation competition promoted by Banco Santander.\n\n⭐ BioAutoML received an honorable mention from the Young Bioinformatics Award 2024, being chosen among the best theses in Bioinformatics and Computational Biology in Brazil, 2024.\n\n⭐ BioAutoML received third place in the ARTUR ZIVIANI THESIS AWARD (SBCAS), being chosen among the best theses in computing applied to health in Brazil, 2024.\n\n## Abstract\n\nRecent technological advances allowed an exponential expansion of biological sequence data and the extraction of meaningful information through Machine Learning (ML) algorithms. This knowledge improved the understanding of the mechanisms related to several fatal diseases, e.g., Cancer and COVID-19, helping to develop innovative solutions, such as CRISPR-based gene editing, coronavirus vaccine, and precision medicine. These advances benefit our society and economy, directly impacting people's lives in various areas, such as health care, drug discovery, forensic analysis, and food processing. Nevertheless, ML-based approaches to biological data require representative, quantitative, and informative features. Many ML algorithms can handle only numerical data, so sequences need to be translated into a numerical feature vector. This process, known as feature extraction, is a fundamental step for elaborating high-quality ML-based models in bioinformatics, by allowing the feature engineering stage, with the design and selection of suitable features. Feature engineering, ML algorithm selection, and hyperparameter tuning are often manual and time-consuming processes, requiring extensive domain knowledge. To deal with this problem, we present a new package, BioAutoML. BioAutoML automatically runs an end-to-end ML pipeline, extracting numerical and informative features from biological sequence databases, using the MathFeature package, and automating the feature selection, ML algorithm(s) recommendation and tuning of the selected algorithm(s) hyperparameters, using Automated ML (AutoML). BioAutoML has two components, divided into four modules, (1) automated feature engineering (feature extraction and selection modules) and (2) Metalearning (algorithm recommendation and hyper-parameter tuning modules). We experimentally evaluate BioAutoML in two different scenarios: (i) prediction of the three main classes of ncRNAs and (ii) prediction of the seven categories of ncRNAs in bacteria, including housekeeping and regulatory types. To assess BioAutoML predictive performance, it is experimentally compared with two other AutoML tools (RECIPE and TPOT). According to the experimental results, BioAutoML can accelerate new studies, reducing the cost of feature engineering processing and either keeping or improving predictive performance.\n\n* First study to propose an automated feature engineering and metalearning pipeline for ncRNA sequences in bacteria;\n    \n* BioAutoML can be applied in multi-class and binary problems;\n    \n* BioAutoML can be used in other DNA/RNA sequences scenarios;\n    \n* BioAutoML can accelerate new studies, reducing the feature engineering time-consuming stage and improving the design and performance of ML pipelines in bioinformatics;\n    \n* BioAutoML does not require specialist human assistance.\n\n<h1 align=\"center\">\n  <img src=\"https://github.com/Bonidia/BioAutoML/blob/main/img/bio-v2-1.png\" alt=\"BioAutoML\" width=\"1000\">\n</h1>\n\n<h1 align=\"center\">\n  <img src=\"https://github.com/Bonidia/BioAutoML/blob/main/img/bio-v4-1.png\" alt=\"BioAutoML\" width=\"900\">\n</h1>\n\n## Authors\n\n* Robson Parmezan Bonidia, Anderson Paulo Avila Santos, Breno Lívio Silva de Almeida, Peter F. Stadler, Ulisses Nunes da Rocha, Danilo Sipoli Sanches, and André Carlos Ponce de Leon Ferreira de Carvalho.\n\n* **Correspondence:** bonidia@usp.br, andre@icmc.usp.br, ulisses.rocha@ufz.de\n\n## Publication\n\nRobson P Bonidia, Anderson P Avila Santos, Breno L S de Almeida, Peter F Stadler, Ulisses N da Rocha, Danilo S Sanches, André C P L F de Carvalho, BioAutoML: automated feature engineering and metalearning to predict noncoding RNAs in bacteria, Briefings in Bioinformatics, 2022, bbac218, [[DOI](https://doi.org/10.1093/bib/bbac218)].\n\n\n## Installing dependencies and package\n\n## Conda - Terminal\n\nInstalling BioAutoML using miniconda, e.g.:\n\n```sh\n$ git clone https://github.com/Bonidia/BioAutoML.git BioAutoML\n\n$ cd BioAutoML\n\n$ git submodule init\n\n$ git submodule update\n```\n\n**1 - Install Miniconda:** \n\n```sh\n\nSee documentation: https://docs.conda.io/en/latest/miniconda.html\n\n$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n\n$ chmod +x Miniconda3-latest-Linux-x86_64.sh\n\n$ ./Miniconda3-latest-Linux-x86_64.sh\n\n$ export PATH=~/miniconda3/bin:$PATH\n\n```\n\n**2 - Create environment:**\n\n```sh\n\nconda env create -f BioAutoML-env.yml -n bioautoml\n\n```\n\n**3 - Activate environment:**\n\n```sh\n\nconda activate bioautoml\n\n```\n\n**4 - You can deactivate the environment, using:**\n\n```sh\n\nconda deactivate\n\n```\n## How to use\n\nSee our [documentation](https://bonidia.github.io/BioAutoML/).\n\n## Citation\n\nIf you use this code in a scientific publication, we would appreciate citations to the following paper:\n\nRobson P Bonidia, Anderson P Avila Santos, Breno L S de Almeida, Peter F Stadler, Ulisses N da Rocha, Danilo S Sanches, André C P L F de Carvalho, BioAutoML: automated feature engineering and metalearning to predict noncoding RNAs in bacteria, Briefings in Bioinformatics, 2022, bbac218, [[DOI](https://doi.org/10.1093/bib/bbac218)].\n\n```sh\n\n@article{10.1093/bib/bbac218,\n    author = {Bonidia, Robson P and Santos, Anderson P Avila and de Almeida, Breno L S and Stadler, Peter F and da Rocha, Ulisses N and Sanches, Danilo S and de Carvalho, André C P L F},\n    title = \"{BioAutoML: automated feature engineering and metalearning to predict noncoding RNAs in bacteria}\",\n    journal = {Briefings in Bioinformatics},\n    year = {2022},\n    month = {06},\n    issn = {1477-4054},\n    doi = {10.1093/bib/bbac218},\n    url = {https://doi.org/10.1093/bib/bbac218},\n    note = {bbac218},\n}\n\n\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/blenderproc",
            "repo_link": "https://github.com/DLR-RM/BlenderProc",
            "readme": "# BlenderProc2\n\n[![Documentation](https://img.shields.io/badge/documentation-passing-brightgreen.svg)](https://dlr-rm.github.io/BlenderProc/)\n[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DLR-RM/BlenderProc/blob/main/examples/basics/basic/basic_example.ipynb)\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n\n<p align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/6104887/137109535-275a2aa3-f5fd-4173-9d16-a9a9b86f66e7.gif\" alt=\"Front readme image\" width=100%>\n</p>\n\nA procedural Blender pipeline for photorealistic rendering.\n\n[Documentation](https://dlr-rm.github.io/BlenderProc) | [Tutorials](#tutorials) | [Examples](#examples) | [ArXiv paper](https://arxiv.org/abs/1911.01911) | [Workshop paper](https://sim2real.github.io/assets/papers/2020/denninger.pdf) | [JOSS article](https://joss.theoj.org/papers/10.21105/joss.04901)\n\n## Features\n\n* Loading: `*.obj`, `*.ply`, `*.blend`, `*.fbx`, BOP, ShapeNet, Haven, 3D-FRONT, etc.\n* Objects: Set or sample object poses, apply physics and collision checking.\n* Materials: Set or sample physically-based materials and textures\n* Lighting: Set or sample lights, automatic lighting of 3D-FRONT scenes.\n* Cameras: Set, sample or load camera poses from file.\n* Rendering: RGB, stereo, depth, normal and segmentation images/sequences.\n* Writing: .hdf5 containers, COCO & BOP annotations.\n\n\n## Installation\n\n### Via pip\n\nThe simplest way to install blenderproc is via pip:\n\n```bash\npip install blenderproc\n```\n\n### Via git\n\nAlternatively, if you need to make changes to blenderproc or you want to make use of the most recent version on the main-branch, clone the repository:\n\n```bash\ngit clone https://github.com/DLR-RM/BlenderProc\n```\n\nTo still make use of the blenderproc command and therefore use blenderproc anywhere on your system, make a local pip installation:\n\n```bash\ncd BlenderProc\npip install -e .\n```\n\n## Usage\n\nBlenderProc has to be run inside the blender python environment, as only there we can access the blender API. \nTherefore, instead of running your script with the usual python interpreter, the command line interface of BlenderProc has to be used.\n\n```bash\nblenderproc run <your_python_script>\n```\n\nIn general, one run of your script first loads or constructs a 3D scene, then sets some camera poses inside this scene and renders different types of images (RGB, distance, semantic segmentation, etc.) for each of those camera poses.\nUsually, you will run your script multiple times, each time producing a new scene and rendering e.g. 5-20 images from it.\nWith a little more experience, it is also possible to change scenes during a single script call, read [here](docs/tutorials/key_frames.md#render-multiple-times) how this is done.\n\n## Quickstart\n\nYou can test your BlenderProc pip installation by running\n\n```bash\nblenderproc quickstart\n```\n\nThis is an alias to `blenderproc run quickstart.py` where `quickstart.py` is:\n\n```python\nimport blenderproc as bproc\nimport numpy as np\n\nbproc.init()\n\n# Create a simple object:\nobj = bproc.object.create_primitive(\"MONKEY\")\n\n# Create a point light next to it\nlight = bproc.types.Light()\nlight.set_location([2, -2, 0])\nlight.set_energy(300)\n\n# Set the camera to be in front of the object\ncam_pose = bproc.math.build_transformation_mat([0, -5, 0], [np.pi / 2, 0, 0])\nbproc.camera.add_camera_pose(cam_pose)\n\n# Render the scene\ndata = bproc.renderer.render()\n\n# Write the rendering into an hdf5 file\nbproc.writer.write_hdf5(\"output/\", data)\n```\n\nBlenderProc creates the specified scene and renders the image into `output/0.hdf5`.\nTo visualize that image, simply call:\n\n```bash\nblenderproc vis hdf5 output/0.hdf5\n```\n\nThats it! You rendered your first image with BlenderProc!\n\n### Debugging in the Blender GUI\n\nTo understand what is actually going on, BlenderProc has the great feature of visualizing everything inside the blender UI.\nTo do so, simply call your script with the `debug` instead of `run` subcommand:\n```bash\nblenderproc debug quickstart.py\n```\n*Make sure that `quickstart.py` actually exists in your working directory.*\n\nNow the Blender UI opens up, the scripting tab is selected and the correct script is loaded.\nTo start the BlenderProc pipeline, one now just has to press `Run BlenderProc` (see red circle in image).\nAs in the normal mode, print statements are still printed to the terminal.\n\n<p align=\"center\">\n<img src=\"images/debug.jpg\" alt=\"Front readme image\" width=500>\n</p>\n\nThe pipeline can be run multiple times, as in the beginning of each run the scene is cleared.\n\n### Breakpoint-Debugging in IDEs\n\nAs blenderproc runs in blenders separate python environment, debugging your blenderproc script cannot be done in the same way as with any other python script.\nTherefore, remote debugging is necessary, which is explained for vscode and PyCharm in the following:\n\n#### Debugging with vscode\n\nFirst, install the `debugpy` package in blenders python environment.\n\n```\nblenderproc pip install debugpy\n```\n\nNow add the following configuration to your vscode [launch.json](https://code.visualstudio.com/docs/python/debugging#_initialize-configurations).\n\n```json\n{                        \n    \"name\": \"Attach\",\n    \"type\": \"python\",\n    \"request\": \"attach\",\n    \"connect\": {\n        \"host\": \"localhost\",\n        \"port\": 5678\n    }\n}\n```\n\nFinally, add the following lines to the top (after the imports) of your blenderproc script which you want to debug.\n\n```python\nimport debugpy\ndebugpy.listen(5678)\ndebugpy.wait_for_client()\n```\n\nNow run your blenderproc script as usual via the CLI and then start the added \"Attach\" configuration in vscode.\nYou are now able to add breakpoints and go through the execution step by step.\n\n#### Debugging with PyCharm Professional\n\nIn Pycharm, go to `Edit configurations...` and create a [new configuration](https://www.jetbrains.com/help/pycharm/remote-debugging-with-product.html#remote-debug-config) based on `Python Debug Server`.\nThe configuration will show you, specifically for your version, which pip package to install and which code to add into the script.\nThe following assumes Pycharm 2021.3:\n\nFirst, install the `pydevd-pycharm` package in blenders python environment.\n\n```\nblenderproc pip install pydevd-pycharm~=212.5457.59\n```\n\nNow, add the following code to the top (after the imports) of your blenderproc script which you want to debug.\n\n```python\nimport pydevd_pycharm\npydevd_pycharm.settrace('localhost', port=12345, stdoutToServer=True, stderrToServer=True)\n```\n\nThen, first run your `Python Debug Server` configuration in PyCharm and then run your blenderproc script as usual via the CLI.\nPyCharm should then go in debug mode, blocking the next code line.\nYou are now able to add breakpoints and go through the execution step by step.\n\n## What to do next?\n\nAs you now ran your first BlenderProc script, your ready to learn the basics:\n\n### Tutorials\n\nRead through the tutorials, to get to know with the basic principles of how BlenderProc is used:\n\n1. [Loading and manipulating objects](docs/tutorials/loader.md)\n2. [Configuring the camera](docs/tutorials/camera.md)\n3. [Rendering the scene](docs/tutorials/renderer.md)\n4. [Writing the results to file](docs/tutorials/writer.md)\n5. [How key frames work](docs/tutorials/key_frames.md)\n6. [Positioning objects via the physics simulator](docs/tutorials/physics.md)\n\n### Examples\n\nWe provide a lot of [examples](examples/README.md) which explain all features in detail and should help you understand how BlenderProc works. Exploring our examples is the best way to learn about what you can do with BlenderProc. We also provide support for some datasets.\n\n* [Basic scene](examples/basics/basic/README.md): Basic example, this is the ideal place to start for beginners\n* [Camera sampling](examples/basics/camera_sampling/README.md): Sampling of different camera positions inside of a shape with constraints for the rotation.\n* [Object manipulation](examples/basics/entity_manipulation/README.md): Changing various parameters of objects.\n* [Material manipulation](examples/basics/material_manipulation/README.md): Material selecting and manipulation.\n* [Physics positioning](examples/basics/physics_positioning/README.md): Enabling simple simulated physical interactions between objects in the scene.\n* [Semantic segmentation](examples/basics/semantic_segmentation/README.md): Generating semantic segmentation labels for a given scene.\n* [BOP Challenge](README_BlenderProc4BOP.md): Generate the pose-annotated data used at the BOP Challenge 2020\n* [COCO annotations](examples/advanced/coco_annotations/README.md): Write COCO annotations to a .json file for selected objects in the scene.\n\nand much more, see our [examples](examples/README.md) for more details.\n\n\n## Contributions\n\nFound a bug? help us by reporting it. Want a new feature in the next BlenderProc release? Create an issue. Made something useful or fixed a bug? Start a PR. Check the [contributions guidelines](CONTRIBUTING.md).\n\n## Change log\n\nSee our [change log](change_log.md). \n\n## Citation \n\nIf you use BlenderProc in a research project, please cite as follows:\n\n```\n@article{Denninger2023, \n    doi = {10.21105/joss.04901},\n    url = {https://doi.org/10.21105/joss.04901},\n    year = {2023},\n    publisher = {The Open Journal}, \n    volume = {8},\n    number = {82},\n    pages = {4901}, \n    author = {Maximilian Denninger and Dominik Winkelbauer and Martin Sundermeyer and Wout Boerdijk and Markus Knauer and Klaus H. Strobl and Matthias Humt and Rudolph Triebel},\n    title = {BlenderProc2: A Procedural Pipeline for Photorealistic Rendering}, \n    journal = {Journal of Open Source Software}\n} \n```\n\n---\n\n<div align=\"center\">\n  <a href=\"https://www.dlr.de/EN/Home/home_node.html\"><img src=\"images/logo.svg\" hspace=\"3%\" vspace=\"60px\"></a>\n</div>\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/boxbeam",
            "repo_link": "https://gitlab.com/dlr-sy/boxbeam",
            "readme": "[![PyPi](https://img.shields.io/pypi/v/boxbeam?label=PyPi)](https://pypi.org/project/boxbeam/)\n[![doi](https://img.shields.io/badge/DOI-10.5281%2Fzenodo.12795533-red.svg)](https://zenodo.org/records/12795533)\n[![pipeline status](https://gitlab.com/dlr-sy/boxbeam/badges/master/pipeline.svg)]()\n\n# BoxBeam\nBoxBeam is a legacy Fortran-based beam calculation tool. It is compiled for Python using [f2py](https://numpy.org/doc/stable/f2py).\n> Installation from source requires an active Fortran compiler (ifort, gfortran). \n## Downloading\nUse GIT to get the latest code base. From the command line, use\n```\ngit clone https://gitlab.dlr.de/fa_sw/boxbeam boxbeam\n```\nIf you check out the repository for the first time, you have to initialize all submodule dependencies first. Execute the following from within the repository. \n```\ngit submodule update --init --recursive\n```\nTo update all refererenced submodules to the latest production level, use\n```\ngit submodule foreach --recursive 'git pull origin $(git config -f $toplevel/.gitmodules submodule.$name.branch || echo master)'\n```\n## Installation\nBoxBeam can be installed from source using [poetry](https://python-poetry.org). If you don't have [poetry](https://python-poetry.org) installed, run\n```\npip install poetry --pre --upgrade\n```\nto install the latest version of [poetry](https://python-poetry.org) within your python environment. Use\n```\npoetry update\n```\nto update all dependencies in the lock file or directly execute\n```\npoetry install\n```\nto install all dependencies from the lock file. Last, you should be able to import BoxBeam as a python package.\n```python\nimport boxbeam\n```\n## Example\nCopy and paste the following text into a new python script to verify the local installation\n```python\nimport os, sys\nimport boxbeam as bbeam\n \nfrom itertools import count, zip_longest\nfrom operator import itemgetter\nfrom collections import OrderedDict\nimport numpy as np\n\ndef toolInitiate(directory):\n    #---INITIATE BOXBEAM VARIABLES\n    bbeam.boxbeam.initialize()\n\n    extendedLogFile = False\n    newPath = directory#+'\\\\TestProfile.out'\n\n    #setting control parameters for BOXBEAM\n    bbeam.steuer.druck = extendedLogFile # extended log file\n    bbeam.steuer.nurqer = False\n    bbeam.steuer.klog = 11\n    bbeam.steuer.kraeft = False # calculate nodal forces (utilization for FE applications)\n\n    #---CHANGE THE NAME OF THE OUTPUT FILE TO THE ACTUAL CROSS SECTION NAME\n    if extendedLogFile:\n        for ffile, bbeamPathVar in zip([\"boxbeam_results.out\", \n                                        \"boxbeam_test.out\"], \n                                        [\"csinfopath\", \n                                         \"vbinfopath\"]):\n\n            fullPathFfile = os.path.abspath(os.path.join(newPath, ffile))\n\n            # 240 is the length of the character variable reserved\n            # within FORTRAN to store the directory name\n            if len(fullPathFfile) > 240:\n                raise Exception(\"Path length of file %s to long!\" % fullPathFfile)\n\n            pathList = [\"\"] * 240\n            pathList[: len(fullPathFfile)] = list(fullPathFfile)\n\n            if bbeamPathVar == \"csinfopath\":\n                self.bbeam.path.csinfopath = np.array(pathList,dtype=\"object\")\n            else:\n                self.bbeam.path.vbinfopath = np.array(pathList,dtype=\"object\")\n\ndef toolCalculate(capCount, webCount, cellCount, yi, zi, yk0, zk0, yklk, zklk, ig1, ig2, iak, ia, \n                    webExtensionalStiffness, webShearStiffness, webRefPlaneDist, webThickness,webDensity):\n    #---ASSIGN GURT DATA\n    bbeam.gurt.ig = capCount\n    \n    #---ASSIGN GURT COORDINATES\n    variableList = np.zeros(bbeam.restr.maxgu-bbeam.gurt.ig).tolist()\n    bbeam.gurt.yi = yi + variableList\n    bbeam.gurt.zi = zi + variableList\n    \n    #---ASSIGN GURT MATERIAL INFORMATION WITHIN BOXBEAM\n    bbeam.gurt.bi = np.zeros(bbeam.restr.maxgu)\n    bbeam.gurt.myi = np.zeros(bbeam.restr.maxgu)\n\n    #---ASSIGN BOXBEAM WAND DATA\n    bbeam.wand.kw = webCount\n    \n    #---ASSIGN WAND COORDINATES\n    variableList = np.zeros(bbeam.restr.maxwa-len(yk0)).tolist()\n    bbeam.wand.yk0 = yk0 + variableList\n    bbeam.wand.yklk = yklk + variableList\n    bbeam.wand.zk0 = zk0 + variableList\n    bbeam.wand.zklk = zklk + variableList\n    \n    #---ASSIGN WAND MATERIAL INFORMATION WITHIN BOXBEAM\n    variableList = np.zeros(bbeam.restr.maxwa-bbeam.wand.kw).tolist()\n    bbeam.wand.it = (5*np.ones(bbeam.wand.kw)).tolist()+variableList\n    bbeam.wand.bk = webExtensionalStiffness+variableList\n    bbeam.wand.gk = webShearStiffness+variableList\n    bbeam.wand.rhok = webDensity+variableList\n    bbeam.wand.e = webRefPlaneDist+variableList\n    \n    #---ASSIGN WAND TOPOLOGY WITHIN BOXBEAM\n    bbeam.wand.th = webThickness+variableList\n    bbeam.wand.ig1 = ig1+variableList\n    bbeam.wand.ig2 = ig2+variableList\n\n    #---ASSIGN BOXBEAM ZELLE DATA\n    bbeam.zelle.az = cellCount\n    variableList = np.zeros(bbeam.restr.maxze-bbeam.zelle.az).tolist()\n    bbeam.zelle.iak = iak+variableList\n    \n    iaArrayTransposed = np.zeros((bbeam.restr.maxze, bbeam.restr.maxgu))\n    for cellNumber in range(int(bbeam.restr.maxze)):\n        if cellNumber < cellCount:\n            iaArrayTransposed[cellNumber, :len(ia[cellNumber])] += ia[cellNumber]\n    bbeam.zelle.ia = iaArrayTransposed.T\n\n    #---ASSIGN BOXBEAM UNIFY LOADS\n    for attrName, load in zip_longest([\"qqx\",\"qqy\",\"qqz\",\"qmx\",\"qmy\",\"qmz\"], reactionForces):\n        setattr(bbeam.spanug, attrName, load)\n\n    #---EXECUTE BOXBEAM FOR CALCULATING THE CROSS SECTION PARAMETERS\n    bbeam.boxbeam.getequivalentxsection()\n\n    crossSectionParamNames = ['YS','ZS','YT','ZT','YMST','ZMST','YMSTAC','ZMSTAC','BX',\n                                'ALPHA','DYYSTE','DZZSTE','DYY','DZZ','DZY','DT','M','IYYS','IZZS','IZYS','ITT']\n\n    crossSectionParameters = {}\n    for param in crossSectionParamNames:\n        crossSectionParameters[param] = float(getattr(bbeam.quer, param.lower()))\n\n    effectiveProps = OrderedDict([\n                        ('EA',crossSectionParameters['BX']    ),\n                        ('EIxx',crossSectionParameters['DYY'] ),\n                        ('EIyy',crossSectionParameters['DZZ'] ),\n                        ('GJ',crossSectionParameters['DT']    ),\n                        ('YS',crossSectionParameters['YS']    ),\n                        ('ZS',crossSectionParameters['ZS']    ),\n                        ])\n\n\nif __name__ == '__main__':\n\n    #Specify folder where output files are to be stored\n    runDir = os.path.join(os.getcwd(),\"boxbeam\")\n    try:\n        os.makedirs(runDir)\n    except WindowsError: \n        pass\n\n    #Tool specific limitations\n    #maxCaps = 22 #variable specifying the maximum number of caps within a BoxBeam cross section - defined in bbeam.pyd\n    #maxWebs = 31 #variable specifying the maximum number of walls within a BoxBeam cross section - defined in bbeam.pyd\n    #maxCells = 10 #variable specifying the maximum number of cells within a BoxBeam cross section - defined in bbeam.pyd\n\n#------------------------------------------------------------------------------------------------------------------------\n# Initiation of boxbeam\n#------------------------------------------------------------------------------------------------------------------------\n\n    toolInitiate(runDir)\n\n#------------------------------------------------------------------------------------------------------------------------\n# Input for profile\n#------------------------------------------------------------------------------------------------------------------------\n\n    calcGeometry = False # If true the material data is set in a fashion, that the geometric properties (e.g. area moments of inertia) can be calculated.\n    \n    thickness1 = 1.25\n    thickness2 = .375\n    if calcGeometry:\n        extensionalStiffness1 = 1.*thickness1\n        extensionalStiffness2 = 1.*thickness2\n        shearStiffness1 = 1.*thickness1\n        shearStiffness2 = 1.*thickness2\n        density1 = 1.*thickness1\n        density2 = 1.*thickness2\n        bbeam.steuer.nurqer = True\n\n        #\"qqx\",\"qqy\",\"qqz\",\"qmx\",\"qmy\",\"qmz\"\n        reactionForces = [0., 0., 0., 0., 0., 0.]     \n        \n    else:\n        extensionalStiffness1 = 7.3335e4*thickness1\n        extensionalStiffness2 = 3.2232e4*thickness2\n        shearStiffness1 = 1.7327e4*thickness1\n        shearStiffness2 = 2.5012e4*thickness2\n        density1 = 0.00158*thickness1\n        density2 = 0.00158*thickness2\n\n        #\"qqx\",\"qqy\",\"qqz\",\"qmx\",\"qmy\",\"qmz\"\n        reactionForces = [0., 0., 500., 0., -62500., 0.]        \n\n    #---RETRIEVING POINT LOCATIONS AND TOPOLOGY\n    yi,zi,yk0,zk0 = [],[],[],[]\n    yklk, zklk, ig1, ig2 = [],[],[],[]\n    iak = []\n    ia = []\n    \n    webExtensionalStiffness = []\n    webShearStiffness, webRefPlaneDist = [], []\n    webThickness, webDensity = [],[]\n    \n    capExtensionalStiffness = []\n    capMass = []\n\n    #definition of simple profile\n    capCount = 8 \n    webCount = 9\n    cellCount = 2\n    \n    yi = [55., 55., -225., 13., 13., 75., -75., 75.]\n    zi = [12., -12., 0., 18., -18., 0., 16., 16.]\n    yk0 = [55., 75., 55., 13., -75., -225., -75., 13., 13., 13.]\n    zk0 = [12., 0., -12., -18., -16., 0., 16., 18., 18., 18.]\n    yklk = [75., 55., 13., -75., -225., -75., 13., 55., 13., 13.] \n    zklk = [0., -12., -18., -16., 0., 16., 18., 12., -18., -18.]\n\n    ig1 = [1, 6, 2, 5, 8, 3, 7, 4, 4]\n    ig2 = [6, 2, 5, 8, 3, 7, 4, 1, 5]\n    iak = [5, 5]\n    ia = [[1, 6, 2, 5, 4], [5, 8, 3, 7, 4]]\n\n    webExtensionalStiffness = [extensionalStiffness1]*(webCount-1)+[extensionalStiffness2]\n    webShearStiffness = [shearStiffness1]*(webCount-1)+[shearStiffness2]\n    webRefPlaneDist = [thickness1/2.]*(webCount-1)+[thickness2/2.]\n    webThickness = [thickness1]*(webCount-1)+[thickness2]\n    webDensity = [density1]*(webCount-1)+[density2]\n\n#------------------------------------------------------------------------------------------------------------------------\n# Assigning variables of boxbeam\n# Executing boxbeam\n# Retrieving results from boxbeam\n#------------------------------------------------------------------------------------------------------------------------\n\n    toolCalculate(\n        capCount, webCount, cellCount, yi, zi, yk0, zk0, yklk, zklk, ig1, ig2, iak, ia, \n        webExtensionalStiffness, webShearStiffness, webRefPlaneDist, webThickness,webDensity\n    )\n```\n## Contact\n* [Marc Garbade](mailto:marc.garbade@dlr.de)\n## Support\n* [List of Contributors](CONTRIBUTING.md)\n",
            "project_id": "59552628"
        },
        {
            "software_organization": "https://helmholtz.software/software/brainprint",
            "repo_link": "https://github.com/Deep-MI/brainprint",
            "readme": "[![PyPI version](https://badge.fury.io/py/brainprint.svg)](https://pypi.org/project/brainprint/)\n# BrainPrint\n\nThis is the `brainprint` python package, a derivative of the original\n[BrainPrint-legacy](https://github.com/Deep-MI/BrainPrint-legacy) scripts,\nwith the primary goal to provide a Python-only version, to integrate the\n[LaPy](https://github.com/Deep-MI/LaPy) package, and to remove dependencies\non third-party software (shapeDNA-* binaries, gmsh, meshfix). As a result,\nsome functionality of the original BrainPrint-legacy scripts is no longer\nmaintained (currently no support of tetrahedral meshes and no support of\ncortical parcellations or label files).\n\n## Installation\n\nUse the following code to install the latest release into your local\nPython package directory:\n\n`python3 -m pip install brainprint`\n\nThis will also install the necessary dependencies, e.g. the [LaPy](https://github.com/Deep-MI/LaPy)\npackage. You may need to add your local Python package directory to your $PATH\nin order to run the scripts.\n\n## Usage\n### Command Line Interface (CLI)\n\nOnce installed, the package provides a `brainprint` executable which can be run from the command line.\n\nThe `brainprint` CLI enables per-subject computation of the individual brainprint descriptors. Its usage and options are summarized below;\ndetailed info is available by calling the script without any arguments from the command line.\n\n```sh\nbrainprint --sdir <directory> --sid <SubjectID>  [--num <num>] [--evec] [--skipcortex] [--norm <surface|volume|geometry|none> ] [--reweight] [--asymmetry] [--outdir <directory>] [--help] [--more-help]\n\nOptions:\n  --help           Show this help message and exit\n  --more-help      Show extensive help message and exit\n\nRequired options:\n  --sid <SubjectID>\n                   Subject ID (FreeSurfer-processed directory inside the\n                   subjects directory)\n  --sdir <directory>\n                   FreeSurfer subjects directory\n\nProcessing directives:\n  --num <num>      Number of eigenvalues/vectors to compute (default: 50)\n  --evec           Switch on eigenvector computation (default: off)\n  --skipcortex     Skip cortical surfaces (default: off)\n  --norm <surface|volume|geometry|none>\n                   Switch on eigenvalue normalization; will be either surface,\n                   volume, or determined by the geometry of the object. Use\n                   \"none\" or leave out entirely to skip normalization.\n  --reweight       Switch on eigenvalue reweighting (default: off)\n  --asymmetry      Perform left-right asymmetry calculation (default: off)\n  --cholmod        Switch on use of (faster) Cholesky decomposition instead\n                   of (slower) LU decomposition (default: off). May require \n                   manual install of scikit-sparse package. \n\nOutput parameters:\n  --outdir=OUTDIR  Output directory (default: <sdir>/<sid>/brainprint)\n  --keep-temp      Whether to keep the temporary files directory or not\n                   by default False\n```\n\n### Python Package\n\n`brainprint` can also be run within a pure Python environment, i.e. installed and imported as a Python package. E.g.:\n\n```python\n>>> from brainprint import Brainprint\n\n>>> subjects_dir = \"/path/to/freesurfer/subjects_dir/\"\n>>> subject_id = \"42\"\n\n>>> bp = Brainprint(subjects_dir=subjects_dir, asymmetry=True, keep_eigenvectors=True)\n>>> results = bp.run(subject_id=subject_id)\n>>> results\n{\"eigenvalues\": PosixPath(\"/path/to/freesurfer/subjects_dir/subject_id/brainprint/subject_id.brainprint.csv\"), \"eigenvectors\": PosixPath(\"/path/to/freesurfer/subjects_dir/subject_id/brainprint/eigenvectors\"), \"distances\": PosixPath(\"/path/to/freesurfer/subjects_dir/subject_id/brainprint/subject_id.brainprint.asymmetry.csv\")}\n```\n\n## Output\n\nThe script will create an output directory that contains a CSV table with\nvalues (in that order) for the area, volume, and first n eigenvalues per each\nFreeSurfer structure. An additional output file will be created if the\nasymmetry calculation is performed and/or for the eigenvectors (CLI `--evecs` flag or `keep_eigenvectors` on class initialization).\n\n## Changes\n\nSince version 0.5.0, some changes break compatibility with earlier versions (0.4.0 and lower) as well as the [original BrainPrint](https://github.com/Deep-MI/BrainPrint-legacy). These changes include:\n\n- for the creation of surfaces from voxel-based segmentations, we have replaced FreeSurfer's marching cube algorithm by scikit-image's marching cube algorithm. Similarly, other FreeSurfer binaries have been replaced by custom Python functions. As a result, a parallel FreeSurfer installation is no longer a requirement for running the brainprint software.\n- we have changed / removed the following composite structures from the brainprint shape descriptor: the left and right *striatum* (composite of caudate, putamen, and nucleus accumbens) and the left and right *ventricles* (composite of lateral, inferior lateral, 3rd ventricle, choroid plexus, and CSF) have been removed; the left and right *cerebellum-white-matter* and *cerebellum-cortex* have been merged into left and right *cerebellum*.\n\nAs a result of these changes, numerical values for the brainprint shape descriptor that are obtained from version 0.5.0 and higher are expected to differ from earlier versions when applied to the same data, but should remain highly correlated with earlier results.\n\nThere are some changes in version 0.4.0 (and lower) in functionality in comparison to the original [BrainPrint](https://github.com/Deep-MI/BrainPrint-legacy)\nscripts:\n\n- currently no support for tetrahedral meshes\n- currently no support for analyses of cortical parcellation or label files\n- no more Python 2.x compatibility\n\n## API Documentation\n\nThe API Documentation can be found at https://deep-mi.org/BrainPrint .\n\n## References\n\nIf you use this software for a publication please cite:\n\n[1] BrainPrint: a discriminative characterization of brain morphology. Wachinger C, Golland P, Kremen W, Fischl B, Reuter M. Neuroimage. 2015;109:232-48. http://dx.doi.org/10.1016/j.neuroimage.2015.01.032 http://www.ncbi.nlm.nih.gov/pubmed/25613439\n\n[2] Laplace-Beltrami spectra as 'Shape-DNA' of surfaces and solids. Reuter M, Wolter F-E, Peinecke N Computer-Aided Design. 2006;38:342-366. http://dx.doi.org/10.1016/j.cad.2005.10.011\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cadet",
            "repo_link": "https://github.com/cadet/CADET-Core",
            "readme": "CADET-Core\n==========\n\n.. image:: https://img.shields.io/github/release/cadet/cadet-core.svg\n   :target: https://github.com/cadet/cadet-core/releases\n\n.. image:: https://github.com/cadet/cadet-core/actions/workflows/ci.yml/badge.svg?branch=master\n   :target: https://github.com/cadet/cadet-core/actions/workflows/ci.yml?query=branch%3Amaster\n\n.. image:: https://anaconda.org/conda-forge/cadet/badges/downloads.svg\n   :target: https://anaconda.org/conda-forge/cadet\n\n.. image:: https://zenodo.org/badge/DOI/10.5281/zenodo.8179015.svg\n   :target: https://doi.org/10.5281/zenodo.8179015\n\n.. image:: https://img.shields.io/badge/JuRSE_Code_Pick-Oct_2024-blue.svg\n   :target: https://www.fz-juelich.de/en/rse/community-initiatives/jurse-code-of-the-month/october-2024\n\n- **Website (including documentation):** https://cadet.github.io\n- **Forum:** https://forum.cadet-web.de\n- **Source:** https://github.com/cadet/cadet-core\n- **Bug reports:** https://github.com/cadet/cadet-core/issues\n- **Demo:** https://www.cadet-web.de \n- **Newsletter:** https://cadet-web.de/newsletter/\n\nInstallation\n------------\nCADET-Core can be installed via conda from the ``conda-forge`` channel.\n\n``conda install -c conda-forge cadet``\n\nThis requires a working `conda installation <https://github.com/conda-forge/miniforge>`_.\n\n`Additional information <https://cadet.github.io/master/getting_started/installation>`_ and a `tutorial <https://cadet.github.io/master/getting_started/tutorials/breakthrough>`_ are available to guide you through the installation and the first steps of using CADET.\n\nCiting\n------------\nThe development of CADET-Core has been a collaborative effort, with multiple dedicated individuals contributing their expertise to create a powerful and versatile open-source software tool.\nCountless hours of hard work have been invested to provide the scientific community with a valuable resource.\nAs an open-source project, CADET-Core relies on the support and recognition from users and researchers to thrive.\nTherefore, we kindly ask that any publications or projects leveraging the capabilities of CADET-Core acknowledge its creators and their contributions by citing an adequate selection of our publications.\n\n**General:**\n\n- Leweke, S.; von Lieres, E.: `Chromatography Analysis and Design Toolkit (CADET) <https://doi.org/10.1016/j.compchemeng.2018.02.025>`_, Computers and Chemical Engineering **113** (2018), 274–294.\n\n- von Lieres, E.; Andersson, J.: `A fast and accurate solver for the general rate model of column liquid chromatography <https://doi.org/10.1016/j.compchemeng.2010.03.008>`_, Computers and Chemical Engineering **34,8** (2010), 1180–1191.\n\n**Major extensions:**\n\n- Breuer, J. M.; Leweke, S.; Schmölder, J.; Gassner, G.; von Lieres, E.: `Spatial discontinuous Galerkin spectral element method for a family of chromatography models in CADET <https://doi.org/10.1016/j.compchemeng.2023.108340>`_, Computers and Chemical Engineering **177** (2023), 108340.\n\n- Zhang, W.; Przybycien T., Schmölder J. , Leweke S. , von Lieres E.: `Solving crystallization/precipitation population balance models in CADET, part I: Nucleation growth and growth rate dispersion in batch and continuous modes on nonuniform grids <https://doi.org/10.1016/j.compchemeng.2024.108612>`_, Computers and Chemical Engineering **183** (2024), 108612.\n\n- Püttmann, A.; Schnittert, S.; Naumann, U.; von Lieres, E.: `Fast and accurate parameter sensitivities for the general rate model of column liquid chromatography <http://dx.doi.org/10.1016/j.compchemeng.2013.04.021>`_, Computers and Chemical Engineering **56** (2013), 46–57.\n\nAdditionally, to ensure reproducibility of your work, we recommend citing the zenodo doi corresponding to the specific CADET-Core release that you used.\n\nFor a comprehensive list and guidance on citing CADET-Core publications, please refer to the publications section of the `documentation <https://cadet.github.io/master/publications.html>`_.\n\nOngoing Development\n-------------------\n\nWe do our best to provide you with a stable API. However, CADET-Core is actively developed and breaking changes can sometimes be unavoidable. For non-developers, it is recommended to upgrade from release to release instead of always working with the most recent commit.\n\nBugs\n----\n\nPlease report any bugs that you find `here <https://github.com/cadet/cadet-core/issues>`_. Or, even better, fork the repository on `GitHub <https://github.com/cadet/cadet-core>`_ and create a pull request (PR) with the fix. \n\nDonations\n---------\n\n`Donations <https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=FCQ2M89558ZAG>`_ for helping to host, maintain, and further develop the CADET-Core project are highly appreciated.\n\n\nCopyright and License Notice\n----------------------------\n\nCopyright (C) 2008-present: The CADET-Core Authors (see `AUTHORS.md <https://github.com/cadet/cadet-core/blob/master/AUTHORS.md>`_).\n\nThis program is free software: you can redistribute it and/or modify it under the terms of the\nGNU General Public License as published by the Free Software Foundation, either version 3 of\nthe License, or (at your option) any later version (see `LICENSE.txt <https://github.com/cadet/cadet-core/blob/master/LICENSE.txt>`_).\n\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without\neven the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License along with this program, see below.\nIf not, see <https://www.gnu.org/licenses/>.\n\nExcept as contained in this notice, the name of a copyright holder shall not be used in advertising\nor otherwise to promote the sale, use, or other dealings in this Software without prior written\nauthorization of the copyright holder.\n\n\nAcknowledgments\n---------------\n\nPlease refer to the `list of contributors <https://github.com/cadet/cadet-core/blob/master/CONTRIBUTING.md>`_ who helped building and funding this project.\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/calibr8",
            "repo_link": "https://github.com/JuBiotech/calibr8",
            "readme": "[![PyPI version](https://img.shields.io/pypi/v/calibr8)](https://pypi.org/project/calibr8)\n[![pipeline](https://github.com/jubiotech/calibr8/workflows/pipeline/badge.svg)](https://github.com/jubiotech/calibr8/actions)\n[![coverage](https://codecov.io/gh/jubiotech/calibr8/branch/master/graph/badge.svg)](https://codecov.io/gh/jubiotech/calibr8)\n[![documentation](https://readthedocs.org/projects/calibr8/badge/?version=latest)](https://calibr8.readthedocs.io/en/latest/?badge=latest)\n[![DOI](https://zenodo.org/badge/306862348.svg)](https://zenodo.org/badge/latestdoi/306862348)\n\n\n# `calibr8`\nThis package provides templates and functions for performing likelihood-based calibration modeling.\nTo see implementation examples & excercises, you can go to [notebooks/](notebooks).\n\n# Installation\n`calibr8` is released on [PyPI](https://pypi.org/project/calibr8/):\n\n```\npip install calibr8\n```\n# Documentation\nRead the package documentation [here](https://calibr8.readthedocs.io/en/latest/?badge=latest).\n\n# Usage and Citing\n`calibr8` is licensed under the [GNU Affero General Public License v3.0](https://github.com/JuBiotech/calibr8/blob/master/LICENSE).\n\nWhen using `calibr8` in your work, please cite the [Helleckes & Osthege et al. (2022) paper](https://doi.org/10.1371/journal.pcbi.1009223) __and__ the [corresponding software version](https://doi.org/10.5281/zenodo.4127012).\n\nNote that the paper is a shared first co-authorship, which can be indicated by <sup>1</sup> in the bibliography.\n\n```bibtex\n@article{calibr8Paper,\n  doi       = {10.1371/journal.pcbi.1009223},\n  author    = {Helleckes$^1$, Laura Marie and\n  \t       Osthege$^1$, Michael and\n\t       Wiechert, Wolfgang and\n\t       von Lieres, Eric and\n\t       Oldiges, Marco},\n  journal   = {PLOS Computational Biology},\n  publisher = {Public Library of Science},\n  title     = {Bayesian and calibration, process modeling and uncertainty quantification in biotechnology},\n  year      = {2022},\n  month     = {03},\n  volume    = {18},\n  url       = {https://doi.org/10.1371/journal.pcbi.1009223},\n  pages     = {1-46},\n  number    = {3}\n}\n\n@software{calibr8version,\n  author    = {Michael Osthege and\n               Laura Helleckes},\n  title     = {JuBiotech/calibr8: v6.5.2},\n  month     = mar,\n  year      = 2022,\n  publisher = {Zenodo},\n  version   = {v6.5.2},\n  doi       = {10.5281/zenodo.4127012},\n  url       = {https://doi.org/10.5281/zenodo.4127012}\n}\n```\n\nHead over to Zenodo to [generate a BibTeX citation](https://doi.org/10.5281/zenodo.4127012) for the latest release.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cat4kit",
            "repo_link": "https://codebase.helmholtz.cloud/cat4kit/cat4kit-docker",
            "readme": "",
            "project_id": "6760"
        },
        {
            "software_organization": "https://helmholtz.software/software/catena",
            "repo_link": "https://gitlab.dlr.de/catena/",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/celldetection",
            "repo_link": "https://github.com/FZJ-INM1-BDA/celldetection",
            "readme": "# Cell Detection\n\n[![Downloads](https://static.pepy.tech/badge/celldetection?l)](https://pepy.tech/project/celldetection)\n[![Test](https://github.com/FZJ-INM1-BDA/celldetection/workflows/Test/badge.svg)](https://github.com/FZJ-INM1-BDA/celldetection/actions?query=workflow%3ATest)\n[![PyPI](https://img.shields.io/pypi/v/celldetection?l)](https://pypi.org/project/celldetection/)\n[![Documentation Status](https://readthedocs.org/projects/celldetection/badge/?version=latest)](https://celldetection.readthedocs.io/en/latest/?badge=latest)\n[![DOI](https://zenodo.org/badge/349111085.svg)](https://zenodo.org/badge/latestdoi/349111085)\n\n## ⭐ Showcase\n\n###### NeurIPS 22 Cell Segmentation Competition\n\n![neurips22](https://raw.githubusercontent.com/FZJ-INM1-BDA/celldetection/main/assets/neurips-cellseg-demo.png \"NeurIPS 22 Cell Segmentation Competition - Find more information here: https://neurips.cc/Conferences/2022/CompetitionTrack\")\n*https://openreview.net/forum?id=YtgRjBw-7GJ*\n\n###### Nuclei of U2OS cells in a chemical screen\n\n![bbbc039](https://raw.githubusercontent.com/FZJ-INM1-BDA/celldetection/main/assets/bbbc039-cpn-u22-demo.png \"BBBC039 demo with CpnU22 - Find the dataset here: https://bbbc.broadinstitute.org/BBBC039\")\n*https://bbbc.broadinstitute.org/BBBC039 (CC0)*\n\n###### P. vivax (malaria) infected human blood\n\n![bbbc041](https://raw.githubusercontent.com/FZJ-INM1-BDA/celldetection/main/assets/bbbc041-cpn-u22-demo.png \"BBBC041 demo with CpnU22 - Find the dataset here: https://bbbc.broadinstitute.org/BBBC041\")\n*https://bbbc.broadinstitute.org/BBBC041 (CC BY-NC-SA 3.0)*\n\n## 🛠 Install\n\nMake sure you have [PyTorch](https://pytorch.org/get-started/locally/) installed.\n\n### PyPI\n\n```\npip install -U celldetection\n```\n\n### GitHub\n\n```\npip install git+https://github.com/FZJ-INM1-BDA/celldetection.git\n```\n\n## 💾 Trained models\n\n```python\nmodel = cd.fetch_model(model_name, check_hash=True)\n```\n\n| model name                                  | training data                                                                                                        |                                           link                                            |\n|---------------------------------------------|----------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------:| \n| `ginoro_CpnResNeXt101UNet-fbe875f1a3e5ce2c` | BBBC039, BBBC038, Omnipose, Cellpose, Sartorius - Cell Instance Segmentation, Livecell, NeurIPS 22 CellSeg Challenge | [🔗](https://celldetection.org/torch/models/ginoro_CpnResNeXt101UNet-fbe875f1a3e5ce2c.pt) |\n\n<details>\n  <summary style=\"font-weight: bold; color: #888888\">Run a demo with a pretrained model</summary>\n\n```python\nimport torch, cv2, celldetection as cd\nfrom skimage.data import coins\nfrom matplotlib import pyplot as plt\n\n# Load pretrained model\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = cd.fetch_model('ginoro_CpnResNeXt101UNet-fbe875f1a3e5ce2c', check_hash=True).to(device)\nmodel.eval()\n\n# Load input\nimg = coins()\nimg = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\nprint(img.dtype, img.shape, (img.min(), img.max()))\n\n# Run model\nwith torch.no_grad():\n    x = cd.to_tensor(img, transpose=True, device=device, dtype=torch.float32)\n    x = x / 255  # ensure 0..1 range\n    x = x[None]  # add batch dimension: Tensor[3, h, w] -> Tensor[1, 3, h, w]\n    y = model(x)\n\n# Show results for each batch item\ncontours = y['contours']\nfor n in range(len(x)):\n    cd.imshow_row(x[n], x[n], figsize=(16, 9), titles=('input', 'contours'))\n    cd.plot_contours(contours[n])\n    plt.show()\n```\n\n</details>\n\n## 🔬 Architectures\n\n```python\nimport celldetection as cd\n```\n\n<details>\n  <summary style=\"font-weight: bold; color: #888888\">Contour Proposal Networks</summary>\n\n- [`cd.models.CPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CPN)\n- [`cd.models.CpnU22`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnU22)\n- [`cd.models.CPNCore`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CPNCore)\n- [`cd.models.CpnResUNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResUNet)\n- [`cd.models.CpnSlimU22`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnSlimU22)\n- [`cd.models.CpnWideU22`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnWideU22)\n- [`cd.models.CpnResNet18FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet18FPN)\n- [`cd.models.CpnResNet34FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet34FPN)\n- [`cd.models.CpnResNet50FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet50FPN)\n- [`cd.models.CpnResNeXt50FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNeXt50FPN)\n- [`cd.models.CpnResNet101FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet101FPN)\n- [`cd.models.CpnResNet152FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet152FPN)\n- [`cd.models.CpnResNet18UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet18UNet)\n- [`cd.models.CpnResNet34UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet34UNet)\n- [`cd.models.CpnResNet50UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet50UNet)\n- [`cd.models.CpnResNeXt101FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNeXt101FPN)\n- [`cd.models.CpnResNeXt152FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNeXt152FPN)\n- [`cd.models.CpnResNeXt50UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNeXt50UNet)\n- [`cd.models.CpnResNet101UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet101UNet)\n- [`cd.models.CpnResNet152UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNet152UNet)\n- [`cd.models.CpnResNeXt101UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNeXt101UNet)\n- [`cd.models.CpnResNeXt152UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnResNeXt152UNet)\n- [`cd.models.CpnWideResNet50FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnWideResNet50FPN)\n- [`cd.models.CpnWideResNet101FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnWideResNet101FPN)\n- [`cd.models.CpnMobileNetV3LargeFPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnMobileNetV3LargeFPN)\n- [`cd.models.CpnMobileNetV3SmallFPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnMobileNetV3SmallFPN)\n\n</details>\n\n<details>\n  <summary style=\"font-weight: bold; color: #888888\">PyTorch Image Models (timm)</summary>\n\nAlso have a look at [Timm Documentation](https://huggingface.co/docs/timm/index).\n\n```python\nimport timm\n\ntimm.list_models(filter='*')  # explore available models\n```\n\n- [`cd.models.CpnTimmMaNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnTimmMaNet)\n- [`cd.models.CpnTimmUNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnTimmUNet)\n- [`cd.models.TimmEncoder`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.timmodels.TimmEncoder)\n- [`cd.models.TimmFPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.TimmFPN)\n- [`cd.models.TimmMaNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.manet.TimmMaNet)\n- [`cd.models.TimmUNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.TimmUNet)\n\n</details>\n\n<details>\n  <summary style=\"font-weight: bold; color: #888888\">Segmentation Models PyTorch (smp)</summary>\n\n```python\nimport segmentation_models_pytorch as smp\n\nsmp.encoders.get_encoder_names()  # explore available models\n```\n\n```python\nencoder = cd.models.SmpEncoder(encoder_name='mit_b5', pretrained='imagenet')\n```\n\nFind a list of [Smp Encoders](https://smp.readthedocs.io/en/latest/encoders.html) in the `smp` documentation.\n\n- [`cd.models.CpnSmpMaNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnSmpMaNet)\n- [`cd.models.CpnSmpUNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.cpn.CpnSmpUNet)\n- [`cd.models.SmpEncoder`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.smp.SmpEncoder)\n- [`cd.models.SmpFPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.SmpFPN)\n- [`cd.models.SmpMaNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.manet.SmpMaNet)\n- [`cd.models.SmpUNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.SmpUNet)\n\n</details>\n\n<details>\n    <summary style=\"font-weight: bold; color: #888888\">U-Nets</summary>\n\n```python\n# U-Nets are available in 2D and 3D\nimport celldetection as cd\n\nmodel = cd.models.ResNeXt50UNet(in_channels=3, out_channels=1, nd=3)\n```\n\n- [`cd.models.U22`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.U22)\n- [`cd.models.U17`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.U17)\n- [`cd.models.U12`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.U12)\n- [`cd.models.UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.UNet)\n- [`cd.models.WideU22`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.WideU22)\n- [`cd.models.SlimU22`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.SlimU22)\n- [`cd.models.ResUNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.ResUNet)\n- [`cd.models.UNetEncoder`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.UNetEncoder)\n- [`cd.models.ResNet50UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.ResNet50UNet)\n- [`cd.models.ResNet18UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.ResNet18UNet)\n- [`cd.models.ResNet34UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.ResNet34UNet)\n- [`cd.models.ResNet152UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.ResNet152UNet)\n- [`cd.models.ResNet101UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.ResNet101UNet)\n- [`cd.models.ResNeXt50UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.ResNeXt50UNet)\n- [`cd.models.ResNeXt152UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.ResNeXt152UNet)\n- [`cd.models.ResNeXt101UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.ResNeXt101UNet)\n- [`cd.models.WideResNet50UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.WideResNet50UNet)\n- [`cd.models.WideResNet101UNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.WideResNet101UNet)\n- [`cd.models.MobileNetV3SmallUNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.MobileNetV3SmallUNet)\n- [`cd.models.MobileNetV3LargeUNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.unet.MobileNetV3LargeUNet)\n\n</details>\n\n<details>\n    <summary style=\"font-weight: bold; color: #888888\">MA-Nets</summary>\n\n```python\n# Many MA-Nets are available in 2D and 3D\nimport celldetection as cd\n\nencoder = cd.models.ConvNeXtSmall(in_channels=3, nd=3)\nmodel = cd.models.MaNet(encoder, out_channels=1, nd=3)\n```\n\n- [`cd.models.MaNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.manet.MaNet)\n- [`cd.models.SmpMaNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.manet.SmpMaNet)\n- [`cd.models.TimmMaNet`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.manet.TimmMaNet)\n\n</details>\n\n<details>\n    <summary style=\"font-weight: bold; color: #888888\">Feature Pyramid Networks</summary>\n\n- [`cd.models.FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.FPN)\n- [`cd.models.ResNet18FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.ResNet18FPN)\n- [`cd.models.ResNet34FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.ResNet34FPN)\n- [`cd.models.ResNet50FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.ResNet50FPN)\n- [`cd.models.ResNeXt50FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.ResNeXt50FPN)\n- [`cd.models.ResNet101FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.ResNet101FPN)\n- [`cd.models.ResNet152FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.ResNet152FPN)\n- [`cd.models.ResNeXt101FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.ResNeXt101FPN)\n- [`cd.models.ResNeXt152FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.ResNeXt152FPN)\n- [`cd.models.WideResNet50FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.WideResNet50FPN)\n- [`cd.models.WideResNet101FPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.WideResNet101FPN)\n- [`cd.models.MobileNetV3LargeFPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.MobileNetV3LargeFPN)\n- [`cd.models.MobileNetV3SmallFPN`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.fpn.MobileNetV3SmallFPN)\n\n</details>\n\n<details>\n    <summary style=\"font-weight: bold; color: #888888\">ConvNeXt Networks</summary>\n\n```python\n# ConvNeXt Networks are available in 2D and 3D\nimport celldetection as cd\n\nmodel = cd.models.ConvNeXtSmall(in_channels=3, nd=3)\n```\n\n- [`cd.models.ConvNeXt`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.convnext.MaNet)\n- [`cd.models.ConvNeXtTiny`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.convnext.ConvNeXtTiny)\n- [`cd.models.ConvNeXtSmall`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.convnext.ConvNeXtSmall)\n- [`cd.models.ConvNeXtBase`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.convnext.ConvNeXtBase)\n- [`cd.models.ConvNeXtLarge`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.convnext.ConvNeXtLarge)\n\n</details>\n\n<details>\n    <summary style=\"font-weight: bold; color: #888888\">Residual Networks</summary>\n\n```python\n# Residual Networks are available in 2D and 3D\nimport celldetection as cd\n\nmodel = cd.models.ResNet50(in_channels=3, nd=3)\n```\n\n- [`cd.models.ResNet18`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.ResNet18)\n- [`cd.models.ResNet34`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.ResNet34)\n- [`cd.models.ResNet50`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.ResNet50)\n- [`cd.models.ResNet101`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.ResNet101)\n- [`cd.models.ResNet152`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.ResNet152)\n- [`cd.models.WideResNet50_2`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.WideResNet50_2)\n- [`cd.models.ResNeXt50_32x4d`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.ResNeXt50_32x4d)\n- [`cd.models.WideResNet101_2`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.WideResNet101_2)\n- [`cd.models.ResNeXt101_32x8d`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.ResNeXt101_32x8d)\n- [`cd.models.ResNeXt152_32x8d`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.resnet.ResNeXt152_32x8d)\n\n</details>\n\n<details>\n    <summary style=\"font-weight: bold; color: #888888\">Mobile Networks</summary>\n\n- [`cd.models.MobileNetV3Large`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.mobilenetv3.MobileNetV3Large)\n- [`cd.models.MobileNetV3Small`](https://docs.celldetection.org/en/latest/celldetection.models.html#celldetection.models.mobilenetv3.MobileNetV3Small)\n\n</details>\n\n## 🐳 Docker\n\nFind us on Docker Hub: https://hub.docker.com/r/ericup/celldetection\n\nYou can pull the latest version of `celldetection` via:\n```\ndocker pull ericup/celldetection:latest\n```\n\n<details>\n    <summary style=\"font-weight: bold; color: #888888\">CPN inference via Docker with GPU</summary>\n\n```\ndocker run --rm \\\n  -v $PWD/docker/outputs:/outputs/ \\\n  -v $PWD/docker/inputs/:/inputs/ \\\n  -v $PWD/docker/models/:/models/ \\\n  --gpus=\"device=0\" \\\n  celldetection:latest /bin/bash -c \\\n  \"python cpn_inference.py --tile_size=1024 --stride=768 --precision=32-true\"\n```\n</details>\n<details>\n    <summary style=\"font-weight: bold; color: #888888\">CPN inference via Docker with CPU</summary>\n\n```\ndocker run --rm \\\n  -v $PWD/docker/outputs:/outputs/ \\\n  -v $PWD/docker/inputs/:/inputs/ \\\n  -v $PWD/docker/models/:/models/ \\\n  celldetection:latest /bin/bash -c \\\n  \"python cpn_inference.py --tile_size=1024 --stride=768 --precision=32-true --accelerator=cpu\"\n```\n</details>\n\n\n\n### Apptainer\n\nYou can also pull our Docker images for the use with [Apptainer](https://apptainer.org/) (formerly [Singularity](https://github.com/apptainer/singularity)) with this command:\n\n```\napptainer pull --dir . --disable-cache docker://ericup/celldetection:latest\n```\n\n\n## 🤗 Hugging Face Spaces\n\nFind us on Hugging Face and upload your own images for segmentation: https://huggingface.co/spaces/ericup/celldetection\n\nThere's also an API (Python & JavaScript), allowing you to utilize community GPUs (currently Nvidia A100) remotely!\n\n<details>\n    <summary style=\"font-weight: bold; color: #888888\">Hugging Face API</summary>\n\n### Python\n\n```python\nfrom gradio_client import Client\n\n# Define inputs (local filename or URL)\ninputs = 'https://raw.githubusercontent.com/scikit-image/scikit-image/main/skimage/data/coins.png'\n\n# Set up client\nclient = Client(\"ericup/celldetection\")\n\n# Predict\noverlay_filename, img_filename, h5_filename, csv_filename = client.predict(\n    inputs,  # str: Local filepath or URL of your input image\n    \n    # Model name\n    'ginoro_CpnResNeXt101UNet-fbe875f1a3e5ce2c',\n    \n    # Custom Score Threshold (numeric value between 0 and 1)\n    False, .9,  # bool: Whether to use custom setting; float: Custom setting\n    \n    # Custom NMS Threshold\n    False, .3142,  # bool: Whether to use custom setting; float: Custom setting\n    \n    # Custom Number of Sample Points\n    False, 128,  # bool: Whether to use custom setting; int: Custom setting\n    \n    # Overlapping objects\n    True,  # bool: Whether to allow overlapping objects\n    \n    # API name (keep as is)\n    api_name=\"/predict\"\n)\n\n\n# Example usage: Code below only shows how to use the results\nfrom matplotlib import pyplot as plt\nimport celldetection as cd\nimport pandas as pd\n\n# Read results from local temporary files\nimg = imread(img_filename)\noverlay = imread(overlay_filename)  # random colors per instance; transparent overlap\nproperties = pd.read_csv(csv_filename)\ncontours, scores, label_image = cd.from_h5(h5_filename, 'contours', 'scores', 'labels')\n\n# Optionally display overlay\ncd.imshow_row(img, img, figsize=(16, 9))\ncd.imshow(overlay)\nplt.show()\n\n# Optionally display contours with text\ncd.imshow_row(img, img, figsize=(16, 9))\ncd.plot_contours(contours, texts=['score: %d%%\\narea: %d' % s for s in zip((scores * 100).round(), properties.area)])\nplt.show()\n```\n\n### Javascript\n\n```javascript\nimport { client } from \"@gradio/client\";\n\nconst response_0 = await fetch(\"https://raw.githubusercontent.com/scikit-image/scikit-image/main/skimage/data/coins.png\");\nconst exampleImage = await response_0.blob();\n\t\t\t\t\t\t\nconst app = await client(\"ericup/celldetection\");\nconst result = await app.predict(\"/predict\", [\n    exampleImage,  // blob: Your input image\n    \n    // Model name (hosted model or URL)\n    \"ginoro_CpnResNeXt101UNet-fbe875f1a3e5ce2c\",\n    \n    // Custom Score Threshold (numeric value between 0 and 1)\n    false, .9,  // bool: Whether to use custom setting; float: Custom setting\n    \n    // Custom NMS Threshold\n    false, .3142,  // bool: Whether to use custom setting; float: Custom setting\n    \n    // Custom Number of Sample Points\n    false, 128,  // bool: Whether to use custom setting; int: Custom setting\n    \n    // Overlapping objects\n    true,  // bool: Whether to allow overlapping objects\n    \n    // API name (keep as is)\n    api_name=\"/predict\"\n]);\n```\n\n</details>\n\n## 🧑‍💻 Napari Plugin\n\nFind our Napari Plugin here: https://github.com/FZJ-INM1-BDA/celldetection-napari </br>\nFind out more about Napari here: https://napari.org\n![bbbc039](https://raw.githubusercontent.com/FZJ-INM1-BDA/celldetection-napari/main/assets/coins-demo.png \"Napari Plugin\")\nYou can install it via pip:\n```\npip install git+https://github.com/FZJ-INM1-BDA/celldetection-napari.git\n```\n\n## 🏆 Awards\n\n- [NeurIPS 2022 Cell Segmentation Challenge](https://neurips22-cellseg.grand-challenge.org/): Winner Finalist Award\n\n## 📝 Citing\n\nIf you find this work useful, please consider giving a **star** ⭐️ and **citation**:\n\n```\n@article{UPSCHULTE2022102371,\n    title = {Contour proposal networks for biomedical instance segmentation},\n    journal = {Medical Image Analysis},\n    volume = {77},\n    pages = {102371},\n    year = {2022},\n    issn = {1361-8415},\n    doi = {https://doi.org/10.1016/j.media.2022.102371},\n    url = {https://www.sciencedirect.com/science/article/pii/S136184152200024X},\n    author = {Eric Upschulte and Stefan Harmeling and Katrin Amunts and Timo Dickscheid},\n    keywords = {Cell detection, Cell segmentation, Object detection, CPN},\n}\n```\n\n## 🔗 Links\n\n- [Article (sciencedirect)](https://www.sciencedirect.com/science/article/pii/S136184152200024X \"Contour Proposal Networks for Biomedical Instance Segmentation\")\n- [PDF (sciencedirect)](https://www.sciencedirect.com/sdfe/reader/pii/S136184152200024X/pdf \"Contour Proposal Networks for Biomedical Instance Segmentation\")\n- [PyPI](https://pypi.org/project/celldetection/ \"CellDetection\")\n- [Documentation](https://docs.celldetection.org \"Documentation\")\n\n## 🧑‍🔬 Thanks!\n\n[![Stargazers repo roster for @FZJ-INM1-BDA/celldetection](http://reporoster.com/stars/FZJ-INM1-BDA/celldetection)](https://github.com/FZJ-INM1-BDA/celldetection/stargazers)\n[![Forkers repo roster for @FZJ-INM1-BDA/celldetection](http://reporoster.com/forks/FZJ-INM1-BDA/celldetection)](https://github.com/FZJ-INM1-BDA/celldetection/network/members)"
        },
        {
            "software_organization": "https://helmholtz.software/software/cellrank",
            "repo_link": "https://github.com/theislab/cellrank",
            "readme": "|PyPI| |Downloads| |CI| |Docs| |Codecov| |Discourse|\n\nCellRank 2: Unified fate mapping in multiview single-cell data\n==============================================================\n.. image:: docs/_static/img/light_mode_overview.png#gh-light-mode-only\n    :width: 600px\n    :align: center\n    :class: only-light\n\n.. image:: docs/_static/img/dark_mode_overview.png#gh-dark-mode-only\n    :width: 600px\n    :align: center\n\n**CellRank** is a modular framework to study cellular dynamics based on Markov state modeling of\nmulti-view single-cell data. See our `documentation`_, and the `CellRank 1`_ and `CellRank 2 manuscript`_ to learn more.\n\n.. important::\n    Please refer to :doc:`our citation guide <https://github.com/theislab/cellrank/blob/main/docs/about/cite.rst>` to cite our software correctly.\n\nCellRank scales to large cell numbers, is fully compatible with the `scverse`_ ecosystem, and easy to use.\nIn the backend, it is powered by `pyGPCCA`_ (`Reuter et al. (2018)`_). Feel\nfree to open an `issue`_ if you encounter a bug, need our help or just want to make a comment/suggestion.\n\nCellRank's key applications\n---------------------------\n- Estimate differentiation direction based on a varied number of biological priors, including RNA velocity\n  (`La Manno et al. (2018)`_, `Bergen et al. (2020)`_), any pseudotime or developmental potential,\n  experimental time points, metabolic labels, and more.\n- Compute initial, terminal and intermediate macrostates.\n- Infer fate probabilities and driver genes.\n- Visualize and cluster gene expression trends.\n- ... and much more, check out our `documentation`_.\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/cellrank.svg\n    :target: https://pypi.org/project/cellrank\n    :alt: PyPI\n\n.. |Downloads| image:: https://static.pepy.tech/badge/cellrank\n    :target: https://pepy.tech/project/cellrank\n    :alt: Downloads\n\n.. |Discourse| image:: https://img.shields.io/discourse/posts?color=yellow&logo=discourse&server=https%3A%2F%2Fdiscourse.scverse.org\n    :target: https://discourse.scverse.org/c/ecosystem/cellrank/\n    :alt: Discourse\n\n.. |CI| image:: https://img.shields.io/github/actions/workflow/status/theislab/cellrank/test.yml?branch=main\n    :target: https://github.com/theislab/cellrank/actions\n    :alt: CI\n\n.. |Docs|  image:: https://img.shields.io/readthedocs/cellrank\n    :target: https://cellrank.readthedocs.io/\n    :alt: Documentation\n\n.. |Codecov| image:: https://codecov.io/gh/theislab/cellrank/branch/main/graph/badge.svg\n    :target: https://codecov.io/gh/theislab/cellrank\n    :alt: Coverage\n\n\n.. _La Manno et al. (2018): https://doi.org/10.1038/s41586-018-0414-6\n.. _Bergen et al. (2020): https://doi.org/10.1038/s41587-020-0591-3\n.. _Reuter et al. (2018): https://doi.org/10.1021/acs.jctc.8b00079\n\n.. _scverse: https://scverse.org/\n.. _pyGPCCA: https://github.com/msmdev/pyGPCCA\n\n.. _CellRank 1: https://www.nature.com/articles/s41592-021-01346-6\n.. _CellRank 2 manuscript: https://doi.org/10.1038/s41592-024-02303-9\n.. _documentation: https://cellrank.org\n\n.. _issue: https://github.com/theislab/cellrank/issues/new/choose\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/chase",
            "repo_link": "https://github.com/ChASE-library/ChASE",
            "readme": "[![License](https://img.shields.io/github/license/ChASE-library/ChASE)](https://github.com/ChASE-library/ChASE/blob/master/LICENSE) [![DOI](https://zenodo.org/badge/349075288.svg)](https://zenodo.org/badge/latestdoi/349075288) [![Latest Version](https://img.shields.io/github/v/release/ChASE-library/ChASE)](https://github.com/ChASE-library/ChASE/releases/latest) [![DOI](https://img.shields.io/badge/DOI-10.1145%2F3313828%20-orange)](https://doi.org/10.1145/3313828) [![DOI](https://img.shields.io/badge/DOI-10.1002%2Fcpe.3394%20-orange)](https://doi.org/10.1002/cpe.3394) [![coverage](https://gitlab.jsc.fz-juelich.de/chase/chase-library/ChASE/badges/master/coverage.svg?job=coverage)](https://gitlab.jsc.fz-juelich.de/chase/chase-library/ChASE/badges/master/coverage.svg)\n<img src=\"docs/images/ChASE_Logo_RGB.png\" alt=\"Matrix Generation Pattern\" style=\"zoom:40%;\" />\n# ChASE: a Chebyshev Accelerated Subspace Eigensolver for Dense Eigenproblems\n\nThe **Ch**ebyshev **A**ccelerated **S**ubspace **E**igensolver (ChASE) is a modern and scalable library based on subspace iteration with polynomial acceleration to solve dense Hermitian (Symmetric) algebraic eigenvalue problems, especially solving dense Hermitian eigenproblems arragend in a sequence. Novel to ChASE is the computation of the spectral estimates that enter in the filter and an optimization of the polynomial degree that further reduces the necessary floating-point operations. \n\nChASE is written in C++ using the modern software engineering concepts that favor a simple integration in application codes and a straightforward portability over heterogeneous platforms. When solving sequences of Hermitian eigenproblems for a portion of their extremal spectrum, ChASE greatly benefits from the sequence’s spectral properties and outperforms direct solvers in many scenarios. The library ships with two distinct parallelization schemes, supports execution over distributed GPUs, and is easily extensible to other parallel computing architectures.\n\n## Use Case and Features\n\n- **Real and Complex:** ChASE is templated for real and complex numbers. So it can be used to solve *real symmetric* eigenproblems as well as *complex Hermitian* ones.\n- **Eigespectrum:** ChASE algorithm is designed to solve for the *extremal portion* of the eigenspectrum of matrix `A`. The library is particularly efficient when no more than `20%` of the extremal portion of the eigenspectrum is sought after. For larger fractions the subspace iteration algorithm may struggle to be competitive. Converge could become an issue for fractions close to or larger than `50%`.\n- **Type of Problem:** ChASE can currently handle only standard eigenvalue problems. \n- **Sequences:** ChASE is particularly efficient when dealing with *sequences of eigenvalue problems*, where the eigenvectors solving for one problem can be use as input to accelerate the solution of the next one.\n- **Vectors input:** Since it is based on subspace iteration, ChASE can receive as input a matrix of vector equal to the number of desired eigenvalues. ChASE can experience substantial speed-ups when this input matrix contains some information about the sought after eigenvectors.\n- **Degree optimization:** For a fixed accuracy level, ChASE can optimize the degree of the Chebyshev polynomial filter so as to minimize the number of FLOPs necessary to reach convergence.\n- **Precision:** ChASE is also templated to work in *Single Precision* (SP) or *Double Precision* (DP).\n\n## Versions of the library\n\nT\nCurrently, the library comes in one main versions: \n\n1. **ChASE-MPI**\n\n   ChASE-MPI is the default version of the library and can be installed with the minimum amount of dependencies (BLAS, LAPACK, and MPI).  It supports different configurations depending on the available hardware resources.\n\n   - **Shared memory build:** This is the simplest configuration and should be exclusively selected when ChASE is used on only one computing node or on a single CPU. \n   - **MPI+Threads build:** On multi-core homogeneous CPU clusters, ChASE is best used in its pure MPI build. In this configuration, ChASE is typically used with one MPI rank per NUMA domain and as many threads as number of available cores per NUMA domain.\n   - **GPU build:** ChASE-MPI can be configured to take advantage of GPUs on heterogeneous computing clusters. Currently we support the use of one GPU per MPI rank. Multiple-GPU per computing node can be used when MPI rank\nnumber per node equals to the GPU number per node.   \n   \n   ChASE-MPI support two types of data distribution of matrix `A` across 2D MPI grid:\n\n   - **Block Distribution**:  each MPI rank of 2D grid is assigned a block of dense matrix **A**.\n\n   - **Block-Cyclic Distribution**: an distribution scheme for implementation of dense matrix computations on distributed-memory machines, to improve the load balance of matrix computation if the amount of work differs for different entries of a matrix. For more details, please refer to [Netlib](https://www.netlib.org/scalapack/slug/node75.html) .\n\n## Quick Start\n\n### Installing Dependencies\n\n```bash\n#Linux Operating System\nsudo apt-get install cmake #install CMake\nsudo apt-get install build-essential #install GNU Compiler\nsudo apt-get install libopenblas-dev #install BLAS and LAPACK\nsudo apt-get install libopenmpi-dev #install MPI\n\n#Apple Mac Operating System \nsudo port install cmake #install CMake\nsudo port install gcc10 #install GNU Compiler\nsudo port select --set gcc mp-gcc10 #Set installed GCC as C compiler\nsudo port install OpenBLAS +native #install BLAS and LAPACK\nsudo port install openmpi #install MPI\nsudo port select --set mpi openmpi-mp-fortran #Set installed MPI as MPI compiler\n```\n\n### Cloning ChASE source code\n\n```bash\ngit clone https://github.com/ChASE-library/ChASE #cloning the ChASE repository\ngit checkout v1.0.0 #it is recommended to check out the latest stable tag.\n```\n\n### Building and Installing the ChASE library\n\n```bash\ncd ChASE/\nmkdir build\ncd build/\ncmake .. -DCMAKE_INSTALL_PREFIX=${ChASEROOT}\nmake install\n```\n\nMore details about the installation on both local machine and clusters, please refer to [User Documentation](https://chase-library.github.io/ChASE/quick-start.html).\n\n## Documentation\n\nThe documentation of ChASE is available [online](https://chase-library.github.io/ChASE/index.html).\n\nCompiling the documentation in local requires  enable `-DBUILD_WITH_DOCS=ON` flag when compiling ChASE library:\n\n```bash\ncmake .. -DBUILD_WITH_DOCS=ON\n```\n\n## Examples\n\nMultiple examples are provided, which helps user get familiar with ChASE. \n\n**Build ChASE with Examples** requires enable `-DBUILD_WITH_EXAMPLES=ON` flag when compiling ChASE library:\n\n```bash\ncmake .. -DBUILD_WITH_EXAMPLES=ON\n```\n\n**5 examples are available** in folder [examples](https://github.com/ChASE-library/ChASE/tree/master/examples):\n\n0. The example [0_hello_world](https://github.com/ChASE-library/ChASE/tree/master/examples/0_hello_world) constructs a simple Clement matrix and find a given number of its eigenpairs.\n\n1. The example [1_sequence_eigenproblems](https://github.com/ChASE-library/ChASE/tree/master/examples/1_sequence_eigenproblems) illustrates how ChASE can be used to solve a sequence of eigenproblems.\n2. The example [2_input_output](https://github.com/ChASE-library/ChASE/tree/master/examples/2_input_output) provides the configuration of parameters of ChASE from command line (supported by Boost); the parallel I/O which loads the local matrices into the computing nodes in parallel.\n3. The example [3_installation](https://github.com/ChASE-library/ChASE/tree/master/examples/3_installation) shows the way to link ChASE to other applications.\n4. The example [4_interface](https://github.com/ChASE-library/ChASE/tree/master/examples/4_interface) shows examples to use the C and Fortran interfaces of ChASE.\n\n## Developers\n\n### Main developers\n\n- Edoardo Di Napoli – Algorithm design and development\n- Xinzhe Wu – Algorithm development, advanced parallel (MPI and GPU) implementation and optimization, developer documentation\n\n### Current contributors\n\n- Davor Davidović – Advanced parallel GPU implementation and optimization\n- Nenad Mijić – ARM-based implementation and optimization, CholeskyQR, unitests, parallel IO\n\n\n### Past contributors\n\n- Xiao Zhang – Integration of ChASE into Jena BSE code\n- Miriam Hinzen, Daniel Wortmann – Integration of ChASE into FLEUR code\n- Sebastian Achilles – Library benchmarking on parallel platforms, documentation\n- Jan Winkelmann – DoS algorithm development and advanced `C++` implementation\n- Paul Springer – Advanced GPU implementation\n- Marija Kranjcevic – OpenMP `C++` implementation\n- Josip Zubrinic – Early GPU algorithm development and implementation\n- Jens Rene Suckert – Lanczos algorithm and GPU implementation\n- Mario Berljafa – Early `C` and `MPI` implementation using the Elemental library\n\n\n## Contribution\n\nThis repository mirrors the principal Gitlab repository. If you want to contribute as developer to this project please contact e.di.napoli@fz-juelich.de.\n\n## How to Cite the Code\n\nThe main reference of ChASE is [1] while [2] provides some early results on scalability and usage on sequences of eigenproblems generated by Materials Science applications.\n\n- [1] J. Winkelmann, P. Springer, and E. Di Napoli. *ChASE: a Chebyshev Accelerated Subspace iteration Eigensolver for sequences of Hermitian eigenvalue problems.* ACM Transaction on Mathematical Software, **45** Num.2, Art.21, (2019). [DOI:10.1145/3313828](https://doi.org/10.1145/3313828) , [[arXiv:1805.10121](https://arxiv.org/abs/1805.10121/) ]\n- [2] M. Berljafa, D. Wortmann, and E. Di Napoli. *An Optimized and Scalable Eigensolver for Sequences of Eigenvalue Problems.* Concurrency & Computation: Practice and Experience **27** (2015), pp. 905-922. [DOI:10.1002/cpe.3394](https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.3394) , [[arXiv:1404.4161](https://arxiv.org/abs/1404.4161) ].\n- [3] X. Wu, D. Davidović, S. Achilles,E. Di Napoli. ChASE: a distributed hybrid CPU-GPU eigensolver for large-scale hermitian eigenvalue problems. Proceedings of the Platform for Advanced Scientific Computing Conference (PASC22). [DOI:10.1145/3539781.3539792](https://dl.acm.org/doi/10.1145/3539781.3539792) , [[arXiv:2205.02491](https://arxiv.org/pdf/2205.02491/) ].\n\n## Copyright and License\n\n[3-Clause BSD License (BSD License 2.0)](https://github.com/ChASE-library/ChASE/blob/master/LICENSE)\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cheetah",
            "repo_link": "https://github.com/desy-ml/cheetah.git",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/chemotion-eln",
            "repo_link": "https://github.com/ComPlat/chemotion_ELN",
            "readme": "# Chemotion [![Badge DOI]][DOI]\n\nAn **Electronic Lab Notebook** for chemists!\n\n---\n\n**⸢ [Installation] ⸥ ⸢ [Documentation] ⸥ ⸢ [Changelog] ⸥**\n\n---\n\n## Tests\n\n![Badge CI]\n\n---\n\n## Acknowledgments\n\nThis project has been funded by the **[DFG]**.\n\n[![DFG Logo]][DFG]\n\n\nFunded by the [Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)](https://www.dfg.de/) under the [National Research Data Infrastructure – NFDI4Chem](https://nfdi4chem.de/) – Projektnummer **441958208** since 2020.\n\n\n---\n\n## License\n\n**Copyright © `2015` - `2023` [Nicole Jung]** <br>\nof the **[Karlsruhe Institute of Technology]**.\n\n> This program is free software:\n>\n> You can redistribute it and / or  modify it under the terms <br>\n> of the GNU Affero General Public License as published by <br>\n> the Free Software Foundation, either version 3 of the <br>\n> License, or (at your option) any later version.\n>\n> This program is distributed in the hope that it will be useful, but <br>\n> WITHOUT ANY WARRANTY; without even the implied warranty <br>\n> of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n>\n> See the GNU Affero General Public License for more details.\n>\n> You should have received a copy of the GNU Affero<br>\n> General Public License along with this program.\n>\n> If not, see <https://www.gnu.org/licenses/>.\n\n\n\n<!----------------------------------------------------------------------------->\n\n[Installation]: https://www.chemotion.net/docs/eln/install_configure\n[Documentation]: https://www.chemotion.net/docs/eln\n[Changelog]: CHANGELOG.md\n\n[DFG]: https://www.dfg.de/en/\n[DFG Logo]: https://chemotion.net/img/logos/DFG_logo.png\n\n[Nicole Jung]: mailto:nicole.jung@kit.edu\n[Karlsruhe Institute of Technology]: https://www.kit.edu/english/\n\n[DOI]: https://doi.org/10.5281/zenodo.1054134\n\n[Badge CI]: https://github.com/ComPlat/chemotion_ELN/actions/workflows/ci.yml/badge.svg?branch=main\n[Badge DOI]: https://zenodo.org/badge/DOI/10.5281/zenodo.1054134.svg\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/climate-index-collection",
            "repo_link": "https://github.com/MarcoLandtHayen/climate_index_collection",
            "readme": "# Climate Index Collection\n\n[![Build Status](https://github.com/MarcoLandtHayen/climate_index_collection/workflows/Tests/badge.svg)](https://github.com/MarcoLandtHayen/climate_index_collection/actions)\n[![codecov](https://codecov.io/gh/MarcoLandtHayen/climate_index_collection/branch/main/graph/badge.svg)](https://codecov.io/gh/MarcoLandtHayen/climate_index_collection)\n[![License:MIT](https://img.shields.io/badge/License-MIT-lightgray.svg?style=flt-square)](https://opensource.org/licenses/MIT)\n[![Docker Image Version (latest by date)](https://img.shields.io/docker/v/mlandthayen/climate_index_collection?label=DockerHub)](https://hub.docker.com/r/mlandthayen/climate_index_collection/tags)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7779883.svg)](https://doi.org/10.5281/zenodo.7779883)\n\n\nCollection of climate indices derived from climate model outputs.\n\n\n## Quickstart: Using the climate indices\n\nThe resulting climate-index time series are published to Zenodo under the DOI [10.5281/zenodo.7779883](https://doi.org/10.5281/zenodo.7779883) and you can obtain the index timeseries by manually downloading the file `climate_indices.csv` from this dataset.\n\nYou can also use [pooch](https://www.fatiando.org/pooch/latest/) to obtain the published index time series programmatically:\n```python\nimport pooch\n\nclimate_indices_file = pooch.retrieve(\n    url=\"doi:10.5281/zenodo.7779883/climate_indices.csv\",\n    known_hash=None,\n)\n```\nWith `climate_indices_file` containing the path to the CSV file either resulting from the code above or from manually setting it to the location of the manually downloaded data, we recommend using [Pandas](https://pandas.pydata.org/docs/) for reading the data:\n```python\nimport pandas as pd\n\nclimate_indices = pd.read_csv(climate_indices_file)\n```\nThis results in a dataframe with the following structure:\n```python\nprint(climate_indices)\n```\n```\n       model  year  month   index                         long_name     value\n0       FOCI     1      1  SAM_ZM  southern_annular_mode_zonal_mean -0.295492\n1       FOCI     1      2  SAM_ZM  southern_annular_mode_zonal_mean  0.530890\n2       FOCI     1      3  SAM_ZM  southern_annular_mode_zonal_mean  1.684005\n3       FOCI     1      4  SAM_ZM  southern_annular_mode_zonal_mean  1.409169\n4       FOCI     1      5  SAM_ZM  southern_annular_mode_zonal_mean  0.984511\n...      ...   ...    ...     ...                               ...       ...\n695647  CESM   999      8      NP                     north_pacific -0.210202\n695648  CESM   999      9      NP                     north_pacific  0.206541\n695649  CESM   999     10      NP                     north_pacific -0.331067\n695650  CESM   999     11      NP                     north_pacific  0.487844\n695651  CESM   999     12      NP                     north_pacific -0.782657\n\n[695652 rows x 6 columns]\n```\nTo apply statistics or to plot all indices, you can apply standard modifications provided by Pandas. Calculating, e.g., the standard deviation of all indices amounts to\n```python\nprint(climate_indices.groupby([\"model\", \"index\"])[[\"value\"]].std())\n```\n```\nmodel  index\nCESM   AMO            0.109084\n       ENSO_12        0.603481\n       ENSO_3         0.881938\n       ENSO_34        0.933544\n       ENSO_4         0.909434\n       NAO_PC         1.000042\n       NAO_ST         1.554596\n       NP             0.569459\n       PDO_PC         1.000042\n...    ...            ...\nFOCI   AMO            0.128715\n       ENSO_12        0.342368\n       ENSO_3         0.600242\n       ENSO_34        0.759405\n       ENSO_4         0.923854\n       NAO_PC         1.000042\n       NAO_ST         1.459676\n       NP             0.644014\n       PDO_PC         1.000042\n...    ...            ...\nName: value, dtype: float64\n```\n\n## Quickstart: Reproducing the dataset\n\nThe Python package in this repository can be installed using [`pip`](https://pip.pypa.io/en/stable/getting-started/#install-a-package-from-github):\n```shell\n$ python -m pip install git+https://github.com/MarcoLandtHayen/climate_index_collection.git@v2023.03.29.1\n```\nThe data from which the indices have been calculated are published under the DOI [10.5281/zenodo.7060385](https://doi.org/10.5281/zenodo.7060385). After downloading the data to, e.g., `./cicmod_data/`, you can run the command line version of this package by\n```shell\n$ climate_index_collection_run --input-path ./cicmod_data/ --output-path .\n```\nwhich will create a file `climate_indices.csv`.\n\nPlease see either `$ climate_index_collection_run --help` on the command line, or the tutorial notebook in [notebooks/Tutorial.ipynb](notebooks/Tutorial.ipynb) for more details.\n\n\n## Development\n\nFor now, we're developing in the Pangeo notebook container. More details: https://github.com/pangeo-data/pangeo-docker-images\n\nTo start a JupyterLab within this container, run\n```shell\n$ docker pull pangeo/pangeo-notebook:2022.07.27\n$ docker run -p 8888:8888 --rm -it -v $PWD:/work -w /work pangeo/pangeo-notebook:2022.07.27 jupyter lab --ip=0.0.0.0\n```\nand open the URL starting on `http://127.0.0.1...`.\n\nThen, open a Terminal within JupyterLab and run\n```shell\n$ python -m pip install -e .\n```\nto have a local editable installation of the package.\n\n## Container Image\n\nThere's a container image: https://hub.docker.com/r/mlandthayen/climate_index_collection\n\n### Use with Docker\n\nYou can use it wherever Docker is installed by running:\n```shell\n$ docker pull mlandthayen/climate_index_collection:<tag>\n$ docker run --rm -v $PWD:/work -w /work mlandthayen/climate_index_collection:<tag> climate_index_collection_run --help\n```\nHere, `<tag>` can either be `latest` or a more specific tag.\n\n### Use with Singularity\n\nYou can use it wherever Singularity is installed by essentially running:\n```shell\n$ singularity pull --disable-cache --dir \"${PWD}\" docker://mlandthayen/climate_index_collection:<tag>\n$ singularity run climate_index_collection_<tag>.sif climate_index_collection_run --help\n```\nHere, `<tag>` can either be `latest` or a more specific tag.\n\n_Note_ that for NESH, it's currently necessary to\n- specify the version of singularity to use, and\n- to make sure to bind mount various parts of the file system explicitly.\n\nSo the full call on NESH would look like:\n```shell\n$ module load singularity/3.5.2\n$ singularity pull --disable-cache --dir \"${PWD}\" docker://mlandthayen/climate_index_collection:<tag>\n$ singularity run -B /sfs -B /gxfs_work1 -B ${PWD}:/work --pwd /work climate_index_collection_<tag>.sif climate_index_collection_run --help\n```\n\n## Release Procedure\n\nA release will contain the specific version of the package (taken care of automatically) and the CSV file created with the full data.\n\n1. _**Draft a release:**_ Go to https://github.com/MarcoLandtHayen/climate_index_collection/releases/new and draft a new release (don't publish yet).\n\n2. _**Prepeare data:**_ For the commit in `main` for which the release is planned, pull the container on NESH (see above) and run:\n```\n$ singularity run -B /sfs -B /gxfs_work1 -B ${PWD}:/work --pwd /work climate_index_collection_<tag>.sif climate_index_collection_run --input-path <path_to_full_data>\n```\n\n3. _**Attach data:**_ Attach the CSV file to the drafted release.\n\n4. _**Publish:**_ By clicking on the `Publish release` button.\n\n--------\n\n<p><small>Project based on the <a target=\"_blank\" href=\"https://github.com/jbusecke/cookiecutter-science-project\">cookiecutter science project template</a>.</small></p>\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cimpredict",
            "repo_link": "https://github.com/tonitacker/CIMPredict",
            "readme": "# CIMPredict \n\n\n## Description:\nCIMPredict is used to generate Fracture Risk Values in % for A timeframe of two years upon consultation.\nThe CIM-blood value and the patients age are used to calculate a Fracture Risk based on a model trained by study data\nthat include CIM-Values and information about fractures that occured within two years.\n\n## Features: \nCIMPredict offers a numerical risk in percent of a patient suffering an osteoporotic fracture within the next two years\n\n## Installation:\n1. Download the ZIP-File found in the releases tab and extract it to your preferred folder\n2. Start CIMPredict.exe\n\nDo not move the EXE-File out of the directory in comes in. You can create a shortcut to the exe if you wish. \nThe functionality of the software relies on the data in the directory.\n\nThe software checks for new versions of the dependencies, thus it may take a few minutes upon first start for the main window to appear.\nDo not interrupt this process\n\n## Usage:\n\nEnter the CIM-Value using a decimal point, not a comma into the dedicated field.\nSimilarly, provide a valid age (between 51 and 90 years).\nThe \"Berechnen\"-button is made accessible once all values are provided. \nClick it to retrieve the fracture risk value.\n\n## License\n\nThis project is licensed under the GNU General Public License v3.0 - see the [LICENSE](./.LICENSE) file for details.\n\n### Contact\n\nFor further information or inquiries, please contact:\n\n- **Name:** Anton Krackhardt\n- **E-Mail:** antonkrackhardt444@gmail.com\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/circlize",
            "repo_link": "https://github.com/jokergoo/circlize",
            "readme": "\r\n\r\n# circlize: circular visualization in R <a href=\"https://jokergoo.github.io/circlize_book/book/\"><img src=\"https://jokergoo.github.io/circlize_book/book/images/circlize_cover.jpg\" width=240 align=\"right\" ></a>\r\n\r\n\r\n[![R-CMD-check](https://github.com/jokergoo/circlize/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/circlize/actions)\r\n[![CRAN](https://www.r-pkg.org/badges/version/circlize)](https://cran.r-project.org/web/packages/circlize/index.html)\r\n[![CRAN](https://cranlogs.r-pkg.org/badges/grand-total/circlize)](https://cran.r-project.org/web/packages/circlize/index.html)\r\n[![Codecov test coverage](https://codecov.io/gh/jokergoo/circlize/branch/master/graph/badge.svg)](https://codecov.io/gh/jokergoo/circlize?branch=master)\r\n\r\nCircular layout is an efficient way for the visualization of huge\r\n    amounts of information. Here the circlize package provides an implementation\r\n    of circular layout generation in R as well as an enhancement of available\r\n    software. The flexibility of this package is based on the usage of low-level\r\n    graphics functions such that self-defined high-level graphics can be easily\r\n    implemented by users for specific purposes. Together with the seamless\r\n    connection between the powerful computational and visual environment in R,\r\n    circlize gives users more convenience and freedom to design figures for\r\n    better understanding complex patterns behind multi-dimensional data.\r\n\r\n## Citation\r\n\r\nZuguang Gu, et al., circlize Implements and enhances circular visualization in R. Bioinformatics (Oxford, England) 2014. [PubMed](https://www.ncbi.nlm.nih.gov/pubmed/24930139)\r\n\r\n## Documentation\r\n\r\nThe full documentations are available at https://jokergoo.github.io/circlize_book/book/ and the online website is at https://jokergoo.github.io/circlize/.\r\n\r\n## Blog posts\r\n\r\nThere are the following blog posts focusing on specific topics.\r\n\r\n- [Make circular heatmaps](https://jokergoo.github.io/2020/05/21/make-circular-heatmaps/)\r\n- [Multiple-group Chord diagram](https://jokergoo.github.io/2020/06/08/multiple-group-chord-diagram/)\r\n- [Changes in circlize 0.4.10](https://jokergoo.github.io/2020/06/14/changes-in-circlize-0.4.10/)\r\n- [Reverse x-axes in the circular plot](https://jokergoo.github.io/2020/08/17/reverse-x-axes-in-the-circular-plot/)\r\n\r\n## Examples\r\n\r\nSee https://jokergoo.github.io/circlize_examples/.\r\n\r\n<img width=\"700\" alt=\"circlize_example\" src=\"https://jokergoo.github.io/circlize_book/book/images/ciclize_examples.jpg\">\r\n\r\n## Install\r\n\r\nThe package can be installed from CRAN:\r\n\r\n```r\r\ninstall.packages(\"circlize\")\r\n```\r\n\r\nor directly from GitHub:\r\n\r\n```r\r\ndevtools::install_github(\"jokergoo/circlize\")\r\n```\r\n\r\n## Basic design\r\n\r\nSince most of the figures are composed of points, lines and polygons,\r\nwe just need to implement functions for drawing points, lines and polygons,\r\nthen the plots will not be restricted in any specific types.\r\n\r\nCurrent there are following low-level graphic functions:\r\n\r\n- `circos.points()`\r\n- `circos.lines()`\r\n- `circos.segments()`\r\n- `circos.rect()`\r\n- `circos.polygon()`\r\n- `circos.text()`\r\n- `circos.axis()`\r\n- `circos.raster()`\r\n- `circos.arrow()`\r\n- `circos.raster()`\r\n- `circos.barplot()`\r\n- `circos.boxplot()`\r\n- `circos.link()`, This maybe the unique feature for circos layout to represent relationships between elements.\r\n\r\nFor drawing points, lines and text through the whole track (among several sectors), the following\r\nfunctions are available:\r\n\r\n- `circos.trackPoints()`\r\n- `circos.trackLines()`\r\n- `circos.trackText()`\r\n\r\nDraw circular heatmaps\r\n\r\n- `circos.heatmap()`\r\n\r\nFunctions to arrange the circular layout:\r\n\r\n- `circos.track()`\r\n- `circos.update()`\r\n- `circos.nested()`\r\n- `circos.par()`\r\n- `circos.info()`\r\n- `circos.clear()`\r\n\r\nTheoretically, you are able to draw most kinds of circular plots by the above functions.\r\n\r\nFor specific use in Genomics, we also implement functions which add graphics in genome scale.\r\n\r\nFunctions to initialize circular plot with genomic coordinates:\r\n\r\n- `circos.initializeWithIdeogram()`\r\n- `circos.genomicInitialize()`\r\n\r\nFunctions to arrange genomic circular layout:\r\n\r\n- `circos.genomicTrack()`\r\n\r\nFunctions to add basic graphics in genomic scale:\r\n\r\n- `circos.genomicPoints()`\r\n- `circos.genomicLines()`\r\n- `circos.genomicText()`\r\n- `circos.genomicRect()`\r\n- `circos.genomicLink()`\r\n\r\nFunctions with specific purpose:\r\n\r\n- `circos.genomicIdeogram()`\r\n- `circos.genomicHeatmap()`\r\n- `circos.genomicLabels()`\r\n- `circos.genomicDensity()`\r\n- `circos.genomicRainfall()`\r\n\r\nFinally, function that draws Chord diagram:\r\n\r\n- `chordDiagram()`\r\n\r\n\r\n## License\r\n\r\nMIT @ Zuguang Gu\r\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/citation-file-format",
            "repo_link": "https://github.com/citation-file-format/citation-file-format",
            "readme": "# Citation File Format\n\n[![Build Status](https://github.com/citation-file-format/citation-file-format/workflows/testing/badge.svg?branch=main)](https://github.com/citation-file-format/citation-file-format/actions/workflows/testing.yml?query=branch%3Amain)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1003149.svg)](https://doi.org/10.5281/zenodo.1003149)\n[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)\n[![Project homepage](https://img.shields.io/badge/Project%20homepage-citation--file--format.github.io-ff0080)](https://citation-file-format.github.io)\n\nThe Citation File Format lets you provide citation metadata for software or datasets \nin plaintext files that are easy to read by both humans and machines.\n\n## Structure\n\nYou can specify citation metadata for your software (or dataset) in a file named `CITATION.cff`. \nThis is what a typical `CITATION.cff` file may look like for research software:\n\n```yaml\ncff-version: 1.2.0\nmessage: If you use this software, please cite it using these metadata.\ntitle: My Research Software\nabstract: This is my awesome research software. It does many things.\nauthors:\n  - family-names: Druskat\n    given-names: Stephan\n    orcid: \"https://orcid.org/1234-5678-9101-1121\"\n  - name: \"The Research Software project\"\nversion: 0.11.2\ndate-released: \"2021-07-18\"\nidentifiers:\n  - description: This is the collection of archived snapshots of all versions of My Research Software\n    type: doi\n    value: \"10.5281/zenodo.123456\"\n  - description: This is the archived snapshot of version 0.11.2 of My Research Software\n    type: doi\n    value: \"10.5281/zenodo.123457\"\nlicense: Apache-2.0\nrepository-code: \"https://github.com/citation-file-format/my-research-software\"\n```\n\nIn addition, the Citation File Format allows you to\n\n- provide references to works that your software or dataset builds on ([see here for more info](schema-guide.md#referencing-other-work));\n- ask people to cite a different, related work instead of the software or dataset itself ([see here for more info](schema-guide.md#credit-redirection)).\n\n## Format specifications :books:\n\n**You can find the complete format specifications in the [Guide to the Citation File Format schema](schema-guide.md).**\n\n## Why should I add a `CITATION.cff` file to my repository? :bulb:\n\nWhen you do this, great things may happen:\n\n1. Users of your software can easily cite it using the metadata from `CITATION.cff`!\n2. If your repository is hosted on GitHub, they will [show the citation information in the sidebar](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-citation-files), which makes it easy for visitors to cite your software or dataset correctly.\n3. When you publish your software on Zenodo via the [GitHub-Zenodo integration](https://docs.github.com/en/repositories/archiving-a-github-repository/referencing-and-citing-content), they will use the metadata from your `CITATION.cff` file.\n4. People can import the correct reference to your software into the [Zotero](https://www.zotero.org) reference manager via a [browser plugin](https://www.zotero.org/download/).\n\n## Creation :heavy_plus_sign:\n\nTo create a `CITATION.cff` file, you can \n\n- use the [**cffinit** website](https://citation-file-format.github.io/cff-initializer-javascript/#/),\n- copy and paste the [example snippet](#structure), and adapt it to your needs, or\n- create a new file called `CITATION.cff` using the *Add file* button on GitHub, and use the template they provide.\n\n## Validation :heavy_check_mark:\n\nYou can validate your `CITATION.cff` file on the command line with the [`cffconvert` Python package](https://pypi.org/project/cffconvert/):\n\n```shell\n# Install cffconvert with pip in user space\npython3 -m pip install --user cffconvert\n\n# Validate your CFF file\ncffconvert --validate\n```\n\nIf you get a Traceback with error messages, look for the relevant validation error and fix it.\nIf the output is very long, it may help if you search it for lines starting with `jsonschema.exceptions.ValidationError`.\n\nIf you prefer to use Docker, you can use the [`cffconvert` Docker image](https://hub.docker.com/r/citationcff/cffconvert):\n\n```bash\ncd <directory-containing-your-CITATION.cff>\ndocker run --rm -v ${PWD}:/app citationcff/cffconvert --validate\n```\n\n<!-- Later, this should link to tutorials -->\n\n## Tools to work with `CITATION.cff` files :wrench:\n\nThere is tooling available to work with `CITATION.cff` files to do different things:\ncreate new files, edit existing files, validate existing files, convert files from the Citation File Format into another format.\nThe following table gives an overview of the tools that we know about. If there is a tool missing from this table, please [open a new issue](https://github.com/citation-file-format/citation-file-format/issues/new/choose) and let us know.\n\n|                | Creation                                                                        | Editing/Updating                                                    | Validation                                                                      | Conversion                                                                                                                                                                                                                                                                                                                                                                                        |\n| -------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Command line   |                                                                                 |                                                                     | • [cffconvert](#validation-heavy_check_mark)                                    | • [cffconvert](https://pypi.org/project/cffconvert/)<br> • [bibtex-to-cff](https://github.com/monperrus/bibtexbrowser/)<br>• [cff-from-621](https://pypi.org/project/cff-from-621/)<br>• [openCARP-CI](https://git.opencarp.org/openCARP/openCARP-CI/-/tree/master/#create_cff)                                                                                                                   |\n| GitHub Actions |                                                                                 |                                                                     | [cff-validator](https://github.com/marketplace/actions/cff-validator)           | • [cffconvert](https://github.com/marketplace/actions/cffconvert)<br>• [codemeta2cff](https://github.com/caltechlibrary/codemeta2cff)                                                                                                                                                                                                                                                             |\n| GitHub Bot     |                                                                                 |                                                                     | [#238](https://github.com/citation-file-format/citation-file-format/issues/238) |                                                                                                                                                                                                                                                                                                                                                                                                   |\n| Docker         |                                                                                 |                                                                     | [cffconvert Docker image](#validation-heavy_check_mark)                         | [cffconvert Docker image](https://hub.docker.com/r/citationcff/cffconvert)                                                                                                                                                                                                                                                                                                                        |\n| Go             |                                                                                 |                                                                     |                                                                                 | • [datatools/codemeta2cff](https://github.com/caltechlibrary/datatools/)                                                                                                                                                                                                                                                                                                                          |\n| Haskell        |                                                                                 | • [cffreference](https://github.com/kevinmatthes/cffreference)      |                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                   |\n| Java           | • [CFF Maven plugin](https://github.com/hexatomic/cff-maven-plugin)             | • [CFF Maven plugin](https://github.com/hexatomic/cff-maven-plugin) |                                                                                 | • [CFF Maven plugin](https://github.com/hexatomic/cff-maven-plugin)                                                                                                                                                                                                                                                                                                                               |\n| JavaScript     |                                                                                 |                                                                     |                                                                                 | • [Citation.js](https://citation.js.org/) [plugin](https://www.npmjs.com/package/@citation-js/plugin-software-formats)                                                                                                                                                                                                                                                                            |\n| Julia          |                                                                                 |                                                                     | • [Bibliography.jl](https://github.com/Humans-of-Julia/Bibliography.jl)         | • [Bibliography.jl](https://github.com/Humans-of-Julia/Bibliography.jl)                                                                                                                                                                                                                                                                                                                           |\n| PHP            |                                                                                 |                                                                     |                                                                                 | • [bibtex-to-cff](https://github.com/monperrus/bibtexbrowser/)                                                                                                                                                                                                                                                                                                                                    |\n| Python         |                                                                                 | • [cff2toml](https://github.com/willynilly/cff2toml)<br> • [doi2cff](https://github.com/citation-file-format/doi2cff) | • [cffconvert](#validation-heavy_check_mark)                                    | • [cff-from-621](https://pypi.org/project/cff-from-621/)<br>• [cff2toml](https://github.com/willynilly/cff2toml)<br>• [cffconvert](https://github.com/citation-file-format/cff-converter-python)<br>• [doi2cff](https://github.com/citation-file-format/doi2cff)<br>• [openCARP-CI](https://git.opencarp.org/openCARP/openCARP-CI/-/tree/master/#create_cff)<br>• [py_bibtex_to_cff_converter](https://github.com/vdplasthijs/py_bibtex_to_cff_converter) |\n| R              |                                                                                 |                                                                     | • [cffr](https://CRAN.R-project.org/package=cffr)                                                                                | • [citation](https://cran.r-project.org/web/packages/citation/)<br>• [r2cff](https://github.com/ocbe-uio/RCFF)<br>• [handlr](https://github.com/ropensci/handlr)<br>• [cffr](https://CRAN.R-project.org/package=cffr)                                                                                                                                                                             |\n| Ruby           | • [ruby-cff](https://github.com/citation-file-format/ruby-cff)                  | • [ruby-cff](https://github.com/citation-file-format/ruby-cff)      | • [ruby-cff](https://github.com/citation-file-format/ruby-cff)                  | • [ruby-cff](https://github.com/citation-file-format/ruby-cff)                                                                                                                                                                                                                                                                                                                                    |\n| Rust           | • [Aeruginous](https://github.com/kevinmatthes/aeruginous-rs)                   | • [Aeruginous](https://github.com/kevinmatthes/aeruginous-rs)       |                                                                                 | • [citeworks](https://github.com/passcod/citeworks)                                                                                                                                                                                                                                                                                                                                               |\n| TypeScript     |                                                                                 |                                                                     |                                                                                 | [#28](https://github.com/citation-file-format/citation-file-format/issues/28#issuecomment-892105342)                                                                                                                                                                                                                                                                                              |\n| Website        | • [cffinit](https://citation-file-format.github.io/cff-initializer-javascript/) |                                                                     |                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                   |\n\n## Maintainers :nerd_face:\n\nThe Citation File Format schema is maintained by\n\n- Stephan Druskat ([@sdruskat](https://github.com/sdruskat/))\n- Jurriaan H. Spaaks ([@jspaaks](https://github.com/jspaaks/))\n\n## Contributing :handshake:\n\nThe Citation File Format is a collaborative project and we welcome suggestions and contributions. We hope one of the invitations below works for you, but if not, please let us know!\n\n:running: **I'm busy, I only have 1 minute**\n- Tell a friend about the Citation File Format, or tweet about it!\n- Give the project a star :star:!\n\n:hourglass_flowing_sand: **I've got 10 minutes - tell me what I should do**\n- Create a `CITATION.cff` file for your repository.\n- Suggest ideas for how you would like to use the Citation File Format, or for an improvement to the format or its tooling.\n- If you know how to validate `CITATION.cff` files, help someone with a validation problem and look at the [issues labeled ![GitHub labels](https://img.shields.io/github/labels/citation-file-format/citation-file-format/validation)](https://github.com/citation-file-format/citation-file-format/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22+label%3Avalidation)\n\n:computer: **I've got a few hours to work on this**\n- Help create tooling for the community by looking at the [issues labeled ![GitHub labels](https://img.shields.io/github/labels/citation-file-format/citation-file-format/tooling)](https://github.com/citation-file-format/citation-file-format/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22+label%3Atooling)\n\n:tada: **I want to help grow the community**\n- Write a blog post or news item for your own community.\n- Organise a hack event or workshop to help others use or improve the Citation File Format.\n\nPlease read the more detailed [contributing guidelines](CONTRIBUTING.md) and [open a GitHub issue](https://github.com/citation-file-format/citation-file-format/issues) to suggest a new idea or let us know about bugs. Please put up pull requests for changes to the format and schema against the `develop` branch!\n\n## License :balance_scale:\n\nCopyright © 2016 - 2023. The Citation File Format Contributors\n\nThis work is licensed under a [Creative Commons Attribution 4.0 International (CC-BY-4.0)](https://creativecommons.org/licenses/by/4.0/legalcode) license.\n\n## Acknowledgments :pray:\n\n**We'd like to thank everyone who has contributed to the Citation File Format!**  \nThey are listed in the [`CITATION.cff`](CITATION.cff) file for this repository. Please open an issue if you find that you are missing from the file.\n\nWe gratefully acknowledge support from:\n\n- The [Institute for Software Technology](https://www.dlr.de/sc/en/desktopdefault.aspx/) of the [German Aerospace Center (DLR)](https://www.dlr.de/en/)\n- The [Netherlands eScience Center](https://www.esciencecenter.nl)\n- The [Software Sustainability Institute](https://software.ac.uk/)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/citychem",
            "repo_link": "https://github.com/matthkarl/citychem",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/climsight",
            "repo_link": "https://github.com/CliDyn/climsight",
            "readme": "# Climate Foresight\n\nPrototype of a system that answers questions about climate change impacts on planned human activities.\n![screencast](https://github.com/koldunovn/climsight/assets/3407313/bf7cd327-c8a9-4a09-bfb5-778269fcd15c)\n\n\n## Running with docker\n\n### simplest: running prebuild container\n\nYou should have [Docker](https://docs.docker.com/engine/install/) installed. Then execute:\n\n```bash\ndocker pull koldunovn/climsight:stable\ndocker run -p 8501:8501 -e OPENAI_API_KEY=$OPENAI_API_KEY climsight\n```\n\nThen open `http://localhost:8501/` in your browser.\n\n### Build and run container with the latest code\n\nYou should have the following packages installed:\n\n- git\n- wget\n- docker\n\nAs long as you have them, do:\n\n```bash\ngit clone https://github.com/koldunovn/climsight.git\ncd climsight\n./download_data.sh\ndocker build -t climsight .\ndocker run -p 8501:8501 climsight\n```\nThen open `http://localhost:8501/` in your browser. If you don't want to add OpenAI key every time, you can expose it through:\n\n```bash\ndocker run -p 8501:8501 -e OPENAI_API_KEY=$OPENAI_API_KEY climsight\n```\nwhere `$OPENAI_API_KEY` not necessarily should be environment variable, you can insert the key directly.\n\nIf you do not have an OpenAI key but want to test Climsight without sending requests to OpenAI, you can run Climsight with the `skipLLMCall` argument:\n```bash\ndocker run -p 8501:8501 -e STREAMLIT_ARGS=\"skipLLMCall\" climsight\n```\n\n## Installation\n\nThe easiest way is to install it through conda or mamba. We recommend mamba, as it's faster. \n\n[Install mamba](https://mamba.readthedocs.io/en/latest/mamba-installation.html#mamba-install) if you don't have it.\n\n```bash\ngit clone https://github.com/koldunovn/climsight.git\ncd climsight\n```\n\nCreate environment and install necessary packages:\n\n```bash\n\nmamba env create -f environment.yml\n```\n\nActivate the environment:\n\n```bash\nconda activate climsight\n```\n## Climsight package installation \n```bash\npip install climsight\n```\n\nFor installation, use either pip alone for all packages and dependencies in a pure Python setup, or use mamba for dependencies followed by pip for Climsight in a Conda environment. Mixing package sources can lead to conflicts and is generally not recommended.\n\n## Before you run\n\nYou have to download example climate data, NaturalEarth coastlines, and the RAG database. To do it simply run:\n\n```bash\npython download_data.py\n```\nIn case you are a developer and want to experiment with the text file based RAG, set the ```--source_files``` flag to ```True``` to also download the origial source files.\n\n```bash\npython download_data.py --source_files=True\n```\n\nYou would also need an [OpenAI API key](https://platform.openai.com/docs/api-reference) to run the prototype. You can provide it as environment variable:\n\n```bash\nexport OPENAI_API_KEY=\"???????\"\n```\n<ins>config settings</ins>\nThere is a possibility to also provide it in the running app. The cost of each request (status September 2023) is about 6 cents with `gpt-4` and about 0.3 cents with `gpt-3.5-turbo` (you can change it in the config file).\nMoreover, if you want to use your own climate data, please adjust the data_settings, variable_mappings, and dimension_mappings according to the structure of your NetCDF files.\n\nAnd you need to export the path of the configuration file. If you don't want to exchange anything and just test the prepared version, simply run\n```bash\nexport CONFIG_PATH=\"./config.yml\"\n```\nOtherwise you might want to adjust this path to direct to an individual config file, but keep in mind that it must be a path relative to the one from where you are running climsight. Also, you will have to adjust the paths in the config file you are using to point back to the climsight data folder. \n\n\nThere is a possibility to also provide it in the running app. The cost of each request (status September 2023) is about 6 cents with `gpt-4` and about 0.3 cents with `gpt-3.5-turbo` (you can change it in the beggining of `climsight.py` script).\n\n\n### Running \n\nChange to the `climsight` folder:\n\n```bash\ncd climsight\nstreamlit run src/climsight/climsight.py\n```\n\nIf you install climsight via pip, make sure to run it in the directory where the data folder has been downloaded:\n```bash\nclimsight\n```\n\nThe browser window should pop up, with the app running. Ask the questions and don't forget to press \"Generate\".\n\n<img width=\"800\" alt=\"Screenshot 2023-09-26 at 15 26 51\" src=\"https://github.com/koldunovn/climsight/assets/3407313/569a4c38-a601-4014-b10d-bd34c59b91bb\">\n\nIf you do not have an OpenAI key but want to test Climsight without sending requests to OpenAI, you can run Climsight with the `skipLLMCall` argument:\n```bash\nstreamlit run src/climsight/climsight.py skipLLMCall\n```\n\n\n## Citation\n\nIf you use or refer to ClimSight in your work, please cite the following publication:\n\nKoldunov, N., Jung, T. Local climate services for all, courtesy of large language models. _Commun Earth Environ_ **5**, 13 (2024). https://doi.org/10.1038/s43247-023-01199-1 \n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cnpypp",
            "repo_link": "https://gitlab.iap.kit.edu/mreininghaus/cnpypp/",
            "readme": "# cnpy++\n\n`cnpy++` is a C++17 library that allows to read and write NumPy data files (.npy and .npz).\nIt is designed in a way to integrate well into the modern C++ ecosystem and it provides features not available\nin any similar C++/npy library.\n\nAdditionally, C bindings are provided for a limited, but most useful subset of the C++ functionality.\n\nIf you find cnpy++ useful for your research, please cite\nM. Reininghaus, *cnpy++: A C++17 library for reading and writing .npy/.npz files*, SoftwareX **21**, 101324 (2023),\ndoi:[10.1016/j.softx.2023.101324](https://doi.org/10.1016/j.softx.2023.101324).\n\n## Motivation\nNumPy data files are a binary data format for serializing multi-dimenstional arrays.\nDue to its simplicity, it is a convenient format for scientific computing to be used not only from within Python. \n\n## Building cnpy++\n\n### Requirements\n\n* a C++17-compatible compiler (gcc and clang have been tested succesfully)\n* libzip-devel (required by default but optional)\n* boost (at least 1.74; if using >=1.78, you can use `boost::span` (see below)\n* optional: pre-installed versions of either Microsoft GSL or gsl-lite\n\n### Instructions\n\ncnpy++ is built via cmake. After downloading the code (say, into `/path/to/cnpy++`), create\na build directory (say, `/path/to/cnpy++-build`). From within that directory, call\n`cmake -DCNPYPP_SPAN_IMPL=<...> /path/to/cnpy++`. cnpy++ needs an implementation of the\n`span<T>` type. This is available in Microsoft GSL, gsl-lite, boost since version 1.78 and in the STL\nif compiling with C++20 support. To select which implementation you want to use, set the CMake\ncache variable `CNPYPP_SPAN_IMPL` to either `MS_GSL`, `GSL_LITE` or `BOOST`. If set to `MS_GSL`\nor `GSL_LITE`, the corresponding library will be downloaded by cmake (using git) if not found already\non the system.\n\nAnother option is `CNPYPP_USE_LIBZIP`, which by default is `ON`, but can be set to `OFF`. In that case,\nall functionality requiring libzip is disabled, i.e. no support for reading/writing NPZ archives.\n\nAfter the cmake invocation returned successfully, call `make cnpy++` to compile the library,\nor just `make` to compile the examples, too.\n\n## Usage\n\n`cnpy++` consists of a header part, `cnpy++.hpp`, which needs to be included in your source file,\nand a compiled part, which can either be a shared or a static library.\n\n\n### Manual\nIf you build `cnpy++` with `cmake -DBUILD_SHARED_LIBS=ON`, you obtain a shared library, `libcnpy++.so`,\nthat you need to link to your executable. On Unix systems with g++ or clang++ compilers, you can run\n\n```bash\ng++ -o my_executable my_executable.cpp -L/path/to/install/dir -lcnpy++\n```\n\nThis works analogously if you use the C bindings with a C compiler.\n\nIn case of a static `cnpy++` build, you need to provide the path to `libcnpy++.a`:\n```bash\ng++ -o my_executable my_executable.cpp /path/to/libcnpy++.a\n```\n\n### cmake-assisted compilation\n\nYou can include cnpy++ in your own cmake-based project without having to install it first e.g. by using\ncmake's `FetchContent`. Add the following snippet to your `CMakeLists.txt`.\n\n```\ninclude(FetchContent)\nFetchContent_Declare(cnpy++\n    GIT_REPOSITORY \"https://gitlab.iap.kit.edu/mreininghaus/cnpypp.git\"\n    GIT_SHALLOW True\n)\nFetchContent_MakeAvailable(cnpy++)\n```\n\n## API documentation\nAll functions, data structures, etc. are placed inside the `cnpypp` namespace. The type alias\n`cnpypp::span<T>` is an alias to the implementation of `span<T>` as explained above.\n\n### Writing data to .npy\n\nTo write data into a NPY file, use one of the overloads of `npy_save()`:\n\n```c++\ntemplate <typename TConstInputIterator>\nvoid npy_save(std::string const& fname, TConstInputIterator start,\n              std::initializer_list<size_t> const shape,\n              std::string_view mode = \"w\",\n              MemoryOrder memory_order = MemoryOrder::C);\n```\nThis function writes data from an interator `start` into the file indicated by the filename `fname`.  \nThe `shape` tuple describes the dimensions of the array, with the total number of elements given\nby the product of all entries of `shape`.  \nThe `mode` parameter can be either \"w\" or \"a\". With \"w\", a potentially existing file is overwritten.\nWith \"a\", data are appended if the file already exists. In that case, the data shape has to match the\nshape in the existing file in all entries except the first.  \nThe `memory_order` parameter indicates the memory order and can be either `MemoryOrder::C`, `MemoryOrder::Fortran`,\nor their aliases `MemoryOrder::RowMajor` and `MemoryOrder::ColumnMajor`.\n\n```c++\ntemplate <typename TConstInputIterator>\nvoid npy_save(std::string const& fname, TConstInputIterator start,\n              cnpypp::span<size_t const> const shape, std::string_view mode = \"w\",\n              MemoryOrder memory_order = MemoryOrder::C)\n```\nUse this overload if `shape` is an array, vector or alike.\n\n```c++\ntemplate <typename TForwardIterator>\nvoid npy_save(std::string const& fname, TForwardIterator first,\n              TForwardIterator last, std::string_view mode = \"w\")\n```\nThis is an overload provided for convenience when the data to be written are available\nvia a pair of multiple-pass forward iterators. They are assumed to be one-dimensional.\n\n```c++\ntemplate <typename T>\nvoid npy_save(std::string const& fname, cnpypp::span<T const> data,\n              std::string_view mode = \"w\")\n```\nThis overload is provided for convenience when your data are in contiguous memory.\n\n```c++\ntemplate <typename TTupleIterator>\nvoid npy_save(std::string const& fname,\n              std::vector<std::string_view> const& labels, TTupleIterator first,\n              cnpypp::span<size_t const> const shape, std::string_view mode = \"w\",\n              MemoryOrder memory_order = MemoryOrder::C)\n```\nWith this overload, it is possible to write labeled \"structured arrays\" (in the terminology of NumPy).\nThe iterator must yield `std::tuple`s of values (e.g. `std::tuple<int, float>`) or references (e.g.\n`std::tuple<int const&, float const&>`). The `label` vector must have a size equal to the number of\nelements in the tuple. A potential use-case is to use a `zip_iterator` from the [range-v3](https://github.com/ericniebler/range-v3)\nlibrary. This way, you can serialize data in a structure-of-arrays layout as array-of-structures.\nAn example of this usage is provided in `examples/range_zip_example.cpp`.\n\n### Writing data to .npz\nNPZ files are just zip archives containing one or more NPY files.\n\n```c++\ntemplate <typename TConstInputIterator>\nvoid npz_save(std::string const& zipname, std::string fname,\n              TConstInputIterator start,\n              std::initializer_list<size_t const> shape,\n              std::string_view mode = \"w\",\n              MemoryOrder memory_order = MemoryOrder::C,\n              CompressionMethod compr_method = CompressionMethod::Deflate)\n              \ntemplate <typename TConstInputIterator>\nvoid npz_save(std::string const& zipname, std::string fname,\n              TConstInputIterator start, cnpypp::span<size_t const> const shape,\n              std::string_view mode = \"w\",\n              MemoryOrder memory_order = MemoryOrder::C,\n              CompressionMethod compr_method = CompressionMethod::Deflate)\n\ntemplate <typename TTupleIterator>\nvoid npz_save(std::string const& zipname, std::string const& fname,\n              std::vector<std::string_view> const& labels, TTupleIterator first,\n              cnpypp::span<size_t const> const shape,\n              std::string_view mode = \"w\",\n              MemoryOrder memory_order = MemoryOrder::C,\n              CompressionMethod compr_method = CompressionMethod::Deflate)\n```\nThe first parameter, `zipname`, refers to the filename of the NPZ archive, while `fname` refers to\nthe filename inside the archive (excluding the \"`.npy`\" extension).\n`shape` and `memory_order` are equal to their counterparts in `npy_save()`.\n`compr_method` defines the compression methods. Valid values are `CompressionMethod::Store` (no compression), `CompressionMethod::Deflate`,\n`CompressionMethod::BZip2`, `CompressionMethod::LZMA` and `CompressionMethod::ZSTD` (the latter two depending on whether\nyour libzip version is sufficiently recent to support these). Note that numpy may not be able to read all of these.\nIf `mode` is equal to `\"w\"`, an already existing NPZ file is overwritten. If equal to `\"a\"`, another\narray is added to the archive. Note that it is not possible to extend an already existing array\nin the same way as it is possible with `npy_save()`.\n\n### Reading data\n```c++\nNpyArray npy_load(std::string const& fname, bool memory_mapped = false)\n```\nreads data from a file with filename `fname`. If `memory_mapped` is false (default), the whole file content is copied into memory.\nIf true, the file gets memory-mapped, meaning its content can be read via pointers just like normal memory. The OS takes care to\nread the requested data from disk when necessary. This is useful when the file is larger than the free memory available.\nThe address space available on 64 bit architectures should be sufficient to map even the largest files.\nThe return type, `NpyArray`, contains the raw data as well as a number of methods to query its metadata and convenience functionality\nlike iterators.\n\n```c++\nNpyArray npz_load(std::string const& fname, std::string const& varname)\n```\nreads the array named `varname` from a NPZ archive with filename `fname` into memory (files with data larger than available memory are currently not supported).\nThe return type, `NpyArray` contains the raw data as well as a number of methods to query its metadata and convenience functionality\nlike iterators.\n\n```c++\nstd::map<std::string, NpyArray> npz_load(std::string const& fname)\n```\nreads all arrays from a NPZ archive with filename `fname` into memory (files with data larger than available memory are currently not supported).\nThe invividual arrays can be accessed from the returned map with their name as key.\n\nThe `NpyArray` class provides the following attributes:\n```c++\nstd::vector<size_t> const NpyArray::shape\n```\nThe shape vector.\n\n```c++\nMemoryOrder NpyArray::memory_order\n```\nThe memory order.\n\n```c++\nstd::vector<std::string> const NpyArray::labels\n```\nA vector of the labels if the array is structured. In case of a plain array without labels,\nthis vector is empty.\n\n```c++\nstd::vector<size_t> const NpyArray::word_sizes\n```\nThe byte sizes (e.g. 4 for `uint32_t`) of the fields of a structured array. In case of a plain array, this vector has only one element.\n\n```c++\ntemplate <typename T>\nT* NpyArray::begin<T>()\n```\nreturns a pointer to the first element, interpreted as type `T`. Note that it makes no sense to provide a `std::tuple` for `T`\nas the data in the file are packed, while a `std::tuple` is likely padded to have its member fields properly aligned. Moreover,\n`std::tuple` does not guarantee any particular order of its members.  \nA number of similar methods are `cbegin<T>()`, `end<T>()`, `cend<T>()`, `data<T>()`.\n\n```c++\ntemplate <typename T>\nsubrange<T const*, T const*> NpyArray::make_range() const\n```\nReturn a range-like object (meaning in particular that it has `begin()`, `end()`, `size()` and alike methods)\nwhich can be used, e.g., in range-based for-loops.\n\n```c++\ntemplate <typename... TArgs>\nsubrange<tuple_iterator<std::tuple<TArgs...>>> NpyArray::tuple_range(bool force_check = false) const\n```\nReturns a range-like object for structured arrays. You need to provide the types of\nthe elements of the structured array as template arguments. If `force_check` is set to `true`, the byte sizes\nof the requested data types are checked against the values found in the file header and an exception is thrown\nif not.\n\n```c++\ntemplate <typename TValueType>\nsubrange<stride_iterator<TValueType>> NpyArray::column_range(std::string_view name) const\n```\nIf you interested only in a particular field of a structured array (data \"column\"). `column_range()` returns\na range that iterates only over the field indicated by its label `name` as parameter.\n\n",
            "project_id": "699"
        },
        {
            "software_organization": "https://helmholtz.software/software/cola",
            "repo_link": "https://github.com/jokergoo/cola",
            "readme": "# cola: A General Framework for Consensus Partitioning <img src=\"https://user-images.githubusercontent.com/449218/54158555-03e3af80-444b-11e9-9773-070823101263.png\" width=250 align=\"right\" style=\"border:4px solid black;\" />\n\n\n[![R-CMD-check](https://github.com/jokergoo/cola/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/cola/actions)\n[ ![bioc](https://bioconductor.org/shields/downloads/devel/cola.svg) ](http://bioconductor.org/packages/stats/bioc/cola)\n[ ![bioc](http://bioconductor.org//shields/lastcommit/devel/bioc/cola.svg) ](http://bioconductor.org/checkResults/devel/bioc-LATEST/cola/)\n\n\n\n## Citation\n\nZuguang Gu, et al., cola: an R/Bioconductor package for consensus partitioning through a general framework, Nucleic Acids Research, 2021. https://doi.org/10.1093/nar/gkaa1146\n\nZuguang Gu, et al., Improve consensus partitioning via a hierarchical procedure. Briefings in bioinformatics 2022. https://doi.org/10.1093/bib/bbac048 \n\n\n\n## Install\n\n*cola* is available on [Bioconductor](http://bioconductor.org/packages/devel/bioc/html/cola.html), you can install it by:\n\n```r\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"cola\")\n```\n\nThe latest version can be installed directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/cola\")\n```\n\n## Methods\n\nThe **cola** supports two types of consensus partitioning.\n\n### Standard consensus partitioning\n\n#### Features\n\n1. It modularizes the consensus clustering processes that various methods can\n   be easily integrated in different steps of the analysis.\n2. It provides rich visualizations for intepreting the results.\n3. It allows running multiple methods at the same time and provides\n   functionalities to compare results in a straightforward way.\n4. It provides a new method to extract features which are more efficient to\n   separate subgroups.\n5. It generates detailed HTML reports for the complete analysis.\n\n\n\n#### Workflow\n\n<img width=\"700\" src=\"https://user-images.githubusercontent.com/449218/52628723-86af3400-2eb8-11e9-968d-b7f47a408818.png\" />\n\nThe steps of consensus partitioning is:\n\n1. Clean the input matrix. The processing are: adjusting outliers, imputing missing\n   values and removing rows with very small variance. This step is optional.\n2. Extract subset of rows with highest scores. Here \"scores\" are calculated by\n   a certain method. For gene expression analysis or methylation data\n   analysis, $n$ rows with highest variance are used in most cases, where\n   the \"method\", or let's call it **\"the top-value method\"** is the variance (by\n   `var()` or `sd()`). Note the choice of \"the top-value method\" can be\n   general. It can be e.g. MAD (median absolute deviation) or any user-defined\n   method.\n3. Scale the rows in the sub-matrix (e.g. gene expression) or not (e.g. methylation data).\n   This step is optional.\n4. Randomly sample a subset of rows from the sub-matrix with probability $p$ and\n   perform partition on the columns of the matrix by a certain partition\n   method, with trying different numbers of subgroups.\n5. Repeat step 4 several times and collect all the partitions.\n6. Perform consensus partitioning analysis and determine the best number of\n   subgroups which gives the most stable subgrouping.\n7. Apply statistical tests to find rows that show significant difference\n   between the predicted subgroups. E.g. to extract subgroup specific genes.\n8. If rows in the matrix can be associated to genes, downstream analysis such\n   as function enrichment analysis can be performed.\n\n#### Usage\n\nThree lines of code to perfrom *cola* analysis:\n\n```r\nmat = adjust_matrix(mat) # optional\nrl = run_all_consensus_partition_methods(\n    mat, \n    top_value_method = c(\"SD\", \"MAD\", ...),\n    partition_method = c(\"hclust\", \"kmeans\", ...),\n    cores = ...)\ncola_report(rl, output_dir = ...)\n```\n\n#### Plots\n\nFollowing plots compare consensus heatmaps with k = 4 under all combinations of methods.\n\n<img src=\"https://user-images.githubusercontent.com/449218/52631118-3a66f280-2ebe-11e9-8dea-0172d9beab91.png\" />\n\n\n### Hierarchical consensus partitioning\n\n\n#### Features\n\n1. It can detect subgroups which show major differences and also moderate differences.\n2. It can detect subgroups with large sizes as well as with tiny sizes.\n3. It generates detailed HTML reports for the complete analysis.\n\n\n#### Hierarchical Consensus Partitioning\n\n\n<img src=\"https://user-images.githubusercontent.com/449218/126491482-31a9496f-cc4d-4c4f-80b7-7b752d8d8d06.png\" width=\"400\" />\n\n\n\n#### Usage\n\nThree lines of code to perfrom hierarchical consensus partitioning analysis:\n\n```r\nmat = adjust_matrix(mat) # optional\nrh = hierarchical_partition(mat, mc.cores = ...)\ncola_report(rh, output_dir = ...)\n```\n\n#### Plots\n\nFollowing figure shows the hierarchy of the subgroups.\n\n<img src=\"https://user-images.githubusercontent.com/449218/100014572-d7b2c280-2dd6-11eb-9265-a84d324122f2.png\" width=\"300\" />\n\nFollowing figure shows the signature genes.\n\n<img src=\"https://user-images.githubusercontent.com/449218/100014657-f913ae80-2dd6-11eb-9bf7-53f733e9f8f0.png\" width=\"600\" />\n\n\n\n## License\n\nMIT @ Zuguang Gu\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/collector-app",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/comando",
            "repo_link": "https://jugit.fz-juelich.de/iek-10/public/optimization/comando",
            "readme": "<!-- This file is part of the COMANDO project which is released under the MIT\nlicense. See file LICENSE for full license details.\n\nAUTHOR: Marco Langiu -->\n# COMANDO\nCOMANDO is a next generation modeling framework for **Component-Oriented Modeling and optimizAtion for Nonlinear Design and Operation of integrated energy systems**.\nAn energy system is considered to be a collection of different interconnected components whose purpose is to satisfy demands of various commodities such as, e.g., electric power, heat and cooling in a variety of different operating conditions.\n\nWhen such a system is built (or extended), there are many design and operational decisions that need to be made.\nIn this context, optimizing the design and operation means finding a set of decisions that results in a minimal value for some generalized costs, taking into account restrictions imposed by individual components, their connections or by other safety-related, social, political, or economic considerations.\n\nCOMANDO provides means to...\n- model existing energy systems and possible extension in a flexible,\n  component-oriented fashion.\n- use the resulting system models to create mathematical optimization problems\n- solve these problems directly or use tools to automatically approximate/\n  reformulate them to a form, more amenable to solution\n\n## Referencing\n\nWhen using COMANDO in an academic context please cite\n[our associated publication](https://doi.org/10.1016/j.compchemeng.2021.107366).\n```bibtex\n@Article{langiu2021comando,\n  title   = {COMANDO: A Next-Generation Open-Source Framework for Energy Systems Optimization},\n  journal = {Computers & Chemical Engineering},\n  volume  = {152},\n  pages   = {107366},\n  year    = {2021},\n  issn    = {0098-1354},\n  doi     = {https://doi.org/10.1016/j.compchemeng.2021.107366},\n  author  = {Marco Langiu and David Yang Shu and Florian Joseph Baader and Dominik Hering and\n             Uwe Bau and André Xhonneux and Dirk Müller and André Bardow and Alexander Mitsos\n             and Manuel Dahmen}\n}\n```\n\n## License\n\nThis project is licensed under the MIT License, for more information please refer to the [LICENSE](LICENSE) file.\n\n## Documentation and support [![Documentation Status](https://readthedocs.org/projects/comando/badge/?version=latest)](https://comando.readthedocs.io/en/latest/?badge=latest)\nThe documentation for COMANDO is hosted on [readthedocs](https://comando.readthedocs.io/en/latest).\nYou can also build it locally, following the [instructions in the docs directory](docs/README.md).\n\n We also have a [Skype group](https://join.skype.com/FLNTDxzn4PVP) where you can ask questions that may be of interest to other users and share your experiences.\n\n## Installation\nAt the moment COMANDO is distributed exclusively via the IEK-10 GitLab server.\nIn the future we plan to upload COMANDO to the Python package index for easy installation with `pip`.\nUntil then we recommend cloning this repository with `git`.\n\n### Installation options\nTo install a basic version of COMANDO issue:\n```shell\n# from the parent directory of this repository...\npython -m pip install .\n```\nAs with most packages, we recommended to install COMANDO within a virtual environment.\nSeveral additional features can be installed by listing them in square brackets and separated by commas, e.g., for the [Pyomo](http://www.pyomo.org/) interface and packages required for automatic linearization you would run:\n```shell\n# from the parent directory of this repository...\n# NOTE: no spaces between features\npython -m pip install .[pyomo,linearization]\n```\nFor a list of all available features refer to [`extra-requirements.txt`](extra-requirements.txt).\n\nIn order to install all available extensions (**recommended**) run:\n```shell\n# from the parent directory of this repository...\npython -m pip install .[all]\n```\nIf you plan on further developing COMANDO, you may want to do an editable user intallation, adding the `-e` flag:\n```shell\n# from the parent directory of this repository...\npython -m pip install -e .[all]\n```\n\nAt this point you have configured COMANDO for the fomulation of models and optimization problems, but not yet for their solution!\nYou can refer to the [interfaces-specific README.md](comando/interfaces/README.md) for insight into which solver and AML interfaces are available and how to install and use them.\n\n### Testing the installation\nWhen comando was installed with the `test` or `dev` features, `pytest` should be available, and you can check if everything worked, by running:\n```shell\n# from the parent directory of this repository...\npython -m pytest tests\n```\nSome tests will be skipped or have expected failures depending on the extras and interfaces you installed.\n\n## Uninstallation\n```shell\n# from anywhere\npython -m pip uninstall comando\n```\n\n## COMANDO Usage\nThis is a short summary of a typical COMANDO workflow.\nFor more detailed information please refer to the documentation.\n\nThe usage of COMANDO can be split into three phases\n\n1. Modeling phase\n   - Component model creation\n   - System model creation\n2. Problem formulation phase\n   - problem generation\n     - objective selection\n     - time-structure selection\n     - scenario-structure selection\n     - providing data\n   - problem reformulation\n     - time discretization\n     - linearization\n     - ...\n3. Problem solution phase\n   - via a solver interface (e.g., [GUROBI](https://www.gurobi.com/), [BARON](https://minlp.com/baron-downloads), [MAiNGO](https://git.rwth-aachen.de/avt.svt/public/maingo))\n   - via an algebraic modeling language (AML) interface (e.g., [GAMS](https://www.gams.com/download/), [PYOMO](http://www.pyomo.org/installation))\n   - via custom algorithm\n\n### Modeling phase\nIn the modeling phase the system behavior is specified in terms of the\ncomponent behavior and system structure.\n\n#### Components\nIn COMANDO a component is the basic building block of an energy system.\nIt represents a model of a generic real-world component, specified via a collection of mathematical expressions in symbolic form.\n\nThe symbols contained in such an expression are either **Parameters** (input data) or **Variables** (representing decisions to be made).\nBoth kinds of symbols may be *'indexed'* or not, i.e., they may represent scalars or vectors of values.\nAn expression that contains any indexed symbol is itself considered to be indexed and it is assumed that all indexed symbols within an expression have conforming dimensions.\n\nWhether a Variable is indexed or not is decided in the modeling phase, by explicitly creating a design variable (scalar) or an operational variable (indexed).\nIn contrast to this, whether a Parameter is indexed or not is decided during the problem formulation phase by assigning a scalar or vector of values.\n\nThe algebraic expressions created in this way can be stored under some name or combined to relational expressions of the form\n\n- e1 <= e2\n- e1 == e2\n- e1 >= e2\n\nconstituting restrictions on the component behavior.\n\nIt is also possible to declare operational variables to be **'states'**, i.e., quantities whose time-derivative is given by some algebraic expression.\nThis allows the consideration of dynamic effects.\n\nComponents may also assign individual algebraic expressions to connectors, allowing them to be interfaced with other components.\nConnectors may be specified as inputs, outputs or bidirectional connectors.\nThe former two restrict the value of the corresponding expression to be nonnegative and nonpositive, respectively, while the latter does not impose additional restrictions.\n\n#### Systems\nSystems are modeled as collections of interconnected components, i.e., a system model consists of a set of components and the specification of how their connectors are connected.\nAs systems inherit from components, they can define additional expressions constraints and connectors (for nesting of subsystems).\n\n### Problem formulation phase\nGiven a system model, COMANDO can currently be used to create a *Problem* object, representing a mathematical optimization problem (OP) of the form:\n\n![](Prob.png)\n\nWhere x and y are the vectors of design- and operation-variables, respectively.\n\n#### Problem generation\nF_I and F_II,s are user-specified scalar and indexed expressions corresponding to one-time and momentary costs, T_s are time horizons for different scenarios s, represented by a set of time-steps with possibly variable length, and S is a set of scenarios with corresponding weights w_s.\n\nThe constraints for the OP are automatically generated from the system model, i.e., all scalar relational expressions are taken as contraints and all indexed relational expressions are taken as constraints, parametrized by t, and s.\n\nThe dependence of the objective and constraint functions on time and scenario can be expressed in terms of the values or parameters p, which are user input.\nThis data can currently be given only in discrete form, i.e., for a discrete time and scenario.\n\n**If any states were defined in the model the corresponding differential equations are currently discretized by default.**\nAn exception is the use of the [Pyomo.DAE](https://pyomo.readthedocs.io/en/stable/modeling_extensions/dae.html) interface, here the time-continuous representation is passed and discretization via collocation can be performed.\nData for the parameter values and initial guesses for the variable values can be provided based on the user-chosen sets T_s and S.\n\n#### Problem reformulation\nIt is possible to use manual or automated reformulations of the original problem formulation.\nAn example reformulation is an automated linearization.\n\n### Problem solution\nGiven a Problem, the user can chose to pass it directly to a solver capable of handling the corresponding problem type, transform the COMANDO Problem to a representation in an AML, or work directly with the COMANDO representation in a custom algorithm to preprocess or solve the Problem.\nA list of available solver and AML interfaces can be found [here](comando/interfaces/README.md).",
            "project_id": "3817"
        },
        {
            "software_organization": "https://helmholtz.software/software/comola",
            "repo_link": "https://github.com/Helmholtz-UFZ/CoMOLA",
            "readme": "# CoMOLA - Constrained Multi-objective Optimization of Land use Allocation\n###### *Michael Strauch and Carola Pätzold*\n###### Contact: michael.strauch@ufz.de\n###### Main reference: [Strauch et al., 2019](https://doi.org/10.1016/j.envsoft.2019.05.003)\n\n### About\nCoMOLA is a free Python tool to optimize the allocation of land use for multiple objectives. It builds upon the open source \"inspyred\" Python library and includes functions for reading, encoding and writing land use maps as well as genome generation and repair mutation algorithms for considering constraints during the optimization procedure. It runs on Windows and Linux and allows for the integration of any model whose prediction (e.g. a value for an ecosystem service) is based on a land use raster map. In its basic form, CoMOLA can be used immediately by inputting a raster map representing the status-quo land use, ready-to-run models written in R including their input data, and (optional) information on constraints. As constraints, the tool can consider (1) transition rules defining which type of land use can be converted into which other type and (2) minimum and maximum area proportions of each land use type within the study area. All relevant settings, such as paths to input data and models as well as optimization-specific parameters (e.g. population size, crossover and mutation rates) and settings related to constraint-handling and raster map-analysis are managed in one single control file (\"config.ini\").\n\n![CoMOLA in a nutshell...](CoMOLA_flowchart.png)\n\nThe tool was systematically tested for different levels of complexity ([Strauch et al., 2019](https://doi.org/10.1016/j.envsoft.2019.05.003)) and applied for agricultural case studies in the Netherlands (Kromme Rijn, 219 km˛) and Central Germany (Lossa, 141 km˛) to best reconcile food production, biodiversity and other ecosystem services ([Verhagen et al., 2018](https://doi.org/10.1016/j.envsci.2018.03.013); [Kaim et al., 2020](https://doi.org/10.3389/frwa.2020.579087)). [Witing et al. (2021)](https://doi.org/10.1111/1365-2664.14176) used CoMOLA to optimize riparian reforestation along the Zwalm River (Belgium) and [Schwarz et al. (2020)](https://doi.org/10.3389/fenvs.2020.00016) optimized a virtual urban region to foster plant species richness, climate regulation and compactness. [Bartkowski et al. (2020)](https://doi.org/10.3389/fenvs.2020.00103) used the tool to investigate the applicability of aligning Agent-Based Modeling with multi-objective land-use allocation. Currently, CoMOLA is providing the optimization environment for the EU research project [OPTAIN](https://www.optain.eu/) (grant agreement No. 862756) to explore optimal strategies to retain water and nutrients in 14 small agricultural catchments across Europe.\n\n## Installation requirements\n\nCoMOLA was developed and tested for Python 2.7.\n\n* Required Python packages\n  * matplotlib\n  * numpy\n  * pylab\n\nFurthermore you need to install R to run external models.\n\n\n## Input\n*(see example files in input folder)*\n\n### Maps\n\n__Land use map (required)__\n\nProvide a land use raster map in ascii format (with consecutive integer values representing the different land use classes, starting with value 1). If no user-defined patch ID map is given, CoMOLA generates a patch ID map where neighboring raster cells of the same type are aggregated.\n\nExample *(land\\_use.asc)*: <pre>\nncols         10\nnrows         10\nxllcorner     4376461.4080843\nyllcorner     5553063.2189224\ncellsize      75\nNODATA_value  -2\n2 6 6 1 1 2 2 3 4 4\n4 6 6 1 5 5 3 6 7 8\n4 2 1 1 4 4 3 3 5 5\n5 2 6 6 8 8 1 1 1 1\n5 7 7 2 5 8 8 4 3 3\n1 7 7 4 6 8 8 4 3 1\n5 2 2 2 6 8 7 5 3 1\n5 5 6 6 3 4 7 5 1 1\n2 2 6 6 3 4 7 3 3 3\n2 6 7 7 3 2 2 1 1 1</pre>\nThis example shows a land use map with 8 land use classes distributed over 100 raster cells. For this example map (and the transition matrix given below) CoMOLA would generate a patch ID map with 39 different patches as shown below. \n\nAutomatically generated patch ID map (if not pre-defined by user): <pre>\nncols         10\nnrows         10\nxllcorner     4376461.4080843\nyllcorner     5553063.2189224\ncellsize      75\nNODATA_value  -2\n1 2 2 3 3 4 4 5 6 6 \n7 2 2 3 8 8 9 10 11 0 \n7 12 3 3 13 13 9 9 14 14 \n15 12 16 16 0 0 17 17 17 17 \n15 18 18 19 20 0 0 21 22 22 \n23 18 18 24 25 0 0 21 22 26 \n27 28 28 28 25 0 29 30 22 26 \n27 27 31 31 32 33 29 30 26 26 \n34 34 31 31 32 33 29 35 35 35 \n34 36 37 37 32 38 38 39 39 39</pre>\n\nThe patch ID map is then encoded as a string of integers (each value is called a gene, representing the land use of a patch) to form the genome of the start individual, i.e. the first individual of the initial population. \n\n__Pre-defined patch ID map (optional)__\n\nIf appropriate provide your own patch ID map as ascii file to delineate the spatial optimization units as needed in your specific case (with consecutive integer values representing the different patches, starting with value 1). For a cell-level optimization, an individual ID must be assigned to each cell. The spatial resolution must be the same as for the land use map. A value of 0 defines patches with a static land use. Whether a land use class is static or not must be also defined in the transition matrix (see below). Static land use classes will be excluded from the optimization.\n\nExample *(patch\\_IDmap\\_eachcell\\_constraint.asc)*: <pre>\nncols         10\nnrows         10\nxllcorner     4376461.4080843\nyllcorner     5553063.2189224\ncellsize      75\nNODATA_value  -2\n1 2 3 4 5 6 7 8 9 10\n11 12 13 14 15 16 17 18 19 0\n20 21 22 23 24 25 26 27 28 29\n30 31 32 33 0 0 34 35 36 37\n38 39 40 41 42 0 0 43 44 45\n46 47 48 49 50 0 0 51 52 53\n54 55 56 57 58 0 59 60 61 62\n63 64 65 66 67 68 69 70 71 72\n73 74 75 76 77 78 79 80 81 82\n83 84 85 86 87 88 89 90 91 92</pre>\nIn this example each cell is a patch and subject to optimization, except those cells with value 0 (which is here land use class 8). Be aware, the more patches you include the more complex is the optimization problem and the more computation time is needed. CoMOLA might perform poor if the numbers of patches is too large (>100).\n\n### Constraints\n\nCoMOLA can handle two types of land use change constraints (simultaneously or stand-alone):\n\n__(1) Transition matrix__\n\nA matrix provided as .txt file defining which type of land use (given in rows) can be converted into which other type (given in columns). 1 = transition is possible, 0 = transition is not possible. \n\nExample *(transition\\_matrix.txt)*: <pre>\n-2 1 2 3 4 5 6 7 8\n1 1 1 1 1 1 1 1 0\n2 1 1 1 1 1 1 1 0\n3 1 1 1 1 1 1 1 0\n4 1 1 1 1 1 1 1 0\n5 1 1 1 1 1 1 1 0\n6 0 0 0 0 0 1 1 0\n7 0 0 0 0 0 0 1 0\n8 0 0 0 0 0 0 0 1</pre>\nPlease note, land use class 8 is defined as static since it cannot be converted into another class, nor can a another class be converted into class 8.\n\n__(2) Total area__\n\nA table provided as .txt file defining minimum and maximum area proportions of each land use type as percentage on total area.\n\nExample *(min\\_max.txt)*: <pre>\nland_use 1 2 3 4 5 6 7 8\nmin 0 0 0 0 0 10 10 0\nmax 100 100 100 100 100 25 30 100</pre>\n\n## External models\n\nCoMOLA handles up to four external models which must be provided as R scripts and stored in separate directories within the models folder (together with their specific input data). Each model evaluates the land use ascii map (as given above) for a specific objective that should be maximized (e.g. a certain ecosystem service). The output of each model is a single value representative for the whole study area (e.g. total agricultural yield) and needs to be written in a .csv file. If the objective value should be minimzed during optimization, multiply the model output with -1.\n\n## Configuration and optimization settings (config.ini)\n\nAll relevant settings, such as paths to input data and models as well as optimization-specific parameters and settings related to constraint-handling and raster map-analysis are managed in one single control file called \"config.ini\". Lines starting with a semicolon (;) are commented out and not used by the algorithm.\n\nconfig.ini example and description of variables: <pre>\n[Dictionary]\n; -----------------------------------------\n; config\\_model \n, Variable                     Description:\n; ----------                   ------------\n; file\\_path\\_R                | file path for R\n; file\\_path\\_Python           | file path for Python\n; modelx\\_folder              | file name of model x folder (1 <= x <= 4)\n; file\\_modelx                | file name of the model x script\n; file\\_outputx               | file name of the output file from model x\n; update\\_filesx              | file names which files of the model folder x \n;                              should be updated in the helping folders\n; max\\_range                  | maximum number of land use classes\n; opt\\_algorithm (string)     | definition of the optimization algorithm,\n;                              available choices are GA or NSGA2 (default)   \n; RPy\\_available (string)     | if RPy2 is available than True or False (default) \n; map                        | if True individuals are printed as ascii map files into the\n;                              model folders else (default) as vectors in a csv file\n; del\\_help\\_folders           | if True (default) delete and create all helping folders \n;                              each time the tool starts, if False you can alternatively\n;                              use the update\\_filex entries for updating important files\n; -----------------------------------------\n; config\\_optimization\\_algorithm \n, Variable                     Description [default value]:\n; ----------                   ------------\n; pop\\_size                   | number of individuals per generation [100]\n; max\\_generations            | maximum number of generations [1]\n; mutation\\_rate              | probability for mutation [0.1]\n; crossover\\_rate             | probability for cross over [1.0]\n; priority                   | land use from NSGA2 candidate is preferred within\n;                              repair mutation [True]\n; maximize                   | direction of optimization [True] \n; extreme\\_seeds              | generate extreme (but feasible) individuals for the first\n;                              generation [False]\n; max\\_repair\\_trials          | maximum number of repair trials within repair mutation\n;                              [10000]  \n; terminator                 | termination criterion, see inspyred docu [default\\_termination]\n; variator                   | variation method, see inspyred docu [default\\_variation]\n;                              for constraint-handling and tabu-memory use repair\\_mutation\n; selector                   | selection method, see inspyred docu [default\\_selection]\n;                              use constrained\\_tournament\\_selection as alternative to \n;                              repair\\_mutation\n;feasible\\_first\\_pop          | if True create feasible individuals for first population\n;                              [False]\n;penalty\\_function            | 1 or 2 (only for constrained\\_tournament\\_selection)\n;                                1: absolute violation measure\n;                                2: normalized violation measure (default)\n;plot\\_results                | if True plot results into a .png file [False]\n; -----------------------------------------\n; config\\_map\\_analysis\n; Variable                     Description [default value]:\n; ----------                   ------------\n; file\\_landuse\\_map           | file name of land use map [none]\n; four\\_neighbours            | analysis of four (True) or eight (False) cell neighbours\n;                            | to generate patches [False]\n; file\\_patch\\_map             | file name of patch ID map [none]\n; file\\_transition            | file name of transition matrix [none]\n; file\\_area                  | file name of total min-max area table [none]\n; file\\_worst\\_fitness         | file name of worst fitness values list [none]\n\n\n[config\\_model]\n\nfile\\_path\\_R = C:/Program Files/R/R-3.3.1/bin/R.exe\nfile\\_path\\_Python = C:/Python27/python.exe\n\nmodel1\\_folder = HabStruct\nfile\\_model1 = HabStruct.R\nfile\\_output1 = HabStruct\\_output.csv \n\nmodel2\\_folder = SYM\nfile\\_model2 = SYM.R\nfile\\_output2 = SYM\\_output.csv \n\nmodel3\\_folder = WYLD\nfile\\_model3 = WYLD.R\nfile\\_output3 = WYLD\\_output.csv \n\n;model4\\_folder = SAR\n;file\\_model4 = SAR.R\n;file\\_output4 = SAR\\_output.csv \n\nmax\\_range = 8\nopt\\_algorithm = NSGA2     \nRPy2\\_available = False\nmap = True\ndel\\_help\\_folders = True\n\n[config\\_optimization\\_algorithm]\n\npop\\_size = 10 \nmax\\_generations = 2\nmutation\\_rate = 0.01\ncrossover\\_rate = 0.9\npriority = True\nmaximize = True\nextreme\\_seeds = False\nmax\\_repair\\_trials = 10000\n\nterminator = special\\_termination,generation\\_termination,diversity\\_termination \nvariator = n\\_point\\_crossover, random\\_reset\\_mutation, repair\\_mutation\n;variator = n\\_point\\_crossover, random\\_reset\\_mutation\n;selector = constrained\\_tournament\\_selection\nfeasible\\_first\\_pop = True\n;penalty\\_function = 2\n;plot\\_results = True\n\n[config\\_map\\_analysis]\n\nfile\\_landuse\\_map = land\\_use.asc\nfour\\_neighbours = True\n;file\\_patch\\_map = patch\\_IDmap\\_eachcell\\_constraint.asc\nfile\\_transition = transition\\_matrix.txt\nfile\\_area = min\\_max.txt\nfile\\_worst\\_fitness = worst\\_fitness\\_values\\_maximize.txt </pre>\n\n## Running CoMOLA\n\nCopy the whole file structure of CoMOLA to your working directory and run \\_\\_init\\_\\_.py from the console: <pre>\npython \\_\\_init\\_\\_.py </pre>\n\nYou can limit the maximum number of threads to be used for parallel computation by adding \"-t x\" to the command, where x is the maximum number of threads, e.g. <pre>\npython \\_\\_init\\_\\_.py -t 2 </pre>\n\n## Output\n\nOnce CoMOLA has been started, a log file (*Time\\_Date\\_optimization\\_log.txt*) is generated in the *output* folder documenting the process of optimization.\n\nA successful run of CoMOLA will provide the following outputs:\n* fitness values for the best solutions (written at the end of the log file and in (*best\\_solutions.csv*)\n* ascii maps for the best solutions \n* the genome and fitness values of all individuals tested in the optimization (*individuals\\_file.csv*)\n\nYou may use the R-script (CoMOLA_postprocessing.R) provided in folder *output\\_analysis* to extract, evaluate and plot the best solutions.\n\nExample plot:\n\n![Example plot](output_analysis/Example_output.png)\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/complexheatmap",
            "repo_link": "https://github.com/jokergoo/ComplexHeatmap",
            "readme": "# Make Complex Heatmaps <a href=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/\"><img src=\"https://jokergoo.github.io/ComplexHeatmap-reference/book/complexheatmap-cover.jpg\" width=240 align=\"right\" style=\"border:2px solid black;\" ></a>\n\n[![R-CMD-check](https://github.com/jokergoo/ComplexHeatmap/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/ComplexHeatmap/actions)\n[![codecov](https://img.shields.io/codecov/c/github/jokergoo/ComplexHeatmap.svg)](https://codecov.io/github/jokergoo/ComplexHeatmap) \n[![bioc](http://www.bioconductor.org/shields/downloads/devel/ComplexHeatmap.svg)](https://bioconductor.org/packages/stats/bioc/ComplexHeatmap/) \n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/ComplexHeatmap.svg)](http://bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html)\n\n<img src=\"http://jokergoo.github.io/complexheatmap_logo.svg\" width=\"550\">\n\n\nComplex heatmaps are efficient to visualize associations between different\nsources of data sets and reveal potential patterns. Here the\n**ComplexHeatmap** package provides a highly flexible way to arrange multiple\nheatmaps and supports various annotation graphics.\n\nThe [**InteractiveComplexHeatmap**](https://github.com/jokergoo/InteractiveComplexHeatmap) package can directly export static complex heatmaps into an interactive Shiny app. Have a try!\n\n## Citation\n\nZuguang Gu, et al., [Complex heatmaps reveal patterns and correlations in multidimensional genomic data](http://bioinformatics.oxfordjournals.org/content/early/2016/05/20/bioinformatics.btw313.abstract), Bioinformatics, 2016.\n\nZuguang Gu. [Complex Heatmap Visualization](https://doi.org/10.1002/imt2.43), iMeta, 2022. \n\n\n## Install\n\n`ComplexHeatmap` is available on [Bioconductor](http://www.bioconductor.org/packages/devel/bioc/html/ComplexHeatmap.html), you can install it by:\n\n```r\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"ComplexHeatmap\")\n```\n\nIf you want the latest version, install it directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/ComplexHeatmap\")\n```\n\n## Usage\n\nMake a single heatmap:\n\n```r\nHeatmap(mat, ...)\n```\n\nA single Heatmap with column annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ...)\nHeatmap(mat, ..., top_annotation = ha)\n```\n\nMake a list of heatmaps:\n\n```r\nHeatmap(mat1, ...) + Heatmap(mat2, ...)\n```\n\nMake a list of heatmaps and row annotations:\n\n```r\nha = HeatmapAnnotation(df = anno1, anno_fun = anno2, ..., which = \"row\")\nHeatmap(mat1, ...) + Heatmap(mat2, ...) + ha\n```\n\n## Documentation\n\nThe full documentations are available at https://jokergoo.github.io/ComplexHeatmap-reference/book/ and the website is at https://jokergoo.github.io/ComplexHeatmap.\n\n## Blog posts\n\nThere are following blog posts focusing on specific topics:\n\n- [Make 3D heatmap](https://jokergoo.github.io/2021/03/24/3d-heatmap/)\n- [Translate from pheatmap to ComplexHeatmap](https://jokergoo.github.io/2020/05/06/translate-from-pheatmap-to-complexheatmap/)\n- [Set cell width/height in the heatmap](https://jokergoo.github.io/2020/05/11/set-cell-width/height-in-the-heatmap/)\n- [Interactive ComplexHeatmap](https://jokergoo.github.io/2020/05/15/interactive-complexheatmap/)\n- [Word cloud as heatmap annotation](https://jokergoo.github.io/2020/05/31/word-cloud-as-heatmap-annotation/)\n- [Which heatmap function is faster?](https://jokergoo.github.io/2020/06/19/which-heatmap-function-is-faster/)\n- [Rasterization in ComplexHeatmap](https://jokergoo.github.io/2020/06/30/rasterization-in-complexheatmap/)\n- [Block annotation over several slices](https://jokergoo.github.io/2020/07/06/block-annotation-over-several-slices/)\n- [Integrate ComplexHeatmap with cowplot package](https://jokergoo.github.io/2020/07/14/integrate-complexheatmap-with-cowplot-package/)\n\n\n## Examples\n\n### Visualize Methylation Profile with Complex Annotations\n\n![complexheatmap_example4](https://user-images.githubusercontent.com/449218/47718635-2ec22980-dc49-11e8-9f01-37becb19e0d5.png)\n\n### Correlations between methylation, expression and other genomic features\n\n![complexheatmap_example3](https://user-images.githubusercontent.com/449218/47718636-2ec22980-dc49-11e8-8db0-1659c27dcf40.png)\n\n### Visualize Cell Heterogeneity from Single Cell RNASeq\n\n![complexheatmap_example2](https://user-images.githubusercontent.com/449218/47718637-2ec22980-dc49-11e8-925e-955c16cfa982.png)\n\n### Making Enhanced OncoPrint\n\n![complexheatmap_example1](https://user-images.githubusercontent.com/449218/47718638-2ec22980-dc49-11e8-845e-21e51d3b8e73.png)\n\n### UpSet plot\n\n<img src=\"https://user-images.githubusercontent.com/449218/102615477-48c76a80-4136-11eb-98d9-3c528844fbe8.png\" width=500 />\n\n### 3D heatmap\n\n![image](https://user-images.githubusercontent.com/449218/112284448-8c77c600-8c89-11eb-8d38-c5538900df20.png)\n\n\n\n## License\n\nMIT @ Zuguang Gu\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cipm",
            "repo_link": "https://github.com/CIPM-tools/CIPM",
            "readme": "# Commit-Based Continuous Integration of architectural Performance Models\n\nThis repository provides the prototypical implementation for the change extraction, change propagation, incremental model update, and adaptive instrumentation of the [CIPM approach](https://sdq.kastel.kit.edu/wiki/CIPM).\n\n# Setup\n\nThis project requires Java 11 for all actions. In particular, if a script is executed in the following, it usually uses Maven to build projects. As a result, the `JAVA_HOME` environment variable must be set, pointing to a JDK 11 (the top-level JDK directory, not the `bin` folder so that Maven can find the Java executable in `%JAVA_HOME%\\bin\\java.exe`). Additionally, any script must be executed from the top-level directory of this repository (and not within the `scripts` directory).\n\nWhen executing one of the scripts, it is possible that the error `Internal error: java.lang.IllegalArgumentException: bundleLocation not found: [home]/.m2/[...]` occurs. In such a case, it can help to delete the file `[home]/.m2/repository/.meta/p2-artifacts.properties` and restart the script.\n\nCurrently, only Windows is supported.\n\n## Build\n\nTo build the complete project for the first time, the script `scripts/build.bat` needs to be executed. Subsequent builds can be executed with the script `scripts/rebuild.bat`.\n\nIf a complete clean build is required, the script `scripts/clean.bat` allows to clean the complete repository with all build artifacts and submodules. Afterward, the script `scripts/build.bat` can be executed again.\n\n## Execute TEAMMATES\n\nWith the script `scripts/build-and-test.bat`, the project is built. In addition, the TEAMMATES case is executed. For more information, see [the test plugin description](commit-based-cipm/tests/cipm.consistency.vsum.test).\n\n## Simple Setup with Eclipse\n\nWith the following steps, the project can be setup within Eclipse to view the source code. It is possible to also edit the code, but not to test it. As a reminder, this project requires Java 11. As Eclipse version, the Eclipse Modeling Tools 2022-09 are currently supported.\n\n1. In Eclipse, install the plugins from the CIPM update site.\n\n1. Import any CIPM plugin.\n\n## Full Setup with Eclipse\n\nThe following steps are necessary to setup the project for development within Eclipse. As a reminder, this project requires Java 11. As Eclipse version, the project currently supports the Eclipse Modeling Tools 2022-09. It requires the installation of Xtext (from the Marketplace), Lombok (from [its update site](https://projectlombok.org/p2)), and Checkstyle (optional, from [update site](https://checkstyle.org/eclipse-cs-update-site)).\n\n1. Execute the `scripts/build.bat` script if it was not executed before.\n\n1. After executing the script, all bundles from `commit-based-cipm/bundles/fi` and `commit-based-cipm/releng-dev` can be imported into the Eclipse instance. The `releng-dev` directory contains the bundle `cipm.consistency.targetplatform` with the `cipm.consistency.targetplatform.target` file. Within Eclipse, open this file and click on `Set as active target platform`. Wait until the target platform is set, loaded, and the plugins are successfully compiled. It is possible that the target platform needs to be reloaded.\n\n1. The project requires a second running Eclipse instance. After all plugins in the first instance has been setup, start the provided `SecondInstance` run configuration. It should start the second instance. In the second instance, import all bundles from `commit-based-cipm/bundles/si` and `commit-based-cipm/tests`. In `cipm.consistency.vsum.test`, the test cases should be executable.\n\n## About the Internal Structure of the Setup\n\nThe current build process provides a replicable build. Therefore, dependencies are provided via Eclipse P2 Update Sites with fixed versions or via Git submodules. In particular, the submodules include JaMoPP, SoMoX, and a specialized old Vitruv version. As the submodules only contain source code, they need to be compiled after cloning the repository or if they are cleaned. The build process contains necessary steps to build the submodules.\n\nThe artifacts from the submodules are also packaged into local Eclipse P2 Update Sites. Unfortunately, Maven Tycho, which is internally used to build the artifacts, does not support local Eclipse P2 Update Sites via file paths and requires HTTP or HTTPS paths instead. Thus, a simple update site server, which serves the local Eclipse P2 Update Sites, is started and stopped during the build process.\n\nThe Reactions language from Vitruv detects the meta-models from Vitruv domains. To find the Vitruv domains, the corresponding lookup mechanisms in Eclipse and in the build process require the domains and domain providers to be built and to be on the classpath. As a consequence, a separation between the bundles is performed. The first half of the bundles (located in `commit-based-cipm/bundles/fi`, also imported into the first Eclipse instance) contain two domains (one for the instrumentation model and one adjusted domain for Java) so that they are built in a first build step and for the second Eclipse instance. In the second build step and in the second Eclipse instance, the built domains can be found by the Reactions language.\n\nNotes on generating code for Reactions in the build process: \n\n1. The plugin containing Reactions requires a `.maven_enable_dsls-generation` file in the plugin directory (the `[plugin name]` directory, not `[plugin name]/src`). \n\n2. Furthermore, all classes or methods imported within a Reactiosn file cannot be located in the same plugin as the Reactions. They need to be in separated plugins.\n\n# Executing the Pipeline with TeaStore or TEAMMATES\n\nThe manual to execute the pipeline with TeaStore or TEAMMATES can be found [here](commit-based-cipm/tests/cipm.consistency.vsum.test). Reference PCM repository models for these executions can be found [here](data).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/copy-paste-imputation",
            "repo_link": "https://github.com/KIT-IAI/CopyPasteImputation",
            "readme": "# Copy-Paste Imputation (CPI) for Energy Time Series\n\nThis repository contains the Python implementation of the Copy-Paste Imputation (CPI) method presented in the following paper:\n>M. Weber, M. Turowski, H. K. Çakmak, R. Mikut, U. Kühnapfel and V. Hagenmeyer, 2021, \"Data-Driven Copy-Paste Imputation for Energy Time Series,\" in IEEE Transactions on Smart Grid, 12, 6, pp. 5409–5419, doi: [10.1109/TSG.2021.3101831](https://doi.org/10.1109/TSG.2021.3101831).\n\n## Installation\n\nTo install this project, perform the following steps:\n1. Clone the project\n2. Open a terminal of the virtual environment where you want to use the project\n3. `cd` into the cloned directory\n4. `pip install .` or `pip install -e .` to install the project editable.\n    * Use `pip install -e .[dev]` to install with development dependencies\n\n## Use\n\n    from cpiets.cpi import CopyPasteImputation\n    import pandas as pd\n\n    cpi = CopyPasteImputation()\n    data = pd.read_csv('data.csv')\n    cpi.fit(data)\n    result = cpi.impute()\n\n### Input Data Requirements\n\n**Example data:**\n\n| time                | energy |\n| ------------------- | ------:|\n| 2012-01-02 00:15:00 |  11.60 |\n| 2012-01-02 00:30:00 |  24.87 |\n| 2012-01-02 00:45:00 |  37.31 |\n\n\nThe names of the columns are arbitrary.\n\n**Assumptions:**\n* There are no missing values (nan) at the start or end of the time series.\n* A day starts with the first value after 0:00 (0:15 in the example above) and ends with 0:00.\n* The time series starts at the beginning of a day and ends at the end of a day.\n\n**Supported time formats:**\n* %Y-%m-%d %H:%M:%S (2020-01-17 13:37:42)\n* %d-%b-%Y %H:%M:%S (17-Jan-2020 13:37:42)\n\n\n## Example\n\nIn this repository, we included example data derived from the [ElectricityLoadDiagrams20112014](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014) data set.\n\nTo run the CPI method with simple test data, you can run the example\n\n    python example/simple_imputation.py\n\nand play around with the parameters.\n\n\n## Funding\n\nThis project is supported by the Helmholtz Association under the Joint Initiative \"Energy System 2050 - A Contribution of the Research Field Energy\".\n\n\n## License\n\nThis code is licensed under the [LGPL-3.0 License](COPYING).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/corc",
            "repo_link": "https://github.com/KIT-TVA/CorC",
            "readme": "# CorC\n\nCbC is an approach to create correct programs incrementally. Guided by pre-/postcondition specifications, a program is developed using refinement rules, guaranteeing the implementation is correct. With [CorC](https://github.com/KIT-TVA/CorC/wiki), we implemented a graphical and textual IDE to create programs following the CbC approach. Starting with an abstract specification, CorC supports CbC developers in refining a program by a sequence of refinement steps and in verifying the correctness of these refinement steps using a deductive verifier.\n\n# C-CorC\nCorC for information flow ([C-CorC](https://github.com/KIT-TVA/CorC/wiki/CorC-for-Information-Flow)) is an extension of CorC. \n\n# Getting Started\n## Java Version\nInstall [**JDK 16**](https://www.oracle.com/java/technologies/javase/jdk16-archive-downloads.html). CorC may not work out of the box with newer versions.\n## Eclipse Modelling Tools\n- Install [Eclipse Modelling Tools (EMT)](https://www.eclipse.org/downloads/packages/release/2023-09/r/eclipse-modeling-tools) (Version 2023-09). \n- Get the latest release of [Z3](https://github.com/Z3Prover/z3/releases) and add the `*/z3-[cur-version]-[x64/x32]-win/bin` folder to the environment variable [PATH](https://www.wikihow.com/Change-the-PATH-Environment-Variable-on-Windows)\n\n## EMT Plugins\n- **Graphiti** Install Graphiti using the update site https://download.eclipse.org/graphiti/updates/release/0.18.0\n\n- **FeatureIDE** Available in [Eclipse Marketplace](https://marketplace.eclipse.org/content/featureide)\n\n- **Mylyn** Available in [Eclipse Marketplace](https://marketplace.eclipse.org/content/mylyn) (Mylyn 3.23)\n\n- **TestNG** Available in [Eclipse Marketplace](https://marketplace.eclipse.org/content/testng-eclipse)\n\n## CorC Setup\n1. Clone the repo:\n    ```sh\n    git clone https://github.com/KIT-TVA/CorC.git\n    ```\n2. In EMT, select `Open Projects... -> CorC` and check the boxes for the following packages:\n    - `de.tu-bs.cs.isf.cbc.exceptions`\n    - `de.tu-bs.cs.isf.cbc.model`\n    - `de.tu-bs.cs.isf.cbc.mutation`\n    - `de.tu-bs.cs.isf.cbc.tool`\n    - `de.tu-bs.cs.isf.cbc.util`\n    - `de.tu-bs.cs.isf.cbcclass.tool`\n    - `de.tu-bs.cs.isf.wizards`\n    - `de.tu_bs.cs.isf.cbc.parser`\n    - `de.tu_bs.cs.isf.cbc.statistics`\n    - `de.tu_bs.cs.isf.cbc.statistics.ui`\n    - `de.tu_bs.cs.isf.commands.toolbar`\n    - `de.tu_bs.cs.isf.lattice`\n\n3.  Open:\n    - `*.cbc.model -> model -> genmodel.genmodel`\n    - `*.cbc.statistics -> model -> cbcstatistics.genmodel` \n    \n    Right click and `Generate Model/Edit/Editor Code` for all files listed.\n    If EMT still displays errors, clean and rebuild all projects as described in the [common issues](#common-issues) section.\n\n4. Select any package and run project as `Eclipse Application`.\n\n# Examples & Case Study Introduction\nWe provide different examples and case studies to explore CorC!\n## Examples\nCreate CorC-examples via `File -> New -> Other... -> CorC -> CorC Examples`.\n## Case studies\nThe repository you checked out contains various software product line case studies in the folder `CaseStudies`. They can be loaded via `File -> Open project from file system`. \n### BankAccount\nThe BankAccount implements basic functions of a bank account such as withdrawals, limits, money transfers and checking the account balance.\n- **BankAccount** Object-oriented implementation with class structure and CbC-Classes.\n- **BankAccountOO** Object-oriented implementation with class structure and CbC-Classes. Non-SPL implementation.\n### Elevator\nThe Elevator implements basic functions of an elevator such as the movement and entering and leaving of persons.\n- **Elevator** Object-oriented implementation with class structure and CbC-Classes.\n### Email\nThe product line Email implements basic functions of an email system including server- and client-side interactions.\n- **EmailOO** Object-oriented implementation with class structure and CbC-Classes. Non-SPL implementation.\n- **EmailFeatureInteraction** Java-Implementation without implementation with CbC.\n### IntegerList\nThe IntegerList implements a list of integers with add and sort operations.\n- **IntegerList** Object-oriented implementation with class structure and CbC-Classes.\n- **IntegerListOO** Object-oriented implementation with class structure and CbC-Classes. Non-SPL implementation.\n\n# Common Issues\n\n**Problem:** EMT gets stuck while trying to generate a model.\n\n**Solution:** Terminate EMT using any process manager and generate the model again.\n\n---\n\n**Problem:** Multiple resolving errors after generating model files.\n\n**Solution:** Clean and rebuild all projects via `Project -> Clean...`.\n\n---\n\n**Problem:** Cycling depedency issues.\n\n**Solution:** Navigate to: `Project -> Properties -> Java Compiler -> Building -> Configure Workspace Settings -> Build path problems -> Circular dependencies` and set the listbox to `Warning`.\n\n---\n\n**Problem:** Errors in certain files about undefined methods and classes.\n\n**Solution:** Changing the compliance: `Project -> Java Compiler -> JDK Complicance -> Use compliance from execution environment 'JavaSE-16'`.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/corsika",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/cosmoscout-vr",
            "repo_link": "https://github.com/cosmoscout/cosmoscout-vr",
            "readme": "<!-- \nSPDX-FileCopyrightText: German Aerospace Center (DLR) <cosmoscout@dlr.de>\nSPDX-License-Identifier: CC-BY-4.0\n -->\n \n<p align=\"center\"> \n  <img src =\"resources/logo/large.svg\" />\n</p>\n\nCosmoScout VR is a modular virtual universe developed at the German Aerospace Center (DLR).\nIt lets you explore, analyze and present huge planetary data sets and large simulation data in real-time.\n\n[![Build Status](https://github.com/cosmoscout/cosmoscout-vr/workflows/Build/badge.svg?branch=main)](https://github.com/cosmoscout/cosmoscout-vr/actions)\n[![REUSE](https://api.reuse.software/badge/github.com/cosmoscout/cosmoscout-vr)](https://api.reuse.software/info/github.com/cosmoscout/cosmoscout-vr)\n[![Coverage Status](https://coveralls.io/repos/github/cosmoscout/cosmoscout-vr/badge.svg?branch=main)](https://coveralls.io/github/cosmoscout/cosmoscout-vr?branch=main)\n[![documentation](https://img.shields.io/badge/Docs-online-34D058.svg)](docs/README.md)\n[![license](https://img.shields.io/badge/License-MIT-purple.svg)](LICENSE.md)\n[![source loc](https://img.shields.io/badge/LoC-15.6k-green.svg)](tools/cloc.sh)\n[![plugin loc](https://img.shields.io/badge/LoC_Plugins-24.5k-green.svg)](tools/cloc.sh)\n[![comments](https://img.shields.io/badge/Comments-8.1k-yellow.svg)](tools/cloc.sh)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3381953.svg)](https://doi.org/10.5281/zenodo.3381953)\n\nThe software can be build on Linux (gcc or clang) and Windows (msvc).\nNearly all dependencies are included as [git submodules](externals), please refer to the [**documentation**](docs) in order to get started.\n\n# Features\n\n<p align=\"center\"> \n  <img src =\"docs/img/banner-mars.jpg\" />\n</p>\n\nBelow is a rough sketch of the possibilities you have with CosmoScout VR.\nWhile this list is far from complete it provides a good overview of the current feature set.\nYou can also read the [**changelog**](docs/changelog.md) to learn what's new in the current version. There is also an [**interesting article in the DLR magazine**](https://dlr.de/dlr/portaldata/1/resources/documents/dlr_magazin_161_EN/DLR-Magazin_161-GB/?page=18), and [**several papers**](docs/citation.md) which provide some insight into the ideas behind CosmoScout VR. \n\n- [X] Solar System Simulation\n  - [X] Positioning of celestial bodies and space crafts based on [SPICE](https://naif.jpl.nasa.gov/naif)\n  - [X] Rendering of highly detailed level-of-detail planets based on WebMapServices (with [csp-lod-bodies](plugins/csp-lod-bodies))\n  - [X] Rendering of configurable atmospheres (Mie- and Rayleigh-scattering) around planets (with [csp-atmospheres](plugins/csp-atmospheres))\n  - [X] Physically based rendering of 3D satellites (with [csp-satellites](plugins/csp-satellites))\n  - [X] Rendering of Tycho, Tycho2 and Hipparcos star catalogues (with [csp-stars](plugins/csp-stars))\n  - [X] Rendering of orbits and trajectories based on SPICE (with [csp-trajectories](plugins/csp-trajectories))\n  - [X] Rendering of shadows\n  - [X] HDR-Rendering\n- [x] Flexible User Interface\n  - [X] Completely written in JavaScript with help of the [Chromium Embedded Framework](https://bitbucket.org/chromiumembedded/cef/src)\n  - [X] Main UI can be drawn in the screen- or world-space\n  - [X] Web pages can be placed on planetary surfaces\n  - [X] Interaction works both in VR and on the Desktop\n  - [x] Clear API between C++ and JavaScript \n- [ ] Cross-Platform\n  - [X] Runs on Linux\n  - [X] Runs on Windows\n  - [ ] Runs on MacOS\n- [ ] System Architecture\n  - [X] Plugin-based - most functionality is loaded at run-time\n  - [ ] Network synchronization of multiple instances\n- [x] Hardware device support - CosmoScout VR basically supports everything which is supported by [ViSTA](https://github.com/cosmoscout/vista) and [VRPN](https://github.com/vrpn/vrpn). The devices below are actively supported (or planned to be supported).\n  - [X] Mouse\n  - [X] Keyboard\n  - [X] HTC-Vive\n  - [X] ART-Tracking systems\n  - [X] 3D-Connexion Space Navigator\n  - [X] Multi-screen systems like tiled displays or CAVE's\n  - [X] Multi-screen systems on distributed rendering clusters\n  - [X] Side-by-side stereo systems\n  - [X] Quad-buffer stereo systems\n  - [X] Anaglyph stereo systems\n  - [x] Game Pads like the X-Box controller\n\n# Getting Started\n\n<p align=\"center\"> \n  <img src =\"docs/img/banner-light-shafts.jpg\" />\n</p>\n\n:warning: _**Warning:** CosmoScout VR is research software which is still under heavy development and changes on a daily basis.\nMany features are badly documented, it will crash without warning and may do other unexpected things.\nWe are working hard on improving the user experience - please [report all issues and suggestions](https://github.com/cosmoscout/cosmoscout-vr/issues) you have!_\n\nFor each release, [binary packages](https://github.com/cosmoscout/cosmoscout-vr/releases) are automatically created via [Github Actions](https://github.com/cosmoscout/cosmoscout-vr/actions).\n\nWhen started for the very first time, some example datasets will be downloaded from the internet.\n**This will take some time!**\nThe progress of this operation is shown on the loading screen.\n\n\nIf the binary releases do not work for you or you want to test the latest features, you have to compile CosmoScout VR yourself.\nThis is actually quite easy as there are several guides in the **[`docs`](docs)** directory to get you started!\n\n# Plugins for CosmoScout VR\n\nCosmoScout VR can be extended via plugins.\nIn fact, without any plugins, CosmoScout VR is just a black and empty universe. Here is a list of plugins which are included in this repository.\nThere are also additional plugins which are listed further below.\n\nCore Plugins | Description | Screenshot\n:----|:-----------------|:----------\n[csp-anchor-labels](plugins/csp-anchor-labels) | Draws a click-able label at each celestial anchor. When activated, the user automatically travels to the selected body. The size and overlapping-behavior of the labels can be adjusted. | ![screenshot](docs/img/csp-anchor-labels.jpg)\n[csp-atmospheres](plugins/csp-atmospheres) | Draws atmospheres around celestial bodies. It supports multiple atmospheric models. | ![screenshot](docs/img/csp-atmospheres.jpg)\n[csp-custom-web-ui](plugins/csp-custom-web-ui) | Allows adding custom HTML-based user interface elements as sidebar-tabs, as floating windows or into free space. | ![screenshot](docs/img/csp-custom-web-ui.jpg)\n[csp-demo-node-editor](plugins/csp-demo-node-editor) | An example on how to use the `csl-node-editor` plugin library for creating data flow graphs within CosmoScout VR. | ![screenshot](docs/img/csp-demo-node-editor.jpg)\n[csp-fly-to-locations](plugins/csp-fly-to-locations) | Adds several quick travel targets to the sidebar. It supports shortcuts to celestial bodies and to specific geographic locations on those bodies. | ![screenshot](docs/img/csp-fly-to-locations.jpg)\n[csp-lod-bodies](plugins/csp-lod-bodies) | Draws level-of-detail planets and moons. This plugin supports the visualization of entire planets in a 1:1 scale. The data is streamed via Web-Map-Services (WMS) over the internet. A dedicated MapServer is required to use this plugin. | ![screenshot](docs/img/csp-lod-bodies.jpg)\n[csp-measurement-tools](plugins/csp-measurement-tools) | Provides several tools for terrain measurements. Like measurement of distances, height profiles, volumes or areas. | ![screenshot](docs/img/csp-measurement-tools.jpg)\n[csp-minimap](plugins/csp-minimap) | Displays a configurable 2D-Minimap in the user interface. | ![screenshot](docs/img/csp-minimap.jpg)\n[csp-recorder](plugins/csp-recorder) | A CosmoScout VR plugin which allows basic capturing of high-quality videos. Requires that `csp-web-api` is enabled. | ![screenshot](docs/img/csp-recorder.jpg)\n[csp-rings](plugins/csp-rings) | Draws simple rings around celestial bodies. The rings can be configured with an inner and an outer radius and a texture. | ![screenshot](docs/img/csp-rings.jpg)\n[csp-satellites](plugins/csp-satellites) | Draws GTLF models at positions based on SPICE data. It uses physically based rendering for surface shading. | ![screenshot](docs/img/csp-satellites.jpg)\n[csp-sharad](plugins/csp-sharad) | Renders radar datasets acquired by the Mars Reconnaissance Orbiter. The SHARAD profiles are rendered inside of Mars, the Martian surface is made translucent in front of the profiles. | ![screenshot](docs/img/csp-sharad.jpg)\n[csp-simple-bodies](plugins/csp-simple-bodies) | Renders simple spherical celestial bodies. The bodies are drawn as an ellipsoid with an equirectangular texture. | ![screenshot](docs/img/csp-simple-bodies.jpg)\n[csp-stars](plugins/csp-stars) | Draws 3D-stars loaded from catalogues. For now Tycho, Tycho2 and the Hipparcos catalogue are supported. | ![screenshot](docs/img/csp-stars.jpg)\n[csp-timings](plugins/csp-timings) | Uses the built-in timer queries of CosmoScout VR to draw on-screen live frame timing statistics. This plugin can also be used to export recorded time series to a CSV file. | ![screenshot](docs/img/csp-timings.jpg)\n[csp-trajectories](plugins/csp-trajectories) | Draws trajectories of celestial bodies and spacecrafts based on SPICE. The color, length, number of samples and the reference frame can be configured. | ![screenshot](docs/img/csp-trajectories.jpg)\n[csp-web-api](plugins/csp-web-api) | Allows to control CosmoScout VR via an HTTP protocol. It also allows capturing screenshots over HTTP. | ![screenshot](docs/img/csp-web-api.jpg)\n[csp-wms-overlays](plugins/csp-wms-overlays) | Overlays time dependent map data from Web-Map-Services (WMS) over bodies rendered by other plugins. | ![screenshot](docs/img/csp-wms-overlays.jpg)\n\nAdditional Plugins | Description | Screenshot\n:----|:-----------------|:----------\n[csp-gaussian-splatting](https://github.com/cosmoscout/csp-gaussian-splatting) | This plugin uses the code provided for the paper \"3D Gaussian Splatting for Real-Time Radiance Field Rendering\" to visualize radiance fields. | ![screenshot](docs/img/csp-gaussian-splatting.jpg)\n[csp-user-study](https://github.com/cosmoscout/csp-user-study) |This plugin was used for the user study of the IEEE Aerospace paper \"CosmoScout VR: A Modular 3D Solar System Based on SPICE\". It can be used to record a series of checkpoints which the user has to fly through. | ![screenshot](docs/img/csp-user-study.jpg)\n\n### Credits\n\nSome badges in this README.md are from [shields.io](https://shields.io). The documentation of CosmoScout VR also uses icons from [simpleicons.org](https://simpleicons.org/).\n\n<p align=\"center\"><img src =\"docs/img/hr.svg\"/></p>\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cp2k",
            "repo_link": "https://github.com/cp2k/cp2k",
            "readme": "# CP2K\n\n[![Release Status][release-badge]][release-link] [![Debian Status][debian-badge]][debian-link]\n[![Fedora Status][fedora-badge]][fedora-link] [![Ubuntu Status][ubuntu-badge]][ubuntu-link]\n[![Arch Status][arch-badge]][arch-link] [![Homebrew Status][homebrew-badge]][homebrew-link]\n[![Docker Status][docker-badge]][docker-link] [![Spack Status][spack-badge]][spack-link]\n[![Conda Status][conda-badge]][conda-link]\n\nCP2K is a quantum chemistry and solid state physics software package that can perform atomistic\nsimulations of solid state, liquid, molecular, periodic, material, crystal, and biological systems.\nCP2K provides a general framework for different modeling methods such as DFT using the mixed\nGaussian and plane waves approaches GPW and GAPW. Supported theory levels include DFT, MP2, RPA, GW,\ntight-binding (xTB, DFTB), semi-empirical methods (AM1, PM3, PM6, RM1, MNDO, ...), and classical\nforce fields (AMBER, CHARMM, ...). CP2K can do simulations of molecular dynamics, metadynamics,\nMonte Carlo, Ehrenfest dynamics, vibrational analysis, core level spectroscopy, energy minimization,\nand transition state optimization using NEB or dimer method.\n\nCP2K is written in Fortran 2008 and can be run efficiently in parallel using a combination of\nmulti-threading, MPI, and CUDA.\n\n## Downloading CP2K source code\n\nTo clone the current master (development version):\n\n```shell\ngit clone --recursive https://github.com/cp2k/cp2k.git cp2k\n```\n\nNote the `--recursive` flag that is needed because CP2K uses git submodules.\n\nTo clone a release version v*x.y*:\n\n```shell\ngit clone -b support/vx.y --recursive https://github.com/cp2k/cp2k.git cp2k\n```\n\nFor more information on downloading CP2K, see [Downloading CP2K](https://www.cp2k.org/download). For\nhelp on git, see [Git Tips & Tricks](https://github.com/cp2k/cp2k/wiki/Git-Tips-&-Tricks).\n\n## Install CP2K\n\nThe easiest way to build CP2K with all of its dependencies is as a\n[Docker container](./tools/docker/README.md).\n\nFor building CP2K from scratch see the [installation instructions](./INSTALL.md).\n\n## Links\n\n- [CP2K.org](https://www.cp2k.org) for showcases of scientific work, tutorials, exercises,\n  presentation slides, etc.\n- [The manual](https://manual.cp2k.org/) with descriptions of all the keywords for the CP2K input\n  file\n- [The dashboard](https://dashboard.cp2k.org) to get an overview of the currently tested\n  architectures\n- [The Google group](https://groups.google.com/group/cp2k) to get help if you could not find an\n  answer in one of the previous links\n- [Acknowledgements](https://www.cp2k.org/funding) for list of institutions and grants that help to\n  fund the development of CP2K\n\n## Directory organization\n\n- [`arch`](./arch): Collection of definitions for different architectures and compilers\n- [`benchmarks`](./benchmarks): Inputs for benchmarks\n- [`data`](./data): Simulation parameters e.g. basis sets and pseudopotentials\n- [`exts`](./exts): Access to external libraries via GIT submodules\n- [`src`](./src): The source code\n- [`tests`](./tests): Inputs for tests and regression tests\n- [`tools`](./tools): Mixed collection of useful scripts related to cp2k\n\nAdditional directories created during build process:\n\n- `lib`: Libraries built during compilation\n- `obj`: Objects and other intermediate compilation-time files\n- `exe`: Where the executables will be located\n\n[arch-badge]: https://img.shields.io/aur/version/cp2k\n[arch-link]: https://aur.archlinux.org/packages/cp2k\n[conda-badge]: https://img.shields.io/conda/vn/conda-forge/cp2k\n[conda-link]: https://anaconda.org/conda-forge/cp2k\n[debian-badge]: https://img.shields.io/debian/v/cp2k\n[debian-link]: https://packages.debian.org/search?keywords=cp2k\n[docker-badge]: https://img.shields.io/docker/v/cp2k/cp2k?label=docker\n[docker-link]: https://hub.docker.com/r/cp2k/cp2k\n[fedora-badge]: https://img.shields.io/fedora/v/cp2k\n[fedora-link]: https://src.fedoraproject.org/rpms/cp2k\n[homebrew-badge]: https://img.shields.io/homebrew/v/cp2k\n[homebrew-link]: https://formulae.brew.sh/formula/cp2k\n[release-badge]: https://img.shields.io/github/v/release/cp2k/cp2k\n[release-link]: https://github.com/cp2k/cp2k/releases\n[spack-badge]: https://img.shields.io/spack/v/cp2k\n[spack-link]: https://packages.spack.io/package.html?name=cp2k\n[ubuntu-badge]: https://img.shields.io/ubuntu/v/cp2k\n[ubuntu-link]: https://packages.ubuntu.com/search?keywords=cp2k\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cryogrid",
            "repo_link": "https://github.com/CryoGrid/CryoGridCommunity_source",
            "readme": "# CryoGrid community model\n\nThis is the community version of *CryoGrid*, a numerical model to investigate land surface processes in the terrestrial cryosphere. This version of *CryoGrid* is implemented in MATLAB.\n\n*Note: This is the latest development of the CryoGrid model family. It comprises the functionalities of previous versions including [CryoGrid3](https://github.com/CryoGrid/CryoGrid3), which is no longer encouraged to be used.*\n\n## Documentation\n\nThe paper [\"The CryoGrid community model - a multi-physics toolbox for climate-driven simulations in the terrestrial cryosphere\"](https://doi.org/10.5194/gmd-16-2607-2023) in published in Geoscientific Model Development and contains a description of the model and instructions to run it (Supplements 1, 3). \n\n## Getting started\n\nBoth [CryoGridCommunity_source](https://github.com/CryoGrid/CryoGridCommunity_source) and [CryoGridCommunity_run](https://github.com/CryoGrid/CryoGridCommunity_run) are required. See [CryoGridCommunity_run](https://github.com/CryoGrid/CryoGridCommunity_run) for details.\nAn instruction video on downloading the CryoGrid community model and running simple simulations is available here: https://www.youtube.com/watch?v=L1GIurc5_J4&t=372s\nThe parameter files and model forcing data for the simple simulations from the video can be downloaded here: http://files.artek.byg.dtu.dk/files/cryogrid/CryoGridExamples/CryoGrid_simpleExamples.zip \n\n## Get involved\n\nThere is an [email group](https://groups.google.com/g/cryogrid) for news, (high-level) discussions and invitation to the annual hackathon, as well as a [slack](https://join.slack.com/t/cryogrid/shared_invite/zt-2487oq3o5-ghOQCw2rLimIk13xft27ZQ) for debugging, (low-level) discussions, community building and other things CryoGrid-related!\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/crystfel",
            "repo_link": "https://gitlab.desy.de/thomas.white/crystfel/",
            "readme": "CrystFEL - Data processing for serial crystallography\n=====================================================\n\nOverview\n--------\n\nCrystFEL is a suite of programs for processing data from [serial\ncrystallography experiments](https://en.wikipedia.org/wiki/Serial_Femtosecond_Crystallography),\nperformed at synchrotron and X-ray free-electron laser facilities, as well as\nin your home lab using an electron microscope.\n\n\nGetting started\n---------------\n\nSee [INSTALL.md](INSTALL.md) for installation instructions, including\nour container registry, installation via package manager and details of\npre-existing installations at X-ray facilities around the world.\n\nCrystFEL can be used from the command line or via a graphical user interface.\nTo start the graphical user interface, run ```crystfel```.\n\nThere is a [video tutorial](https://vimeo.com/585412404), as well as a [text\ntutorial](doc/articles/tutorial.rst) to get you started with processing via the\nGUI.\n\nFor command-line use, standard ```man``` pages are available.  Start with\n```man crystfel```.  The manual pages are also\n[available on the web](https://www.desy.de/~twhite/crystfel/manual.html).\n\n\nDocumentation\n-------------\n\n* [Basic Tutorial](doc/articles/tutorial.rst)\n* [Which indexing method(s) should I use?](doc/articles/indexer-choice.rst)\n* [How to choose the right point group for merging](doc/articles/pointgroup.rst)\n* [How to increase data processing speed](doc/articles/speed.rst)\n* [Real-time data processing](doc/articles/online.rst)\n* [Processing electron diffraction data](doc/articles/electrons.rst)\n* [Symmetry classification for serial crystallography](doc/twin-calculator.pdf)\n* [Matrix conventions used in CrystFEL code](doc/matrix-notation.pdf) - for\n  developers, written mostly for my own benefit.\n* [Hit rate graph](doc/hitrate.png)\n* [Examples folder](doc/examples) - contains some template input files.\n* [Contributing to CrystFEL](CONTRIBUTING.md) - including how to cite CrystFEL\n  and how to find good first issues to work on.\n* [Citation list](https://www.desy.de/~twhite/crystfel/citations.html) - please\n  send us details of your paper, if it's missing!\n* [Scripts folder](scripts) - a miscellany of smaller programs to help at\n  various stages of data processing.\n\n\nJournal articles and book chapters\n----------------------------------\n\n* [Processing serial crystallography data with CrystFEL: a step-by-step\n  guide](https://doi.org/10.1107/S205979831801238X) - covers command-line\n  processing only (pre-dates the GUI).\n* [Recent developments in CrystFEL](http://dx.doi.org/10.1107/S1600576716004751) -\n  now somewhat out of date, but contains some useful information about the\n  algorithms used.\n* [Crystallography and Molecular Imaging using X-ray\n  Lasers](https://doi.org/10.23730/CYRSP-2018-001.605) - an introduction to the\n  biological aspects and possibilities, written for physicists (in contrast to\n  most other articles, which introduce the physical aspects for biologists!).\n* [Original paper about CrystFEL](http://dx.doi.org/10.1107/S0021889812002312)\n  from 2012.  Not open access, but a \"reprint\" is available\n  [here](https://www.desy.de/~twhite/crystfel/db5097-reprint.pdf).\n* [Climbing the Data Mountain: Processing of SFX\n  Data](https://link.springer.com/chapter/10.1007/978-3-030-00551-1_7) -\n  emphasizes data volume issues for XFELs.  Unfortunately not open access.\n* [Processing of XFEL\n  Data](https://link.springer.com/protocol/10.1007/978-1-4939-7000-1_13) -\n  describes the entire processing pipeline.  Unfortunately not open access.\n\n\nAwards\n------\n\nIn 2017, the development of CrystFEL was recognised with the [Max von Laue\nPrize](https://www.desy.de/news/news_search/index_eng.html?openDirectAnchor=1202)\nfrom the [German Society for Crystallography (DGK)](https://dgk-home.de/en/).\n\n\nCiting CrystFEL\n---------------\n\nPlease see [CONTRIBUTING.md](CONTRIBUTING.md) for citation instructions.\n\n\nRelated software\n----------------\n\n[OnDA Monitor](https://www.ondamonitor.com/) for real-time monitoring of data\nquality.  Read [the paper](https://doi.org/10.1107/s1600576716007469).\n\n[Pixel Anomaly Detection Tool](https://github.com/gihankaushyal/PixelAnomalyDetectorTool)\nuses machine learning techniques to find misbehaving detector pixels.\nRead [the paper](https://doi.org/10.1107/s1600576724000116).\n\n[Careless](https://github.com/rs-station/careless) scales and merges data\nusing variational inference.  Use its `stream2mtz` script to import data from\nCrystFEL.  Read [the paper](http://dx.doi.org/10.1038/s41467-022-35280-8).\n\n[DatView](https://github.com/nstander/DatView) helps with multivariate analysis\nof large datasets.  Read [the paper](https://doi.org/10.1107/s1600576719012044).\n[More information here](https://sites.google.com/view/zatsepinlab/resources/datview)\nincluding a tutorial and manual.\n\n\nFunding acknowledgements\n------------------------\n\nDevelopment of CrystFEL is primarily funded by the\n[Helmholtz Association](https://www.helmholtz.de/) via\n[DESY](https://www.desy.de/).\n\nPartial funding for CrystFEL has been provided by:\n\n* The consortium DAPHNE4NFDI in the context of the work of the NFDI e.V. The\n  consortium is funded by the Deutsche Forschungsgemeinschaft (DFG, German\n  Research Foundation) - project number 460248799 (2022-).\n\n* European Union’s Horizon 2020 research and innovation programme under grant\n  agreement No 857641 ([ExPaNDS](https://expands.eu/)) (2019-2023).\n\n* [X-Probe](http://x-probe.org/), a project of the European Union's 2020\n  Research and Innovation Program Under the Marie Skłodowska-Curie grant\n  agreement 637295 (2015-2018).\n\n* The [BMBF](https://www.bmbf.de/) German-Russian Cooperation\n  [SyncFELMed](http://www.syncfelmed.org/), grant 05K14CHA (2014-2017).\n\n* [BioStruct-X](https://www.biostruct-x.eu/), a project funded by the Seventh\n  Framework Programme (FP7) of the European Commission (2011-2016).\n\n\nLicence\n-------\n\nCopyright © 2012-2024 Deutsches Elektronen-Synchrotron DESY, a research centre\nof the Helmholtz Association.\n\nSee [AUTHORS](AUTHORS) as well as individual source code files for full details\nof contributors.\n\nCrystFEL is free software: you can redistribute it and/or modify it under the\nterms of the GNU General Public License as published by the Free Software\nFoundation, either version 3 of the License, or (at your option) any later\nversion.\n\nCrystFEL is distributed in the hope that it will be useful, but WITHOUT ANY\nWARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE.  See the GNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License along with\nCrystFEL.  If not, see <http://www.gnu.org/licenses/>.\n\n\n",
            "project_id": "6"
        },
        {
            "software_organization": "https://helmholtz.software/software/cuas-mpi",
            "repo_link": "https://github.com/tudasc/CUAS-MPI",
            "readme": "# CUAS-MPI &middot; [![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)\n## What is CUAS-MPI?\nCUAS-MPI is an MPI parallel implementation of the Confined-Unconfined Aquifer System model ([CUAS18](#ref-CUAS-2018)) for subglacial hydrology.\nThe implementation relies on the parallel data structures and linear system solvers provided by the Portable, Extensible Toolkit for Scientific Computation ([PETSc](https://petsc.org/)).\nThe model uses a one-layer equivalent porous medium (EPM) approach for efficient (channel-like) and inefficient (cavity-like) subglacial water transport.\nA two-dimensional Darcy-type groundwater flow equation with spatially and temporarily varying hydraulic transmissivity is solved considering confined and unconfined aquifer conditions.\n\n## How to use it?\n\nOne of the integration tests can be used to generate a simple setup to explore the modelling choices and command line options.\nThe example below needs `ncks` and `ncap2` from the [NCO toolkit](https://nco.sourceforge.net/) to manipulate the NetCDF files.\n\n```\n# modifiy according to your installation\nCUAS_BUILD_DIR=$CUAS_ROOT/CUAS-MPI/cmake-build-debug/\n\n# number of MPI processes\nNN=4\n\n#\n# generate simple input file from example integration test\n#\nexact=$CUAS_BUILD_DIR/test/cuascore/integration/test-exactSteadySolution\nmpirun -n $NN $exact 1000.0 101 101 31 86400 out0.nc\n# convert output to CUAS-MPI input and forcing file format\nncks -O -d time,-1 -v topg,bnd_mask,thk out0.nc input.nc\nncap2 -O -s \"bmelt=watersource * 365*24*3600\" out0.nc forcing.nc\n\n# run a simple experiment \n#\ncuas=$CUAS_BUILD_DIR/tools/cuas.exe\n\n# set-up the solver\nTOL=\"-ksp_rtol 1e-7 -ksp_atol 1e-15 -ksp_max_it 10000 -ksp_converged_use_min_initial_residual_norm\"\nexport PETSC_OPTIONS=\"-options_left -ksp_initial_guess_nonzero -pc_type bjacobi -ksp_type gmres $TOL\"\n\n# make use of many options for this example\nmpirun -n $NN  $cuas --totaltime '15 days' --dt '1 hour' --saveEvery 1 --verbose --outputSize large \\\n       --doChannels --Tmax 100  --Tmin 1.e-08 --initialHead Nzero  $opts \\\n       --conductivity 10 --layerThickness 0.1 \\\n       --flowConstant 3.4e-24 --cavityBeta 5e-4 --basalVelocityIce 1e-6 --supplyMultiplier 1.0 \\\n       --forcingFile forcing.nc  \\\n       input.nc output.nc\n```\n\n## How to install?\n\n### Requirements\n\n- c++ compiler\n  - at least support for c++ 17\n  - the code is tested using gcc/10.2.0\n- MPI\n  - we use OpenMPI\n    - https://www.open-mpi.org/\n    - version 4.0.x and 4.1.x\n- PETSc\n  - https://petsc.org/\n  - we tested version 3.14.6\n  - with MPI support\n- netcdf-c\n  - https://www.unidata.ucar.edu/software/netcdf/\n  - we use version 4.7.4\n  - with MPI and hdf5 1.8.22\n\n### Build\n\nStarting from the CUAS-MPI directory:\n```\ncmake -B build -DCMAKE_BUILD_TYPE=Release -DPETSC_DIR=<petsc-root-directory> -DNETCDF_DIR=<netcdf-root-directory>\ncmake --build build\ncmake --install build --prefix <prefix>\n```\nYou may want to use legacy cmake calls to generate Makefiles and build CUAS-MPI:\n```\nmkdir build\ncd build\ncmake .. -DCMAKE_BUILD_TYPE=Release -DPETSC_DIR=<petsc-root-directory> -DNETCDF_DIR=<netcdf-root-directory> -DCMAKE_INSTALL_PREFIX=<prefix>\nmake\nmake install\n```\n\nCUAS-MPI makes use of the following options:\n| Option | Default | Description                                                                                                  |\n| --- | :---: |--------------------------------------------------------------------------------------------------------------|\n| `CUAS_ENABLE_TESTS` | `OFF` | Enables targets building tests. |\n| `CUAS_ENABLE_DOCS` | `OFF` | Enables targets building documentation. |\n\n## References\n\n<table style=\"border:0px\">\n<tr>\n    <td valign=\"top\"><a name=\"ref-CUAS-2018\"></a>[CUAS18]</td>\n    <td>Beyer, Sebastian and Kleiner, Thomas and Aizinger, Vadym and Rückamp, Martin and Humbert, Angelika\n    <a href=https://doi.org/10.5194/tc-12-3931-2018>\n    A confined–unconfined aquifer model for subglacial hydrology and its application to the Northeast Greenland Ice Stream</a>.\n    In <i>The Cryosphere</i>, pages 3931–3947, 2018.</td>\n</tr>\n<tr>\n    <td valign=\"top\"><a name=\"ref-CUAS-2023\"></a>[CUAS23]</td>\n    <td>Fischler, Yannic and Kleiner, Thomas and Bischof, Christian and Schmiedel, Jeremie and Sayag, Roiy and\n        Emunds, Raban and Oestreich, Lennart Frederik and Humbert, Angelika\n    <a href=https://doi.org/10.5194/gmd-16-5305-2023>\n    A parallel implementation of the confined–unconfined aquifer system model for subglacial hydrology: design,\n    verification, and performance analysis (CUAS-MPI v0.1.0) </a>.\n    In <i>Geoscientific Model Development</i>, pages 5305-5322, 2023.</td>\n</tr>\n</table>\n\n## CUAS-MPI Applications\n\n- Wolovick, Micheal and Humbert, Angelika and Kleiner, Thomas and Rückamp, Martin\n  [Regularization and L-curves in ice sheet inverse models: a case study in the Filchner-Ronne catchment](https://doi.org/10.5194/tc-17-5027-2023),\n  <i>The Cryosphere</i>, vol. 17, no. 12, pages 5027–5060, 2023.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cubegui",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/perftools/cubegui",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/cubelib",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/perftools/cubelib",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/cubew",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/perftools/cubew",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/cudamemtest",
            "repo_link": "https://github.com/ComputationalRadiationPhysics/cuda_memtest",
            "readme": "# cuda_memtest\n\nThis software tests GPU memory for hardware errors and soft errors using CUDA (or OpenCL).\n\n## Note for this Fork\n\nThis is a fork of the original, yet long-time unmaintained project at https://sourceforge.net/projects/cudagpumemtest/ .\n\nAfter our fork in 2013 (v1.2.3), we primarily focused on support for newer CUDA versions and support of newer Nvidia hardware.\nPull-requests maintaining the OpenCL versions are nevertheless still welcome.\n\n## License\n\nIllinois Open Source License\n\nUniversity of Illinois/NCSA  \nOpen Source License\n\nCopyright 2009-2012,    University of Illinois.  All rights reserved.  \nCopyright 2013-2019,    The developers of PIConGPU at Helmholtz-Zentrum Dresden-Rossendorf\n\nDeveloped by:\n\n  Innovative Systems Lab  \n  National Center for Supercomputing Applications  \n  http://www.ncsa.uiuc.edu/AboutUs/Directorates/ISL.html\n\nForked and maintained for newer Nvidia GPUs since 2013 by:\n\n  Axel Huebl and Rene Widera  \n  Computational Radiation Physics Group  \n  Helmholtz-Zentrum Dresden-Rossendorf  \n  https://www.hzdr.de/crp\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of \nthis software and associated documentation files (the \"Software\"), to deal with \nthe Software without restriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell copies of the \nSoftware, and to permit persons to whom the Software is furnished to do so, subject\nto the following conditions:\n\n* Redistributions of source code must retain the above copyright notice, this list \n  of conditions and the following disclaimers.\n\n* Redistributions in binary form must reproduce the above copyright notice, this list\n  of conditions and the following disclaimers in the documentation and/or other materials\n  provided with the distribution.\n\n* Neither the names of the Innovative Systems Lab, the National Center for Supercomputing\n  Applications, nor the names of its contributors may be used to endorse or promote products\n  derived from this Software without specific prior written permission.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, \nINCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR\nPURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT \nOR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER \nDEALINGS WITH THE SOFTWARE.\n\n## Compile and Run\n\n### Compile for CUDA\n\nInside the source directory, run:\n```bash\nmkdir build\ncd build\n# build for NVIDIA architecture sm_35\ncmake -DCMAKE_CUDA_ARCHITECTURES=35 .. \nmake\n```\n\n### Compile for HIP\n\nInside the source directory, run:\n```bash\nmkdir build\ncd build\n# build for NVIDIA architecture MI2XX\ncmake -DCUDA_MEMTEST_BACKEND=hip -DGPU_TARGETS=gfx90a ..\nmake\n```\n\nNote: \n  - In CMake, `..` is the path to the source directory.\n  - You can find the architecture for your NVIDIA GPU on [this site](https://developer.nvidia.com/cuda-gpus).\n\nWe also provide the package `cuda-memtest` in the [Spack package manager](https://spack.io) .\n\n### Run\n\n```\ncuda_memtest\n```\nThe default behavior is running the test on all the GPUs available infinitely.\nThere are options to change the default behavior. \n\n```\ncuda_memtest --disable_all --enable_test 10\ncuda_memtest --stress\n```\nThis runs test 10 (the stress test). `--stress` is equivalent to `--disable_all --enable_test 10 --exit_on_error`\n\n```\ncuda_memtest --stress --num_iterations 100 --num_passes 1\n```\nThis one does a quick sanity check for GPUs with a short run of test 10. More on this later.\n\nSee help message by \n\n```\ncuda_memtest --help\n```\n\n### Sanity Check\n\nThere is a simple script `sanity_check.sh` in the directory. \nThis script does a quick check if one GPU or all GPUs are in bad health.\n\nExample usage: \n```bash\n# copy the cuda_memtest binary first into the same location as this script, e.g.\ncd ..\nmv build/cuda_memtest .\n```\n```\n./sanity_check.sh 0   //check GPU 0\n./sanity_check.sh 1   //check GPU 1 \n./sanity_check.sh     //check All GPUs in the system\n```\n\nFork note: We just run the `cuda_memtest` binary directly.\nConsider this script as a source for inspiration, or so.\n\n### Known Issues\n\n* Even if you compile with AMD HIP the tool binary will be named `cuda_memtest`. \n\n* If you run on AMD GPUs via HIP the tool will mention everywhere CUDA instead of HIP.\n\n* We are **not** maintaining the OpenCL version of this code base.\n  Pull requests restoring and updating the OpenCL capabilities are welcome.\n\n## Test Descriptions\n\n### List of all Tests\n\nRunning \n```\ncuda_memtest --list_tests\n```\nwill print out all tests and their short descriptions, as of 6/18/2009, we implemented 11 tests\n\n```\nTest0 [Walking 1 bit] \nTest1 [Own address test] \nTest2 [Moving inversions, ones&zeros] \nTest3 [Moving inversions, 8 bit pat] \nTest4 [Moving inversions, random pattern] \nTest5 [Block move, 64 moves] \nTest6 [Moving inversions, 32 bit pat] \nTest7 [Random number sequence] \nTest8 [Modulo 20, random pattern] \nTest9 [Bit fade test]  ==disabled by default==\nTest10 [Memory stress test] \n```\n\n### The General Algorithm\n\nFirst a kernel is launched to write a pattern.\nThen we exit the kernel so that the memory can be flushed. Then we start a new kernel to read\nand check if the value matches the pattern. An error is recorded if it does not match for each \nmemory location. In the same kernel, the complement of the pattern is written after the checking. \nThe third kernel is launched to read the value again and checks against the complement of the pattern. \n\n### Detailed Description\n\nTest 0 `[Walking 1 bit]`  \n\tThis test changes one bit a time in memory address to see it\n\tgoes to a different memory location. It is designed to test\n\tthe address wires. \n\nTest 1 `[Own address test]`  \n\tEach Memory location is filled with its own address. The next kernel checks if the \n\tvalue in each memory location still agrees with the address.\n\nTest 2 `[Moving inversions, ones&zeros]`  \n\tThis test uses the moving inversions algorithm with patterns of all\n\tones and zeros. \n\nTest 3 `[Moving inversions, 8 bit pat]`  \n\tThis is the same as test 1 but uses a 8 bit wide pattern of\n\t\"walking\" ones and zeros.  This test will better detect subtle errors\n\tin \"wide\" memory chips. \n\nTest 4 `[Moving inversions, random pattern]`  \n\tTest 4 uses the same algorithm as test 1 but the data pattern is a\n\trandom number and it's complement. This test is particularly effective\n\tin finding difficult to detect data sensitive errors. The random number \n\tsequence is different with each pass so multiple passes increase effectiveness.\n\nTest 5 `[Block move, 64 moves]`  \n\tThis test stresses memory by moving block memories. Memory is initialized\n\twith shifting patterns that are inverted every 8 bytes.  Then blocks\n\tof memory are moved around.  After the moves\n\tare completed the data patterns are checked.  Because the data is checked\n\tonly after the memory moves are completed it is not possible to know\n\twhere the error occurred.  The addresses reported are only for where the\n\tbad pattern was found.\n\nTest 6 `[Moving inversions, 32 bit pat]`  \n\tThis is a variation of the moving inversions algorithm that shifts the data\n\tpattern left one bit for each successive address. The starting bit position\n\tis shifted left for each pass. To use all possible data patterns 32 passes\n\tare required.  This test is quite effective at detecting data sensitive\n\terrors but the execution time is long.\n\nTest 7 `[Random number sequence]`  \n\tThis test writes a series of random numbers into memory.  A block (1 MB) of memory\n\tis initialized with random patterns. These patterns and their complements are\n\tused in moving inversions test with rest of memory.\n\nTest 8 `[Modulo 20, random pattern]`  \n\tA random pattern is generated. This pattern is used to set every 20th memory location\n\tin memory. The rest of the memory location is set to the complement of the pattern.\n\tRepeat this for 20 times and each time the memory location to set the pattern is shifted right.\n\nTest 9 `[Bit fade test, 90 min, 2 patterns]`  \n\tThe bit fade test initializes all of memory with a pattern and then\n\tsleeps for 90 minutes. Then memory is examined to see if any memory bits\n\thave changed. All ones and all zero patterns are used. This test takes\n\t3 hours to complete. The Bit Fade test is disabled by default\n\nTest 10 `[memory stress test]`  \n\tStress memory as much as we can. A random pattern is generated and a kernel of large grid size\n\tand block size is launched to set all memory to the pattern. A new read and write kernel is launched\n\timmediately after the previous write kernel to check if there is any errors in memory and set the\n\tmemory to the complement. This process is repeated for 1000 times for one pattern. The kernel is \n\twritten as to achieve the maximum bandwidth between the global memory and GPU.\n\tThis will increase the chance of catching software error. In practice, we found this test quite useful \n\tto flush hardware errors as well.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/cupla",
            "repo_link": "https://github.com/alpaka-group/cupla",
            "readme": "**cupla** - C++ User interface for the Platform Independent Library alpaka\n==========================================================================\n\n[![Code Status dev](https://gitlab.com/hzdr/crp/cupla/badges/dev/pipeline.svg?key_text=dev)](https://gitlab.com/hzdr/crp/cupla/pipelines/dev/latest)\n\n![cupla Release](doc/logo/cupla_logo_320x210.png)\n\n**cupla** [[qχɑpˈlɑʔ]](https://en.wiktionary.org/wiki/Qapla%27) is a simple user\ninterface for the platform independent parallel kernel\nacceleration library\n[**alpaka**](https://github.com/alpaka-group/alpaka).\nIt follows a similar concept as the\n[NVIDIA® CUDA® API](https://developer.nvidia.com/cuda-zone) by\nproviding a software layer to manage accelerator devices.\n**alpaka** is used as backend for **cupla**.\n\nPlease keep in mind that a first, [\"find & replace\"](doc/PortingGuide.md) port\nfrom **CUDA to cupla(x86)** will result in rather bad performance. In order to\nreach decent performance on x86 systems you just need to add the **alpaka**\n[element level](doc/TuningGuide.md) to your kernels.\n\n(*Read as:* add some *tiling* to your CUDA kernels by letting the same thread\ncompute a fixed number of elements (N=4..16) instead of just computing one\n*element* per thread. Also, make the number of elements in your tiling a\n*compile-time constant* and your CUDA code (N=1) will just stay with the\nvery same performance while adding single-source performance portability for,\ne.g., x86 targets).\n\n\nSoftware License\n----------------\n\n**cupla** is licensed under **LGPLv3** or later.\n\nFor more information see [LICENSE.md](LICENSE.md).\n\n\nDependencies\n------------\n\n- **cmake 3.22.0** or higher (depends on the used alpaka version)\n- **[alpaka 1.0.0](eba6db5d8efc3c2585470085e76ba3dcab510e49)** or newer  \n  - alpaka is loaded as `git subtree` within **cupla**, see [INSTALL.md](INSTALL.md)\n\nUsage\n-----\n\n- See our notes in [INSTALL.md](INSTALL.md).\n- Checkout the [guide](doc/PortingGuide.md) how to port your project.\n- Checkout the [tuning guide](doc/TuningGuide.md) for a step further to performance\n  portable code.\n- Checkout the [interoperability guide](doc/InteroperabilityGuide.md) to learn more on\n  how to use **cupla** with software developed with an **alpaka** compatible interface.\n\n[cupla can be used as a header-only library and without the CMake build system](doc/ConfigurationHeader.md)\n\nContributing\n------------\n\nAny pull request will be reviewed by a [maintainer](https://github.com/orgs/alpaka-group/teams/alpaka-maintainers).\n\nThanks to all [active and former contributors](.rodare.json).\n\n\nTrademarks Disclaimer\n---------------------\n\nAll product names and trademarks are the property of their respective owners.\nCUDA® is a trademark of the NVIDIA Corporation.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/damnit",
            "repo_link": "https://github.com/European-XFEL/DAMNIT",
            "readme": "# DAMNIT\n\n[![Documentation Status](https://readthedocs.org/projects/damnit/badge/?version=latest)](https://damnit.readthedocs.io/en/latest/?badge=latest)\n[![codecov](https://codecov.io/gh/European-XFEL/DAMNIT/graph/badge.svg?token=NGwo3ShLNw)](https://codecov.io/gh/European-XFEL/DAMNIT)\n\nDAMNIT is a tool developed at the European XFEL to help users create an\nautomated overview of their experiment. Check out the documentation for more\ninformation: https://damnit.rtfd.io\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/dasf-messaging-python",
            "repo_link": "https://codebase.helmholtz.cloud/dasf/dasf-messaging-python",
            "readme": "",
            "project_id": "11976"
        },
        {
            "software_organization": "https://helmholtz.software/software/datadesc",
            "repo_link": "https://github.com/FZJ-IEK3-VSA/DataDesc/",
            "readme": "<a href=\"https://www.fz-juelich.de/en/iek/iek-3\"><img src=\"https://raw.githubusercontent.com/OfficialCodexplosive/README_Assets/862a93188b61ab4dd0eebde3ab5daad636e129d5/FJZ_IEK-3_logo.svg\" alt=\"FZJ Logo\" width=\"300px\"></a>\n\n# DataDesc\n\nThe framework surrounding DataDesc, a metadata schema for software documentation with focus on interfaces, comes with a machine-actionable metadata exchange format and a software toolkit supporting the documentation, extraction and publication of software metadata.\n\n## Features\nDataDesc combines four distinct python software packages:\n- a form to convert general software metadata into a DataDesc compliant JSON file\n- a parser for extracting extensive metadata information from python source code to DataDesc compliant JSON\n- a tool for combining two DataDesc compliant JSON files into a single one\n- a tool for uploading DataDesc compliant files to the ORKG, GitHub, PyPI, and more\n\n## Installation\nThe framework can be installed directly via git - this will preserve the connection to the GitHub repository:\n```bash\n\tgit clone https://github.com/FZJ-IEK3-VSA/DataDesc\n```\n\nMost parts of this framework are out-of-the-box solutions which do not need to be installed. For others, a proper installation and usage instruction is provided alongside the files themselves.\n\n## License\n\nMIT License\n\nCopyright (c) 2024 Patrick Kuckertz (FZJ/IEK-3), Jan-Maris Göpfert (FZJ/IEK-3), Oliver Karras (TIB), David Neuroth (FZJ/IEK-3), Julian Schönau (FZJ/IEK-3), Rodrigo Pueblas (FZJ/IEK-3), Stephan Ferenz (University of Oldenburg/ Dept. of Computer Science), Felix Engel (TIB), Noah Pflugradt (FZJ/IEK-3), Jann Michael Weinand (FZJ/IEK-3), Leander Kotzur (FZJ/IEK-3), Astrid Nieße (University of Oldenburg/ Dept. of Computer Science), Sören Auer (TIB), Detlef Stolten (FZJ/IEK-3, RWTH)\n\nYou should have received a copy of the MIT License along with this program.\nIf not, see https://opensource.org/licenses/MIT\n\n## About Us\n\nThe [Institute of Energy and Climate Research - Techno-economic Systems Analysis (IEK-3)](https://www.fz-juelich.de/en/iek/iek-3) belongs to the [Forschungszentrum Jülich](https://www.fz-juelich.de/en). The department's interdisciplinary research is focusing on energy-related process and systems analyses. Data searches and system simulations are used to determine energy and mass balances, as well as to evaluate performance, emissions and costs of energy systems. The results are used for performing comparative assessment studies between the various systems. The current priorities include the development of energy strategies, in accordance with the German Federal Government’s greenhouse gas reduction targets, by designing new infrastructures for sustainable and secure energy supply chains and by conducting cost analysis studies for integrating new technologies into future energy market frameworks.\n\nThe [Data Science & Digtal Libraries research group](https://www.tib.eu/en/research-development/research-groups-and-labs/data-science-digital-libraries) belonging to the [TIB - Leibniz Information Centre for Science and Technology](https://www.tib.eu/en/) was established in July 2017 by the call of Prof. Dr. Sören Auer, which was jointly conducted with [Leibniz Universität Hannover](https://www.uni-hannover.de/de/). The research group serves TIB's strategic goal of improving access to and work with information, data and knowledge. The overall objective of the research group is to transform the current document-based knowledge communication in the sciences (Scholarly Communication) into knowledge-based communication (\"from papers to knowledge graphs\").\n\nThe Digitalized Energy Systems (DES) group is part of the Department of Computer Science of the University of Oldenburg. The group was established by Prof. Astrid Nieße in 2020. The group works in the field of energy informatics and focuses on distributed artificial intelligence, like agent-based systems, strategy learning in energy markets and machine learning approaches for cyber-physical energy systems (CPES).  With the high importance of data and open software in this field, research data management and how to integrate both FAIRness and industry involvement in CPES research, is a rising research area in the DES group.\n\n## Acknowledgements\nThe authors would like to thank the Federal Ministry for Economic Affairs and Energy of Germany (BMWi) for supporting this work with a grant for the project LOD-GEOSS (03EI1005B).\n\nFurthermore, the authors would like to thank the German Federal Government, the German State Governments, and the Joint Science Conference (GWK) for their funding and support as part of the NFDI4Ing consortium. Funded by the German Research Foundation (DFG) - project number: 442146713.\n\nIn addition, the work was supported by the Lower Saxony Ministry of Science and Culture within the Lower Saxony ‘‘Vorab’’ of the Volkswagen Foundation under Grant 11-76251-13-3/19–ZN3488 (ZLE), and by the Center for Digital Innovation (ZDIN).\n\nThis work was also supported by the Helmholtz Association under the program \"Energy System Design\".\n\n<a href=\"https://www.bmwk.de/Navigation/EN/Home/home.html\"><img src=\"https://www.bmwk.de/SiteGlobals/BMWI/StyleBundles/Bilder/bmwi_logo_en.svg?__blob=normal&v=13\" alt=\"BMWK Logo\" width=\"130px\"></a>\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/datalad",
            "repo_link": "https://github.com/datalad/datalad",
            "readme": "     ____            _             _                   _\n    |  _ \\    __ _  | |_    __ _  | |       __ _    __| |\n    | | | |  / _` | | __|  / _` | | |      / _` |  / _` |\n    | |_| | | (_| | | |_  | (_| | | |___  | (_| | | (_| |\n    |____/   \\__,_|  \\__|  \\__,_| |_____|  \\__,_|  \\__,_|\n                                                  Read me\n\n[![DOI](https://joss.theoj.org/papers/10.21105/joss.03262/status.svg)](https://doi.org/10.21105/joss.03262)\n[![Test Status](https://github.com/datalad/datalad/actions/workflows/test.yml/badge.svg)](https://github.com/datalad/datalad/actions/workflows/test.yml)\n[![Build status](https://ci.appveyor.com/api/projects/status/github/datalad/datalad?branch=master&svg=true)](https://ci.appveyor.com/project/mih/datalad/branch/master)\n[![Extensions](https://github.com/datalad/datalad/actions/workflows/test_extensions.yml/badge.svg)](https://github.com/datalad/datalad/actions/workflows/test_extensions.yml)\n[![Linters](https://github.com/datalad/datalad/actions/workflows/lint.yml/badge.svg)](https://github.com/datalad/datalad/actions/workflows/lint.yml)\n[![codecov.io](https://codecov.io/github/datalad/datalad/coverage.svg?branch=master)](https://codecov.io/github/datalad/datalad?branch=master)\n[![Documentation](https://readthedocs.org/projects/datalad/badge/?version=latest)](http://datalad.rtfd.org)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![GitHub release](https://img.shields.io/github/release/datalad/datalad.svg)](https://GitHub.com/datalad/datalad/releases/)\n[![Supported Python versions](https://img.shields.io/pypi/pyversions/datalad)](https://pypi.org/project/datalad/)\n[![Testimonials 4](https://img.shields.io/badge/testimonials-4-brightgreen.svg)](https://github.com/datalad/datalad/wiki/Testimonials)\n[![https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg](https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg)](https://singularity-hub.org/collections/667)\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](https://github.com/datalad/datalad/blob/master/CODE_OF_CONDUCT.md)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.808846.svg)](https://doi.org/10.5281/zenodo.808846)\n[![RRID](https://img.shields.io/badge/RRID-SCR__003931-blue)](https://identifiers.org/RRID:SCR_003931)\n<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->\n[![All Contributors](https://img.shields.io/badge/all_contributors-52-orange.svg?style=flat-square)](#contributors-)\n<!-- ALL-CONTRIBUTORS-BADGE:END -->\n\n## Distribution\n\n[![Anaconda](https://anaconda.org/conda-forge/datalad/badges/version.svg)](https://anaconda.org/conda-forge/datalad)\n[![Arch (AUR)](https://repology.org/badge/version-for-repo/aur/datalad.svg?header=Arch%20%28%41%55%52%29)](https://repology.org/project/datalad/versions)\n[![Debian Stable](https://badges.debian.net/badges/debian/stable/datalad/version.svg)](https://packages.debian.org/stable/datalad)\n[![Debian Unstable](https://badges.debian.net/badges/debian/unstable/datalad/version.svg)](https://packages.debian.org/unstable/datalad)\n[![Fedora Rawhide package](https://repology.org/badge/version-for-repo/fedora_rawhide/datalad.svg?header=Fedora%20%28rawhide%29)](https://repology.org/project/datalad/versions)\n[![Gentoo (::science)](https://repology.org/badge/version-for-repo/gentoo_ovl_science/datalad.svg?header=Gentoo%20%28%3A%3Ascience%29)](https://repology.org/project/datalad/versions)\n[![PyPI package](https://repology.org/badge/version-for-repo/pypi/datalad.svg?header=PyPI)](https://repology.org/project/datalad/versions)\n\n# 10000-ft. overview\n\nDataLad's purpose is to make data management and data distribution more accessible.\nTo do so, it stands on the shoulders of [Git] and [Git-annex] to deliver a\ndecentralized system for data exchange. This includes automated ingestion of\ndata from online portals and exposing it in readily usable form as Git(-annex)\nrepositories - or datasets. However, the actual data storage and permission\nmanagement remains with the original data provider(s).\n\nThe full documentation is available at http://docs.datalad.org and\nhttp://handbook.datalad.org provides a hands-on crash-course on DataLad.\n\n# Extensions\n\nA number of extensions are available that provide additional functionality for\nDataLad. Extensions are separate packages that are to be installed in addition\nto DataLad. In order to install DataLad customized for a particular domain, one\ncan simply install an extension directly, and DataLad itself will be\nautomatically installed with it. An [annotated list of\nextensions](http://handbook.datalad.org/extension_pkgs.html) is available in\nthe [DataLad handbook](http://handbook.datalad.org).\n\n\n# Support\n\nThe documentation for this project is found here:\nhttp://docs.datalad.org\n\nAll bugs, concerns, and enhancement requests for this software can be submitted here:\nhttps://github.com/datalad/datalad/issues\n\nIf you have a problem or would like to ask a question about how to use DataLad,\nplease [submit a question to\nNeuroStars.org](https://neurostars.org/new-topic?body=-%20Please%20describe%20the%20problem.%0A-%20What%20steps%20will%20reproduce%20the%20problem%3F%0A-%20What%20version%20of%20DataLad%20are%20you%20using%20%28run%20%60datalad%20--version%60%29%3F%20On%20what%20operating%20system%20%28consider%20running%20%60datalad%20plugin%20wtf%60%29%3F%0A-%20Please%20provide%20any%20additional%20information%20below.%0A-%20Have%20you%20had%20any%20luck%20using%20DataLad%20before%3F%20%28Sometimes%20we%20get%20tired%20of%20reading%20bug%20reports%20all%20day%20and%20a%20lil'%20positive%20end%20note%20does%20wonders%29&tags=datalad)\nwith a `datalad` tag.  NeuroStars.org is a platform similar to StackOverflow\nbut dedicated to neuroinformatics.\n\nAll previous DataLad questions are available here:\nhttp://neurostars.org/tags/datalad/\n\n\n# Installation\n\n## Debian-based systems\n\nOn Debian-based systems, we recommend enabling [NeuroDebian], via which we\nprovide recent releases of DataLad. Once enabled, just do:\n\n    apt-get install datalad\n\n## Gentoo-based systems\n\nOn Gentoo-based systems (i.e. all systems whose package manager can parse ebuilds as per the [Package Manager Specification]), we recommend [enabling the ::science overlay], via which we\nprovide recent releases of DataLad. Once enabled, just run:\n\n    emerge datalad\n\n## Other Linux'es via conda\n\n    conda install -c conda-forge datalad\n\nwill install the most recently released version, and release candidates are\navailable via\n\n    conda install -c conda-forge/label/rc datalad\n\n## Other Linux'es, macOS via pip\n\nBefore you install this package, please make sure that you [install a recent\nversion of git-annex](https://git-annex.branchable.com/install).  Afterwards,\ninstall the latest version of `datalad` from\n[PyPI](https://pypi.org/project/datalad). It is recommended to use\na dedicated [virtualenv](https://virtualenv.pypa.io):\n\n    # Create and enter a new virtual environment (optional)\n    virtualenv --python=python3 ~/env/datalad\n    . ~/env/datalad/bin/activate\n\n    # Install from PyPI\n    pip install datalad\n\nBy default, installation via pip installs the core functionality of DataLad,\nallowing for managing datasets etc.  Additional installation schemes\nare available, so you can request enhanced installation via\n`pip install datalad[SCHEME]`, where `SCHEME` could be:\n\n- `tests`\n     to also install dependencies used by DataLad's battery of unit tests\n- `full`\n     to install all dependencies.\n\nMore details on installation and initial configuration can be found in the\n[DataLad Handbook: Installation].\n\n# License\n\nMIT/Expat\n\n\n# Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) if you are interested in internals or\ncontributing to the project.\n\n## Acknowledgements\n\nThe DataLad project received support through the following grants:\n\n- US-German collaboration in computational neuroscience (CRCNS) project\n  \"DataGit: converging catalogues, warehouses, and deployment logistics into a\n  federated 'data distribution'\" (Halchenko/Hanke), co-funded by the US National\n  Science Foundation (NSF 1429999) and the German Federal Ministry of\n  Education and Research (BMBF 01GQ1411).\n\n- CRCNS US-German Data Sharing \"DataLad - a decentralized system for integrated\n  discovery, management, and publication of digital objects of science\"\n  (Halchenko/Pestilli/Hanke), co-funded by the US National Science Foundation\n  (NSF 1912266) and the German Federal Ministry of Education and Research\n  (BMBF 01GQ1905).\n\n- Helmholtz Research Center Jülich, FDM challenge 2022\n\n- German federal state of Saxony-Anhalt and the European Regional Development\n  Fund (ERDF), Project: Center for Behavioral Brain Sciences, Imaging Platform\n\n- ReproNim project (NIH 1P41EB019936-01A1).\n\n- Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under grant\n  SFB 1451 ([431549029](https://gepris.dfg.de/gepris/projekt/431549029),\n  INF project)\n\n- European Union’s Horizon 2020 research and innovation programme under grant\n  agreements:\n  - [Human Brain Project SGA3 (H2020-EU.3.1.5.3, grant no. 945539)](https://cordis.europa.eu/project/id/945539)\n  - [VirtualBrainCloud (H2020-EU.3.1.5.3, grant no. 826421)](https://cordis.europa.eu/project/id/826421)\n\nMac mini instance for development is provided by\n[MacStadium](https://www.macstadium.com/).\n\n\n### Contributors ✨\n\nThanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/glalteva\"><img src=\"https://avatars2.githubusercontent.com/u/14296143?v=4?s=100\" width=\"100px;\" alt=\"glalteva\"/><br /><sub><b>glalteva</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=glalteva\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/adswa\"><img src=\"https://avatars1.githubusercontent.com/u/29738718?v=4?s=100\" width=\"100px;\" alt=\"adswa\"/><br /><sub><b>adswa</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=adswa\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/chrhaeusler\"><img src=\"https://avatars0.githubusercontent.com/u/8115807?v=4?s=100\" width=\"100px;\" alt=\"chrhaeusler\"/><br /><sub><b>chrhaeusler</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=chrhaeusler\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/soichih\"><img src=\"https://avatars3.githubusercontent.com/u/923896?v=4?s=100\" width=\"100px;\" alt=\"soichih\"/><br /><sub><b>soichih</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=soichih\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mvdoc\"><img src=\"https://avatars1.githubusercontent.com/u/6150554?v=4?s=100\" width=\"100px;\" alt=\"mvdoc\"/><br /><sub><b>mvdoc</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=mvdoc\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mih\"><img src=\"https://avatars1.githubusercontent.com/u/136479?v=4?s=100\" width=\"100px;\" alt=\"mih\"/><br /><sub><b>mih</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=mih\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yarikoptic\"><img src=\"https://avatars3.githubusercontent.com/u/39889?v=4?s=100\" width=\"100px;\" alt=\"yarikoptic\"/><br /><sub><b>yarikoptic</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=yarikoptic\" title=\"Code\">💻</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/loj\"><img src=\"https://avatars2.githubusercontent.com/u/15157717?v=4?s=100\" width=\"100px;\" alt=\"loj\"/><br /><sub><b>loj</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=loj\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/feilong\"><img src=\"https://avatars2.githubusercontent.com/u/2242261?v=4?s=100\" width=\"100px;\" alt=\"feilong\"/><br /><sub><b>feilong</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=feilong\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jhpoelen\"><img src=\"https://avatars2.githubusercontent.com/u/1084872?v=4?s=100\" width=\"100px;\" alt=\"jhpoelen\"/><br /><sub><b>jhpoelen</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=jhpoelen\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/andycon\"><img src=\"https://avatars1.githubusercontent.com/u/3965889?v=4?s=100\" width=\"100px;\" alt=\"andycon\"/><br /><sub><b>andycon</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=andycon\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nicholsn\"><img src=\"https://avatars3.githubusercontent.com/u/463344?v=4?s=100\" width=\"100px;\" alt=\"nicholsn\"/><br /><sub><b>nicholsn</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=nicholsn\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/adelavega\"><img src=\"https://avatars0.githubusercontent.com/u/2774448?v=4?s=100\" width=\"100px;\" alt=\"adelavega\"/><br /><sub><b>adelavega</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=adelavega\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kskyten\"><img src=\"https://avatars0.githubusercontent.com/u/4163878?v=4?s=100\" width=\"100px;\" alt=\"kskyten\"/><br /><sub><b>kskyten</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=kskyten\" title=\"Code\">💻</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/TheChymera\"><img src=\"https://avatars2.githubusercontent.com/u/950524?v=4?s=100\" width=\"100px;\" alt=\"TheChymera\"/><br /><sub><b>TheChymera</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=TheChymera\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/effigies\"><img src=\"https://avatars0.githubusercontent.com/u/83442?v=4?s=100\" width=\"100px;\" alt=\"effigies\"/><br /><sub><b>effigies</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=effigies\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jgors\"><img src=\"https://avatars1.githubusercontent.com/u/386585?v=4?s=100\" width=\"100px;\" alt=\"jgors\"/><br /><sub><b>jgors</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=jgors\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/debanjum\"><img src=\"https://avatars1.githubusercontent.com/u/6413477?v=4?s=100\" width=\"100px;\" alt=\"debanjum\"/><br /><sub><b>debanjum</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=debanjum\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/nellh\"><img src=\"https://avatars3.githubusercontent.com/u/11369795?v=4?s=100\" width=\"100px;\" alt=\"nellh\"/><br /><sub><b>nellh</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=nellh\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/emdupre\"><img src=\"https://avatars3.githubusercontent.com/u/15017191?v=4?s=100\" width=\"100px;\" alt=\"emdupre\"/><br /><sub><b>emdupre</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=emdupre\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/aqw\"><img src=\"https://avatars0.githubusercontent.com/u/765557?v=4?s=100\" width=\"100px;\" alt=\"aqw\"/><br /><sub><b>aqw</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=aqw\" title=\"Code\">💻</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vsoch\"><img src=\"https://avatars0.githubusercontent.com/u/814322?v=4?s=100\" width=\"100px;\" alt=\"vsoch\"/><br /><sub><b>vsoch</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=vsoch\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kyleam\"><img src=\"https://avatars2.githubusercontent.com/u/1297788?v=4?s=100\" width=\"100px;\" alt=\"kyleam\"/><br /><sub><b>kyleam</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=kyleam\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/driusan\"><img src=\"https://avatars0.githubusercontent.com/u/498329?v=4?s=100\" width=\"100px;\" alt=\"driusan\"/><br /><sub><b>driusan</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=driusan\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/overlake333\"><img src=\"https://avatars1.githubusercontent.com/u/28018084?v=4?s=100\" width=\"100px;\" alt=\"overlake333\"/><br /><sub><b>overlake333</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=overlake333\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/akeshavan\"><img src=\"https://avatars0.githubusercontent.com/u/972008?v=4?s=100\" width=\"100px;\" alt=\"akeshavan\"/><br /><sub><b>akeshavan</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=akeshavan\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jwodder\"><img src=\"https://avatars1.githubusercontent.com/u/98207?v=4?s=100\" width=\"100px;\" alt=\"jwodder\"/><br /><sub><b>jwodder</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=jwodder\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bpoldrack\"><img src=\"https://avatars2.githubusercontent.com/u/10498301?v=4?s=100\" width=\"100px;\" alt=\"bpoldrack\"/><br /><sub><b>bpoldrack</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=bpoldrack\" title=\"Code\">💻</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yetanothertestuser\"><img src=\"https://avatars0.githubusercontent.com/u/19335420?v=4?s=100\" width=\"100px;\" alt=\"yetanothertestuser\"/><br /><sub><b>yetanothertestuser</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=yetanothertestuser\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/christian-monch\"><img src=\"https://avatars.githubusercontent.com/u/17925232?v=4?s=100\" width=\"100px;\" alt=\"Christian Mönch\"/><br /><sub><b>Christian Mönch</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=christian-monch\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mattcieslak\"><img src=\"https://avatars.githubusercontent.com/u/170026?v=4?s=100\" width=\"100px;\" alt=\"Matt Cieslak\"/><br /><sub><b>Matt Cieslak</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=mattcieslak\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mikapfl\"><img src=\"https://avatars.githubusercontent.com/u/7226087?v=4?s=100\" width=\"100px;\" alt=\"Mika Pflüger\"/><br /><sub><b>Mika Pflüger</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=mikapfl\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://me.ypid.de/\"><img src=\"https://avatars.githubusercontent.com/u/1301158?v=4?s=100\" width=\"100px;\" alt=\"Robin Schneider\"/><br /><sub><b>Robin Schneider</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=ypid\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://orcid.org/0000-0003-4652-3758\"><img src=\"https://avatars.githubusercontent.com/u/7570456?v=4?s=100\" width=\"100px;\" alt=\"Sin Kim\"/><br /><sub><b>Sin Kim</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=kimsin98\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/DisasterMo\"><img src=\"https://avatars.githubusercontent.com/u/49207524?v=4?s=100\" width=\"100px;\" alt=\"Michael Burgardt\"/><br /><sub><b>Michael Burgardt</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=DisasterMo\" title=\"Code\">💻</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://remi-gau.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/6961185?v=4?s=100\" width=\"100px;\" alt=\"Remi Gau\"/><br /><sub><b>Remi Gau</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=Remi-Gau\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mslw\"><img src=\"https://avatars.githubusercontent.com/u/11985212?v=4?s=100\" width=\"100px;\" alt=\"Michał Szczepanik\"/><br /><sub><b>Michał Szczepanik</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=mslw\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bpinsard\"><img src=\"https://avatars.githubusercontent.com/u/1155388?v=4?s=100\" width=\"100px;\" alt=\"Basile\"/><br /><sub><b>Basile</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=bpinsard\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/taylols\"><img src=\"https://avatars.githubusercontent.com/u/28018084?v=4?s=100\" width=\"100px;\" alt=\"Taylor Olson\"/><br /><sub><b>Taylor Olson</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=taylols\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jdkent.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/12564882?v=4?s=100\" width=\"100px;\" alt=\"James Kent\"/><br /><sub><b>James Kent</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=jdkent\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/xgui3783\"><img src=\"https://avatars.githubusercontent.com/u/19381783?v=4?s=100\" width=\"100px;\" alt=\"xgui3783\"/><br /><sub><b>xgui3783</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=xgui3783\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/tstoeter\"><img src=\"https://avatars.githubusercontent.com/u/4901704?v=4?s=100\" width=\"100px;\" alt=\"tstoeter\"/><br /><sub><b>tstoeter</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=tstoeter\" title=\"Code\">💻</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jsheunis.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/10141237?v=4?s=100\" width=\"100px;\" alt=\"Stephan Heunis\"/><br /><sub><b>Stephan Heunis</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=jsheunis\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://www.mmmccormick.com\"><img src=\"https://avatars.githubusercontent.com/u/25432?v=4?s=100\" width=\"100px;\" alt=\"Matt McCormick\"/><br /><sub><b>Matt McCormick</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=thewtex\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/vickychenglau\"><img src=\"https://avatars.githubusercontent.com/u/22065437?v=4?s=100\" width=\"100px;\" alt=\"Vicky C Lau\"/><br /><sub><b>Vicky C Lau</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=vickychenglau\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://chris-lamb.co.uk\"><img src=\"https://avatars.githubusercontent.com/u/133209?v=4?s=100\" width=\"100px;\" alt=\"Chris Lamb\"/><br /><sub><b>Chris Lamb</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=lamby\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/asmacdo\"><img src=\"https://avatars.githubusercontent.com/u/1028657?v=4?s=100\" width=\"100px;\" alt=\"Austin Macdonald\"/><br /><sub><b>Austin Macdonald</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=asmacdo\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://nobodyinperson.de\"><img src=\"https://avatars.githubusercontent.com/u/19148271?v=4?s=100\" width=\"100px;\" alt=\"Yann Büchau\"/><br /><sub><b>Yann Büchau</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=nobodyinperson\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/matrss\"><img src=\"https://avatars.githubusercontent.com/u/9308656?v=4?s=100\" width=\"100px;\" alt=\"Matthias Riße\"/><br /><sub><b>Matthias Riße</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=matrss\" title=\"Code\">💻</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/Aksoo\"><img src=\"https://avatars.githubusercontent.com/u/141905668?v=4?s=100\" width=\"100px;\" alt=\"Aksoo\"/><br /><sub><b>Aksoo</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=Aksoo\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/dguibert\"><img src=\"https://avatars.githubusercontent.com/u/1178864?v=4?s=100\" width=\"100px;\" alt=\"David Guibert\"/><br /><sub><b>David Guibert</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=dguibert\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/alliesw\"><img src=\"https://avatars.githubusercontent.com/u/72238329?v=4?s=100\" width=\"100px;\" alt=\"Alex Shields-Weber\"/><br /><sub><b>Alex Shields-Weber</b></sub></a><br /><a href=\"https://github.com/datalad/datalad/commits?author=alliesw\" title=\"Code\">💻</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\n[![macstadium](https://uploads-ssl.webflow.com/5ac3c046c82724970fc60918/5c019d917bba312af7553b49_MacStadium-developerlogo.png)](https://www.macstadium.com/)\n\n[Git]: https://git-scm.com\n[Git-annex]: http://git-annex.branchable.com\n[setup.py]: https://github.com/datalad/datalad/blob/master/setup.py\n[NeuroDebian]: http://neuro.debian.net\n[Package Manager Specification]: https://projects.gentoo.org/pms/latest/pms.html\n[enabling the ::science overlay]: https://github.com/gentoo/sci#manual-install-\n\n[DataLad Handbook: Installation]: http://handbook.datalad.org/en/latest/intro/installation.html\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/datalad-container-extension",
            "repo_link": "https://github.com/datalad/datalad-container",
            "readme": "     ____          _           _                 _\n    |  _ \\   __ _ | |_   __ _ | |      __ _   __| |\n    | | | | / _` || __| / _` || |     / _` | / _` |\n    | |_| || (_| || |_ | (_| || |___ | (_| || (_| |\n    |____/  \\__,_| \\__| \\__,_||_____| \\__,_| \\__,_|\n                                       Container\n\n[![Build status](https://ci.appveyor.com/api/projects/status/k4eyq1yygcvwf7wk/branch/master?svg=true)](https://ci.appveyor.com/project/mih/datalad-container/branch/master) [![Travis tests status](https://app.travis-ci.com/datalad/datalad-container.svg?branch=master)](https://app.travis-ci.com/datalad/datalad-container) [![codecov.io](https://codecov.io/github/datalad/datalad-container/coverage.svg?branch=master)](https://codecov.io/github/datalad/datalad-container?branch=master) [![Documentation](https://readthedocs.org/projects/datalad-container/badge/?version=latest)](http://datalad-container.rtfd.org) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) [![GitHub release](https://img.shields.io/github/release/datalad/datalad-container.svg)](https://GitHub.com/datalad/datalad-container/releases/) [![PyPI version fury.io](https://badge.fury.io/py/datalad-container.svg)](https://pypi.python.org/pypi/datalad-container/) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3368666.svg)](https://doi.org/10.5281/zenodo.3368666) ![Conda](https://anaconda.org/conda-forge/datalad-container/badges/version.svg)\n\nThis extension enhances DataLad (http://datalad.org) for working with\ncomputational containers. Please see the [extension\ndocumentation](http://datalad-container.rtfd.org)\nfor a description on additional commands and functionality.\n\nFor general information on how to use or contribute to DataLad (and this\nextension), please see the [DataLad website](http://datalad.org) or the\n[main GitHub project page](http://datalad.org).\n\n\n## Installation\n\nBefore you install this package, please make sure that you [install a recent\nversion of git-annex](https://git-annex.branchable.com/install).  Afterwards,\ninstall the latest version of `datalad-container` from\n[PyPi](https://pypi.org/project/datalad-container). It is recommended to use\na dedicated [virtualenv](https://virtualenv.pypa.io):\n\n    # create and enter a new virtual environment (optional)\n    virtualenv --system-site-packages --python=python3 ~/env/datalad\n    . ~/env/datalad/bin/activate\n\n    # install from PyPi\n    pip install datalad_container\n\nIt is also available for conda package manager from conda-forge:\n\n    conda install -c conda-forge datalad-container\n\n\n## Support\n\nThe documentation of this project is found here:\nhttp://docs.datalad.org/projects/container\n\nAll bugs, concerns and enhancement requests for this software can be submitted here:\nhttps://github.com/datalad/datalad-container/issues\n\nIf you have a problem or would like to ask a question about how to use DataLad,\nplease [submit a question to\nNeuroStars.org](https://neurostars.org/tags/datalad) with a ``datalad`` tag.\nNeuroStars.org is a platform similar to StackOverflow but dedicated to\nneuroinformatics.\n\nAll previous DataLad questions are available here:\nhttp://neurostars.org/tags/datalad/\n\n## Acknowledgements\n\nDataLad development is supported by a US-German collaboration in computational\nneuroscience (CRCNS) project \"DataGit: converging catalogues, warehouses, and\ndeployment logistics into a federated 'data distribution'\" (Halchenko/Hanke),\nco-funded by the US National Science Foundation (NSF 1429999) and the German\nFederal Ministry of Education and Research (BMBF 01GQ1411). Additional support\nis provided by the German federal state of Saxony-Anhalt and the European\nRegional Development Fund (ERDF), Project: Center for Behavioral Brain\nSciences, Imaging Platform.  This work is further facilitated by the ReproNim\nproject (NIH 1P41EB019936-01A1).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/datalad-next-extension",
            "repo_link": "https://github.com/datalad/datalad-next",
            "readme": "# DataLad NEXT extension\n\n[![All Contributors](https://img.shields.io/github/all-contributors/datalad/datalad-next?color=ee8449&style=flat-square)](#contributors)\n[![Build status](https://ci.appveyor.com/api/projects/status/dxomp8wysjb7x2os/branch/main?svg=true)](https://ci.appveyor.com/project/mih/datalad-next/branch/main)\n[![codecov](https://codecov.io/gh/datalad/datalad-next/branch/main/graph/badge.svg?token=2P8rak7lSX)](https://codecov.io/gh/datalad/datalad-next)\n[![docs](https://github.com/datalad/datalad-next/workflows/docs/badge.svg)](https://github.com/datalad/datalad-next/actions?query=workflow%3Adocs)\n[![Documentation Status](https://readthedocs.org/projects/datalad-next/badge/?version=latest)](http://docs.datalad.org/projects/next/en/latest/?badge=latest)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![GitHub release](https://img.shields.io/github/release/datalad/datalad-next.svg)](https://GitHub.com/datalad/datalad-next/releases/)\n[![PyPI version fury.io](https://badge.fury.io/py/datalad-next.svg)](https://pypi.python.org/pypi/datalad-next/)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6833099.svg)](https://doi.org/10.5281/zenodo.6833099)\n[![Hatch project](https://img.shields.io/badge/%F0%9F%A5%9A-Hatch-4051b5.svg)](https://github.com/pypa/hatch)\n\nThis DataLad extension can be thought of as a staging area for additional\nfunctionality, or for improved performance and user experience. Unlike other\ntopical or more experimental extensions, the focus here is on functionality\nwith broad applicability. This extension is a suitable dependency for other\nsoftware packages that intend to build on this improved set of functionality.\n\n## Installation\n\n```\n# create and enter a new virtual environment (optional)\n$ virtualenv --python=python3 ~/env/dl-next\n$ . ~/env/dl-next/bin/activate\n# install from PyPi\n$ python -m pip install datalad-next\n```\n\n## How to use\n\nAdditional commands provided by this extension are immediately available\nafter installation. However, in order to fully benefit from all improvements,\nthe extension has to be enabled for auto-loading by executing:\n\n    git config --global --add datalad.extensions.load next\n\nDoing so will enable the extension to also alter the behavior the core DataLad\npackage and its commands.\n\n## Summary of functionality provided by this extension\n\n- A replacement sub-system for credential handling that is able to handle arbitrary\n  properties for annotating a secret, and facilitates determining suitable\n  credentials while minimizing avoidable user interaction, without compromising\n  configurability. A convenience method is provided that implements a standard\n  workflow for obtaining a credential.\n- A user-facing `credentials` command to set, remove, and query credentials.\n- The `create-sibling-...` commands for the platforms GitHub, GIN, GOGS, Gitea\n  are equipped with improved credential handling that, for example, only stores\n  entered credentials after they were confirmed to work, or auto-selects the\n  most recently used, matching credentials, when none are specified.\n- A `create-sibling-webdav` command for hosting datasets on a WebDAV server via\n  a sibling tandem for Git history and file storage. Datasets hosted on WebDAV\n  in this fashion are cloneable with `datalad-clone`. A full annex setup\n  for storing complete datasets with historical file content version, and an\n  additional mode for depositing single-version dataset snapshot are supported.\n  The latter enables convenient collaboration with audiences that are not using\n  DataLad, because all files are browsable via a WebDAV server's point-and-click\n  user interface.\n- Enhance `datalad-push` to automatically export files to git-annex special\n  remotes configured with `exporttree=yes`.\n- Speed-up `datalad-push` when processing non-git special remotes. This particularly\n  benefits less efficient hosting scenarios like WebDAV.\n- Enhance `datalad-siblings enable` (`AnnexRepo.enable_remote()`) to automatically\n  deploy credentials for git-annex special remotes that require them.\n- `git-remote-datalad-annex` is a Git remote helper to push/fetch to any\n  location accessible by any git-annex special remote.\n- `git-annex-backend-XDLRA` (originally available from the `mihextras` extension)\n  is a custom external git-annex backend used by `git-remote-datalad-annex`. A base\n  class to facilitate development of external backends in Python is also provided.\n- Enhance `datalad-configuration` to support getting configuration from \"global\"\n  scope without a dataset being present.\n- New modular framework for URL operations. This framework directly supports operation\n  on `http(s)`, `ssh`, and `file` URLs, and can be extended with custom functionality\n  for additional protocols or even interaction with specific individual servers.\n  The basic operations `download`, `upload`, `delete`, and `stat` are recognized,\n  and can be implemented. The framework offers uniform progress reporting and\n  simultaneous content has computation. This framework is meant to replace and\n  extend the downloader/provide framework in the DataLad core package. In contrast\n  to its predecessor it is integrated with the new credential framework, and\n  operations beyond downloading.\n- `git-annex-remote-uncurl` is a special remote that exposes the new URL\n  operations framework via git-annex. It provides flexible means to compose\n  and rewrite URLs (e.g., to compensate for storage infrastructure changes)\n  without having to modify individual URLs recorded in datasets. It enables\n  seamless transitions between any services and protocols supported by the\n  framework. This special remote can replace the `datalad` special remote\n  provided by the DataLad core package.\n- A `download` command is provided as a front-end for the new modular URL\n  operations framework.\n- A `python-requests` compatible authentication handler (`DataladAuth`) that\n  interfaces DataLad's credential system.\n- Boosted throughput of DataLad's `runner` component for command execution.\n- Substantially more comprehensive replacement for DataLad's `constraints` system\n  for type conversion and parameter validation.\n- Windows and Mac client support for RIA store access.\n- A `next-status` command that is A LOT faster than `status`, and offers\n  a `mono` recursion mode that shows modifications of nested dataset\n  hierarchies relative to the state of the root dataset.\n  Requires Git v2.31 (or later).\n\n## Summary of additional features for DataLad extension development\n\n- Framework for uniform command parameter validation. Regardless of the used\n  API (Python, CLI, or GUI), command parameters are uniformly validated. This\n  facilitates a stricter separation of parameter specification (and validation)\n  from the actual implementation of a command. The latter can now focus on a\n  command's logic only, while the former enables more uniform and more\n  comprehensive validation and error reporting. Beyond per-parameter validation\n  and type-conversion also inter-parameter dependency validation and value\n  transformations are supported.\n- Improved composition of importable functionality. Key components for `commands`,\n  `annexremotes`, `datasets` (etc) are collected in topical top-level modules that\n  provide \"all\" necessary pieces in a single place.\n- `webdav_server` fixture that automatically deploys a local WebDAV\n  server.\n- Utilities for HTTP handling\n  - `probe_url()` discovers redirects and authentication requirements for an HTTP\n    URL\n  - `get_auth_realm()` returns a label for an authentication realm that can be used\n    to query for matching credentials\n- Utilities for special remote credential management:\n  - `get_specialremote_credential_properties()` inspects a special remote and returns\n    properties for querying a credential store for matching credentials\n  - `update_specialremote_credential()` updates a credential in a store after\n    successful use\n  - `get_specialremote_credential_envpatch()` returns a suitable environment \"patch\"\n    from a credential for a particular special remote type\n- Helper for runtime-patching other datalad code (`datalad_next.utils.patch`)\n- Base class for implementing custom `git-annex` backends.\n- A set of `pytest` fixtures to:\n  - check that no global configuration side-effects are left behind by a test\n  - check that no secrets are left behind by a test\n  - provide a temporary configuration that is isolated from a user environment\n    and from other tests\n  - provide a temporary secret store that is isolated from a user environment\n    and from other tests\n  - provide a temporary credential manager to perform credential deployment\n    and manipulation isolated from a user environment and from other tests\n- An `iter_subproc()` helper that enable communication with subprocesses\n  via input/output iterables.\n- A `shell` context manager that enables interaction with (remote) shells,\n  including support for input/output iterables for each shell-command execution\n  within the context.\n\n## Patching the DataLad core package.\n\nSome of the features described above rely on a modification of the DataLad core\npackage itself, rather than coming in the form of additional commands. Loading\nthis extension causes a range of patches to be applied to the `datalad` package\nto enable them. A comprehensive description of the current set of patch is\navailable at http://docs.datalad.org/projects/next/en/latest/#datalad-patches\n\n## Developing with DataLad NEXT\n\nThis extension package moves fast in comparison to the core package. Nevertheless,\nattention is paid to API stability, adequate semantic versioning, and informative\nchangelogs.\n\n### Public vs internal API\n\nAnything that can be imported directly from any of the sub-packages in\n`datalad_next` is considered to be part of the public API. Changes to this API\ndetermine the versioning, and development is done with the aim to keep this API\nas stable as possible. This includes signatures and return value behavior.\n\nAs an example: `from datalad_next.runners import iter_git_subproc` imports a\npart of the public API, but `from datalad_next.runners.git import\niter_git_subproc` does not.\n\n### Use of the internal API\n\nDevelopers can obviously use parts of the non-public API. However, this should\nonly be done with the understanding that these components may change from one\nrelease to another, with no guarantee of transition periods, deprecation\nwarnings, etc.\n\nDevelopers are advised to never reuse any components with names starting with\n`_` (underscore). Their use should be limited to their individual subpackage.\n\n## Acknowledgements\n\nThis DataLad extension was developed with funding from the Deutsche\nForschungsgemeinschaft (DFG, German Research Foundation) under grant SFB 1451\n([431549029](https://gepris.dfg.de/gepris/projekt/431549029), INF project).\n\n\n## Contributors\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://psychoinformatics.de/\"><img src=\"https://avatars.githubusercontent.com/u/136479?v=4?s=100\" width=\"100px;\" alt=\"Michael Hanke\"/><br /><sub><b>Michael Hanke</b></sub></a><br /><a href=\"https://github.com/datalad/datalad-next/issues?q=author%3Amih\" title=\"Bug reports\">🐛</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=mih\" title=\"Code\">💻</a> <a href=\"#content-mih\" title=\"Content\">🖋</a> <a href=\"#design-mih\" title=\"Design\">🎨</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=mih\" title=\"Documentation\">📖</a> <a href=\"#financial-mih\" title=\"Financial\">💵</a> <a href=\"#fundingFinding-mih\" title=\"Funding Finding\">🔍</a> <a href=\"#ideas-mih\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#infra-mih\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">🚇</a> <a href=\"#maintenance-mih\" title=\"Maintenance\">🚧</a> <a href=\"#mentoring-mih\" title=\"Mentoring\">🧑‍🏫</a> <a href=\"#platform-mih\" title=\"Packaging/porting to new platform\">📦</a> <a href=\"#projectManagement-mih\" title=\"Project Management\">📆</a> <a href=\"https://github.com/datalad/datalad-next/pulls?q=is%3Apr+reviewed-by%3Amih\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"#talk-mih\" title=\"Talks\">📢</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=mih\" title=\"Tests\">⚠️</a> <a href=\"#tool-mih\" title=\"Tools\">🔧</a> <a href=\"#userTesting-mih\" title=\"User Testing\">📓</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/catetrai\"><img src=\"https://avatars.githubusercontent.com/u/18424941?v=4?s=100\" width=\"100px;\" alt=\"catetrai\"/><br /><sub><b>catetrai</b></sub></a><br /><a href=\"https://github.com/datalad/datalad-next/commits?author=catetrai\" title=\"Code\">💻</a> <a href=\"#design-catetrai\" title=\"Design\">🎨</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=catetrai\" title=\"Documentation\">📖</a> <a href=\"#ideas-catetrai\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=catetrai\" title=\"Tests\">⚠️</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/effigies\"><img src=\"https://avatars.githubusercontent.com/u/83442?v=4?s=100\" width=\"100px;\" alt=\"Chris Markiewicz\"/><br /><sub><b>Chris Markiewicz</b></sub></a><br /><a href=\"#maintenance-effigies\" title=\"Maintenance\">🚧</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=effigies\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/mslw\"><img src=\"https://avatars.githubusercontent.com/u/11985212?v=4?s=100\" width=\"100px;\" alt=\"Michał Szczepanik\"/><br /><sub><b>Michał Szczepanik</b></sub></a><br /><a href=\"https://github.com/datalad/datalad-next/issues?q=author%3Amslw\" title=\"Bug reports\">🐛</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=mslw\" title=\"Code\">💻</a> <a href=\"#content-mslw\" title=\"Content\">🖋</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=mslw\" title=\"Documentation\">📖</a> <a href=\"#example-mslw\" title=\"Examples\">💡</a> <a href=\"#ideas-mslw\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#infra-mslw\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">🚇</a> <a href=\"#maintenance-mslw\" title=\"Maintenance\">🚧</a> <a href=\"https://github.com/datalad/datalad-next/pulls?q=is%3Apr+reviewed-by%3Amslw\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"#talk-mslw\" title=\"Talks\">📢</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=mslw\" title=\"Tests\">⚠️</a> <a href=\"#tutorial-mslw\" title=\"Tutorials\">✅</a> <a href=\"#userTesting-mslw\" title=\"User Testing\">📓</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://jsheunis.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/10141237?v=4?s=100\" width=\"100px;\" alt=\"Stephan Heunis\"/><br /><sub><b>Stephan Heunis</b></sub></a><br /><a href=\"https://github.com/datalad/datalad-next/issues?q=author%3Ajsheunis\" title=\"Bug reports\">🐛</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=jsheunis\" title=\"Code\">💻</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=jsheunis\" title=\"Documentation\">📖</a> <a href=\"#ideas-jsheunis\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#maintenance-jsheunis\" title=\"Maintenance\">🚧</a> <a href=\"#talk-jsheunis\" title=\"Talks\">📢</a> <a href=\"#userTesting-jsheunis\" title=\"User Testing\">📓</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/bpoldrack\"><img src=\"https://avatars.githubusercontent.com/u/10498301?v=4?s=100\" width=\"100px;\" alt=\"Benjamin Poldrack\"/><br /><sub><b>Benjamin Poldrack</b></sub></a><br /><a href=\"https://github.com/datalad/datalad-next/issues?q=author%3Abpoldrack\" title=\"Bug reports\">🐛</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=bpoldrack\" title=\"Code\">💻</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/yarikoptic\"><img src=\"https://avatars.githubusercontent.com/u/39889?v=4?s=100\" width=\"100px;\" alt=\"Yaroslav Halchenko\"/><br /><sub><b>Yaroslav Halchenko</b></sub></a><br /><a href=\"https://github.com/datalad/datalad-next/issues?q=author%3Ayarikoptic\" title=\"Bug reports\">🐛</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=yarikoptic\" title=\"Code\">💻</a> <a href=\"#infra-yarikoptic\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">🚇</a> <a href=\"#maintenance-yarikoptic\" title=\"Maintenance\">🚧</a> <a href=\"#tool-yarikoptic\" title=\"Tools\">🔧</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/christian-monch\"><img src=\"https://avatars.githubusercontent.com/u/17925232?v=4?s=100\" width=\"100px;\" alt=\"Christian Mönch\"/><br /><sub><b>Christian Mönch</b></sub></a><br /><a href=\"https://github.com/datalad/datalad-next/commits?author=christian-monch\" title=\"Code\">💻</a> <a href=\"#design-christian-monch\" title=\"Design\">🎨</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=christian-monch\" title=\"Documentation\">📖</a> <a href=\"#ideas-christian-monch\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"https://github.com/datalad/datalad-next/pulls?q=is%3Apr+reviewed-by%3Achristian-monch\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=christian-monch\" title=\"Tests\">⚠️</a> <a href=\"#userTesting-christian-monch\" title=\"User Testing\">📓</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/adswa\"><img src=\"https://avatars.githubusercontent.com/u/29738718?v=4?s=100\" width=\"100px;\" alt=\"Adina Wagner\"/><br /><sub><b>Adina Wagner</b></sub></a><br /><a href=\"#a11y-adswa\" title=\"Accessibility\">️️️️♿️</a> <a href=\"https://github.com/datalad/datalad-next/issues?q=author%3Aadswa\" title=\"Bug reports\">🐛</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=adswa\" title=\"Code\">💻</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=adswa\" title=\"Documentation\">📖</a> <a href=\"#example-adswa\" title=\"Examples\">💡</a> <a href=\"#maintenance-adswa\" title=\"Maintenance\">🚧</a> <a href=\"#projectManagement-adswa\" title=\"Project Management\">📆</a> <a href=\"https://github.com/datalad/datalad-next/pulls?q=is%3Apr+reviewed-by%3Aadswa\" title=\"Reviewed Pull Requests\">👀</a> <a href=\"#talk-adswa\" title=\"Talks\">📢</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=adswa\" title=\"Tests\">⚠️</a> <a href=\"#tutorial-adswa\" title=\"Tutorials\">✅</a> <a href=\"#userTesting-adswa\" title=\"User Testing\">📓</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/jwodder\"><img src=\"https://avatars.githubusercontent.com/u/98207?v=4?s=100\" width=\"100px;\" alt=\"John T. Wodder II\"/><br /><sub><b>John T. Wodder II</b></sub></a><br /><a href=\"https://github.com/datalad/datalad-next/commits?author=jwodder\" title=\"Code\">💻</a> <a href=\"#infra-jwodder\" title=\"Infrastructure (Hosting, Build-Tools, etc)\">🚇</a> <a href=\"https://github.com/datalad/datalad-next/commits?author=jwodder\" title=\"Tests\">⚠️</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/candleindark\"><img src=\"https://avatars.githubusercontent.com/u/12135617?v=4?s=100\" width=\"100px;\" alt=\"Isaac To\"/><br /><sub><b>Isaac To</b></sub></a><br /><a href=\"https://github.com/datalad/datalad-next/commits?author=candleindark\" title=\"Code\">💻</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/datasail",
            "repo_link": "https://github.com/kalininalab/DataSAIL",
            "readme": "# DataSAIL: Data Splitting Against Information Leaking \n\n![testing](https://github.com/kalininalab/glyles/actions/workflows/test.yaml/badge.svg)\n[![docs-image](https://readthedocs.org/projects/glyles/badge/?version=latest)](https://datasail.readthedocs.io/en/latest/index.html)\n[![codecov](https://codecov.io/gh/kalininalab/DataSAIL/branch/main/graph/badge.svg)](https://codecov.io/gh/kalininalab/DataSAIL)\n[![anaconda](https://anaconda.org/kalininalab/datasail/badges/version.svg)](https://anaconda.org/kalininalab/datasail)\n[![update](https://anaconda.org/kalininalab/datasail/badges/latest_release_date.svg)](https://anaconda.org/kalininalab/datasail)\n[![license](https://anaconda.org/kalininalab/datasail/badges/license.svg)](https://anaconda.org/kalininalab/datasail)\n[![downloads](https://anaconda.org/kalininalab/datasail/badges/downloads.svg)](https://anaconda.org/kalininalab/datasail)\n![Python 3](https://img.shields.io/badge/python-3-blue.svg)\n[![DOI](https://zenodo.org/badge/598109632.svg)](https://doi.org/10.5281/zenodo.13938602)\n\nDataSAIL: [![platforms](https://anaconda.org/kalininalab/datasail/badges/platforms.svg)](https://anaconda.org/kalininalab/datasail)\nDataSAIL-lite: [![platforms](https://anaconda.org/kalininalab/datasail-lite/badges/platforms.svg)](https://anaconda.org/kalininalab/datasail-lite)\n\nDataSAIL is a tool that splits data while minimizing Information Leakage. This tool formulates the splitting of a \ndataset as a constrained minimization problem and computes the assignment of data points to splits while minimizing the \nobjective function that accounts for information leakage.\n\nInternally, DataSAIL uses disciplined quasi-convex programming and binary quadratic programs to formulate the \noptimization task. DataSAIL utilizes solves like [SCIP](https://scipopt.org/), one of the fastest non-commercial \nsolvers for this type of problem, and [MOSEK](https://mosek.com), a commercial solver that distributes free licenses \nfor academic use. There are other options; please check the documentation.\n\nApart from the short overview, you can find a more detailed explanation of the tool on \n[ReadTheDocs](https://datasail.readthedocs.io/en/latest/index.html). \n\n## Installation\n\nDataSAIL is installable from [conda](https://anaconda.org/kalininalab/datasail) using\n[mamba](https://mamba.readthedocs.io/en/latest/installation/mamba-installation.html>).\nusing\n\n````shell\nmamba create -n sail -c conda-forge -c kalininalab -c bioconda datasail\nconda activate sail\npip install grakel\n````\n\nto install it into a new empty environment or\n\n````shell\nmamba install -c conda-forge -c kalininalab -c bioconda -c mosek datasail\npip install grakel\n````\n\nto install DataSAIL in an already existing environment. Alternatively, one can install DataSAIL-lite from conda. \nDataSAIL-lite is a version of DataSAIL that does not install all clustering algorithms as the standard DataSAIL.\nInstalling either package usually takes less than 5 minutes.\n\nDataSAIL is available for Python 3.8 and newer.\n\n## Usage\n\nDataSAIL is installed as a command-line tool. So, in the conda environment, DataSAIL has been installed to, you can run \n\n````shell\ndatasail --e-type P --e-data <path_to_fasta> --e-sim mmseqs --output <path_to_output_path> --technique C1e\n````\n\nto split a set of proteins that have been clustered using mmseqs. For a full list of arguments, run `datasail -h` and \ncheckout [ReadTheDocs](https://datasail.readthedocs.io/en/latest/index.html). There is a more detailed explanation of the arguments and example notebooks. The runtime largy depends on the number and type of splits to be computed and the size of the dataset. For small datasets (less then 10k samples) DataSAIL finished within minutes. On large datasets (more than 100k samples) it can take several hours to complete.\n\n## When to use DataSAIL and when not to use\n\nOne can distinguish two main ways to train a machine-learning model on biological data. \n* Either the model shall be applied to data substantially different from the data to train on. In this case, it \n  is essential to have test cases that correctly model this real-world application scenario by being as dissimilar as \n  possible to the training data. \n* Or the training dataset already covers the whole space of possible samples shown to the model.\n\nDataSAIL is created to compute complex data splits by separating data based on similarities. This makes \ncomplex data splits for the first scenario. So, you can use DataSAIL when your model is applied to data  \ndifferent from your training data but not if the data in the application is more or less the same as in the training.\n\n## Citation\n\nIf you used DataSAIL to split your data, please cite DataSAIL in your publication.\n````\n@article{joeres2023datasail,\n  title={DataSAIL: Data Splitting Against Information Leakage},\n  author={Joeres, Roman and Blumenthal, David B. and Kalinina, Olga V},\n  journal={bioRxiv},\n  pages={2023--11},\n  year={2023},\n  publisher={Cold Spring Harbor Laboratory}\n}\n````\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/dcache",
            "repo_link": "https://github.com/dCache/dcache",
            "readme": "common: Test commit\nFritz Heiden\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/deeploki",
            "repo_link": "https://gitlab.com/qtb-hhu/marine/DeepLOKI",
            "readme": "# DeepLOKI\n\nZooplankton plays a crucial role in the ocean’s ecology, serving as a foundational component in\nthe food chain by consuming phytoplankton or other zooplankton and furthermore influencing\nnutrient cycling. This pivotal role distinguishes them from other species that reside at higher\ntrophic levels. The vertical distribution of zooplankton in the ocean is patchy, and its relation\nto hydrographical conditions cannot be fully deciphered using traditional net casts due to the\nlarge depth intervals sampled. Optical systems that continuously take images during the cast\ncan help bridge this gap. The Lightframe On-sight Keyspecies Investigation (LOKI) concentrates\nzooplankton with a net that leads to a flow-through chamber with a camera taking images with\nup to 20 frames sec−1. These high-resolution images allow for the determination of zooplankton\ntaxa, often even to genus or species level, and, in the case of copepods, developmental stages.\nEach cruise produces a substantial volume of images, ideally requiring onboard analysis, which\npresently consumes a significant amount of time and necessitates internet connectivity to access\nthe EcoTaxa Web service. To enhance the analyses, we developed an AI-based software\nframework named DeepLOKI, utilizing Deep Transfer Learning with a Convolution Neural Network\nBackbone. Our DeepLOKI image recognition tool can be applied directly on board. We trained\nand validated the model on pre-labeled images from four cruises, while images from a fifth\ncruise were used for testing. The best-performing model, utilizing the self-supervised pre-trained\nResNet18 Backbone, achieved a notable average classification accuracy of 83.9 %, surpassing\nthe regularly and frequently used method EcoTaxa (default) in this field by a factor of two. \nIn summary, we developed a tool for pre-sorting high-resolution black and white zooplankton images\nwith high accuracy, which will simplify and quicken the final annotation process. In addition, we\nprovide a user-friendly graphical interface for the DeepLOKI framework for efficient and concise\nprocesses leading up to the classification stage. Moreover, performing latent space analysis on\nthe self-supervised pre-trained ResNet18 Backbone could prove advantageous in identifying\nanomalies such as deviations in image parameter settings. This, in turn, enhances the quality\ncontrol of the data. Our methodology remains agnostic to the specific imaging end system used,\nsuch as Loki, UVP, or ZooScan, as long as there is a sufficient amount of appropriately labeled\ndata available to enable effective task performance by our algorithms.\n\n# Installation Guide\nhttps://pytorch.org/get-started/locally/\n\npip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1\n\n```\nbrew install python@3.10\npip3 install torch torchvision torchaudio\npip3 install -r requirements_.txt\n```\n\n# Usage\nFirst download the example_haul.zip, model_ckpt.zip, loki.zip. and the sort.zip from\n[Download Here](https://uni-duesseldorf.sciebo.de/s/okWh4728VwnCBGp).\nExtract them.\nloki folder in the DeepLoki_ folder on root level. (here are our models stored)\n\nCopy the update_allcruises_df_validated_5with_zoomie_20230727.csv to output.\nCopy the update_wo_artefacts_test_dataset_PS992_20230727_nicole.csv to output.\n\nCopy the example_haul folder to data/ .\nCopy the sort folder to data/5_cruises/ .\nCopy the content to saved_models/ .\n\nImage analysis: Run start_app.py\n\nImage Labeling: Run start_app_sort.py\n\n# Training - Data needed and computing power\n\nTraining: Run train_pytorch_lightning_model.py\n\nPreTraining: Run pretrain/pretrain_with_dino_paper_resnet_dino450.py\n\n# Software used\nTraining and Validation was performed on an Nvidia A$100$ (Nvidia Corp., Santa Clara, CA, USA) and on Apple M1 MAX with 32 GB (Apple, USA), depending on the computational power needed, for example self-supervised pre-training was performed on a Hyper performing cluster with Nvidia A$100$. <br>\nOn the Macbook Pro (Apple, USA) we used:<br>\nPython VERSION:3.10.5<br>\npyTorch VERSION:13.1.3<br>\nOn the cluster we used cluster specifics versions of the software:<br>\nPython VERSION:3.10.5 <br>\npyTorch VERSION:13.1.3<br>\nCUDNN VERSION:1107)<br>\n\n# Authors\nRaphael Kronberg and Ellen Oldenburg\n\n# Support \nIf you **really** like this repository and find it useful, please consider (★) **starring** it, so that it can reach a broader audience of like-minded people. It would be highly appreciated !\n\n# Contributing to DeepLOKI\nIf you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub ([Link text Here](https://github.com/rakro101/DeepLOKI)) issues. \n\n\n# License , citation and acknowledgements\nPlease advice the **LICENSE.md** file. For usage of third party libraries and repositories please advise the respective distributed terms. Please cite our paper, when using this code:\n\n```\n@software{kronbergapplicationsdeeploki,\n  title={DeepLOKI- A deep learning based approach to identify Zooplankton taxa on high-resolution images from the optical plankton recorder LOKI},\n  author={Kronberg, Raphael Marvin and Oldenburg, Ellen}\n  year = {2023},\n  url = {https://github.com/rakro101/DeepLOKI},\n}\n```\n",
            "project_id": "61815716"
        },
        {
            "software_organization": "https://helmholtz.software/software/deploy2zenodo",
            "repo_link": "https://gitlab.com/deploy2zenodo/deploy2zenodo",
            "readme": "---\nauthor: Daniel Mohr\ndate: 2024-11-29\nlicense: Apache-2.0\nhome: https://gitlab.com/deploy2zenodo/deploy2zenodo\nmirror: https://github.com/deploy2zenodo/deploy2zenodo\nlatest_release: https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/permalink/latest\ndoi: 10.5281/zenodo.10112959\n---\n\n# `deploy2zenodo`\n\n[[_TOC_]]\n\n## preamble\n\n[`deploy2zenodo`](https://gitlab.com/projects/51392274) is a\n[shell](https://en.wikipedia.org/wiki/Bourne_shell) script to deploy\nyour data to [Zenodo](https://zenodo.org/).\nYou can use it in a [CI pipeline](https://docs.gitlab.com/ee/ci/pipelines/) as\nan automatic workflow.\n\nEnvironmental variables allow very flexible use.\nDepending on the selected flags, the data can be curated before deployment\nin a merge request, in the zenodo web interface or not curated at all.\n\n**Note:** `deploy2zenodo` is primarily designed for the Zenodo API.\nIt may also work with other APIs like\n[Invenio RDM](https://inveniosoftware.org/products/rdm/),\nbut compatibility is not guaranteed.\nTest the script with any new API before using it.\n\n## intention\n\nTo satisfy the FAIR[^fair1] principles[^fair2], publications should be\ndeployed to an open repository. In this way the publication gets a PID\n([persistent identifier](https://en.wikipedia.org/wiki/Persistent_identifier))\nand at least the metadata is publicly accessible, findable and citable.\nFurthermore, current discussions about KPIs\n([key performance indicator](https://en.wikipedia.org/wiki/Performance_indicator))\nfor software and data publications also lead to the need to generate PIDs\nfor software and data.\n\n[^fair1]: [FAIR Principles](https://www.go-fair.org/fair-principles/)\n\n[^fair2]: [An interpretation of the FAIR principles to guide implementations in the HMC digital ecosystem.](https://doi.org/10.3289/HMC_publ_01)\n\nEspecially software usually is not citable by a PID.\nTo overcome this and make software academically significant we provide here a\ntool for automatic publication to the open repository [zenodo](https://zenodo.org/).\n\nIn principal the same is true for all kind of scientific data\n(e. g. measurements, software and results such as papers).\nFor every data managed in a version control system an automatic publication\nto an open repository is useful[^versioning].\n\n[^versioning]: [Guidance on Versioning of Digital Assets.](https://doi.org/10.3289/HMC_publ_04)\n\nSoftware in particular is subject to frequent changes, resulting in many\nversions. This leads to the urge to automate the publishing process.\nThis is not only about making the software usable through software repositories,\nbut also about the citability of individual versions.\n\n## how-to\n\nThere are many possibilities to use `deploy2zenodo` but in this how-to section\nwe will focus on a few typically use cases.\n\n### simple workflow\n\nThis workflow reflects the primary focus of `deploy2zenodo`.\n\nGo to your zenodo account and create an\n[access token](https://developers.zenodo.org/?shell#authentication).\n\nStore it in a [GitLab CI/CD variable](https://docs.gitlab.com/ee/ci/variables/)\nas `DEPLOY2ZENODO_ACCESS_TOKEN`. Use the flags\n[Mask variable](https://docs.gitlab.com/ee/ci/variables/index.html#mask-a-cicd-variable)\nand [Protect variable](https://docs.gitlab.com/ee/ci/variables/index.html#protect-a-cicd-variable).\nMasking ensures that the variable is not displayed in the CI/CD logs, and\nprotecting the variable limits access to authorized users.\nKeep in mind the token is sensitive and private information.\nTherefore you should not share it or make it public available.\n\nThen the [GitLab CI/CD pipeline](https://docs.gitlab.com/ee/ci/pipelines/)\ncould look like (we use here [sandbox.zenodo.org](https://sandbox.zenodo.org/)\ninstead of [zenodo.org](https://zenodo.org/) for testing purpose):\n\n```yaml\ninclude:\n  - remote: 'https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/permalink/latest/downloads/deploy2zenodo.yaml'\n\nprepare_release_and_deploy2zenodo:\n  stage: build\n  image:\n    name: alpine:latest\n  variables:\n    DEPLOY2ZENODO_JSON: \"mymetadata.json\"\n  script:\n    # prepare\n    - TAG=$(grep version library.properties | cut -d \"=\" -f 2)\n    - |\n      echo '{\"metadata\":{\"creators\":[{\"name\":\"family, given\"}],\\\n        \"license\":{\"id\":\"GPL-3.0-or-later\"},\"title\":\"test script alpine\",\\\n        \"version\":\"***\",\"upload_type\":\"software\"}}' | \\\n        jq \".metadata.version = \\\"$TAG\\\"\" | tee \"$DEPLOY2ZENODO_JSON\"\n    # prepare release\n    - echo \"DESCRIPTION=README.md\" > variables.env\n    - echo \"TAG=$TAG\" >> variables.env\n    # prepare deploy2zenodo\n    - echo \"DEPLOY2ZENODO_JSON=$DEPLOY2ZENODO_JSON\" >> variables.env\n    - DEPLOY2ZENODO_UPLOAD=\"v$TAG.zip\"\n    - git archive --format zip --output \"$DEPLOY2ZENODO_UPLOAD\" \"$TAG\"\n    - echo \"DEPLOY2ZENODO_UPLOAD=$DEPLOY2ZENODO_UPLOAD\" >> variables.env\n  artifacts:\n    reports:\n      dotenv: variables.env\n    paths:\n      - $DEPLOY2ZENODO_JSON\n\nrelease_job:\n  stage: deploy\n  rules:\n    - if: $CI_COMMIT_TAG\n      when: never\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n  image:\n    registry.gitlab.com/gitlab-org/release-cli:latest\n  script:\n    - cat /etc/os-release\n  release:\n    name: 'v$TAG'\n    description: '$DESCRIPTION'\n    tag_name: '$TAG'\n    ref: '$CI_COMMIT_SHA'\n\ndeploy2zenodo:\n  rules:\n    - if: $CI_COMMIT_TAG\n      when: never\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n  variables:\n    DEPLOY2ZENODO_API_URL: \"https://sandbox.zenodo.org/api\"\n    DEPLOY2ZENODO_DEPOSITION_ID: \"create NEW record\"\n```\n\nWe use here 3 jobs:\n\n* The job `prepare_release_and_deploy2zenodo` prepares the\n  variables and data for the following jobs. You can choose how to get\n  the variables and data from your project/repository.\n  (see hints in [DEPLOY2ZENODO_JSON](#deploy2zenodo_json) and\n  [DEPLOY2ZENODO_UPLOAD](#deploy2zenodo_upload))\n* The job `release_job` uses the workflow\n  [Create release metadata in a custom script](https://docs.gitlab.com/ee/user/project/releases/release_cicd_examples.html#create-release-metadata-in-a-custom-script).\n* The job `deploy2zenodo` publishes the data to zenodo.\n\nThe variables are passed between the jobs using\n[dotenv variables](https://docs.gitlab.com/ee/ci/yaml/artifacts_reports.html#artifactsreportsdotenv).\nAnd the data are passed using\n[job artifacts](https://docs.gitlab.com/ee/ci/jobs/job_artifacts.html).\n\nAfter the first run of the above pipeline (job `deploy2zenodo`) adapt\n`DEPLOY2ZENODO_DEPOSITION_ID` to store the record id. Only then you are\nable to release new versions to zenodo.\n\nIn this example, `prepare_release_and_deploy2zenodo` always runs\nwhile the other jobs only run when the default branch is changed.\nThis makes it possible to check the artifacts during a merge request.\n\nThe used environment variables (see [script parameter](#script-parameter)) can\nbe provided in many different ways as a\n[GitLab CI/CD variable](https://docs.gitlab.com/ee/ci/variables/), e. g.:\n\n* [CI/CD variable in the UI](https://docs.gitlab.com/ee/ci/variables/#define-a-cicd-variable-in-the-ui)\n  * not stored in the repository\n  * possible to [Mask variable](https://docs.gitlab.com/ee/ci/variables/index.html#mask-a-cicd-variable)\n  * possible to [Protect variable](https://docs.gitlab.com/ee/ci/variables/index.html#protect-a-cicd-variable)\n  * used for private data (e. g. access token)\n* [CI/CD variable in the .gitlab-ci.yml](https://docs.gitlab.com/ee/ci/variables/#define-a-cicd-variable-in-the-gitlab-ciyml-file)\n  * stored in the repository\n  * in public projects also publicly accessable\n\nYou should think about which information to store at which place.\nHere a few simple considerations:\n\n| variable | private data | note |\n| ------ | ------ | ------ |\n| DEPLOY2ZENODO_API_URL | no | Should a user find your publication? |\n| DEPLOY2ZENODO_ACCESS_TOKEN | YES | Should not be shared with anyone! |\n| DEPLOY2ZENODO_DEPOSITION_ID | no | Should a user find your publication? |\n| DEPLOY2ZENODO_JSON | ? | Is the publication public? |\n| DEPLOY2ZENODO_UPLOAD | ? | Is the publication public? |\n\nSometimes it is easier to change the variable in the UI.\nFor example in your first step you should set\n`DEPLOY2ZENODO_API_URL=\"https://sandbox.zenodo.org/api\"` and\n`DEPLOY2ZENODO_DEPOSITION_ID=\"create NEW record\"` to initiate and test your\npipeline. After success you should change to\n`DEPLOY2ZENODO_API_URL=\"https://zenodo.org/api\"`.\nAnd after you have created your first record, also change\n`DEPLOY2ZENODO_DEPOSITION_ID` to the returned value to update your dataset\nnext time (and not create a new one). If you store these variables in the user\ninterface, you can change them without touching your repository.\nOn the other hand, the metadata provided via `DEPLOY2ZENODO_JSON` and the\ndata provided via `DEPLOY2ZENODO_UPLOAD` may be created dynamically and\nit could therefore make sense to create these variables dynamically as well.\n\nThere are also optional variables that can help to adapt the workflow to the\nthe individual use case.\nFor example, [DEPLOY2ZENODO_SKIP_PUBLISH](#deploy2zenodo_skip_publish) allows\nyou to curate the upload to zenodo in the zenodo web interface before\npublishing. This is especially useful if you are setting up the workflow for\nthe first time in your own project -- but can also be used at any time.\n\nDepending on where variables are defined, they have different priorities.\nFor example, CI variables defined in the UI have priority and override the\nvariables stored in the `.gitlab-ci.yml` file with the\n[keyword `variables`](https://docs.gitlab.com/ee/ci/yaml/#variables).\nVariables that are defined at job level, in the `script`, `before_script` or\n`after_script` sections, have the highest priority\n\nAn example test project is [deploy2zenodo_test_simple_workflow_update](https://gitlab.com/projects/51647607).\n\n### very simple workflow\n\nIt is not necessary to create a release for publication. But we think this\nis the typically use case for software publication.\n\nFor a very simple workflow running when creating a tag,\nyou could use something like:\n\n```yaml\ninclude:\n  - remote: 'https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/permalink/latest/downloads/deploy2zenodo.yaml'\n\ndeploy2zenodo:\n  stage: deploy\n  rules:\n    - if: $CI_COMMIT_TAG\n  variables:\n    DEPLOY2ZENODO_API_URL: \"https://sandbox.zenodo.org/api\"\n    DEPLOY2ZENODO_JSON: \"CITATION.json\"\n    DEPLOY2ZENODO_DEPOSITION_ID: \"create NEW record\"\n    DEPLOY2ZENODO_UPLOAD: \"$CI_PROJECT_NAME-$CI_COMMIT_TAG.zip\"\n    DEPLOY2ZENODO_ADD_IsCompiledBy_DEPLOY2ZENODO: \"yes\"\n    DEPLOY2ZENODO_ADD_IsNewVersionOf: \"yes\"\n    DEPLOY2ZENODO_ADD_IsPartOf: \"yes\"\n    DEPLOY2ZENODO_GET_METADATA: \"result.json\"\n  before_script:\n    - env\n    - echo https://dl-cdn.alpinelinux.org/alpine/edge/community >> /etc/apk/repositories\n    - apk add --no-cache cffconvert curl git jq\n    - publication_date=$(echo \"$CI_COMMIT_TIMESTAMP\" | grep -Eo \"^[0-9]{4}-[0-9]{2}-[0-9]{2}\")\n    - |\n      cffconvert -i CITATION.cff -f zenodo | \\\n        jq -c '{\"metadata\": .} | .metadata += {\"upload_type\": \"software\"}' | \\\n        jq -c \".metadata.related_identifiers += [\n          {\\\"relation\\\": \\\"isDerivedFrom\\\",\n          \\\"identifier\\\": \\\"$CI_SERVER_URL/projects/$CI_PROJECT_ID\\\"}] |\n          .metadata.version = \\\"$CI_COMMIT_TAG\\\" |\n          .metadata.publication_date = \\\"$publication_date\\\"\" | \\\n        tee \"$DEPLOY2ZENODO_JSON\" | jq -C .\n    - git archive --format zip --output \"$DEPLOY2ZENODO_UPLOAD\" \"$CI_COMMIT_TAG\"\n  artifacts:\n    paths:\n      - $DEPLOY2ZENODO_JSON\n      - $DEPLOY2ZENODO_GET_METADATA\n```\n\nSuch a simple workflow uses\n\n* [deploy_deploy2zenodo_to_zenodo](https://gitlab.com/projects/52008252)\n  in the job `deploy2zenodo` to publish itself.\n* [2024-10_waw_fdm](https://codebase.helmholtz.cloud/projects/14469)\n  in the job `deploy2zenodo` to publish a poster.\n\n### triggered workflow\n\nIn many projects there is more than one maintainer. Therefore it is not\npossible to store the user token for zenodo as CI variable in the project.\nOtherwise, the user token would be shared with the other maintainers.\n\nUsing this triggered workflow allows to restrict the use of the user token\nto a specific zenodo record for other maintainers.\n\nBut the project `A` with more than one maintainer can trigger a pipeline in\nanother (private) project `B` with only one maintainer, e. g.:\n\n```yaml\ntrigger:\n  stage: .post\n  rules:\n    - if: $CI_COMMIT_TAG\n      when: never\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n  image:\n    name: alpine:latest\n  script:\n    - apk add --no-cache curl\n    - curl -X POST --fail -F token=\"$TRIGGER_TOKEN\" -F ref=main \"$TRIGGER_URL\"\n```\n\nStoring the `TRIGGER_TOKEN` as protected and\n[masked CI variable](https://docs.gitlab.com/ee/ci/variables/index.html#mask-a-cicd-variable)\n(or maybe even [hide CI variable](https://docs.gitlab.com/ee/ci/variables/index.html#hide-a-cicd-variable))\nin project `A` allows any maintainer to use it and trigger the pipeline.\n\nIn the project `B` only 1 mainainer exists and you can use\ndeploy2zenodo as normal, e. g.:\n\n```yaml\ninclude:\n  - remote: 'https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/permalink/latest/downloads/deploy2zenodo.yaml'\n\nprepare_deploy2zenodo:\n  image:\n    name: alpine:latest\n  script:\n    - PROJECT_A_REPO=$(mktemp -d)\n    - git clone --branch main --depth 1 \"$PROJECT_A_URL\" \"$PROJECT_A_REPO\"\n    # create zip archive from latest tag\n    - |\n      (cd \"$PROJECT_A_REPO\" && \\\n       git archive --format zip -o \"$DEPLOY2ZENODO_UPLOAD\" \\\n       \"$(git tag | sort -t \".\" -n -k 3 | tail -n 1)\")\n  artifacts:\n    expire_in: 1 hrs\n    paths:\n      - $DEPLOY2ZENODO_UPLOAD\n\nmy_deploy2zenodo:\n  extends: .deploy2zenodo\n  # variables set in the script could not be overwritten by the trigger source\n  before_script:\n    - |\n      DEPLOY2ZENODO_DEPOSITION_ID=\"create NEW record\"\n      DEPLOY2ZENODO_API_URL=\"https://sandbox.zenodo.org/api\"\n    - !reference [deploy2zenodo, before_script]\n\ndeploy2zenodo:\n  rules:\n    - if: '\"0\" == \"1\"'\n      when: never\n```\n\nThere are various ways to trigger a pipeline, e. g:\n\n* [trigger a pipeline by trigger token](https://docs.gitlab.com/ee/ci/triggers/)\n* trigger using [Multi-project pipelines](https://docs.gitlab.com/ee/ci/pipelines/downstream_pipelines.html#multi-project-pipelines)\n\nIn the CI pipeline above the token method is used. In the\n[CI pipeline of deploy2zenodo](https://gitlab.com/deploy2zenodo/deploy2zenodo/-/blob/main/.gitlab-ci.yml?ref_type=heads)\nthe multi-project pipeline is used.\n\n**Be careful**:\nThe trigger job from project `A` may overwrite variables in the triggered\njob from project `B`. This could lead to security concerns.\nMaybe [Restrict who can override variables](https://docs.gitlab.com/ee/ci/variables/index.html#restrict-who-can-override-variables)\ncould help to overcome this.\n\nMore details:\nIn project `A` something exists that should be published on zenodo.\nIn project `B` the content of project `A` is published on zenodo.\nThe pipeline in project `B` can be triggered so that this happens\nautomatically when corresponding changes are made in project `A`\n(e. g. merge to default branch).\nProject `B` should rely as little as possible on project `A`.\nUnfortunately, variables can be transferred when triggering (from project `A`)\nand these are not trustworthy.\nFor example, a maintainer from project `A` could pass `DEPLOY2ZENODO_API_URL`\nin this way and thus force communication to another server.\nThis could cause the user token to be leaked.\nTo avoid this, define the variable in the script -- as shown in the example\nabove.\nHowever, it is no problem to save the user token in project `B` as\nCI variable `DEPLOY2ZENODO_ACCESS_TOKEN`.\nThis variable could then be overwritten from project `A`, but not read out.\n\nAnother possibility is to use\n[Secrets management providers](https://docs.gitlab.com/ee/ci/pipelines/pipeline_security.html#secrets-management-providers).\n\nThis triggered workflow is used in\n[file_hook_server_timestamping](https://gitlab.com/dlr-pa/file_hook_server_timestamping)\ntogether with\n[deploy_file_hook_server_timestamping_to_zenodo](https://gitlab.dlr.de/deploy2zenodo/deploy_file_hook_server_timestamping_to_zenodo).\n\n### complex workflow\n\nThis workflow splits the deploying to zenodo in steps. This allows to use\nthe zenodo record (e. g. the DOI) already in the data to publish.\n\n```yaml\ninclude:\n  - remote: 'https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/permalink/latest/downloads/deploy2zenodo.yaml'\n\ndeploy2zenodo:\n  rules:\n    - if: '\"0\" == \"1\"'\n      when: never\n\nprepare_deploy2zenodo_step1:\n  script:\n    - ...\n\ndeploy2zenodo-step1:\n  variables:\n    - DEPLOY2ZENODO_SKIP_PUBLISH: \"true\"\n    - DEPLOY2ZENODO_GET_METADATA: \"newmetadata.json\"\n  extends: .deploy2zenodo\n  image:\n    name: alpine:latest\n  before_script:\n    - !reference [deploy2zenodo, before_script]\n  script:\n    - !reference [deploy2zenodo, script]\n    - echo \"DEPLOY2ZENODO_GET_METADATA=$DEPLOY2ZENODO_GET_METADATA\" > variables.env\n  artifacts:\n    paths:\n      - $DEPLOY2ZENODO_GET_METADATA\n    reports:\n      dotenv: variables.env\n\nprepare_release:\n  script:\n    - echo \"use the file \\\"$DEPLOY2ZENODO_GET_METADATA\\\"\"\n    - ...\n\nrelease_job:\n  script:\n    - ...\n\nprepare_deploy2zenodo_step2:\n  script:\n    - ...\n\ndeploy2zenodo-step2:\n  variables:\n    DEPLOY2ZENODO_SKIP_NEW_VERSION: \"true\"\n  extends: .deploy2zenodo\n  image:\n    name: alpine:latest\n  before_script:\n    - apk add --no-cache curl jq\n```\n\nIn the step `prepare_release` you can use [jq](https://github.com/jqlang/jq)\nto extract data. For example the preserved DOI is available by:\n\n```sh\njq .metadata.prereserve_doi.doi \"$DEPLOY2ZENODO_GET_METADATA\"\n```\n\nSuch a complex workflow uses\n[2024-10_waw_fdm_talk](https://codebase.helmholtz.cloud/projects/14501)\nto publish a poster. Instead of creating a release, as shown above, the\nposter is built in the job `build` using the DOI previously created in\nthe job `deploy2zenodo-step1`.\n\n### very complex workflow\n\n`deploy2zenodo` uses a combination of the [triggered workflow](https://gitlab.com/deploy2zenodo/deploy2zenodo#triggered-workflow)\nand the [complex workflow](https://gitlab.com/deploy2zenodo/deploy2zenodo#complex-workflow)\nto publish itself. This is described in [deploy_deploy2zenodo_to_zenodo](https://gitlab.com/projects/52008252).\n\n## script parameter\n\nInstead of command line parameters we use environment variables.\n\nYou have to provide the following variables:\n\n| variable | content |\n| ------ | ------ |\n| DEPLOY2ZENODO_API_URL | The URL of the API to use. |\n| DEPLOY2ZENODO_ACCESS_TOKEN | access token of zenodo |\n| DEPLOY2ZENODO_DEPOSITION_ID | id of the deposition/record on zenodo |\n| DEPLOY2ZENODO_JSON | file name with metadata in JSON format to upload |\n| DEPLOY2ZENODO_UPLOAD | file name(s) to upload |\n\nThere are other optional variables:\n\n| variable | content |\n| ------ | ------ |\n| DEPLOY2ZENODO_SKIP_PUBLISH | prepare record, but skip publishing |\n| DEPLOY2ZENODO_DRYRUN | skip communicating with the external URL |\n| DEPLOY2ZENODO_SKIPRUN | skip everything, only prints commands to execute |\n| DEPLOY2ZENODO_SKIP_NEW_VERSION | skip creating new version |\n| DEPLOY2ZENODO_GET_METADATA | write actual metadata to a file |\n| DEPLOY2ZENODO_SKIP_UPLOAD | skip upload of data |\n| DEPLOY2ZENODO_CURL_MAX_TIME | max time for curl |\n| DEPLOY2ZENODO_CURL_MAX_TIME_PUBLISH | max time for curl during publishing |\n| DEPLOY2ZENODO_ADD_IsCompiledBy_DEPLOY2ZENODO | reference deploy2zenodo |\n| DEPLOY2ZENODO_ADD_IsNewVersionOf | reference previous version |\n| DEPLOY2ZENODO_ADD_IsPartOf | reference DOI for all versions |\n\n### DEPLOY2ZENODO_API_URL\n\nYou can use the API of your own zenodo instance or you can use the\nofficial [zenodo instance](https://about.zenodo.org/):\n\n| state | URL |\n| ------ | ------ |\n| production | [`https://zenodo.org/api`](https://zenodo.org/api) |\n| testing | [`https://sandbox.zenodo.org/api`](https://sandbox.zenodo.org/api) |\n\n### DEPLOY2ZENODO_ACCESS_TOKEN\n\nTo access your zenodo account you have to provide an\n[access token](https://developers.zenodo.org/?shell#authentication).\n\n### DEPLOY2ZENODO_DEPOSITION_ID\n\nTo update an existing record you have to provide the `id` of this record.\n\nIf you want to create a new record please set `DEPLOY2ZENODO_DEPOSITION_ID`\nto `create NEW record`,\ne. g. `DEPLOY2ZENODO_DEPOSITION_ID=\"create NEW record\"`.\nAfter creating this record read the script output\nand adapt `DEPLOY2ZENODO_DEPOSITION_ID` for the next run with the returned\nrecord `id`.\n\n### DEPLOY2ZENODO_JSON\n\nThe given file should contain the metadata in JSON format.\n\nYou can write this file on your own, e. g.:\n\n```json\n{\n  \"metadata\": {\n    \"title\": \"foo\",\n    \"upload_type\": \"software\",\n    \"creators\": [\n      {\n        \"name\": \"ich\",\n        \"affiliation\": \"bar\"\n      }\n    ],\n    \"description\": \"foos description\"\n  }\n}\n```\n\nYou can find the necessary and possible fields on\n[zenodo: Deposit metadata](https://developers.zenodo.org/#representation).\n\nOr [cffconvert](https://github.com/citation-file-format/cffconvert) can help\nharvesting the necessary metadata in JSON format from a\n[CITATION.cff file](https://github.com/citation-file-format/citation-file-format).\nUnfortunately we need [jq](https://github.com/jqlang/jq) to correct the format,\ne. g.:\n\n```sh\ncffconvert -i CITATION.cff -f zenodo | \\\n  jq '{\"metadata\": .} | .metadata += {\"upload_type\": \"software\"}' | \\\n  tee CITATION.json\n```\n\nSince you need to adapt the output of the conversion you can also use more\ngeneral tools like [yq](https://mikefarah.gitbook.io/yq/) to convert\na CITATION.cff file (YAML format) to JSON format.\n\nThe JSON format zenodo accepts is much more general and provides many more\noptions than the Citation File Format. For many purposes the CITATION.cff\nis enough, but otherwise you can see a description of the metadata in the\nGitHub integration of\nzenodo[^githubintegration] [^githubintegration2] [^githubintegration3]\nusing `zenodo.json`, the description of the metadata in\nzenodo|Developers[^zenodoDevelopers] or InvenioRDM[^metadatareference] and\nthe unofficial description of\nzenodo upload metadata schema[^zenodouploadmetadataschema].\n\n[^githubintegration]: [developers.zenodo.org GitHub](https://developers.zenodo.org/#github)\n[^githubintegration2]: [github.com Referencing and citing content](https://docs.github.com/en/repositories/archiving-a-github-repository/referencing-and-citing-content)\n[^githubintegration3]: [github: \"import\" past releases to Zenodo](https://github.com/zenodo/zenodo/issues/1463)\n\n[^zenodoDevelopers]: [zenodo|Developers](https://developers.zenodo.org/#deposit-metadata)\n\n[^metadatareference]: [InvenioRDM: Metadata reference](https://inveniordm.docs.cern.ch/reference/metadata/)\n\n[^zenodouploadmetadataschema]: [Zenodo upload metadata schema](https://github.com/zenodraft/metadata-schema-zenodo)\n\nAs `description` you can use HTML. For example you could use\n[pandoc](https://pandoc.org/) to convert your `README.md` to HTML and\n[jq](https://github.com/jqlang/jq) to add the HTML code as JSON\nvalue (`jq` will escape appropriate characters if necessary):\n\n```sh\npandoc -o README.html README.md\necho '{\"metadata\":{\"title\":\"foo\",\"upload_type\":\"software\",\n  \"creators\":[{\"name\":\"ich\",\"affiliation\":\"bar\"}],\n  \"description\":\"foos description\"}}' | \\\n  jq --rawfile README README.html '.metadata.description = $README' | \\\n  tee metadata.json\n```\n\n### DEPLOY2ZENODO_UPLOAD\n\nThe given file(s) will be uploaded as data. Typically this would be an archive.\n\nFor example you can create an archive of a tag from a git repository:\n\n```sh\nTAG=0.0.3\ngit archive --format zip --output $TAG.zip $TAG\n```\n\nFile names with spaces are not supported. Instead, if `DEPLOY2ZENODO_UPLOAD`\ncontains space(s), the string is split at the spaces.\nEach individual block represents a file and these files will be uploaded.\n\nThe reason not supporting spaces is that\n[you cannot create a CI/CD variable that is an array](https://docs.gitlab.com/ee/ci/variables/index.html#store-multiple-values-in-one-variable).\n\nIf you really not want to provide data set `DEPLOY2ZENODO_UPLOAD` to\n`do NOT provide data`, e. g. `DEPLOY2ZENODO_UPLOAD=\"do NOT provide data\"`.\nIf you want to upload 4 files with these names change the order.\n\nNot every zenodo instance supports metadata-only records\n(configured by `canHaveMetadataOnlyRecords`?).\nFor example the official [zenodo instance](https://about.zenodo.org/)\ndoes not allow metadata-only records!\nIn this case an empty dummy file is uploaded.\nIf this is the case, you should think about respecting the implicit request\nof the used zenodo instance to provide some data.\n\n### DEPLOY2ZENODO_SKIP_PUBLISH\n\nIf this variable is not empty the publishing step is skipped, e. g.:\n\n```sh\n DEPLOY2ZENODO_SKIP_PUBLISH=\"true\"\n```\n\nOnly the record is prepared -- metadata and data is uploaded -- but not\npublished.\nYou can see what will be published as a preview in the web interface of zenodo\nand initiate the publishing by pressing the button in the web interface.\n\nThis helps to integrate `deploy2zenodo` in your project.\nBut you may also want to curate the upload each time before it is published.\n\nTogether with DEPLOY2ZENODO_SKIP_NEW_VERSION this allows to split deploying\nto zenodo in steps.\n\n### DEPLOY2ZENODO_DRYRUN\n\nIf this variable is not empty the communication to the given URL is skipped.\nBut your parameters are analyzed. This could help to integrate `deploy2zenodo`\nin your project.\n\n### DEPLOY2ZENODO_SKIPRUN\n\nIf this variable is not empty nearly everything is skipped.\nOnly the commands to be executed are echoed. This is for debugging purpose.\n\n### DEPLOY2ZENODO_SKIP_NEW_VERSION\n\nIf this variable is not empty the step creating a new version is skipped.\nThis allows to split deploying to zenodo in steps.\n\nBetween creating a new version and deploying to zenodo you can\nuse the zenodo record (e. g. the DOI) already in the data to publish:\n\n```sh\njq .metadata.prereserve_doi.doi \"$DEPLOY2ZENODO_GET_METADATA\" >> README.md\n```\n\nUsing a [manual job](https://docs.gitlab.com/ee/ci/jobs/job_control.html#create-a-job-that-must-be-run-manually)\nallows you to first check the artifacts and data to be published\nbefore the last job run.\n\n### DEPLOY2ZENODO_GET_METADATA\n\nIf this variable is not empty the metadata of the record is stored in a\nfile with this name.\nThis is useful for logging or further processing after deployment.\n\nTo get these data at the end of the script an additional communication\nwith the DEPLOY2ZENODO_API_URL server is done.\n\nIn the CI pipeline you could store the result as artifacts, e. g.:\n\n```yaml\ndeploy2zenodo:\n  variables:\n    DEPLOY2ZENODO_GET_METADATA: \"result.json\"\n  artifacts:\n    paths:\n      - $DEPLOY2ZENODO_GET_METADATA\n```\n\nYou can extract values from the metadata. For example to get the DOI\nto site all versions:\n\n```yaml\nmy_deploy2zenodo:\n  extends: .deploy2zenodo\n  script:\n    - !reference [deploy2zenodo, script]\n    - jq -r .conceptdoi \"$DEPLOY2ZENODO_GET_METADATA\"\n```\n\n### DEPLOY2ZENODO_SKIP_UPLOAD\n\nIf this variable is not empty skip uploading the data. This is only\nallowed if DEPLOY2ZENODO_SKIP_PUBLISH is not empty, too.\n\nIf you split deploying to zenodo in steps using DEPLOY2ZENODO_SKIP_PUBLISH and\nDEPLOY2ZENODO_SKIP_NEW_VERSION you can avoid unnecessary traffic by using also\nDEPLOY2ZENODO_SKIP_UPLOAD.\n\n### DEPLOY2ZENODO_CURL_MAX_TIME\n\nMax time for curl (`--max-time` flag) in seconds for normal use.\nDefault value is 60.\n\n### DEPLOY2ZENODO_CURL_MAX_TIME_PUBLISH\n\nMax time for curl (`--max-time` flag) in seconds during publishing.\nDefault value is 300.\n\n### DEPLOY2ZENODO_ADD_IsCompiledBy_DEPLOY2ZENODO\n\nIf this variable is not empty a reference to deploy2zenodo is added.\nSomething like (but with the DOI of the used version) will be added to your\nprovided JSON file:\n\n```json\n{\n  \"metadata\": {\n    \"related_identifiers\": [\n      {\n        \"relation\": \"IsCompiledBy\",\n        \"identifier\": \"10.5281/zenodo.10112959\",\n        \"scheme\": \"doi\",\n        \"resource_type\": \"software\"\n      }\n    ]\n  }\n}\n```\n\n### DEPLOY2ZENODO_ADD_IsNewVersionOf\n\nIf this variable is not empty a reference to the previous version of your\nrecord is referenced.\nSomething like (but with the DOI of the old version and the appropriate\nresource_type) will be added to your provided JSON file:\n\n```json\n{\n  \"metadata\": {\n    \"related_identifiers\": [\n      {\n        \"relation\": \"IsNewVersionOf\",\n        \"identifier\": \"10.5281/zenodo.10908332\",\n        \"scheme\": \"doi\",\n        \"resource_type\": \"software\"\n      }\n    ]\n  }\n}\n```\n\nThis can only work if DEPLOY2ZENODO_SKIP_NEW_VERSION is not used! If you split\nthe run in 2 steps (the first one with DEPLOY2ZENODO_SKIP_PUBLISH and the\nsecond one with DEPLOY2ZENODO_SKIP_NEW_VERSION) you have to find the old\nversion in the first run by yourself and provide it in the second run.\nThis is done in [deploy_deploy2zenodo_to_zenodo](https://gitlab.com/projects/52008252)\nin the jobs `deploy_deploy2zenodo_step1` and `deploy_deploy2zenodo_step2`\nto publish `deploy2zenodo`. This is something like:\n\n```yaml\nstep1:\n  variables:\n    DEPLOY2ZENODO_ADD_IsNewVersionOf: \"yes\"\n  after_script:\n    - |\n      LATESTDOI=\"$(jq -r \".metadata.related_identifiers[] |\n      select(.relation==\\\"isNewVersionOf\\\") | .identifier\" \\\n      \"$DEPLOY2ZENODO_GET_METADATA\")\"\n    - |\n      LATESTUPLOADTYPE=\"$(jq -r \".metadata.related_identifiers[] |\n      select(.relation==\\\"isNewVersionOf\\\") | .resource_type\" \\\n      \"$DEPLOY2ZENODO_GET_METADATA\")\"\n    - |\n      {\n      echo \"LATESTDOI=$LATESTDOI\"\n      echo \"LATESTUPLOADTYPE=$LATESTUPLOADTYPE\"\n      } | tee variables.env\n  artifacts:\n    reports:\n      dotenv: variables.env\n```\n\n```yaml\nstep2:\n  needs:\n    - job: step1\n  variables:\n    DEPLOY2ZENODO_SKIP_NEW_VERSION: \"true\"\n  before_script:\n    - tmpjson=\"$(mktemp)\"\n    - |\n      jq \".metadata.related_identifiers += [\n      {\n      \\\"relation\\\":\\\"IsNewVersionOf\\\", \\\"identifier\\\":\\\"$LATESTDOI\\\",\n      \\\"scheme\\\":\\\"doi\\\", \\\"resource_type\\\":\\\"$LATESTUPLOADTYPE\\\"\n      }]\" \"$DEPLOY2ZENODO_JSON\" | tee \"$tmpjson\"\n    - mv \"$tmpjson\" \"$DEPLOY2ZENODO_JSON\"\n```\n\nNote that [after_script](https://docs.gitlab.com/ee/ci/yaml/#after_script)\nworks differently than `before_script` or `script` and does not affect the\njob exit code.\n\n### DEPLOY2ZENODO_ADD_IsPartOf\n\nIf this variable is not empty a reference to all versions of your record is\nreferenced.\nSomething like (but with the DOI of all versions and the appropriate\nresource_type) will be added to your provided JSON file:\n\n```json\n{\n  \"metadata\": {\n    \"related_identifiers\": [\n      {\n        \"relation\": \"IsPartOf\",\n        \"identifier\": \"10.5281/zenodo.10112959\",\n        \"scheme\": \"doi\",\n        \"resource_type\": \"software\"\n      }\n    ]\n  }\n}\n```\n\nThis only works, if DEPLOY2ZENODO_DEPOSITION_ID is not given\nas `create NEW record`.\n\n## CI pipeline\n\nUsing the keyword\n[`include`](https://docs.gitlab.com/ee/ci/yaml/index.html#include)\nit is possible to include YAML files and/or CI pipelines in your\n[GitLab](https://about.gitlab.com/) CI pipeline.\nIn this way you can use a template of `deploy2zenodo` for your CI pipeline.\n\nYou can use the latest version\n[deploy2zenodo.yaml](https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/permalink/latest/downloads/deploy2zenodo.yaml)\nin your CI pipeline.\nOr you can use any special versions, e. g.\n[deploy2zenodo.yaml v0.1.0](https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/0.1.0/downloads/deploy2zenodo.yaml).\n\nThe provided job is called `deploy2zenodo` and you can overwrite or enhance\nthe defined job as you need (e. g. defining when to run or defining variables).\n\nA simple example choosing the stage to run could be:\n\n```yaml\ninclude:\n  - remote: 'https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/permalink/latest/downloads/deploy2zenodo.yaml'\n\ndeploy2zenodo:\n  stage: deploy\n```\n\nThe provided GitLab CI template of `deploy2zenodo` uses\n[`alpine:latest`](https://hub.docker.com/_/alpine)\nand installs necessary software [curl](https://curl.se/) and\n[jq](https://github.com/jqlang/jq) in `before_script`.\nTo use other images you must adapt it, e. g.:\n\n```yaml\ninclude:\n  - remote: 'https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/permalink/latest/downloads/deploy2zenodo.yaml'\n\ndeploy2zenodo:\n  image:\n    name: almalinux:latest\n  before_script:\n    - echo \"nothing to do\"\n```\n\n## script\n\nYou can use the script directly. But that is not our main focus of\n`deploy2zenodo`, so we keep it short. For example:\n\n```sh\nSCRIPTURL=https://gitlab.com/deploy2zenodo/deploy2zenodo/-/releases/permalink/latest/downloads/deploy2zenodo\nexport DEPLOY2ZENODO_API_URL=https://sandbox.zenodo.org/api\nexport DEPLOY2ZENODO_ACCESS_TOKEN=***\nexport DEPLOY2ZENODO_DEPOSITION_ID=\"create NEW record\"\nexport DEPLOY2ZENODO_JSON=metadata.json\nexport DEPLOY2ZENODO_UPLOAD=\"foo.zip bar.md\"\nexport DEPLOY2ZENODO_SKIP_PUBLISH=\"true\"\nexport DEPLOY2ZENODO_DRYRUN=\"\"\nexport DEPLOY2ZENODO_SKIPRUN=\"\"\nexport DEPLOY2ZENODO_SKIP_NEW_VERSION=\"\"\nexport DEPLOY2ZENODO_GET_METADATA=\"upload.json\"\nexport DEPLOY2ZENODO_SKIP_UPLOAD=\"\"\nexport DEPLOY2ZENODO_CURL_MAX_TIME=\"\"\nexport DEPLOY2ZENODO_CURL_MAX_TIME_PUBLISH=\"\"\ncurl -L \"$SCRIPTURL\" | tee deploy2zenodo.sh | sh\n```\n\nIt's worth noting that we try to handle private information such as the\naccess token in a secure way in the script, it is still a sensitive piece of\ninformation that should not be shared with anyone who does not need access to\nthe corresponding Zenodo account.\n\n**Important:** Using the script as described in this section (e. g. on a\ndesktop computer) does not allow for the masking of CI variables, which can\nexpose sensitive information such as access tokens. We recommend that users\ntake steps to mitigate this risk.\n\n## harvesting\n\nAs already mentioned you have to provide the metadata and the data to upload.\n\nIn my opinion, this is very dependent on the project.\nIn many programming languages, there is a convention to store metadata such\nas name, author, description, version and license in certain\nfiles (`pyproject.toml`, `library.properties`, ...).\nIn order to deploy this information to zenodo, it must be available in a\ncertain format and with a certain vocabulary. The already mentioned\n[cffconvert](https://github.com/citation-file-format/cffconvert) tries to do\nthis at least for cff files.\nOther tools such as [somesy](https://github.com/Materials-Data-Science-and-Informatics/somesy)\nhave a somewhat different focus, but they can also help in a pipeline/toolchain.\nFor example, you could use it to convert a typical python `pyproject.toml`\ninto `CITATION.cff` and then use\n[cffconvert](https://github.com/citation-file-format/cffconvert) and\n[jq](https://github.com/jqlang/jq) to get metadata for zenodo.\nHowever, [hermes](https://docs.software-metadata.pub/en/latest/) should also\nbe mentioned here. hermes tries to merge metadata from different sources and\nto provide it for zenodo.\n\n## curating\n\nYou have various options for curating the data for publication.\n\nThe typical workflow in software development is to work in developer or\nfeature branches and then merge them with the default branch (e. g. `main`).\nThis is usually done in a merge request. If the harvesting of metadata and\ndata is already taking place in a CI pipeline at this point, this can also\nbe checked in the merge request.\n\nIf publishing is prevented by using `DEPLOY2ZENODO_SKIP_PUBLISH`,\nthe preview in the zenodo web interface can be used to check the result.\n\nIf you have implemented a stable, functioning process, curation can also be\nomitted and publishing can be fully automated.\n\n## license: Apache-2.0\n\n`deploy2zenodo` has the license [Apache-2.0](http://www.apache.org/licenses/LICENSE-2.0).\n\n```txt\nCopyright 2023, 2024 Daniel Mohr and\n   Deutsches Zentrum fuer Luft- und Raumfahrt e. V., D-51170 Koeln\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n",
            "project_id": "51392274"
        },
        {
            "software_organization": "https://helmholtz.software/software/deus",
            "repo_link": "https://github.com/gfzriesgos/deus",
            "readme": "# deus\n\n[![codecov](https://codecov.io/gh/gfzriesgos/deus/branch/master/graph/badge.svg)](https://codecov.io/gh/gfzriesgos/deus)\n\n**D**amage-**E**xposure-**U**pdate-**S**ervice\n\nCommand line program for the damage computation in a multi risk scenario\npipeline for earthquakes, tsnuamis, ashfall & lahars.\n\n## Citation\nBrinckmann, Nils; Gomez-Zapata, Juan Camilo; Pittore, Massimiliano; Rüster, Matthias (2021): DEUS: Damage-Exposure-Update-Service. V. 1.0. GFZ Data Services. https://doi.org/10.5880/riesgos.2021.011\n\n## What is it?\n\nThis is the service to update a given exposure file (as it is the output\nof the assetmaster script) and update the building and damage classes\nwith given fragility functions and intensity values.\n\n## Copyright & License\nCopyright © 2021 Helmholtz Centre Potsdam GFZ German Research Centre for Geosciences, Potsdam, Germany\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n\nhttps://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n\n## Project\n\nDeus was developed in the scope of the RIESGOS project:\nMulti-Risk Analysis and Information System Components for the Andes Region (https://www.riesgos.de/en)\n\n\n## Documentation\n\nYou can look up several documentation pages:\n\n- [Setup and installation](doc/Setup.md)\n- [Example run](doc/ExposureModel.md)\n- [Shakemaps](doc/EarthQuakeShakemap.md) and [Intensity files](doc/IntensityFile.md)\n- [Exposure models](doc/ExposureModel.md)\n- [Fragility functions](doc/FragilityFunctions.md)\n- [Loss](doc/LossData.md)\n- [Schema mappings](doc/SchemaMapping.md)\n\n## Scope of deus\n\nDeus was created in the riesgos project for working in multi risk scenarios.\nIt should be provided as a web processing service by the GFZ.\n\n## You still have questions\n\nIf we don't cover important things in the documentation, please feel free to\ncreate an issue or send a mail at\n<nils.brinckmann@gfz-potsdam.de> or <pittore@gfz-potsdam.de>.\n\n## Can I use deus for xyz?\n\nYes! But you may have to code a bit yourself. The code is written against interfaces\nand already provides several implementations for some of them.\n\nAims for the following development of deus is the support of more and more\nhazards with their intensity files, their fragility functions and their schemas.\n\nYou can also take a look into the [TODOs](TODO.md).\n\n## Will there only be one deus?\n\nThere is deus and there is volcanus (a special deus version \"volcanus\"\nthat works with shapefiles for intensities - it uses a column LOAD and a unit of kPa -\nto allow a special ashfall service in the RIESGOS demonstrator).\n\nThe two services only differ in the intensity provider.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/digital-earth-viewer",
            "repo_link": "https://git.geomar.de/digital-earth/digital-earth-viewer",
            "readme": "# Digital Earth Viewer\r\n\r\nThe Digital Earth Viewer is a tool for the visualisation and exploration of geospatial data in true 3D over time. It runs on Windows, MacOS and Linux and only requires a modern webbrowser to use. Common file formats such as CSV, netCDF, GeoTIFF and many more are natively supported.\r\n\r\nIf you want to reference the Digital Earth Viewer in your work, please cite \"[Visualising geospatial time series datasets in realtime with the Digital Earth Viewer](https://www.sciencedirect.com/science/article/pii/S0097849322000103)\". The Digital Earth Viewer was [presented at EuroVis 2021](https://youtu.be/iIRBpXOWuPg?t=123). [Here](https://diglib.eg.org/bitstream/handle/10.2312/envirvis20211081/033-037.pdf) we present the software architecture and [here](https://diglib.eg.org/bitstream/handle/10.2312/envirvis20211082/039-042.pdf) we demonstrate a use case.\r\n\r\nDevelopment is part of [Digital Earth](https://www.digitalearth-hgf.de). \r\n\r\n\r\n\r\n## License\r\n\r\nCopyright Jens Greinert, Valentin Buck, Flemming Stäbler, Everardo Gonzalez, Jochen Mohrmann at the GEOMAR Helmholtz-Centre 2021.\r\n\r\nThe Digital Earth Viewer is licensed under the EUPL v.1.2.\r\n\r\nThis means for you:\r\n- by downloading, using or modifying this software, you choose to accept this license ([section 10](LICENSE.md#10-Acceptance-of-the-Licence))\r\n- you are free to use, reproduce and modify the work ([section 2](LICENSE.md#2-Scope-of-the-rights-granted-by-the-Licence))\r\n- you need to keep intact all license, copyright and other attribution notices ([section 5](LICENSE.md#5-Obligations-of-the-Licensee))\r\n- if you modify the software, you need to prominently mark it as such and provide the modified source code under this or a later version of this license ([section 5](LICENSE.md#5-Obligations-of-the-Licensee))\r\n- you accept that we do not offer warranty for this work ([section 7](LICENSE.md#7-Disclaimer-of-Warranty)) and are not liable for damages caused by it ([section 8](LICENSE.md#8-Disclaimer-of-Liability))\r\n\r\nA full license text can be found in the file [LICENSE.md](LICENSE.md).\r\nTranslations are available at https://joinup.ec.europa.eu/collection/eupl/eupl-text-eupl-12 \r\n\r\n## Release and Download\r\n\r\nThe gitlab builds new versions of the Digital Earth Viewer daily.\r\n\r\nClick on your operating system icon to download a bundled desktop executable.\r\n\r\n[<img width=\"120px\" src=\"documentation/icons/Logo-ubuntu_no_r_-black_orange-hex.svg.png\">](https://git.geomar.de/digital-earth/digital-earth-viewer/-/jobs/artifacts/master/raw/tileserver/target/release/digitalearthviewer?job=build_linux)\r\n\r\n[<img width=\"120px\" src=\"documentation/icons/320px-Windows_darkblue_2012.svg.png\">](https://git.geomar.de/digital-earth/digital-earth-viewer/-/jobs/artifacts/master/raw/tileserver/target/x86_64-pc-windows-gnu/release/digitalearthviewer.exe?job=build_crosscompile)\r\n\r\n[<img width=\"120px\" src=\"documentation/icons/1920px-MacOS_wordmark__2017_.svg.png \">](builds/macos/digitalearthviewer?inline=false)\r\n\r\nThere are also [releases](https://git.geomar.de/digital-earth/digital-earth-viewer/-/releases) prepared every few months which contain other platform builds as well.\r\n\r\n## Manual\r\n\r\n[<img width=\"120px\" src=\"documentation/icons/DEV_Handbook_Icon.png\">](https://git.geomar.de/digital-earth/digital-earth-viewer/-/wikis/home)\r\n[User Manual](https://git.geomar.de/digital-earth/digital-earth-viewer/-/wikis/home)\r\n\r\n\r\n## Running A Prebuilt Binary Locally\r\nThe Server hosts the website and the tiles on http://127.0.0.1:8080. It should automatically open in your default browser.\r\nYou can change the port using the `PORT` environment variable.\r\n\r\n## Building The Tileserver\r\n\r\nBuilding the tileserver takes the same steps on Windows, Linux and MacOS:\r\n* [Download and install Rust](https://rustup.rs).\r\n    * On some systems you might have to log out and log in again for the `PATH` environment variable to update after installation. You may even have to set it manually.\r\n* Switch to the `nightly` branch. Note that some components of the rust compiler may not be available with every nightly build.\r\n    * `tileserver` needs to be built with `nightly` because it uses various unstable features.\r\n    * Switch using `$ rustup default nightly`.\r\n* Install a C++ compiler, e.g. `msvc` on Windows or `gcc` on Linux.\r\n    * Be careful to have an up-to-date version of the `msvc`. It is usually installed with the [Visual Studio Community Edition](https://visualstudio.microsoft.com/download) or the [Microsoft Build Tools for C++](https://visualstudio.microsoft.com/visual-cpp-build-tools/).\r\n* Install [cmake](https://cmake.org/).\r\n* Install [GNU M4](https://www.gnu.org/software/m4/m4.html). On Windows, it is available through [`mingw-get`](http://www.mingw.org/wiki/Getting_Started) or msys.\r\n    * This is required to build `hdf5` for static linking.\r\n* Build using `$ cargo build` or `$ cargo build --release` from the tileserver directory. A first-time build may take 15 minutes or more. Later builds will be faster.\r\n    * Check out `Cargo.toml` which lists in the `[features]` section optional features that do not get compiled into the binary by default. For example, you can bundle the client into the server binary. \r\n    * Be sure to have sufficient disk space to store the build artifacts. Building both `dev` and `release` will result in several GB of build artifacts for incremental builds, even though the release binary is only 25 MB. Use a filesystem that supports symbolic links (not FAT32).\r\n* Build with `--features bundled` to include the tileclient into the server binary. Otherwise you'll have to build the tileclient for development.\r\n\r\n## Building The Tileclient For Development\r\n\r\n* Install [`node`](https://nodejs.org/).\r\n* Run `$ npm install` in the tileclient directory.\r\n\r\nRun `$ npm run compileAssets; npm run dev` in the tileclient directory to get live updates of the client during development.\r\n\r\nThis will rebuild the client on code changes. If you alter/add shaders or colormaps you will have to exit and rerun the command so changes become visible.\r\n**Changes to any of the data models may require deleting cache databases.**\r\n`tileclient` development files are served by the tileserver from `tileserver/dist/`, which is managed by `vue-cli`. \r\n### Reference Documents\r\n\r\n* [WebGL Fundamentals](https://git.geomar.de/snippets/119#webgl)\r\n* [Renderer Implementation Details](https://git.geomar.de/snippets/120#webgl-rendering-of-4d-geodata)\r\n",
            "project_id": "1748"
        },
        {
            "software_organization": "https://helmholtz.software/software/dirschema",
            "repo_link": "https://github.com/Materials-Data-Science-and-Informatics/dirschema",
            "readme": "![Project status](https://img.shields.io/badge/project%20status-alpha-%23ff8000)\n[\n![Docs](https://img.shields.io/badge/read-docs-success)\n](https://materials-data-science-and-informatics.github.io/dirschema)\n[\n![CI](https://img.shields.io/github/actions/workflow/status/Materials-Data-Science-and-Informatics/dirschema/ci.yml?branch=main&label=ci)\n](https://github.com/Materials-Data-Science-and-Informatics/dirschema/actions/workflows/ci.yml)\n[\n![Test Coverage](https://materials-data-science-and-informatics.github.io/dirschema/main/coverage_badge.svg)\n](https://materials-data-science-and-informatics.github.io/dirschema/main/coverage)\n[\n![PyPIPkgVersion](https://img.shields.io/pypi/v/dirschema)\n](https://pypi.org/project/dirschema/)\n\n<!-- --8<-- [start:abstract] -->\n# dirschema\n\n<br />\n<div>\n<img style=\"center-align: middle;\" alt=\"DirSchema Logo\" src=\"https://raw.githubusercontent.com/Materials-Data-Science-and-Informatics/Logos/main/DirSchema/DirSchema_Logo_Text.png\" width=70% height=70% />\n&nbsp;&nbsp;\n</div>\n<br />\n\nA directory structure and metadata linter based on JSON Schema.\n\n[JSON Schema](https://json-schema.org/) is great for validating (files containing) JSON\nobjects that e.g. contain metadata, but these are only the smallest pieces in the\norganization of a whole directory structure, e.g. of some dataset of project.\nWhen working on datasets of a certain kind, they might contain various types of data,\neach different file requiring different accompanying metadata, based on its file type\nand/or location.\n\n**DirSchema** combines JSON Schemas and regexes into a solution to enforce structural\ndependencies and metadata requirements in directories and directory-like archives.\nWith it you can for example check that:\n\n* only files of a certain type are in a location (e.g. only `jpg` files in directory `img`)\n* for each data file there exists a metadata file (e.g. `test.jpg` has `test.jpg_meta.json`)\n* each metadata file is valid according to some JSON Schema\n\nIf validating these kinds of constraints looks appealing to you, this tool is for you!\n\n**Dirschema features:**\n\n* Built-in support for schemas and metadata stored as JSON or YAML\n* Built-in support for checking contents of ZIP and HDF5 archives\n* Extensible validation interface for advanced needs beyond JSON Schema\n* Both a Python library and a CLI tool to perform the validation\n\n<!-- --8<-- [end:abstract] -->\n<!-- --8<-- [start:quickstart] -->\n\n## Installation\n\n```\npip install dirschema\n```\n\n## Getting Started\n\nThe `dirschema` tool needs as input:\n\n* a DirSchema YAML file (containing a specification), and\n* a path to a directory or file (e.g. zip file) that should be checked.\n\nYou can run it like this:\n\n```\ndirschema my_dirschema.yaml DIRECTORY_OR_ARCHIVE_PATH\n```\n\nIf the validation was successful, there will be no output.\nOtherwise, the tool will output a list of errors (e.g. invalid metadata, missing files, etc.).\n\nYou can also use `dirschema` from other Python code as a library:\n\n```python\nfrom dirschema.validate import DSValidator\nDSValidator(\"/path/to/dirschema\").validate(\"/dataset/path\")\n```\n\nSimilarly, the method will return an error dict, which will be empty if the validation succeeded.\n\n<!-- --8<-- [end:quickstart] -->\n\n**You can find more information on using and contributing to this repository in the\n[documentation](https://materials-data-science-and-informatics.github.io/dirschema/main).**\n\n<!-- --8<-- [start:citation] -->\n\n## How to Cite\n\nIf you want to cite this project in your scientific work,\nplease use the [citation file](https://citation-file-format.github.io/)\nin the [repository](https://github.com/Materials-Data-Science-and-Informatics/dirschema/blob/main/CITATION.cff).\n\n<!-- --8<-- [end:citation] -->\n<!-- --8<-- [start:acknowledgements] -->\n\n## Acknowledgements\n\nWe kindly thank all\n[authors and contributors](https://materials-data-science-and-informatics.github.io/dirschema/latest/credits).\n\n<div>\n<img style=\"vertical-align: middle;\" alt=\"HMC Logo\" src=\"https://github.com/Materials-Data-Science-and-Informatics/Logos/raw/main/HMC/HMC_Logo_M.png\" width=50% height=50% />\n&nbsp;&nbsp;\n<img style=\"vertical-align: middle;\" alt=\"FZJ Logo\" src=\"https://github.com/Materials-Data-Science-and-Informatics/Logos/raw/main/FZJ/FZJ.png\" width=30% height=30% />\n</div>\n<br />\n\nThis project was developed at the Institute for Materials Data Science and Informatics\n(IAS-9) of the Jülich Research Center and funded by the Helmholtz Metadata Collaboration\n(HMC), an incubator-platform of the Helmholtz Association within the framework of the\nInformation and Data Science strategic initiative.\n\n<!-- --8<-- [end:acknowledgements] -->\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/displam",
            "repo_link": "https://gitlab.com/dlr-sy/displam",
            "readme": "[![PyPi](https://img.shields.io/pypi/v/displam?label=PyPi)](https://pypi.org/project/displam/)\n[![doi](https://img.shields.io/badge/DOI-10.5281%2Fzenodo.12628293-red.svg)](https://zenodo.org/records/12628293)\n[![pipeline status](https://gitlab.com/dlr-sy/displam/badges/disp_python/pipeline.svg)]()\n\n# Displam\nDisplam is a legacy Fortran-based program for the calculation of the phase velocity of Lamb waves of plate composite structures.\n> Installation from source requires an active open source fortran compiler (gfortran). Intel Fortran is not yet supported. \n## Downloading\nUse GIT to get the latest code base. From the command line, use\n```\ngit clone https://gitlab.dlr.de/fa_sw/displam displam\n```\nIf you check out the repository for the first time, you have to initialize all submodule dependencies first. Execute the following from within the repository. \n```\ngit submodule update --init --recursive\n```\nTo update all refererenced submodules to the latest production level, use\n```\ngit submodule foreach --recursive 'git pull origin $(git config -f $toplevel/.gitmodules submodule.$name.branch || echo master)'\n```\n\n## Installation\nDisplam can be installed directly using pip\n```\npip install displam\n```\nor from source using [poetry](https://python-poetry.org). If you don't have [poetry](https://python-poetry.org) installed, run\n```\npip install poetry --pre --upgrade\n```\nto install the latest version of [poetry](https://python-poetry.org) within your python environment. Use\n```\npoetry update\n```\nto update all dependencies in the lock file or directly execute\n```\npoetry install\n```\nto install all dependencies from the lock file. Last, you should be able to use Displam as a CLI tool:\n```cmd\ndisplam <Input file>\n```  \nIf you omit the input file name displam will try to read the input data from a file named sample.inp. An output file disp.txt and a log file log.txt will be created. \n\n## Output\nThe output file contains the dispersion data for the problem defined in the input file. A header line is followed by one record per line. Each record consists of the following data:\n```\n  1. fd/(MHz*mm)  - frequency * plate thickness\n  2. cp/(km/sec)  - phase velocity\n  3. w/(1/�sec)   - circular frequency\n  4. k/(1/m)      - wave number\n  5. mode         - wave mode ('S' for symmetric, 'A' for antisymmetric\n                    and 'H' for quasi-horizontal shear mode)\n  6. uu0 - uu2    - complex displacement vector at the upper surface of\n                    the laminate\n  7. ul0 - ul2    - complex displacement vector at the lower surface of\n                    the laminate\n```\nThe columns are seperated by tab-characters. You can open the output file with Excel or any text editor.\n\n## Example\nCopy and paste the following text up to the end of this file to a new text file to use it as a sample input file as explained under [Installation](#Installation)\n```\n#\n# Input file for displam\n#\n############################################################### File format ###\n#\n#   Input is parsed line by line. Everything after a '#' character is ignored,\n#   so it's possible to append comments to input lines. Empty lines are \n#   ignored. White space separates keywords and input parameters and may be\n#   entered as spaces or tabs. Lines may not be longer than 1000 characters\n#   (excluding comments).\n#\n#   The following four sections must be present in this file. Each section is\n#   initiated with its keyword in capital letters in an otherwise empty line.\n#\n#     LAYUP    - stacking sequence of the plate\n#     WAVE     - wave propagation parameters\n#     RANGE    - parameter ranges for circular frequency and phase velocity\n#     MATERIAL - material database\n#\n#   The format of the input lines in each section is explained in the comments\n#   above each section.\n\n############################################################# LAYUP section ###\n#\n#   The layers of the stacking sequence are specified from top to bottom\n#   of the laminate. Three parameters must be specified per line:\n#\n#     1. material id string as specified in the MATERIAL section\n#     2. layer thickness in mm\n#     3. layer orientation in degrees\n#\n#   A layer orientation of 0 degree means that the 1-direction of local (layer\n#   material) and global (laminate) direction coincide.\n#\nLAYUP\n\tcfrp_generic   \t\t0.250\t 0.\n\ttitanium    \t\t0.500\t90.\n\tcfrp_generic\t\t0.250\t 0.\n\n############################################################## WAVE section ###\n#\n#   pa - angle of wave propagation w.r.t. global coordinates in degrees.\n#   ia - angle of incident wave w.r.t. transverse axis in degrees.\n#        90.0 is horizontal (in-plane) incident wave.\nWAVE\n\tpa\t\t 0.01\n\tia\t\t90.00\t\t# values other than 90� are not validated yet\n\n############################################################# RANGE section ###\n#\n#   cp - 3 values for start, end, and number of increments for phase velocity.\n#        Unit of phase velocity is in km / s.\n#   fq - 3 values for start, end, and number of increments for frequency.\n#        Unit of frequencies must be MHz.\nRANGE\n\tcp\t\t0.1\t\t14.0\t 200\t# unit is km/s\n\tfq\t\t0.1\t\t 3.0\t 200\t# unit is MHz\n\n########################################################## MATERIAL section ###\n#\n#   Each line starts with an identification string of up to 12 alphanumeric\n#   characters and '_'. It is followed by the number of independent stiffness\n#   constants (nsc) and the density in g / cm^3.\n#\n#   Transversely isotropic (nsc = 5) and orthotropic (nsc = 9) materials are\n#   supported. After the density the stiffness parameters must be specified\n#   in GPa for Young's and shear moduli in the following order\n#\n#     transversely isotropic  E1, E2, G12, G23, nu12\n#     orthotropic             E1, E2, E3, G12, G23, G31, nu12, nu23, nu31\n#\n#   The 3-direction is the out-of-plane direction.\n#\nMATERIAL\n#\t123456789012  nsc\t\t rho\t\tstiffness coefficients\n\talu             5\t\t2.70\t\t 69.9\t 70.1\t26.30\t26.20\t0.33\n\ttitanium        5\t\t4.50\t\t115.9\t116.1\t43.95\t43.85\t0.32\n\tcfrp_generic    5\t\t1.55\t\t150.0\t  9.00\t 5.00\t 4.00\t0.30\n\tcfrp_rose       5\t\t1.58\t\t123.9\t 11.256\t 6.73\t 3.81\t0.31\n```\n\n## Contact\n* [Marc Garbade](mailto:marc.garbade@dlr.de)\n",
            "project_id": "57638441"
        },
        {
            "software_organization": "https://helmholtz.software/software/dl4pude",
            "repo_link": "https://github.com/PedestrianDynamics/DL4PuDe",
            "readme": "# `DL4PuDe:` A hybrid framework of deep learning and visualization for pushing behavior detection in pedestrian dynamics\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.8257076.svg)](https://doi.org/10.5281/zenodo.8257076\n) [![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](./LICENSE)  ![Python 3.7 | 3.8](https://img.shields.io/badge/Python-3.7|3.8-blue.svg)  ![GPU](https://img.shields.io/badge/GPU-No-yellow) ![RAM16GB](https://img.shields.io/badge/RAM-16GB-red)  \n\nThis repository is for the DL4PuDe framework, along with its  published [paper](https://www.mdpi.com/1424-8220/22/11/4040/htm), which is as follows.\n```\nAlia, Ahmed, Mohammed Maree, and Mohcine Chraibi. 2022. \"A Hybrid Deep Learning and Visualization Framework for Pushing Behavior Detection in Pedestrian Dynamics\" Sensors 22, no. 11: 4040. \n```\n## Content\n1. <a href=\"#aim\"> Framework aim. </a>\n2. <a href=\"#motivation\"> Framework Motivation. </a>\n3. <a href=\"#defention\"> Pushing Behavior Defention. </a>\n4. <a href=\"#architecture\"> Framework Architecture. </a>\n5. <a href=\"#install\"> How to install and use the framework. </a>\n6. <a href=\"#demo\"> Demo. </a>\n7. <a href=\"#videos\"> Experiments Videos. </a>\n8. <a href=\"#cnn\"> CNN-based Classifiers </a>\n    * <a href=\"#cnnsource\"> Source code for building and training CNN-based classifiers. </a>\n    * <a href=\"#trained\"> Trained CNN-based classifiers. </a>\n    * <a href=\"#evaluate\"> Source code for evaluating the trained CNN-based classifiers. </a>\n    *  <a href=\"#test\"> Test sets. </a>\n9. <a href=\"#list\"> List of papers that cited this work. </a>\n\n## Aim of `Dl4PuDe` Framework\n<a name=\"aim\">\n\n`Dl4PuDe`  aims to automatically detect and annotate pushing behavior at the patch level in video recordings of human crowds. \n\n## Motivation of `Dl4PuDe` Framework\n<a name=\"motivation\">\n\nTo assist researchers in the field of crowd dynamics in gaining a better understanding of pushing dynamics, which is crucial for effectively managing a comfortable and safe crowd.\n\n## Pushing Behavior Defention\n<a name=\"defention\">\n\nIn this article, pushing can be defined as a behavior that pedestrians use to reach a target faster.\n\n\n###### An example of pushing strategy\n<img src=\"./files/example.gif\" width=\"300px\"/>\n\n###### Entering the event faster\n<img src=\"./files/snakemotion.jpg\" width=\"300px\"/>\n \n\n## The Architecture of `DL4PuDe`\n<a name=\"architecture\">\n\n`DL4PuDe` mainly relied on the power of EfficientNet-B0-based classifier, RAFT and wheel visualization methods.\n\n<img src=\"./files/framework1.png\"/>\nKindly note that we use the <a href=\"https://github.com/princeton-vl/RAFT\" />[RAFT repository] </a> for optical flow estimation in our project.\n\n**Example**\n<table border=\"0\" width=\"100%\" align=\"center\">\n<tr>\n   <th align=\"cenetr\"> Input video </th>\n   <th align=\"cenetr\"> Output video * </th>\n   \n</tr>\n<tr>\n   <td align=\"center\"> <img src=\"./files/input150-distorted.gif\" width=\"300\"/> </td>\n   <td align=\"center\"> <img src=\"./files/output150-distorted.gif\" width=\"200\"/> </td>\n</tr>\n<tr>\n   <td colspan=\"2\"> * The framework detects pushing patches every 12 frames (12/25 s), the red boxes refer to the pushing patches. </td>\n</tr>\n</table>\n\n## Installation\n<a name=\"install\">\n\n1. Clone the repository in your directory.\n```\ngit clone https://github.com/PedestrianDynamics/DL4PuDe.git\n```\n2. Install the required libraries.\n```\npip install -r libraries.txt\n```\n3. Run the framework. \n```\npython3 run.py --video [input video path]  \n               --roi [\"x coordinate of left-top ROI corner\" \"y coordinate of left-top ROI corner\"\n               \"x coordinate of  right-bottom ROI corner\" \"y coordinate of right-bottom ROI corner\" ] \n               --patch [rows cols]    \n               --ratio [scale of video]   \n               --angle [angle in degrees for rotating the input video to make crowd flow direction\n               from left to right ---> ]\n```   \n## Demo \n<a name=\"demo\">\n\n>Run the following command\n\n```   \npython3 run.py --video ./videos/150.mp4  --roi 380 128 1356 1294 --patch 3 3 --ratio 0.5  --angle 0\n```  \n> Then, you will see the following details.\n\n<img src=\"./files/run.png\"/>\n\n> When the progress of the framework is complete, it will generate the annotated video in the framework directory. Please note that the \"150 annotated video\" is available on the directory root under the \"150-demo.mp4\" name.\n\n## Experiments Videos\n<a name=\"videos\">\n\nThe original experiments videos that are used in this work are available through the [Pedestrian Dynamics Data Archive hosted](http://ped.fz-juelich.de/da/2018crowdqueue) by the Forschungszentrum Juelich. Also, the undistorted videos are available by [this link.](https://drive.google.com/drive/folders/16eZhC9mnUQUXxUeIUXd6xwBU2fSf3qCz?usp=sharing) \n\n## CNN-based Classifiers\n<a name=\"cnn\">\n\nWe use four CNN-based classifiers for building and evaluating our classifier, including EfficientNet-B0, MobileNet, InceptionV3, and ResNet50. The source code for building, training and evaluating the CNN-based classifiers, as well as the trained classifiers are available in the below links.\n1. Source code for building and training the CNN-based classifiers. <a name=\"cnnsource\">\n   * [EfficientNet-B0-based classifier.](./CNN/CNN-Architectures/efficientNetB0.ipynb)\n   * [MobileNet-based classifier.](./CNN/CNN-Architectures/InceptionV3.ipynb)\n   * [InceptionV3-based classifier.](./CNN/CNN-Architectures/InceptionV3.ipynb)\n   * [ResNet50-based classifier.](./CNN/CNN-Architectures/ResNet50.ipynb)\n2. [Trained CNN-based classifiers.](https://drive.google.com/drive/folders/1vmgYufnt4_NNQUE9PGYZLkrn5DmErENu?usp=sharing) <a name=\"trained\">\n3. CNN-based classifiers Evaluation. <a name=\"#evaluate\">\n   * [Patch-based medium RAFT-MIM12 dataset.](./CNN/Classifiers-evaluation/patch-based-medium-RAFT-MIM12/)\n   * [Patch-based medium RAFT-MIM25 dataset.](./CNN/Classifiers-evaluation/patch-based-medium-RAFT-MIM25/)\n   * [Patch-based small RAFT-MIM12 dataset.](./CNN/Classifiers-evaluation/patch-based-small-RAFT-MIM12/)\n   * [Patch-based small RAFT-MIM25 dataset.](./CNN/Classifiers-evaluation/patch-based-small-RAFT-MIM25/)\n   * [Patch-based medium FB-MIM12 dataset.](./CNN/Classifiers-evaluation/patch-based-medium-FB-MM12/)\n   * [Frame-based RAFT-MIM12 dataset.](./CNN/Classifiers-evaluation/frame-based-RAFT-MIM12/)\n   * [Frame-based RAFT-MIM25 dataset.](./CNN/Classifiers-evaluation/frame-based-RAFT-MIM25/)\n4. [Patch-based MIM test sets.](./CNN/Classifiers-evaluation/test-sets/) <a name=\"test\">\n5. MIM training and validation sets are available from the corresponding authors upon request.\n \n## List of papers that cited this work \n<a name=\"list\">\n\nTo access the list of papers citing this work, kindly click on this [link.](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14553227952079022657&as_sdt=5)\n\n## Citation\n\nIf you utilize this framework or the generated dataset in your work, please cite it using the following BibTex entry:\n```\nAlia, Ahmed, Mohammed Maree, and Mohcine Chraibi. 2022. \"A Hybrid Deep Learning and Visualization Framework for Pushing Behavior Detection in Pedestrian Dynamics\" Sensors 22, no. 11: 4040. \n```\n\n\n## Acknowledgments\n* This work was funded by the German Federal Ministry of Education and Research (BMBF: funding number 01DH16027) within the Palestinian-German Science Bridge project framework, and partially by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)—491111487.\n\n* Thanks to the Forschungszentrum Juelich, Institute for Advanced Simulation-7, for making the Pedestrian Dynamics Data Archive publicly accessible under the CC Attribution 4.0 International license.\n\n* Thanks to Anna Sieben, Helena Lügering, and Ezel Üsten for developing the rating system and annotating the pushing behavior in the video experiments.\n\n* Thanks to the authors of the paper titled ``RAFT: Recurrent All Pairs Field Transforms for Optical Flow'' for making the RAFT source code available.\n\n\n \n"
        },
        {
            "software_organization": "https://helmholtz.software/software/earth-system-model-evaluation-tool-esmvaltool",
            "repo_link": "https://github.com/ESMValGroup/ESMValTool",
            "readme": "[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity)\n[![made-with-python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/)\n[![Documentation Status](https://readthedocs.org/projects/esmvaltool/badge/?version=latest)](https://esmvaltool.readthedocs.io/en/latest/?badge=latest)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3401363.svg)](https://doi.org/10.5281/zenodo.3401363)\n[![Chat on Matrix](https://matrix.to/img/matrix-badge.svg)](https://matrix.to/#/#ESMValGroup_Lobby:gitter.im)\n[![CircleCI](https://circleci.com/gh/ESMValGroup/ESMValTool/tree/main.svg?style=svg)](https://circleci.com/gh/ESMValGroup/ESMValTool/tree/main)\n[![Test in Full Development Mode](https://github.com/ESMValGroup/ESMValTool/actions/workflows/test-development.yml/badge.svg)](https://github.com/ESMValGroup/ESMValTool/actions/workflows/test-development.yml)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/79bf6932c2e844eea15d0fb1ed7e415c)](https://app.codacy.com/gh/ESMValGroup/ESMValTool/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![Docker Build Status](https://img.shields.io/docker/automated/esmvalgroup/esmvaltool)](https://hub.docker.com/r/esmvalgroup/esmvaltool/)\n[![Anaconda-Server Badge](https://img.shields.io/conda/vn/conda-forge/ESMValTool?color=blue&label=conda-forge&logo=conda-forge&logoColor=white)](https://anaconda.org/conda-forge/esmvaltool)\n![stand with Ukraine](https://badgen.net/badge/stand%20with/UKRAINE/?color=0057B8&labelColor=FFD700)\n\n![esmvaltoollogo](https://raw.githubusercontent.com/ESMValGroup/ESMValTool/main/doc/sphinx/source/figures/ESMValTool-logo-2-glow.png)\n\n- [**Documentation**](https://docs.esmvaltool.org/en/latest/)\n- [**ESMValTool Website**](https://www.esmvaltool.org/)\n- [**ESMValTool Tutorial**](https://tutorial.esmvaltool.org/index.html)\n- [**ESMValGroup Project on GitHub**](https://github.com/ESMValGroup)\n- [**Gallery**](https://docs.esmvaltool.org/en/latest/gallery.html)\n- [**`conda-forge` package feedstock**](https://github.com/conda-forge/esmvaltool-suite-feedstock)\n\n# Introduction\n\nESMValTool is a community-developed climate model diagnostics and evaluation software package, driven\nboth by computational performance and scientific accuracy and reproducibility. ESMValTool is open to both\nusers and developers, encouraging open exchange of diagnostic source code and evaluation results from the\nCoupled Model Intercomparison Project [CMIP](https://www.wcrp-climate.org/wgcm-cmip) ensemble. For a\ncomprehensive introduction to ESMValTool please visit our\n[documentation](https://docs.esmvaltool.org/en/latest/introduction.html) page.\n\n# Running esmvaltool\n\nDiagnostics from ESMValTool are run using [recipe](https://docs.esmvaltool.org/en/latest/recipes/index.html)\nfiles that contain pointers to the requested data types, directives for the preprocessing steps that data\nwill be subject to, and directives for the actual diagnostics that will be run with the now preprocessed data.\nData preprocessing is done via the [ESMValCore](https://docs.esmvaltool.org/projects/ESMValCore/en/latest/quickstart/index.html) package, a pure Python, highly-optimized scientific library, developed by the ESMValTool core developers,\nand that performs a number of common analysis tasks\nsuch as regridding, masking, levels extraction etc. [Diagnostics](https://docs.esmvaltool.org/en/latest/develop/diagnostic.html) are written in a variety of programming languages (Python, NCL, R, Julia) and are developed by the wider\nscientific community, and included after a scientific and technical review process.\n\n# Input data\n\nESMValTool can run with the following types of [data as input](https://docs.esmvaltool.org/en/latest/input.html):\n\n- CMIP6\n- CMIP5\n- CMIP3\n- [observational and re-analysis datasets](https://docs.esmvaltool.org/en/latest/input.html#supported-datasets-for-which-a-cmorizer-script-is-available)\n- obs4MIPs\n- ana4mips\n- CORDEX ([work in progress](https://docs.esmvaltool.org/en/latest/input.html#cordex-note))\n\n# Getting started\n\nPlease see [getting started](https://docs.esmvaltool.org/en/latest/quickstart/index.html) on our instance of Read the Docs as well as [ESMValTool tutorial](https://tutorial.esmvaltool.org/index.html). The tutorial is a set of lessons that together teach skills needed to work with ESMValTool in climate-related domains.\n\n## Getting help\n\nThe easiest way to get help, if you cannot find the answer in the documentation in our [docs](https://docs.esmvaltool.org), is to open an [issue on GitHub](https://github.com/ESMValGroup/ESMValTool/issues).\n\n## Contributing\n\nIf you would like to contribute a new diagnostic or feature, please have a look at our [contribution guidelines](https://docs.esmvaltool.org/en/latest/community/index.html).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/easywave",
            "repo_link": "https://git.gfz-potsdam.de/id2/geoperil/easyWave",
            "readme": "# easyWave\n\neasyWave is an application that is used to simulate tsunami generation and propagation in the context of early warning. It makes use of GPU acceleration to speed up the calculations. easyWave is licensed under the [EUPL](https://joinup.ec.europa.eu/page/eupl-text-11-12) (v1.1 or later), complemented with the following provision: For the scientific transparency and verification of results obtained and communicated to the public after using a modified version of the work, You (as the recipient of the source code and author of this modified version, used to produce the published results in scientific communications) commit to make this modified source code available in a repository that is easily and freely accessible for a duration of five years after the communication of the obtained results.\n\n\n# Download\n\nThe latest CPU version supports multi-threading on shared memory systems using OpenMP.\n\n * [easywave_r34_omp_i386.tar.gz](bin/r34/easywave_r34_omp_i386.tar.gz)\n * [easywave_r34_omp_x64.tar.gz](bin/r34/easywave_r34_omp_x64.tar.gz)\n * [easywave_r34_src.tar.gz](bin/r34/easywave_r34_src.tar.gz)\n\nYou can download one of the following packages to use the single-threaded version or a pre-compiled GPU binary instead.\n\n * [easywave_r17_gpu_i386.tar.gz](bin/r17/easywave_r17_gpu_i386.tar.gz)\n * [easywave_r17_gpu_x64.tar.gz](bin/r17/easywave_r17_gpu_x64.tar.gz)\n * [easywave_r17_i386.tar.gz](bin/r17/easywave_r17_i386.tar.gz)\n * [easywave_r17_x64.tar.gz](bin/r17/easywave_r17_x64.tar.gz)\n * [easywave_r17_src.tar.gz](bin/r17/easywave_r17_src.tar.gz)\n\n\n# Getting started\n\nThe following sections will explain how to install and use easyWave. The guide is written for Unix-based systems and assumes that a bash shell is used. Other shells may require little modifications.\n\n\n## Installation\n\nYou can install easyWave in three different ways:\n\n 1. Download a pre-built binary package appropriate for your system.\n 2. Download a source file archive and compile on your own.\n 3. Check out a development branch via git\n\nIn the following all the possibilities are described.\n\n\n### 1. Using binaries\n\n 1. [Download](#download) a suitable package according to your platform into some folder DIR.\n 2. Extract the package with an archive manager. Therefore open a terminal, browse to the download directory and run the following command:\n```shell\ntar -xzf <package>.tar.gz\n```\n\n 3. You can now use easyWave by specifying the absolute path /DIR/easywave/bin/easywave. However you can also add the bin-folder of easyWave to your `$PATH` variable like that:\n```shell\nexport PATH=$PATH:$PWD/easywave/bin\n```\n**Note**: To make the change permanent add the above command to your `.bashrc`, but replace `$PWD` with the working directory.  Afterwards you can run easyWave simply by its program name: `easywave`\n\nThe installation is complete. You can now continue with the [Examples](#examples) section.\n\n\n### 2. From a source archive\n\n 1. [Download](#download) the source archive to an arbitrary directory in your file system.\n 2. Open a terminal, browse to the selected directory and unpack the downloaded archive (This will create a directory named `easywave` that contains all sources that are necessary to build the executables.):\n```shell\ntar -xzf <source>.tar.gz\n```\n\n 3. The `configure` script will search your system for compatible tools to compile the source code. It will also set some default options for the installation process. You can customize these options on the command line. To get a list of options type `./configure --help`. If the above steps have been successfully completed all binary files have been created.  Change to this directory and build the sources: \n```shell\ncd easywave\n./configure\nmake\n```\n\n 4. You could now install easyWave to the specified installation directory (default: `/usr/local/easywave`) by typing:\n```shell\nmake install\n```\n**Note**: If the installation directory is not writable by the current user, you have to run the above command as root. \nAfter that easyWave was successfully installed and is ready to use. We recommend to add the installation's bin-directory to the `$PATH` variable to use easyWave from any location.\n\n\n### 3. From the git repository\n\nYou can download the latest development state or any custom branch of easyWave directly from the `git` repository. For this, you need `git` installed on your system.\n\n 1. Open a terminal and browse to a directory where you want to place a copy of easyWave.\n 2. Check out the trunk:\n```shell\ngit clone https://gitext.gfz-potsdam.de/geoperil/easyWave.git\n```\n\n 3. Run the following instructions:\n```shell\ncd easyWave/code\n./bootstrap\n./configure\nmake\nmake install\n```\n\nFor details see [Section 2](#2-from-a-source-archive)\n\nThe git clone will also include some contents that is not part of the distributed tar.gz archive. Especially the tests/ directory can be useful to ensure program functionality. For details see section [Test](#tests).\n\n\n## Examples\n\nTo get familiar with easyWave we provide some example input files that can be used to run certain simulations. In the following we will give the instructions for getting started with easyWave.\n\n 1. Create a directory on your file system where the example files should be placed.\n 2. Download the [archive](data/examples.tar.gz) that contains the examples into the newly created directory.\n 3. Open a terminal, browse to the selected directory and unpack the downloaded archive:\nThis will create a directory named `examples` that contains all example files. \n**Note**: In the following we will assume that you have added easyWave to your `$PATH` and thus it can simply be called by its name. Otherwise you have to add the full path when calling easywave. \n```shell\ntar -xzf examples.tar.gz\n```\n\n 4. Now you can run your first simulation with the following command:\n```shell\neasywave -grid examples/e2Asean.grd -source examples/BengkuluSept2007.flt -time 120\n```\neasyWave will simulate the tsunami generation and propagation from the given source according to the underlying grid file for a duration of 120 minutes. This can take a moment. However the progress is shown at run time. If the calculation is finished the following files have been created:\n  * `eWave.2D.sshmax`: Contains the maximum wave heights.\n  * `eWave.2D.XXXXX.ssh`: Contains the wave heights after XXXXX seconds of simulation.\n  * `eWave.2D.time`: Contains the estimated arrival times.\n  * `easywave.log`: Contains log messages.\n\nTo visualize the results you can use the scripts supplied with the easyWave installation. To show the maximum wave heights run the following command:\n```shell\nsshmax2png.sh -grd examples/e2Asean.grd\n```\n\nThis will create a file named `eWave.2D.png`. You can open this file with your default image viewer.\nYou can also visualize the wave propagation at a particular time. Simply run:\n```shell\nssh2png.sh -grd examples/e2Asean.grd 03600\n```\n\nThis again generates an image file that in this case is named `eWave.2D.03600.png`. It contains the wave propagation after 3600 seconds (= 1 hour). \nFurthermore you can display the given points of interests if easyWave was started with a corresponding POI file:\n```shell\npoi2png.sh -grd examples/e2Asean.grd examples/poiIndonesia.poi\n```\n\n\n## Tests\n\nThe `tests/` directory contains some python scripts that can be used to compare different easyWave versions with each other. You should always perform tests if you have made changes. This makes sure that your version still yields satisfying results.\n\nTo invoke a test run you mainly need to call `tests.py`. To obtain the test cases two configuration files were used. You can specify them with the arguments `--instances` (`-i`) and `--scenarios` (`-s`). The file given by `--instances` should include paths to easyWave instances that should be compared to each other. Each line should contain exactly two instances separated by a semicolon. For example:\n\n```shell\n@../src/easywave; @../src/easywave -gpu\n```\n\nThis leads to a comparison of the CPU and GPU version of an easyWave instance located in the `src/` directory. The @ sign should be included everywhere you want to specify a path relative to the `tests/` directory. It will be expanded automatically.\n\nThe file given by `--scenarios` should contain all parameters that should be added to the both compared easyWave instances, thus creating a scenario. You can set multiple scenarios (one per line) which are processed in order. For example:\n\n```shell\n-grid @grids/e2Asean.grd -source @faults/BengkuluSept2007.flt -time 300\n-grid @grids/g08Japan.grd -source @faults/uz.Tohoku11.grd -time 300\n```\n\nThe `tests/` directory already includes two default configuration files (`instances.cfg` and `scenarios.cfg`) which can be used to run a large test. However you need some additional files which must be downloaded first. To do so, simply type:\n\n```shell\ndownload.py\n```\n\nNote: This will download some large grid-files. \nAfterwards you can run `test.py` without passing any parameter. In this case the default configuration from `instances.cfg` and `scenarios.cfg` is used.\n\n\n## Additional material\n\nThe links below refer to some additional documentation about easyWave. Parts of them may be out of date, so you should always consult this page to get the latest information.\n\n * [easyWave_About.pdf](doc/easyWave_About.pdf) \n * [easyWave_StartingGuide.pdf](doc/easyWave_StartingGuide.pdf)\n\n\n",
            "project_id": "263"
        },
        {
            "software_organization": "https://helmholtz.software/software/egsim",
            "repo_link": "https://github.com/rizac/egsim",
            "readme": "eGSIM is a web service for selecting and testing  ground shaking models (GSIM) \nin Europe, developed by the [GFZ](https://www.gfz-potsdam.de/) \nin the framework of the Thematic Core Services for Seismology of \n[EPOS](https://www.epos-eu.org/) under the umbrella of \n[EFEHR](http://www.efehr.org/en/home/)\n\n<p align=\"middle\">\n    <a title='EFEHR' href='www.efehr.org'><img height='50' src='http://www.efehr.org/export/system/modules/ch.ethz.sed.bootstrap.efehr2021/resources/img/logos/efehr.png'></a>\n    &nbsp;\n    <a title='GFZ' href='https://www.gfz-potsdam.de/'><img height='50' src='https://www.gfz-potsdam.de/fileadmin/gfz/GFZ.svg'></a>\n    &nbsp;\n    <a title='EPOS' href='https://www.epos-eu.org/'><img height='50' src='https://www.epos-eu.org/themes/epos/logo.svg'></a>\n    <br>\n</p>\n\nThe web portal (and API documentation) is available at:\n\n# https://egsim.gfz-potsdam.de\n\n## Citation\n\n> Zaccarelli, Riccardo; Weatherill, Graeme (2020): eGSIM - a Python library and web application to select and test Ground Motion models. GFZ Data Services. https://doi.org/10.5880/GFZ.2.6.2023.007\n\n# Table of contents\n\n   * [Installation](#installation)\n   * [Usage](#usage)\n   * [Packages upgrade](#packages-upgrade)\n   * [Django](#django)\n     * [Starting a Python terminal shell](#starting-a-python-terminal-shell)\n     * [Complete DB reset](#Complete-DB-reset)\n     * [Repopulating the DB](#Re-populating-the-DB)\n     * [Admin panel](#admin-panel)\n     * [Create a custom management command](#Create-a-custom-management-command)  \n     * [Add new predefined flatfiles](#Add-new-predefined-flatfiles)\n     * [Add new regionalization](#Add-new-regionalization)\n     \n\nDISCLAIMER: **This document does not cover the server installation of \nthe web app**, which is publicly available at the URL above. \n**Here you can find instructions on**:\n\n - How to install  eGSIM as local Python library \n   (`import egsim.smtk` in your code)\n - (For developers and contributors) How to install the Django app locally for testing,\n   features addition, maintenance\n\n\n# Installation\n\n\n## Requirements\n\n```bash\nsudo apt-get update # pre-requisite\nsudo apt-get install gcc  # optional\nsudo apt-get install git python3-venv python3-pip python3-dev\n```\n\n(The command above are Ubuntu specific, in macOS install brew and type\n`brew install` instead of `apt-get install`. *Remove python3-dev as it does not\nexist on macOS*).\n\nThis web service uses a *specific* version of Python (Open `setup.py` and \ncheck `python_requires=`. As of January 2022, it's `>=3.11`) *which you must \ninstall* in addition to the Python version required by your system, and use\nit. Any command `python3` hereafter will refer to the required Python version.\n\n\n## Clone repository\n\nSelect a `root directory` (e.g. `/root/path/to/egsim`), and clone egsim into the\nso-called egsim directory:\n\n```bash\ngit clone https://github.com/rizac/eGSIM.git egsim\n```\n\n## Create and activate Python virtual env\n\nMove to whatever directory you want (usually the egsim directory above) and then:\n\n```bash\npython3 -m venv .env/<ENVNAME>  # create python virtual environment (venv)\nsource .env/<ENVNAME>/bin/activate  # activate venv\n```\n\n**NOTE: From now on, all following operations must have the virtualenv \nactivated FIRST**\n\n## Install\n\nAssuming you are in the egsim directory with a virtualenv <VENVNAME>:\n\n```console\nsource .env/<ENVNAME>/bin/activate\npip install -r ./requirements.txt\n```\n\n### eGSIM as local library\n\nIf you want to use eGSIM locally using the \nstrong motion toolkit package only (`from egsim.smtk import ...`\nin your code):\n\n```console\nsource .env/<ENVNAME>/bin/activate\npip install -r ./requirements.lib.txt\n```\n\n#### Run tests \n\n(remember to `pip install pytest` first)\n```bash\npytest -vvv ./tests/smtk\n```\n\n## Run Test\n\n(web app tests. For testing the library only, see above)\n\n> Note: the value of `DJANGO_SETTINGS_MODULE` in the examples below \n> must be changed in production\n\nMove in the `egsim directory` and type:\n\n```bash\nexport DJANGO_SETTINGS_MODULE=egsim.settings_debug; pytest -xvvv ./tests/\n```\n(x=stop at first error, v*=increase verbosity). \n\nwith coverage report:\n\n```bash\nexport DJANGO_SETTINGS_MODULE=egsim.settings_debug; pytest --cov=egsim --cov-report=html -xvvv ./tests/\n```\n\n<details>\n<summary>Configure PyCharm</summary>\nFor **PyCharm users**, you need to configure the environment variable\nfor all tests. Go to:\n\n- Run\n  - Edit Configurations\n    - Python tests\n    \nAnd then under **Environment variables:** add:\n\n`DJANGO_SETTINGS_MODULE=egsim.settings_debug`\n\n(type several env vars separated by ;)\n\n</details>\n\n\n# Usage\n\n> Note: the value of `DJANGO_SETTINGS_MODULE` in the examples below \n> must be changed in production\n\nIf you didn't do already, perform \na [Complete DB reset](#Complete-DB-reset)\n(**one-time only operation**)\n\nIf you want to access the admin panel, see [the admin panel](#admin-panel).\n\n**To run the program in your local browser**, type:\n\n```bash\nexport DJANGO_SETTINGS_MODULE=\"egsim.settings_debug\";python manage.py runserver \n```\n\n<details>\n<summary>Configure PyCharm</summary>\nFor **PyCharm users**, you can implement a service, which can be run as any\nPyCharm configuration in debug mode, allowing to open the browser \nand stop at specific point in the code (the PyCharm window will popup \nautomatically in case). \nTo implement a service, go to:\n\n- Run\n  - Edit Configurations\n    - Add new configuration\n\nthen under **Run**:\n - between `script` and `module` (should be a combo box) choose `script`,\n   and in the next text field put `manage.py`\n - script parameters: `runserver`\n - And then under **Environment variables:** add:\n   `DJANGO_SETTINGS_MODULE=egsim.settings_debug`\n   (type several env vars separated by ;)\n\nYou should see in the `Services` tab appearing the script name, so you can\nrun / debug it normally\n\n</details>\n\n\n## Packages upgrade\n\n\n```console\nsource .env/<ENVNAME>/bin/activate\npip install --upgrade pip setuptools\n```\n\nUpgrade OpenQuake (**optional**). The operation below should be performed in\nvery specific cases only (important bugfixes or features) because\n**being OpenQuake often backward incompatible** it might require additional \ncode fixes and feedbacks from scientific experts or OpenQuake developers.\nFirst, **open `setup.py` and comment the line of `install_requires` where OpenQuake\nis installed** (should be starting with `openquake.engine`). Then \n(note that `pip install openquake` works but is not the recommended way):\n```console\npip install -r \"https://raw.githubusercontent.com/gem/oq-engine/master/requirements-py311-macos_x86_64.txt\"\n# pip install -r \"https://raw.githubusercontent.com/gem/oq-engine/master/requirements-py311-linux64.txt\"\n```\n\n\nInstall eGSIM Python library, upgrading its dependencies:\n```console\npip install -U . && pip freeze >./requirements.lib.txt && pip install pytest\n```\n\nRun tests:\n```console\npytest -vvv ./tests/smtk\n```\n\nInstall eGSIM web app, upgrading its dependencies:\n```console\npip install -U --upgrade-strategy eager \".[web]\"\npip freeze > ./requirements.txt\n```\n\nRun tests:\n```console\nexport DJANGO_SETTINGS_MODULE=egsim.settings_debug; pytest -xvvv ./tests/\n```\n\nChange `setup.py` and set the current OpenQuake version in \n`install_requires` (uncomment it if commented). Optionally,\nremove egsim from requirements.txt (it might interfere with Django web?*).\n\nEventually, **commit and push**\n\n\n# Django\n\nRemember to **activate the Python virtualenv** in all examples below\n\n<details>\n<summary>\nBrief Introduction to some important concepts and key terms (click to show)\n</summary>\n\n - [Settings file](https://docs.djangoproject.com/en/stable/topics/settings/): \n   A Django settings file contains all the configuration of your Django \n   installation. The settings file referred in this document, \n   included in this git repo, is for debug and local deployment only.\n   On production, a separate settings file is used, located on the server \n   outside the git repo and **not shared for security reasons**.\n\n   \n - [manage.py](https://docs.djangoproject.com/en/stable/ref/django-admin/) or\n   `django-admin` is Django’s command-line utility for administrative tasks.\n   It is invoked from the terminal within your Python virtualenv (see examples\n   in this document) by providing the settings file via:\n   ```bash\n   export DJANGO_SETTINGS_MODULE=<settings_file_path> python manage.py <command>\n   ```\n   Django allows also the implementation of custom management commands.\n   eGSIM implements `egsim-init` in order to populate the db (more details \n   below)\n\n\n - [app](https://docs.djangoproject.com/en/stable/intro/reusable-apps/) a \n   Django app is a Python package that is specifically intended for use in \n   a Django project. An application may use common Django conventions, such as \n   having models, tests, urls, and views submodules. In our case, the Django\n   project is the egsim root directory (created with the command\n   `django-admin startproject egsim`), and the *Django apps* inside it are \n   \"api\" (the core web API) and \"app\" (the *web app*, i.e. the part of eGSIM\n   delivered over the Internet through a browser interface), that relies on \n   the \"api\" code.\n   Inside the settings file (variable `INSTALLED_APPS`) is configured the list \n   of all applications that are enabled in the eGSIM project. This includes not \n   only our \"api\" app, that tells Django to create the eGISM tables when\n   initializing the database, but also several builtin Django apps, e.g. the \n   Django `admin` app, visible through the [Admin panel](#admin-panel).\n\n</details>\n\n## Starting a Python terminal shell\n\n> Note: the value of `DJANGO_SETTINGS_MODULE` in the examples below \n> must be changed in production\n\nTyping `python` on the terminal does not work as one needs to\ninitialize Django settings. The Django `shell` command does this:\n\n```bash\nexport DJANGO_SETTINGS_MODULE=\"egsim.settings_debug\";python manage.py shell \n```\n\n## Get Django uploaded files directory\n\nIf you did not set it explicitly in `settings.FILE_UPLOAD_TEMP_DIR` \n(by default is missing), then Django will put uploaded files \nin the standard temporary directory which you can get easily by \ntyping:\n\n```bash\npython -c \"import tempfile;print(tempfile.gettempdir())\"\n```\n\n## Complete DB reset\n\n> Note: the value of `DJANGO_SETTINGS_MODULE` in the examples below \n> must be changed in production\n\nWe perform a complete DB reset every time we change something \nin the Database schema (see `egsim.api.models.py`), e.g. a table, \na column, a constraint.\n\n<details>\n<summary>(if you wonder why we do not use DB migrations, click here)</summary>\n\nThe usual way to change a DB in a web app is to create and run\nmigrations \n([full details here](https://docs.djangoproject.com/en/stable/topics/migrations/)),\nwhich allow to keep track of all changes (moving back and forth if necessary) \nwhilst preserving the data stored in the DB. \nHowever, none of those features is required in eGSIM: DB data is predefined\nand would be regenerated from scratch in any case after any new migration.\nConsequently, **upon changes in the DB, a complete DB reset is an easier \nprocedure**.\n\nIn any case (**just for reference**), the steps to create and run migrations \nin eGSIM are the following:\n\n```bash\nexport DJANGO_SETTINGS_MODULE=\"egsim.settings_debug\";python manage.py makemigrations egsim --name <migration_name>\nexport DJANGO_SETTINGS_MODULE=\"egsim.settings_debug\";python manage.py migrate egsim\n```\nAnd then repopulate the db:\n```bash\nexport DJANGO_SETTINGS_MODULE=\"egsim.settings_debug\";python manage.py egsim_init\n```\n\nNotes: \n  - The `make_migration` command just generates a migration file, it doesn't \n    change the db. The `migrate` command does that, by means of the migration \n    files generated. For details on Django migrations, see:\n    - https://realpython.com/django-migrations-a-primer/#changing-models\n    - https://docs.djangoproject.com/en/stable/topics/migrations/#workflow \n  - <migration_name> will be a suffix appended to the migration file, use it\n    like you would use a commit message in `git`).\n  - When running `migrate`, if the migration \n    will introduce new non-nullable fields, maybe better to run \n    `manage.py flush` first to empty all tables, to avoid conflicts\n    \"egsim\" above is the app name. If you omit the app, all apps will be \n    migrated. The command `migrate` does nothing if it detects that there is \n    nothing to migrate\n</details>\n\nTo perform a complete db reset:\n\n - delete or rename the database of the settings file used and *all* migration \n   files. In dev mode they are:\n   - `egsim/db.sqlite3`\n   - `egsim/api/migrations/0001_initial.py` (there should be only one. If there \n     are others, delete all of them)\n - Execute:\n   ```bash\n   export DJANGO_SETTINGS_MODULE=\"egsim.settings_debug\";python manage.py makemigrations && python manage.py migrate && python manage.py egsim_init\n   ```\n - `git add` the newly created migration file (in dev mode it's \n   `egsim/api/migrations/0001_initial.py`)\n - [**Optional**] re-add the Django admin superuser(s) as explained in the\n   [admin panel](#admin-panel)\n\nNotes:\n - Commands explanation:\n   - `makemigrations` creates the necessary migration file(s) from Python \n     code and existing migration file(s)\n   - `migrate` re-create the DB via the generated migration file(s)\n   - `egsim_init` repopulates the db with eGSIM data\n\n\n## Re-populating the DB\n \nWe repopulate the DB when  **its schema has not changed** but its data \nneeds to, e.g., OpenQuake is upgraded, or new data is implemented \n(new regionalization or flatfile), or a bug in the code has been \nfixed. The operations are similar but simpler than a complete Db Rest:\n\n- delete or rename the database of the settings file used:\n   - `egsim/db.sqlite3`\n- Execute: \n  ```bash\n  export DJANGO_SETTINGS_MODULE=\"egsim.settings_debug\";python manage.py migrate && python manage.py egsim_init\n  ```\n- [**Optional**] most likely (not tested, please check) you need to re-add \n  the Django admin superuser(s) as explained in the [admin panel](#admin-panel)\n   \n\n## Admin panel\n\n> Note: the value of `DJANGO_SETTINGS_MODULE` in the examples below \n> must be changed in production\n\nThis command allows the user to check database data from the \nweb browser. For further details, check the \n[Django doc](https://docs.djangoproject.com/en/stable/ref/django-admin/)\n\nThe database must have been created and populated (see [Usage](#usage)). \n\nCreate a superuser (to be done **once only** ):\n```bash\nexport DJANGO_SETTINGS_MODULE=\"egsim.settings_debug\";python manage.py createsuperuser\n```\nand follow the instructions.\n\nStart the program (see [Usage](#Usage)) and then navigate in the browser to \n`[SITE_URL]/admin` (in development mode, `http://127.0.0.1:8000/admin/`)\n\n*Note: Theoretically, you can modify db data from the browser, e.g., hide some \nmodel, regionalization or predefined flatfile. Persistent changes should be\nimplemented in Python code and then run a [Complete DB reset](#Complete-DB-reset)*\n\n\n## Create a custom management command\n\nSee `egsim/api/management/commands/README.md`.\n\nThe next two sections will describe how to store\nnew data (regionalizations and flatfiles) that will be\nmade available in eGSIM with the `egsim_init` command\n(see [Complete DB reset](#Complete-DB-reset) for details)\n\n\n## Add new predefined flatfiles\n\n- Add the file (CSV or zipped CSV) in\n  `managements/commands/data/flatfiles`. \n  If the file is too big try to zip it. \n  **If it is more than few tens of Mb, then do not commit it** (explain in \n  the section `details` - see below - how to get the source file). \n  When zipping in macOS you will probably need to\n  [exclude or remove (after zipping) the MACOSX folder](https://stackoverflow.com/q/10924236)~~\n- \n- Implement a new `FlatfileParser` class in \n  `management/commands/flatfile_parsers`. Take another parser, copy it \n  and follow instructions.\n  The parser goal is to read the file and convert it into a harmonized HDF \n  table\n\n- Add binding file -> parser in the Python `dict`:\n  `management.commands._egsim_flatfiles.Command.PARSER`\n\n- (Optional) Add the file refs \n  in `management/commands/data/references.yaml`, e.g. reference, url, the \n  file name that will be used in the API (if missing, defaults to the file \n  name without extension)\n\n- Repopulate all eGSIM tables (command `egsim_init`)\n\nImplemented flatfiles sources (click on the items below to expand)\n\n<details>\n<summary>ESM 2018 flatfile</summary>\n\n- Go to https://esm.mi.ingv.it//flatfile-2018/flatfile.php\n(with username and password, you must be registered \n  beforehand it's relatively fast and simple)\n\n- Download `ESM_flatfile_2018.zip`, uncompress and extract\n  `ESM_flatfile_SA.csv` from there \n  \n- `ESM_flatfile_SA.csv` is our raw flatfile, compress it \n  again (it's big) into this directory as \n  `ESM_flatfile_2018_SA.zip`\n \n- If on macOS, type the command above to remove the\n  macOS folder from the zip\n</details>\n\n\n## Add new regionalization\n\n- Add two files *with the same basename* and extensions in \n  `managements/commands/data/regionalization_files`:\n\n  - <name>.geojson (regionalization, aka regions collection) and\n  - <name>.json (region -> gsim mapping)\n  \n  See already implemented files for an example\n\n- (Optional) Add the file refs \n  in `management/commands/data/references.yaml`, e.g. reference, url, the \n  file name that will be used in the API (if missing, defaults to the file \n  name without extension)\n\n- Repopulate all eGSIM tables (command `egsim_init`)\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ehrapy",
            "repo_link": "https://github.com/theislab/ehrapy",
            "readme": "[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Build](https://github.com/theislab/ehrapy/actions/workflows/build.yml/badge.svg)](https://github.com/theislab/ehrapy/actions/workflows/build.yml)\n[![Codecov](https://codecov.io/gh/theislab/ehrapy/branch/master/graph/badge.svg)](https://codecov.io/gh/theislab/ehrapy)\n[![License](https://img.shields.io/github/license/theislab/ehrapy)](https://opensource.org/licenses/Apache2.0)\n[![PyPI](https://img.shields.io/pypi/v/ehrapy.svg)](https://pypi.org/project/ehrapy/)\n[![Python Version](https://img.shields.io/pypi/pyversions/ehrapy)](https://pypi.org/project/ehrapy)\n[![Read the Docs](https://img.shields.io/readthedocs/ehrapy/latest.svg?label=Read%20the%20Docs)](https://ehrapy.readthedocs.io/)\n[![Test](https://github.com/theislab/ehrapy/actions/workflows/test.yml/badge.svg)](https://github.com/theislab/ehrapy/actions/workflows/test.yml)\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)\n\n<img src=\"https://user-images.githubusercontent.com/21954664/156930990-0d668468-0cd9-496e-995a-96d2c2407cf5.png\" alt=\"ehrapy logo\">\n\n# ehrapy overview\n\n![fig1](https://github.com/user-attachments/assets/7927aa20-751c-4e73-8939-1e4b1c465570)\n\n## Features\n\n-   Exploratory and targeted analysis of Electronic Health Records\n-   Quality control & preprocessing\n-   Visualization & Exploration\n-   Clustering & trajectory inference\n\n## Installation\n\nYou can install _ehrapy_ via [pip] from [PyPI]:\n\n```console\n$ pip install ehrapy\n```\n\n## Usage\n\nPlease have a look at the [Usage documentation](https://ehrapy.readthedocs.io/en/latest/usage/usage.html) and the [tutorials](https://ehrapy.readthedocs.io/en/latest/tutorials/index.html).\n\n```python\nimport ehrapy as ep\n```\n\n## Citation\n\n[Heumos, L., Ehmele, P., Treis, T. et al. An open-source framework for end-to-end analysis of electronic health record data. Nat Med (2024). https://doi.org/10.1038/s41591-024-03214-0](https://www.nature.com/articles/s41591-024-03214-0).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/electrode",
            "repo_link": "https://github.com/robeme/lammps",
            "readme": "This is the LAMMPS software package.\n\nLAMMPS stands for Large-scale Atomic/Molecular Massively Parallel\nSimulator.\n\nCopyright (2003) Sandia Corporation.  Under the terms of Contract\nDE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains\ncertain rights in this software.  This software is distributed under\nthe GNU General Public License.\n\n----------------------------------------------------------------------\n\nLAMMPS is a classical molecular dynamics simulation code designed to\nrun efficiently on parallel computers.  It was developed at Sandia\nNational Laboratories, a US Department of Energy facility, with\nfunding from the DOE.  It is an open-source code, distributed freely\nunder the terms of the GNU Public License (GPL) version 2.\n\nThe code is maintained by the LAMMPS development team who can be emailed\nat developers@lammps.org.  The LAMMPS WWW Site at www.lammps.org has\nmore information about the code and its uses.\n\nThe LAMMPS distribution includes the following files and directories:\n\nREADME                     this file\nLICENSE                    the GNU General Public License (GPL)\nbench                      benchmark problems\ncmake                      CMake build files\ndoc                        documentation\nexamples                   simple test problems\nfortran                    Fortran wrapper for LAMMPS\nlib                        additional provided or external libraries\npotentials                 interatomic potential files\npython                     Python wrappers for LAMMPS\nsrc                        source files\ntools                      pre- and post-processing tools\n\nPoint your browser at any of these files to get started:\n\nhttps://docs.lammps.org/Manual.html         LAMMPS manual\nhttps://docs.lammps.org/Intro.html          hi-level introduction\nhttps://docs.lammps.org/Build.html          how to build LAMMPS\nhttps://docs.lammps.org/Run_head.html       how to run LAMMPS\nhttps://docs.lammps.org/Commands_all.html   Table of available commands\nhttps://docs.lammps.org/Library.html        LAMMPS library interfaces\nhttps://docs.lammps.org/Modify.html         how to modify and extend LAMMPS\nhttps://docs.lammps.org/Developer.html      LAMMPS developer info\n\nYou can also create these doc pages locally:\n\n% cd doc\n% make html                # creates HTML pages in doc/html\n% make pdf                 # creates Manual.pdf\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/elephant",
            "repo_link": "https://github.com/NeuralEnsemble/elephant",
            "readme": "# Elephant - Electrophysiology Analysis Toolkit\n\n[![Coverage Status](https://coveralls.io/repos/github/NeuralEnsemble/elephant/badge.svg?branch=master)](https://coveralls.io/github/NeuralEnsemble/elephant?branch=master)\n[![Documentation Status](https://readthedocs.org/projects/elephant/badge/?version=latest)](https://elephant.readthedocs.io/en/latest/?badge=latest)\n[![![PyPi]](https://img.shields.io/pypi/v/elephant)](https://pypi.org/project/elephant/)\n[![Statistics](https://img.shields.io/pypi/dm/elephant)](https://seladb.github.io/StarTrack-js/#/preload?r=neuralensemble,elephant)\n[![Gitter](https://badges.gitter.im/python-elephant/community.svg)](https://gitter.im/python-elephant/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n[![DOI Latest Release](https://zenodo.org/badge/10311278.svg)](https://zenodo.org/badge/latestdoi/10311278)\n[![tests](https://github.com/NeuralEnsemble/elephant/actions/workflows/CI.yml/badge.svg)](https://github.com/NeuralEnsemble/elephant/actions/workflows/CI.yml)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6191/badge)](https://bestpractices.coreinfrastructure.org/projects/6191)\n[![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F-green)](https://fair-software.eu)\n[![Twitter](https://img.shields.io/twitter/follow/PyElephant?style=social)](https://twitter.com/pyelephant)\n[![Fosstodon](https://img.shields.io/badge/@elephant-6364FF?logo=mastodon&logoColor=fff&style=flat)](https://fosstodon.org/@elephant)\n\n\n*Elephant* package analyses all sorts of neurophysiological data:\nspike trains, LFP, analog signals. The input-output data format is either\n[Neo](https://github.com/NeuralEnsemble/python-neo), Quantity or Numpy array.\n\n\n### More Information\n\n* Documentation: https://elephant.readthedocs.io/en/latest/\n* Mailing list: https://groups.google.com/group/neuralensemble\n\n\n#### Visualization of Elephant analysis objects\n\nViziphant package (https://github.com/INM-6/viziphant) is developed by Elephant\nteam for plotting and visualization of the output of Elephant functions in a\nfew lines of code.\n\n\n#### License\n \nModified BSD License, see [LICENSE.txt](LICENSE.txt) for details.\n\n\n#### Copyright\n\n:copyright: 2014-2024 by the [Elephant team](doc/authors.rst).\n\n\n#### Acknowledgments\n\nSee [acknowledgments](doc/acknowledgments.rst).\n\n\n#### Citation\n\nSee [citations](doc/citation.rst).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/emipy",
            "repo_link": "https://jugit.fz-juelich.de/network-science-group/emipy",
            "readme": "[![pipeline status](https://jugit.fz-juelich.de/network-science-group/emipy/badges/main/pipeline.svg)](https://jugit.fz-juelich.de/network-science-group/emipy/-/commits/main)\n[![coverage report](https://jugit.fz-juelich.de/network-science-group/emipy/badges/main/coverage.svg)](https://jugit.fz-juelich.de/network-science-group/emipy/-/commits/main)\n[![PyPI version](https://img.shields.io/pypi/v/emipy.svg)](https://pypi.org/project/emipy/)\n[![Documentation build status](https://img.shields.io/readthedocs/emipy.svg)](https://readthedocs.org/projects/emipy/builds/)\n![Python version](https://img.shields.io/pypi/pyversions/emipy.svg)\n![LICENSE](https://img.shields.io/pypi/l/emipy.svg)\n\n# About\nemipy is a package for processing data of pollutant releases and pollutant transfers.\nIt's main target is to enable a fast output of individual data set requests and to provide visualisation options.\n\nThe data are provided by the [European Environment Agency](https://www.eea.europa.eu/data-and-maps/data/member-states-reporting-art-7-under-the-european-pollutant-release-and-transfer-register-e-prtr-regulation-23) and [Eurostat](https://ec.europa.eu/eurostat/de/web/gisco/overview).\n\n# Documentation\nFor the documentation take a look over [here](https://emipy.readthedocs.io/en/latest/).\n\n# Contribution\nWe are happy about ideas for new features or concrete implementations in emipy. \nJust get in touch and we will hopefully work together on your subject ASAP.\n\nTo contribute changes:\n\n1. Fork the project on [GitLab](https://jugit.fz-juelich.de/network-science-group/emipy)\n2. Create a feature branch to work in your fork\n3. Commit your changes to the feature branch\n4. Push the branch to [GitLab](https://jugit.fz-juelich.de/network-science-group/emipy)\n5. Create a new pull request from the feature branch on [GitLab](https://jugit.fz-juelich.de/network-science-group/emipy)\n\n# Contact\nFor contact write a mail to p.boettcher@fz-juelich.de\n",
            "project_id": "4404"
        },
        {
            "software_organization": "https://helmholtz.software/software/enpt",
            "repo_link": "https://git.gfz-potsdam.de/EnMAP/GFZ_Tools_EnMAP_BOX/EnPT",
            "readme": "\n.. image:: https://enmap.git-pages.gfz-potsdam.de/GFZ_Tools_EnMAP_BOX/EnPT/img/EnPT_logo_final.svg\n   :width: 300px\n   :alt: EnPT Logo\n\n============================\nEnPT - EnMAP Processing Tool\n============================\n\nThe EnPT Python package is an automated pre-processing pipeline for the new EnMAP hyperspectral satellite data.\nIt provides free and open-source features to transform EnMAP Level-1B data to Level-2A. The package has been developed\nat the German Research Centre for Geosciences Potsdam (GFZ) as an alternative to the processing chain of the EnMAP\nGround Segment.\n\n* Please check the documentation_ for installation and usage instructions and in depth information.\n* Information on how to **cite the EnPT Python package** can be found in the\n  `CITATION <https://git.gfz-potsdam.de/EnMAP/GFZ_Tools_EnMAP_BOX/EnPT/-/blob/main/CITATION>`__ file.\n\n\nLicense\n-------\nFree software: GNU General Public License v3 or later (GPLv3+)\n\nAll images contained in any (sub-)directory of this repository are licensed under the CC0 license which can be found\n`here <https://creativecommons.org/publicdomain/zero/1.0/legalcode.txt>`__.\n\nFeature overview\n----------------\n\n* read EnMAP Level-1B input data\n* radiometric conversion to top-of-atmosphere radiance\n* dead pixel correction\n* atmospheric correction (based on SICOR_ for land and `ACwater Polymer`_ via Polymer_ for water surfaces)\n* optional export of additional results from atmospheric parameter retrieval\n* detection and correction of geometric misregistrations compared to user provided spatial reference (based on AROSICS_)\n* orthorectification\n* write EnMAP Level-2A output data\n\nStatus\n------\n\n|badge1| |badge2| |badge3| |badge4| |badge5| |badge6| |badge7| |badge8| |badge9|\n\n.. |badge1| image:: https://git.gfz-potsdam.de/EnMAP/GFZ_Tools_EnMAP_BOX/EnPT/badges/main/pipeline.svg\n    :target: https://git.gfz-potsdam.de/EnMAP/GFZ_Tools_EnMAP_BOX/EnPT/pipelines\n\n.. |badge2| image:: https://git.gfz-potsdam.de/EnMAP/GFZ_Tools_EnMAP_BOX/EnPT/badges/main/coverage.svg\n    :target: https://enmap.git-pages.gfz-potsdam.de/GFZ_Tools_EnMAP_BOX/EnPT/coverage/\n\n.. |badge3| image:: https://img.shields.io/static/v1?label=Documentation&message=GitLab%20Pages&color=orange\n    :target: https://enmap.git-pages.gfz-potsdam.de/GFZ_Tools_EnMAP_BOX/EnPT/doc/\n\n.. |badge4| image:: https://img.shields.io/pypi/v/enpt.svg\n    :target: https://pypi.python.org/pypi/enpt\n\n.. |badge5| image:: https://img.shields.io/conda/vn/conda-forge/enpt.svg\n        :target: https://anaconda.org/conda-forge/enpt\n\n.. |badge6| image:: https://img.shields.io/pypi/l/enpt.svg\n    :target: https://git.gfz-potsdam.de/EnMAP/GFZ_Tools_EnMAP_BOX/EnPT/-/blob/main/LICENSE\n\n.. |badge7| image:: https://img.shields.io/pypi/pyversions/enpt.svg\n    :target: https://img.shields.io/pypi/pyversions/enpt.svg\n\n.. |badge8| image:: https://img.shields.io/pypi/dm/enpt.svg\n    :target: https://pypi.python.org/pypi/enpt\n\n.. |badge9| image:: https://zenodo.org/badge/253474970.svg\n   :target: https://zenodo.org/badge/latestdoi/253474970\n\nSee also the latest coverage_ report and the pytest_ HTML report.\n\nHistory / Changelog\n-------------------\n\nYou can find the protocol of recent changes in the EnPT package\n`here <https://git.gfz-potsdam.de/EnMAP/GFZ_Tools_EnMAP_BOX/EnPT/-/blob/main/HISTORY.rst>`__.\n\nCredits\n-------\n\nThis software was developed within the context of the EnMAP project supported by the DLR Space Administration with\nfunds of the German Federal Ministry of Economic Affairs and Energy (on the basis of a decision by the German\nBundestag: 50 EE 1529) and contributions from DLR, GFZ and OHB System AG.\n\nSentinel-2 spatial reference test data have been provided by ESA.\n\nThis package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage\n.. _documentation: https://enmap.git-pages.gfz-potsdam.de/GFZ_Tools_EnMAP_BOX/EnPT/doc\n.. _coverage: https://enmap.git-pages.gfz-potsdam.de/GFZ_Tools_EnMAP_BOX/EnPT/coverage/\n.. _pytest: https://enmap.git-pages.gfz-potsdam.de/GFZ_Tools_EnMAP_BOX/EnPT/test_reports/report.html\n.. _SICOR: https://git.gfz-potsdam.de/EnMAP/sicor\n.. _AROSICS: https://git.gfz-potsdam.de/danschef/arosics\n.. _`ACwater Polymer`: https://gitlab.awi.de/phytooptics/acwater\n.. _Polymer: https://forum.hygeos.com\n",
            "project_id": "88"
        },
        {
            "software_organization": "https://helmholtz.software/software/enrichedheatmap",
            "repo_link": "https://github.com/jokergoo/EnrichedHeatmap",
            "readme": "# Make Enriched Heatmaps\n\n[![R-CMD-check](https://github.com/jokergoo/EnrichedHeatmap/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/EnrichedHeatmap/actions)\n[![codecov](https://img.shields.io/codecov/c/github/jokergoo/EnrichedHeatmap.svg)](https://codecov.io/github/jokergoo/EnrichedHeatmap)\n[![bioc](https://bioconductor.org/shields/downloads/devel/EnrichedHeatmap.svg)](https://bioconductor.org/packages/stats/bioc/EnrichedHeatmap/) \n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/EnrichedHeatmap.svg)](http://bioconductor.org/packages/devel/bioc/html/EnrichedHeatmap.html)\n\n \n\nEnriched heatmap is a special type of heatmap which visualizes the enrichment of genomic signals on specific target regions. It is broadly used to visualize e.g. how histone marks are enriched to specific sites.\n\nThere are several tools that can make such heatmap (e.g. [ngs.plot](https://github.com/shenlab-sinai/ngsplot) or [deepTools](https://github.com/fidelram/deepTools)). Here we implement Enriched heatmap by [ComplexHeatmap](https://github.com/jokergoo/ComplexHeatmap) package. Since this type of heatmap is just a normal heatmap but with some fixed settings, with the functionality of ComplexHeatmap, it would be much easier to customize the heatmap as well as concatenating a list of heatmaps to show correspondance between differnet data sources.\n\n### Citation\n\nZuguang Gu, et al., EnrichedHeatmap: an R/Bioconductor package for comprehensive visualization of genomic signal associations, 2018. BMC Genomics. [link](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4625-x)\n\n### Install\n\n**EnrichedHeatmap** is available on [Bioconductor](http://bioconductor.org/packages/devel/bioc/html/EnrichedHeatmap.html), you can install it by:\n\n```{r}\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"EnrichedHeatmap\") \n```\n\nIf you want the latest version, install it directly from GitHub:\n\n```{r}\nlibrary(devtools)\ninstall_github(\"jokergoo/ComplexHeatmap\")\ninstall_github(\"jokergoo/EnrichedHeatmap\")\n```\n\n### Example\n\nLike other tools, the task involves two steps:\n\n1. Normalize the accosiations between genomic signals and target regions to a matrix.\n2. Draw heatmaps.\n\n```{r}\nmat1 = normalizeToMatrix(H3K4me3, tss, value_column = \"coverage\", \n    extend = 5000, mean_mode = \"w0\", w = 50)\nmat2 = normalizeToMatrix(meth, tss, value_column = \"meth\", mean_mode = \"absolute\",\n    extend = 5000, w = 50, background = NA, smooth = TRUE)\n```\n\n```{r}\npartition = kmeans(mat1, centers = 3)$cluster\nlgd = Legend(at = c(\"cluster1\", \"cluster2\", \"cluster3\"), title = \"Clusters\", \n    type = \"lines\", legend_gp = gpar(col = 2:4))\nht_list = Heatmap(partition, col = structure(2:4, names = as.character(1:3)), name = \"partition\",\n              show_row_names = FALSE, width = unit(3, \"mm\")) +\n          EnrichedHeatmap(mat1, col = c(\"white\", \"red\"), name = \"H3K4me3\", row_split = partition,\n              top_annotation = HeatmapAnnotation(lines = anno_enriched(gp = gpar(col = 2:4))), \n              column_title = \"H3K4me3\") + \n          EnrichedHeatmap(mat2, name = \"methylation\",\n              top_annotation = HeatmapAnnotation(lines = anno_enriched(gp = gpar(col = 2:4))), \n              column_title = \"Methylation\") +\n          Heatmap(log2(rpkm+1), col = c(\"white\", \"orange\"), name = \"log2(rpkm+1)\", \n              show_row_names = FALSE, width = unit(5, \"mm\"))\ndraw(ht_list, main_heatmap = \"H3K4me3\", gap = unit(c(2, 10, 2), \"mm\"))\n```\n\n![image](https://cloud.githubusercontent.com/assets/449218/14768684/41a6d534-0a49-11e6-800a-36ce15ad83ca.png)\n\nAlso when signals are discreate values. E.g. chromatin states:\n\n![test](https://user-images.githubusercontent.com/449218/36900761-e3d2ff86-1e24-11e8-865c-2cedb2674707.png)\n\nActually you can generate rather complex heatmaps:\n\n<img width=\"1043\" alt=\"screen shot 2017-10-13 at 10 42 42\" src=\"https://user-images.githubusercontent.com/449218/31608873-50c497d6-b272-11e7-8d81-cd88156d18aa.png\">\n\n\n### License\n\nMIT @ Zuguang Gu\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/esm-tools",
            "repo_link": "https://github.com/esm-tools/esm_tools",
            "readme": "=========\nESM Tools\n=========\n\nDocumentation\n-------------\n\n.. image:: https://readthedocs.org/projects/esm-tools/badge/?version=latest\n\nFor our complete documentation, please check https://esm-tools.readthedocs.io/en/latest/index.html.\n\nHow to cite this software\n-------------------------\nTo cite ESM-Tools, please use the following DOI: https://zenodo.org/doi/10.5281/zenodo.3737927. This DOI represents all versions of the software, and will always pointing to the latest version available on https://zenodo.org.\n\n\nBefore you continue\n-------------------\n\nYou will need python 3 (possibly version 3.6 or newer), a version of git that is not ancient (everything newer than 2.10 should be good), and up-to-date pip (``pip install -U pip``) to install the `esm_tools`. That means that on the supported machines, you could for example use the following settings:\n\nalbedo::\n\n    $ module load git\n    $ module load python\n\nlevante.dkrz.de::\n\n    $ module load git\n    $ module load python3\n\nglogin.hlrn.de / blogin.hlrn.de::\n\n    $ module load git\n    $ module load anaconda3\n\njuwels.fz-juelich.de::\n\n    $ module load Stages/2022\n    $ module load git\n    $ module load Python/3.9.6\n\naleph::\n\n    $ module load git\n    $ module load python\n\nNote that some machines might raise an error ``conflict netcdf_c`` when loading ``anaconda3``. In that case you will need to swap ``netcdf_c`` with ``anaconda3``::\n\n    $ module unload netcdf_c\n    $ module load anaconda3\n\n\n\nInstalling\n----------\n\n1. First, make sure you add the following lines to one of your login or profile files, i.e. ``~/.bash_profile``, ``~/.bashrc``, ``~/.profile``, etc.::\n\n        $ export PATH=$PATH:~/.local/bin\n        $ export LC_ALL=en_US.UTF-8\n        $ export LANG=en_US.UTF-8\n\n2. Inside the same login or profile file, add also the ``module`` commands necessary for the HPC system you are using (find the lines in the section above).\n\n3. You can choose to source now your login or profile file, so that the ``module`` and ``export`` commands are run (e.g. ``$ source ~/.bash_profile``).\n\n4. To use the new version of the ESM-Tools, now rewritten in Python, clone this repository::\n\n        $ git clone https://github.com/esm-tools/esm_tools.git\n\n5. Then, run the ``install.sh``::\n\n        $ ./install.sh\n\nYou should now have the command line tools ``esm_master`` and ``esm_runscripts``, which replace the old version.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/esmvalcore",
            "repo_link": "https://github.com/ESMValGroup/ESMValCore",
            "readme": "# ESMValCore package\n\n[![Documentation Status](https://readthedocs.org/projects/esmvalcore/badge/?version=latest)](https://esmvaltool.readthedocs.io/en/latest/?badge=latest)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3387139.svg)](https://doi.org/10.5281/zenodo.3387139)\n[![Chat on Matrix](https://matrix.to/img/matrix-badge.svg)](https://matrix.to/#/#ESMValGroup_Lobby:gitter.im)\n[![CircleCI](https://circleci.com/gh/ESMValGroup/ESMValCore/tree/main.svg?style=svg)](https://circleci.com/gh/ESMValGroup/ESMValCore/tree/main)\n[![codecov](https://codecov.io/gh/ESMValGroup/ESMValCore/branch/main/graph/badge.svg?token=wQnDzguwq6)](https://codecov.io/gh/ESMValGroup/ESMValCore)\n[![Codacy Badge](https://app.codacy.com/project/badge/Grade/5d496dea9ef64ec68e448a6df5a65783)](https://app.codacy.com/gh/ESMValGroup/ESMValCore/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)\n[![Anaconda-Server Badge](https://img.shields.io/conda/vn/conda-forge/ESMValCore?color=blue&label=conda-forge&logo=conda-forge&logoColor=white)](https://anaconda.org/conda-forge/esmvalcore)\n[![Github Actions Test](https://github.com/ESMValGroup/ESMValCore/actions/workflows/run-tests.yml/badge.svg)](https://github.com/ESMValGroup/ESMValCore/actions/workflows/run-tests.yml)\n[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/ESMValGroup/ESMValCore/main.svg)](https://results.pre-commit.ci/latest/github/ESMValGroup/ESMValCore/main)\n\n![esmvaltoollogo](https://raw.githubusercontent.com/ESMValGroup/ESMValCore/main/doc/figures/ESMValTool-logo-2-glow.png)\n\nESMValCore: core functionalities for the ESMValTool, a community diagnostic\nand performance metrics tool for routine evaluation of Earth System Models\nin the Climate Model Intercomparison Project (CMIP).\n\n# Getting started\n\nPlease have a look at the\n[documentation](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/quickstart/install.html)\nto get started.\n\n## Using the ESMValCore package to run recipes\n\nThe ESMValCore package provides the `esmvaltool` command, which can be used to run\n[recipes](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/recipe/overview.html)\nfor working with CMIP-like data.\nA large collection of ready to use\n[recipes and diagnostics](https://docs.esmvaltool.org/en/latest/recipes/index.html)\nis provided by the\n[ESMValTool](https://github.com/ESMValGroup/ESMValTool)\npackage.\n\n## Using ESMValCore as a Python library\n\nThe ESMValCore package provides various functions for:\n\n-   Finding data in a directory structure typically used for CMIP data.\n\n-   Reading CMIP/CMOR tables and using those to check model and observational data.\n\n-   ESMValTool preprocessor functions based on\n    [iris](https://scitools-iris.readthedocs.io) for e.g. regridding,\n    vertical interpolation, statistics, correcting (meta)data errors, extracting\n    a time range, etcetera.\n\nread all about it in the\n[API documentation](https://docs.esmvaltool.org/projects/esmvalcore/en/latest/api/esmvalcore.html).\n\n## Getting help\n\nThe easiest way to get help if you cannot find the answer in the documentation\non [readthedocs](https://docs.esmvaltool.org), is to open an\n[issue on GitHub](https://github.com/ESMValGroup/ESMValCore/issues).\n\n## Contributing\n\nContributions are very welcome, please read our\n[contribution guidelines](https://docs.esmvaltool.org/projects/ESMValCore/en/latest/contributing.html)\nto get started.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ethosfine-framework-for-integrated-energy-system-assessment",
            "repo_link": "https://github.com/FZJ-IEK3-VSA/FINE",
            "readme": "<!-- markdownlint-disable line-length no-inline-html -->\n# ETHOS.FINE - Framework for Integrated Energy System Assessment\n\n[![Build Status](https://travis-ci.com/FZJ-IEK3-VSA/FINE.svg?branch=master)](https://travis-ci.com/FZJ-IEK3-VSA/FINE)\n[![Version](https://img.shields.io/pypi/v/FINE.svg)](https://pypi.python.org/pypi/FINE)\n[![Conda Version](https://img.shields.io/conda/vn/conda-forge/fine.svg)](https://anaconda.org/conda-forge/fine)\n[![Documentation Status](https://readthedocs.org/projects/vsa-fine/badge/?version=latest)](https://vsa-fine.readthedocs.io/en/latest/)\n[![PyPI - License](https://img.shields.io/pypi/l/FINE)](https://github.com/FZJ-IEK3-VSA/FINE/blob/master/LICENSE.txt)\n[![codecov](https://codecov.io/gh/FZJ-IEK3-VSA/FINE/branch/master/graph/badge.svg)](https://codecov.io/gh/FZJ-IEK3-VSA/FINE)\n\n<a href=\"https://www.fz-juelich.de/en/ice/ice-2\"><img src=\"https://github.com/FZJ-IEK3-VSA/README_assets/blob/main/JSA-Header.svg?raw=True\" alt=\"Forschungszentrum Juelich Logo\" width=\"300px\"></a>\n\nThe ETHOS.FINE python package provides a framework for modeling, optimizing and assessing energy systems. With the provided framework, systems with multiple regions, commodities, time steps and investment periods can be modeled. Target of the optimization is the minimization of the systems net present value (NPV) while considering technical and environmental constraints. If only one investment period is considered, the net present value is equal to the total annual costs (TAC). Besides using the full temporal resolution, an interconnected typical period storage formulation can be applied, that reduces the complexity and computational time of the model.\n\nThis Readme provides information on the installation of the package. For further information have a look at the [documentation](https://vsa-fine.readthedocs.io/en/latest/).\n\nETHOS.FINE is used for the modelling of a diverse group of optimization problems within the [Energy Transformation PatHway Optimization Suite (ETHOS) at ICE-2](https://www.fz-juelich.de/de/ice/ice-2/leistungen/model-services).  \n\nIf you want to use ETHOS.FINE in a published work, please [**kindly cite following publication**](https://www.sciencedirect.com/science/article/pii/S036054421830879X) which gives a description of the first stages of the framework. The python package which provides the time series aggregation module and its corresponding literature can be found [here](https://github.com/FZJ-IEK3-VSA/tsam).\n\n## Installation \nThere are several options for the installation of ETHOS.FINE. You can install it via PyPI or from conda-forge.\nFor detailed information, have a look at the [installation documentation](https://vsa-fine.readthedocs.io/en/latest/installationDoc.html).\n\nNOTE: If you want to work on the source code of FINE, see [Editable install from conda-forge](#editable-install-from-conda-forge).\n\nIf you would like to run ETHOS.FINE for your analysis we recommend to install it directly from conda-forge into a new Python environment with\n\n```bash\nmamba create --name fine --channel conda-forge fine\n```\n\n**Note on Mamba vs.Conda:** `mamba` commands can be substitued with `conda`. We highly recommend using [(Micro-)Mamba](https://mamba.readthedocs.io/en/latest/) instead of Conda. The recommended way to use Mamba on your system is to install the [Miniforge distribution](https://github.com/conda-forge/miniforge#miniforge3). They offer installers for Windows, Linux and OS X. In principle, Conda and Mamba are interchangeable. The commands and concepts are the same. The distributions differ in the methodology for determining dependencies when installing Python packages. Mamba relies on a more modern methodology, which (with the same result) leads to very significant time savings during the installation of ETHOS.FINE. Switching to Mamba usually does not lead to any problems, as it is virtually identical to Conda in terms of operation.\n\n**Note on the solver:** \nThe functionality of ETHOS.FINE depends on the following C libraries that need to be installed on your system. If you do not know how to install those, consider installing from conda-forge. The mamba/conda installation comes with [GLPK](https://www.gnu.org/software/glpk/) [(installation for Windows)](https://sourceforge.net/projects/winglpk/files/latest/download) as Mixed Integer Linear Programming (MILP) solver. If you want to solve large problems it is highly recommended to install [GUROBI](http://www.gurobi.com/). See [\"Installation of an optimization solver\"](https://vsa-fine.readthedocs.io/en/latest/installationDoc.html#installation-of-an-optimization-solver) in the documentation for more information.\n\n\n## Examples\n\nA number of [examples](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples) shows the capabilities of ETHOS.FINE.\n\n- [00_Tutorial](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/00_Tutorial)\n  - In this application, an energy supply system, consisting of two regions, is modeled and optimized. Recommended as starting point to get to know to ETHOS.FINE.\n- [01_1node_Energy_System_Workflow](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/01_1node_Energy_System_Workflow)\n  - In this application, a single region energy system is modeled and optimized. The system includes only a few technologies.\n- [02_EnergyLand](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/02_EnergyLand)\n  - In this application, a single region energy system is modeled and optimized. Compared to the previous examples, this example includes a lot more technologies considered in the system.\n- [03_Multi-regional_Energy_System_Workflow](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/03_Multi-regional_Energy_System_Workflow)\n  - In this application, an energy supply system, consisting of eight regions, is modeled and optimized. The example shows how to model multi-regional energy systems. The example also includes a notebook to get to know the optional performance summary. The summary shows how the optimization performed.\n- [04_Model_Run_from_Excel](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/04_Model_Run_from_Excel)\n  - ETHOS.FINE can also be run by excel. This example shows how to read and run a model using excel files.\n- [05_District_Optimization](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/05_District_Optimization)\n  - In this application, a small district is modeled and optimized. This example also includes binary decision variables.\n- [06_Water_Supply_System](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/06_Water_Supply_System)\n  - The application cases of ETHOS.FINE are not limited. This application shows how to model the water supply system.\n- [07_NetCDF_to_save_and_set_up_model_instance](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/07_NetCDF_to_save_and_set_up_model_instance)\n  - This example shows how to save the input and optimized results of an energy system Model instance to netCDF files to allow reproducibility.\n- [08_Spatial_and_technology_aggregation](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/08_Spatial_and_technology_aggregation)\n  - These two examples show how to reduce the model complexity. Model regions can be aggregated to reduce the number of regions (spatial aggregation). Input parameters are automatically adapted. Furthermore, technologies can be aggregated to reduce complexity, e.g. reducing the number of different PV components (technology aggregation). Input parameters are automatically adapted.\n- [09_Stochastic_Optimization](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/9_Stochastic_Optimizatio)\n  - In this application, a stochastic optimization is performed. It is possible to perform the optimization of an energy system model with different input parameter sets to receive a more robust solution.\n- [10_PerfectForesight](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/10_PerfectForesight)\n  - In this application, a transformation pathway of an energy system is modeled and optimized showing how to handle several investment periods with time-dependent assumptions for costs and operation.\n- [11_Partload](https://github.com/FZJ-IEK3-VSA/FINE/tree/develop/examples/11_Partload)\n  - In this application, a hydrogen system is modeled and optimized considering partload behavior of the electrolyzer.\n\n## Notes for developers\n\n### Editable install from conda-forge\n\nIt is recommended to create a clean environment with conda to use ETHOS.FINE because it requires many dependencies.\n\n```bash\nmamba env create --name fine --file requirements_dev.yml\nmamba activate fine\n```\n\nInstall ETHOS.FINE as editable install and without checking the dependencies from pypi with\n\n```bash\npython -m pip install --no-deps --editable .\n```\n\n### Editable install from pypi\n\nIf you do not want to use conda-forge consider the steps in section [Installation from pipy](#Installation-from-pipy) and install ETHOS.FINE as editable install and with developer dependencies with\n\n```bash\npython -m pip install --editable .[develop]\n```\n\n### Good coding style\n\nWe use [ruff](https://docs.astral.sh/ruff) to ensure good coding style. Make\nsure to use it before contributing to the code base with\n\n```bash\nruff check fine\n```\n\n## License\n\nMIT License\n\nCopyright (C) 2016-2024 FZJ-ICE-2\n\nActive Developers: Theresa Groß, Kevin Knosala, Noah Pflugradt, Johannes Behrens, Julian Belina, Arne Burdack, Toni Busch, Philipp Dunkel, David Franzmann, Patrick Freitag, Thomas Grube, Heidi Heinrichs, Maximilian Hoffmann, Jason Hu, Shitab Ishmam, Sebastian Kebrich, Felix Kullmann, Jochen Linßen, Rachel Maier, Shruthi Patil, Jan Priesmann, Julian Schönau, Maximilian Stargardt, Lovindu Wijesinghe, Christoph Winkler, Detlef Stolten\n\nAlumni: Robin Beer, Henrik Büsing, Dilara Caglayan, Timo Kannengießer, Leander Kotzur, Stefan Kraus, Peter Markewitz, Lars Nolting,Stanley Risch, Martin Robinius, Bismark Singh, Andreas Smolenko, Peter Stenzel, Chloi Syranidou, Johannes Thürauf, Lara Welder, Michael Zier\n\nYou should have received a copy of the MIT License along with this program.\nIf not, see https://opensource.org/licenses/MIT\n\n\n## About Us \n\n<a href=\"https://www.fz-juelich.de/en/ice/ice-2\"><img src=\"https://github.com/FZJ-IEK3-VSA/README_assets/blob/main/iek3-square.png?raw=True\" alt=\"Institute image ICE-2\" width=\"280\" align=\"right\" style=\"margin:0px 10px\"/></a>\n\nWe are the <a href=\"https://www.fz-juelich.de/en/ice/ice-2\">Institute of Climate and Energy Systems (ICE) - Jülich Systems Analysis</a> belonging to the <a href=\"https://www.fz-juelich.de/en\">Forschungszentrum Jülich</a>. Our interdisciplinary department's research is focusing on energy-related process and systems analyses. Data searches and system simulations are used to determine energy and mass balances, as well as to evaluate performance, emissions and costs of energy systems. The results are used for performing comparative assessment studies between the various systems. Our current priorities include the development of energy strategies, in accordance with the German Federal Government’s greenhouse gas reduction targets, by designing new infrastructures for sustainable and secure energy supply chains and by conducting cost analysis studies for integrating new technologies into future energy market frameworks.\n\n## Contributions and Support\nEvery contributions are welcome:\n- If you have a question, you can start a [Discussion](https://github.com/FZJ-IEK3-VSA/FINE/discussions). You will get a response as soon as possible.\n- If you want to report a bug, please open an [Issue](https://github.com/FZJ-IEK3-VSA/FINE/issues/new). We will then take care of the issue as soon as possible.\n- If you want to contribute with additional features or code improvements, open a [Pull request](https://github.com/FZJ-IEK3-VSA/FINE/pulls).\n\n## Code of Conduct\nPlease respect our [code of conduct](CODE_OF_CONDUCT.md).\n\n## Acknowledgement\nThis work was initially supported by the Helmholtz Association under the Joint Initiative [\"Energy System 2050   A Contribution of the Research Field Energy\"](https://www.helmholtz.de/en/research/energy/energy_system_2050/). \n\nThe authors also gratefully acknowledge financial support by the Federal Ministry for Economic Affairs and Energy of Germany as part of the project [METIS](http://www.metis-platform.net/) (project number 03ET4064, 2018-2022).\n\nThis work was supported by the Helmholtz Association under the program [\"Energy System Design\"](https://www.helmholtz.de/en/research/research-fields/energy/energy-system-design/).\n\n<p float=\"left\">\n<a href=\"https://www.helmholtz.de/en/\"><img src=\"https://www.helmholtz.de/fileadmin/user_upload/05_aktuelles/Marke_Design/logos/HG_LOGO_S_ENG_RGB.jpg\" alt=\"Helmholtz Logo\" width=\"200px\"></a>\n</p>\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/hisim",
            "repo_link": "https://github.com/FZJ-IEK3-VSA/HiSim",
            "readme": " [![PyPI Version](https://img.shields.io/pypi/v/hisim.svg)](https://pypi.python.org/pypi/hisim)\n [![PyPI - License](https://img.shields.io/pypi/l/hisim)](LICENSE)\n \n <a href=\"https://www.fz-juelich.de/en/iek/iek-3\"><img src=\"https://www.fz-juelich.de/static/media/Logo.2ceb35fc.svg\" alt=\"Forschungszentrum Juelich Logo\" width=\"230px\"></a> \n\n# ETHOS.HiSim - Household Infrastructure and Building Simulator\n\nETHOS.HiSim is a Python package for simulation and analysis of household scenarios and building systems using modern\ncomponents as alternative to fossil fuel based ones. This package integrates load profiles generation of electricity\nconsumption, heating demand, electricity generation, and smart strategies of modern components, such as\nheat pump, battery, electric vehicle or thermal energy storage. ETHOS.HiSim is a package under development by\nForschungszentrum Jülich und Hochschule Emden/Leer. For detailed documentation, please\naccess [ReadTheDocs](https://household-infrastructure-simulator.readthedocs.io/en/latest/) of this repository.\n\n\n# Install Graphviz\n\nIf you want to use the feature that generates system charts, you need to install GraphViz in your system. If you don't\nhave Graphviz installed, you will experience error messages about a missing dot.exe under Windows.\n\nFollow the installation instructions from here:\nhttps://www.graphviz.org/download/\n\n(or simply disable the system charts)\n\nClone Repository\n-----------------------\nTo clone this repository, enter the following command to your terminal:\n\n```python\ngit clone https://github.com/FZJ-IEK3-VSA/HiSim.git\n```\n\nVirtual Environment\n-----------------------\nBefore installing `ETHOS.Hisim`, it is recommended to set up a Python virtual environment. Let `hisimvenv` be the name of\nvirtual environment to be created. For Windows users, setting the virtual environment in the path `\\Hisim` is done with\nthe command line:\n\n```python\npython -m venv hisimvenv\n```\n\nAfter its creation, the virtual environment can be activated in the same directory:\n\n```python \nhisimvenv\\Scripts\\activate\n```\n\nFor Linux/Mac users, the virtual environment is set up and activated as follows:\n\n```python \nvirtual hisimvenv source hisimvenv/bin/activate\n```\n\nAlternatively, Anaconda can be used to set up and activate the virtual environment:\n\n```python \nconda create -n hisimvenv python=3.9\nconda activate hisimvenv\n```\n\nWith the successful activation, `ETHOS.HiSim` is ready to be locally installed.\n\nInstall Package\n------------------------\nAfter setting up the virtual environment, install the package to your local libraries:\n\n```python\npip install -e .\n```\n\nOptional: Set Environment Variables\n-----------------------\nCertain components might access APIs to retrieve data. In order to use them, you need to set the url and key as environment variables. This can be done with an `.env` file wihtin the HiSim root folder or with system tools. The environment variables are:\n\n```\nUTSP_URL\nUTSP_API_KEY\n```\n\nRun Simple System Setups\n-----------------------\nRun the python interpreter in the `HiSim/system_setups` directory with the following command:\n\n```python\npython ../hisim/hisim_main.py simple_system_setup_one.py\n```\nor\n\n```python\npython ../hisim/hisim_main.py simple_system_setup_two.py\n```\n\nThis command executes `hisim_main.py` on the setup function `setup_function` implemented in the files `simple_system_setup_one.py`\nand `simple_system_setup_two.py` that are stored in `HiSim/system_setups`.\nThe results can be visualized under directory `results` created under the same directory where the script with the setup\nfunction is located.\n\nRun Basic Household System Setup\n-----------------------\nThe directory `HiSim/system_setups` also contains a basic household configuration in the script `basic_household.py`.\nIt can be executed with the following command:\n\n```python\npython ../hisim/hisim_main.py basic_household.py\n```\n\nThe system is set up with the following elements:\n\n* Occupancy (Residents' Demands)\n* Weather\n* Photovoltaic System\n* Building\n* Heat Pump\n\nHence, photovoltaic modules and the heat pump are responsible to cover the electricity the thermal energy demands as\nbest as possible. As the name of the setup function says, the components are explicitly connected to each other, binding\ninputs correspondingly to its output sequentially. This is difference then automatically connecting inputs and outputs\nbased its similarity. For a better understanding of explicit connection, proceed to session `IO Connecting Functions`.\n\nGeneric Setup Function Walkthrough\n---------------------\nThe basic structure of a setup function follows:\n\n1. Set the simulation parameters (See `SimulationParameters` class in `hisim/hisim/component.py`)\n1. Create a `Component` object and add it to `Simulator` object\n    1. Create a `Component` object from one of the child classes implemented in `hisim/hisim/components`\n        1. Check if `Component` class has been correctly imported\n    1. If necessary, connect your object's inputs with previous created `Component` objects' outputs.\n    1. Finally, add your `Component` object to `Simulator` object\n1. Repeat step 2 while all the necessary components have been created, connected and added to the `Simulator` object.\n\nOnce you are done, you can run the setup function according to the description in the simple system setup run.\n\nPackage Structure\n-----------\nThe main program is executed from `hisim/hisim/hisim_main.py`. The `Simulator`(`simulator.py`) object groups `Component`\ns declared and added from the setups functions. The `ComponentWrapper`(`simulator.py`) gathers together the `Component`s\ninside an `Simulator` Object. The `Simulator` object performs the entire simulation under the\nfunction `run_all_timesteps` and stores the results in a Python pickle `data.pkl` in a subdirectory\nof `hisim/hisim/results` named after the executed setup function. Plots and the report are automatically generated from\nthe pickle by the class `PostProcessor` (`hisim/hisim/postprocessing/postprocessing.py`).\n\nComponent Class\n-----------\nA child class inherits from the `Component` class in `hisim/hisim/component.py` and has to have the following methods\nimplemented:\n\n* i_save_state: updates previous state variable with the current state variable\n* i_restore_state: updates current state variable with the previous state variable\n* i_simulate: performs a timestep iteration for the `Component`\n* i_doublecheck: checks if the values are expected throughout the iteration\n\nThese methods are used by `Simulator` to execute the simulation and generate the results.\n\nList of `Component` Children\n-----------\nTheses classes inherent from `Component` (`component.py`) class and can be used in your setup function to customize\ndifferent configurations. All `Component` class children are stored in `hisim/hisim/components` directory. Some of these\nclasses are:\n\n- `RandomNumbers` (`random_numbers.py`)\n- `SimpleController` (`simple_controller.py`)\n- `SimpleSotrage` (`simple_storage.py`)\n- `Transformer` (`transformer.py`)\n- `PVSystem` (`pvs.py`)\n- `CHPSystem` (`chp_system.py`)\n- `Csvload` (`csvload.py`)\n- `SumBuilderForTwoInputs` (`sumbuilder.py`)\n- `SumBuilderForThreeInputs` (`sumbuilder.py`)\n- ToDo: more components to be added\n\nConnecting Input/Outputs\n-----------\nLet `my_home_electricity_grid` and `my_appliance` be Component objects used in the setup function. The\nobject `my_apppliance` has an output `ElectricityOutput` that has to be connected to an object `ElectricityGrid`. The\nobject `my_home_electricity_grid` has an input `ElectricityInput`, where this connection takes place. In the setup\nfunction, the connection is performed with the method `connect_input` from the `Simulator` class:\n\n```python\nmy_home_electricity_grid.connect_input(input_fieldname=my_home_electricity_grid.ELECTRICITY_INPUT,\n                                       src_object_name=my_appliance.component_name,\n                                       src_field_name=my_appliance.ELECTRICITY_OUTPUT)\n```\n\nConfiguration Automator\n-----------\nA configuration automator is under development and has the goal to reduce connections calls among similar components.\n\nPost Processing\n-----------\nAfter the simulator runs all time steps, the post processing (`postprocessing.py`) reads the persistent saved results,\nplots the data and\ngenerates a report.\n\n## Contributions and Collaborations\nETHOS.HiSim welcomes any kind of feedback, contributions, and collaborations. \nIf you are interested in joining the project, adding new features, or providing valuable insights, feel free to reach out (email to k.rieck@fz-juelich.de) and participate in our HiSim developer meetings held every second Monday. Additionally, we encourage you to utilize our Issue section to share feedback or report any bugs you encounter.\nWe look forward to your contributions and to making meaningful improvements. \nHappy coding!\n\n## License\n\nMIT License\n\nCopyright (C) 2020-2021 Noah Pflugradt, Leander Kotzur, Detlef Stolten, Tjarko Tjaden, Kevin Knosala, Sebastian Dickler, Katharina Rieck, David Neuroth, Johanna Ganglbauer, Vitor Zago, Frank Burkard, Maximilian Hillen, Marwa Alfouly, Franz Oldopp, Markus Blasberg\n\nYou should have received a copy of the MIT License along with this program.\nIf not, see https://opensource.org/licenses/MIT\n\n## About Us\n\n<a href=\"https://www.fz-juelich.de/iek/iek-3/DE/Home/home_node.html\"><img src=\"https://www.fz-juelich.de/SharedDocs/Bilder/IEK/IEK-3/Abteilungen2015/VSA_DepartmentPicture_2019-02-04_459x244_2480x1317.jpg?__blob=normal\" alt=\"Institut TSA\"></a>\n\nWe are\nthe [Institute of Energy and Climate Research - Techno-economic Systems Analysis (IEK-3)](https://www.fz-juelich.de/iek/iek-3/DE/Home/home_node.html)\nbelonging to the [Forschungszentrum Jülich](www.fz-juelich.de/). Our interdisciplinary institute's research is focusing\non energy-related process and systems analyses. Data searches and system simulations are used to determine energy and\nmass balances, as well as to evaluate performance, emissions and costs of energy systems. The results are used for\nperforming comparative assessment studies between the various systems. Our current priorities include the development of\nenergy strategies, in accordance with the German Federal Government’s greenhouse gas reduction targets, by designing new\ninfrastructures for sustainable and secure energy supply chains and by conducting cost analysis studies for integrating\nnew technologies into future energy market frameworks.\n\n## Contributions and Users\n\nDevelopment Partners:\n\n**Hochschule Emden/Leer** inside the project \"Piegstrom\".\n\n**4ward Energy** inside the EU project \"WHY\" \n\n## Acknowledgement\n\nThis work was supported by the Helmholtz Association under the Joint\nInitiative [\"Energy System 2050   A Contribution of the Research Field Energy\"](https://www.helmholtz.de/en/research/energy/energy_system_2050/)\n.\n\nFor this work weather data is based on data from [\"German Weather Service (Deutscher Wetterdienst-DWD)\"](https://www.dwd.de/DE/Home/home_node.html/) and [\"NREL National Solar Radiation Database\"](https://nsrdb.nrel.gov/data-viewer/download/intro/) (License: Creative Commons Attribution 3.0 United States License); individual values are averaged.\n\n<a href=\"https://www.helmholtz.de/en/\"><img src=\"https://www.helmholtz.de/fileadmin/user_upload/05_aktuelles/Marke_Design/logos/HG_LOGO_S_ENG_RGB.jpg\" alt=\"Helmholtz Logo\" width=\"200px\" style=\"float:right\"></a>\n\n<a href=\"https://www.dwd.de/\"><img src=\"https://www.dwd.de/SharedDocs/bilder/DE/logos/dwd/dwd_logo_258x69.png?__blob=normal&v=1\" alt=\"DWD Logo\" width=\"200px\" style=\"float:right\"></a>\n\nThis project has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 891943. \n\n<img src=\"eulogo.png\" alt=\"EU Logo\" width=\"200px\" style=\"float:right\"></a>\n\n<a href=\"https://www.why-h2020.eu/\"><img src=\"whylogo.jpg\" alt=\"WHY Logo\" width=\"200px\" style=\"float:right\"></a>\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ethospenalps",
            "repo_link": "https://github.com/FZJ-IEK3-VSA/ETHOS_PeNALPS",
            "readme": "| Name | Version | Platforms | Daily Tests |\n|---|---|---|---|\n|[![Conda Recipe](https://img.shields.io/badge/recipe-ethos_penalps-green.svg)](https://anaconda.org/conda-forge/ethos_penalps)|[![Conda Version](https://img.shields.io/conda/vn/conda-forge/ethos_penalps.svg)](https://anaconda.org/conda-forge/ethos_penalps)|[![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/ethos_penalps.svg)](https://anaconda.org/conda-forge/ethos_penalps) |![example workflow](https://github.com/FZJ-IEK3-VSA/ETHOS_PeNALPS/actions/workflows/daily_tests.yml/badge.svg)\n\n<a href=\"https://www.fz-juelich.de/en/iek/iek-3\"><img src=\"https://github.com/FZJ-IEK3-VSA/README_assets/blob/main/FJZ_IEK-3_logo.svg?raw=True\" alt=\"Forschungszentrum Juelich Logo\" width=\"300px\"></a> \n# ETHOS.PeNALPS\n\nETHOS.PeNALPS (Petri Net Agent based Load Profile Simulator) is a Python library for the simulation of load profiles of industrial manufacturing processes. It is part of [ETHOS (Energy Transformation Pathway Optimization Suite)](https://go.fzj.de/ethos_suite). Load profiles are energy demand time series. Processes that can be simulated using ETHOS.PeNALPS include, for example, steel, paper, and industrial food production. One or multiple product orders are passed to the model which starts the simulation and eventually creates the desired load profiles.\n\n# Working Principle\n\nThe figure below shows the main conceptual objects of ETHOS.PeNALPS which are:\n\n- Generic model objects\n- Material flow simulations\n- Production plans\n- Result load profiles\n\nThe model of the material flow simulation is created by users based on generic simulation\nobjects. After the material flow simulation is completed, a set of production orders is passed to the model to start the simulation. The simulation generates a production plan that tracks the activity of each node to fulfill the requested set of orders. Based on the activity in the production plan, the load profiles are created for each node in therein. \n\n\n![Main Component Overview](paper/main_component_overview.png)\n*Depiction of the main components and workflow of ETHOS.PeNALPS*\n\nThe [HTML documentation provides a tutorial](https://ethospenalps.readthedocs.io/en/latest/ethos_penalps_tutorial/0_overview.html) for ETHOS.PeNALPS. The executable files for the tutorial are located in the example section of this repository. Also two examples for a [toffee production process](https://ethospenalps.readthedocs.io/en/latest/examples/toffee_example.html) and a [b-pillar production process](https://ethospenalps.readthedocs.io/en/latest/examples/b_pillar_example.html) are available.\n\n\n# Installation\n\n## Requirements\nThe installation process uses a Conda-based Python package manager. We highly recommend using Mamba instead of Anaconda. The recommended way to use Mamba on your system is to install the Miniforge distribution. They offer installers for Windows, Linux and OS X. Have a look at the [Mamba installation guide](https://mamba.readthedocs.io/en/latest/installation/mamba-installation.html) for further details. If you prefer to stick to Anaconda you should install the [libmamba solver which is a lot faster than the classic conda solver](https://www.anaconda.com/blog/a-faster-conda-for-a-growing-community). Otherwise the installation of ETHOS.PeNALPS might take very long or does not succeed at all.  \n\n```\nconda install -n base conda-libmamba-solver\nconda config --set solver libmamba\n```\n\nPlease note that the installation time of the solver can be very long if you have installed a lot of other packages into you conda base environment. In the following the commands mamba and conda are exchangeable if you prefer to use conda.\n\n## Installation via conda-forge\nThe simplest way ist to install ETHOS.PeNALPS into a fresh environment from conda-forge with:\n\nCreate a new environment\n```python\nmamba create -n penalps_env \n```\n\nActivate the environment\n```python\nmamba activate penalps_env\n```\n\nInstall ETHOS.PeNALPS from conda forge\n```python\nmamba install -c conda-forge ethos_penalps\n```\n\n## Installation from Github for Development\n\nFirst the repository must be cloned from Github\n\n```python\ngit clone https://github.com/FZJ-IEK3-VSA/ETHOS_PeNALPS.git\n```\nThen change the directory to the root folder of the repository.\n```python\ncd ETHOS_PeNALPS\n```\n\nCreate a new environment from the environment.yml file with all required dependencies.\n```python\nmamba env create --file=environment.yml\n```\n\nActivate the new environment.\n```python\nmamba activate ethos_penalps\n```\n\nInstall ethos_penalps locally in editable to mode for development.\n```python\npip install -e .\n```\n\n# Tests\n\nThe library can be tested by running pytest with the following command from the root folder.\n\n```python\npytest\n```\n\n# Documentation \n\nA ReadTheDocs Documentation can be found [here](http://ethospenalps.readthedocs.io/).\n\n\n# Contributing\n\nContributions are welcome, and they are greatly appreciated! Every little bit\nhelps, and credit will always be given.\n\nYou can contribute in many ways:\n\n## Types of Contributions\n\n\n### Report Bugs\n\n\nReport bugs at https://github.com/FZJ-IEK3-VSA/ETHOS_PeNALPS/issues.\n\nIf you are reporting a bug, please include:\n\n* Your operating system name and version.\n* Any details about your local setup that might be helpful in troubleshooting.\n* Detailed steps to reproduce the bug.\n\n### Fix Bugs\n\nLook through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help\nwanted\" is open to whoever wants to implement it.\n\n### Implement Features\n\nLook through the GitHub issues for features. Anything tagged with \"enhancement\"\nand \"help wanted\" is open to whoever wants to implement it.\n\n### Write Documentation\n\nETHOS.PeNALPS could always use more documentation, whether as part of the\nofficial ETHOS.PeNALPS docs, in docstrings, or even on the web in blog posts,\narticles, and such.\n\n### Submit Feedback\n\n\nThe best way to send feedback is to file an issue at https://github.com/FZJ-IEK3-VSA/ETHOS_PeNALPS/issues.\n\nIf you are proposing a feature:\n\n- Explain in detail how it would work.\n- Keep the scope as narrow as possible, to make it easier to implement.\n- Remember that this is a volunteer-driven project, and that contributions\n  are welcome :)"
        },
        {
            "software_organization": "https://helmholtz.software/software/ethosreflow",
            "repo_link": "https://github.com/FZJ-IEK3-VSA/ethos.REFLOW",
            "readme": "# REFLOW: Renewable Energy potentials workFLOW manager\r\n\r\n<a href=\"https://www.fz-juelich.de/en/iek/iek-3\"><img src=\"https://github.com/FZJ-IEK3-VSA/README_assets/blob/main/FJZ_IEK-3_logo.svg?raw=True\" alt=\"Forschungszentrum Juelich Logo\" width=\"300px\"></a>\r\n\r\nREFLOW is a workflow manager tool designed to streamline and automate tasks related to renewable energy potential analyses. It is built with Luigi and provides an automated, robust framework for data acquisition, processing, land/sea eligibility analysis, technology placements, simulations and visualizations. It is build with transparency and reproducibility in mind. \r\n\r\n## Requirements\r\n* Python\r\n* An IDE (e.g. PyCharm, Visual Studio Code, etc.)\r\n* Unix-like system or bash on Windows\r\n* *optional*: Docker Desktop if running in container\r\n\r\n## Getting Started\r\n\r\n### Try an example project - Aachen technical wind potential\r\n\r\nWe highly recommend starting with the example workflow to get a feel for how REFLOW works. The example project is a simple technical wind energy potential analysis for a small region in Germany. \r\n\r\nTo run this analysis, follow these steps:\r\n1. Clone this repository to your local machine using:\r\n    ```bash\r\n    git clone https://github.com/FZJ-IEK3-VSA/ethos.REFLOW.git\r\n    ```\r\n\r\n2. Navigate to the example project directory:\r\n    ```bash\r\n    cd reflow/example_workflows/aachen_technical\r\n    ```\r\n3. Follow the instructions in the README.md file in the example project directory.\r\n\r\n\r\n### Initial Setup for a new project\r\n\r\nTo start your own new project using REFLOW, follow these steps:\r\n\r\n1. Clone this repository to your local machine using:\r\n    ```bash\r\n    git clone https://github.com/FZJ-IEK3-VSA/ethos.REFLOW.git\r\n    ```\r\n\r\n2. **Initialize a new Project:** Navigate to the **main REFLOW repo (this repo)** and run the initialize_project.py script by executing:\r\n    ```bash\r\n    python initialize_project.py\r\n    ```\r\n    You will be prompted to enter the name of your new project and the parent directory where it should be created.\r\n\r\n3. Create the main REFLOW python environment by running:\r\n    ```bash\r\n    conda env create -f required_software/requirements-reflow.yml\r\n    ```\r\n    Activate the environment by running:\r\n    ```bash\r\n    conda activate reflow\r\n    ```\r\n\r\n4. We recommend using a seperate conda environment for each software package which needs to be run outside of the main REFLOW environment. For example, if you are using WAsP, you can create a new environment which contains the PyWAsP package by:\r\n\r\n    4.1. Creating an environment file for the WAsP python package under the `required_software` directory. \r\n    You can use the provided `requirements-glaes.yml` file from the Aachen technical example as a template.\r\n\r\n    4.2. If the new environment file is in the required_software directory, the environment will automatically be created during the first task of the REFLOW workflow. \r\n\r\n    4.3. You can then run whichever task's script is needed inside the environment within your main REFLOW workflow. Do this by using a wrapper script which activates the environment, runs the task, and then deactivates the environment. (Again, see the Aachen technical example for reference.)\r\n\r\n**Optional but recommended - work with GIT:**\r\n\r\n5. **Create a New Git Repository**: Navigate into your new project directory and initilize it as a git repository:\r\n    ```bash\r\n    cd path/to/your-project-name\r\n    git init\r\n    git add .\r\n    git commit -m \"Initial commit\"\r\n    ```\r\n6. **Create an Empty Repository on Github** (or any other Git hosting service): Ensure the repository name matches your project's name. \r\n    Do not initialize the repository with a README, .gitignore or license.\r\n\r\n7. **Link your local repository to the remote repository**: Make sure you are in your new project directory and run the following commands:\r\n    ```bash\r\n    git remote add origin https://github.com/your-username/your-repo-name.git\r\n    git branch -M main\r\n    git push -u origin main\r\n    ```\r\n\r\nYou can now start working on your project and push your changes to the remote repository.\r\n\r\n## Examples\r\n\r\nThe example workflows are located in the `example_workflows` directory. Each example contains a README.md file with detailed instructions on how to run the workflow.\r\n\r\nWe recommend starting with the [Aachen technical wind potential example](example_workflows/aachen_technical/) to get a feel for how REFLOW works.\r\n\r\n## License\r\n\r\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE.txt) file for details.\r\n\r\nCopyright (c) 2024 Tristan Pelser (FZJ IEK-3), Jann Michael Weinand (FZJ IEK-3), Patrick Kuckertz (FZJ IEK-3), Detlef Stolten (FZJ IEK-3)\r\n\r\nYou should have received a copy of the MIT License along with this program.\r\nIf not, see https://opensource.org/licenses/MIT\r\n\r\n## About Us\r\n\r\n<a href=\"https://www.fz-juelich.de/en/iek/iek-3\"><img src=\"https://github.com/FZJ-IEK3-VSA/README_assets/blob/main/iek3-square.png?raw=True\" alt=\"Institute image IEK-3\" width=\"280\" align=\"right\" style=\"margin:0px 10px\"/></a>\r\n\r\nWe are the [Complex Energy System Modesl and Data Structures](https://www.fz-juelich.de/en/iek/iek-3/research/integrated-models-and-strategies/complex-energy-system-models-and-data-structures) department at the [Institute of Energy and Climate Research: Techno-economic Systems Analysis (IEK-3)](https://www.fz-juelich.de/en/iek/iek-3), belonging to the Forschungszentrum Jülich. Our interdisciplinary department's research is focusing on energy-related process and systems analyses. Data searches and system simulations are used to determine energy and mass balances, as well as to evaluate performance, emissions and costs of energy systems. The results are used for performing comparative assessment studies between the various systems. Our current priorities include the development of energy strategies, in accordance with the German Federal Government’s greenhouse gas reduction targets, by designing new infrastructures for sustainable and secure energy supply chains and by conducting cost analysis studies for integrating new technologies into future energy market frameworks.\r\n\r\n## Acknowledgements\r\n\r\nThe authors would like to thank the German Federal Government, the German State Governments, and the Joint Science Conference (GWK) for their funding and support as part of the NFDI4Ing consortium. Funded by the German Research Foundation (DFG) – 442146713, this work was also supported by the Helmholtz Association as part of the program “Energy System Design”.\r\n\r\n<p float=\"left\">\r\n<a href=\"https://www.helmholtz.de/en/\"><img src=\"https://www.helmholtz.de/fileadmin/user_upload/05_aktuelles/Marke_Design/logos/HG_LOGO_S_ENG_RGB.jpg\" alt=\"Helmholtz Logo\" width=\"200px\"></a>\r\n</p>\r\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ethoszoomin",
            "repo_link": "https://github.com/FZJ-IEK3-VSA/ETHOS.zoomin",
            "readme": "ETHOS.zoomin: A spatial disaggregation workflow tool developed within the LOCALISED project.\n==============================\n\nA workflow tool that:\n1. Pulls data from a database.\n2. Disaggregates it based on proxy specifications present in the database.\n3. Evaulates quality rating - based on quality of the data to be disaggregated, proxy data and \nthe confidence in the assigned proxy.  \n4. Dumps the disaggregated data into the database.\n\n--------\n\nInstallation steps \n------------\n\n0. Before you begin:\n\nPlease make sure you have mamba installed in your base environment\n    ```bash\n    conda install mamba -c conda-forge\n    ```\nAlso create the initial database. Steps to create the Database will follow soon. \n\n\n1. Clone this repository:\n    ```bash\n    git clone https://jugit.fz-juelich.de/iek-3/shared-code/localised/ETHOS.zoomin.git\n    ```\n\n2. Install dependencies and the repo in a clean conda environment:\n    ```bash\n    cd ETHOS.zoomin\n    mamba env create -n zoomin --file=requirements.yml\n    conda activate zoomin\n    pip install -e .\n    ```\n\n3. Run the workflow from command line:\n    ```bash\n    bash run_deployment.sh\n    ```\n\n<p><small>Project based on the <a target=\"_blank\" href=\"https://drivendata.github.io/cookiecutter-data-science/\">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>"
        },
        {
            "software_organization": "https://helmholtz.software/software/elias",
            "repo_link": "https://gitlab.kit.edu/julian.quinting/elias-2.0",
            "readme": "# EuLerian Identification of ascending AirStreams - ELIAS 2.0\nThis repository includes code and CNN models to derive conditional probabilities of WCB inflow, ascent, and outflow from data at a comparably low spatial and temporal resolution. The models which are contained in the repository directory ./models/ are referred to as _time-lag models_ in Quinting and Grams (2021). For any questions, error reports etc please contact the corresponding author of the study julian.quinting _at_ kit.edu\n\n> Quinting, J. F. and Grams, C. M.: EuLerian Identification of ascending AirStreams (ELIAS 2.0) in numerical weather prediction and climate models – Part 1: Development of deep learning model, Geosci. Model Dev., 15, 715–730, https://doi.org/10.5194/gmd-15-715-2022, 2022. \n\nApplication examples of the convolutional neural networks are provided in a companion study\n\n>  Quinting, J. F., Grams, C. M., Oertel, A., and Pickl, M.: EuLerian Identification of ascending AirStreams (ELIAS 2.0) in numerical weather prediction and climate models – Part 2: Model application to different datasets, Geosci. Model Dev., 15, 731–744, https://doi.org/10.5194/gmd-15-731-2022, 2022. \n\n**Important: If you are using ELIAS 2.0 in a publication please include a reference to** \n> Quinting, J. F. and Grams, C. M.: EuLerian Identification of ascending AirStreams (ELIAS 2.0) in numerical weather prediction and climate models – Part 1: Development of deep learning model, Geosci. Model Dev., 15, 715–730, https://doi.org/10.5194/gmd-15-715-2022, 2022.\n\n## Prerequisites\nInstall the conda environment using `conda env create -f conda_env.yml.` Alternatively, install the following packages in a new conda environment.\n```\nconda create -n tf tensorflow\nconda activate tf\nconda install -c conda-forge matplotlib\nconda install -c conda-forge netCDF4\nconda install -c conda-forge keras\nconda install -c anaconda xarray\nconda install -c numba numba\nconda install -c conda-forge windspharm\nconda install -c anaconda scipy\nconda install -c conda-forge tensorflow\n```\n\n## Data\nELIAS 2.0 is trained on ERA-Interim data at a global latitude-longitude grid of **1.0° grid spacing**. The input data need to be provided on the same grid. Input data are needed at the following **pressure levels**: 1000, 850, 700, 500, 300, 200 hPa. These variables are required: **temperature (T), specific humidity (qv), geopotential (phi), zonal wind (u), and meridional wind (v)**. Based on these variables the following predictors are derived on the fly:\n| P | WCB inflow | WCB ascent | WCB outflow |\n| ------ | ------ | ------ | ------|\n| 1 | 700-hPa thickness advection | 850-hPa relative vorticity | 300-hPa relative humidity |\n| 2 | 850-hPa meridional moisture flux | 700-hPa relative humidity | 300-hPa irrotational wind speed |\n| 3 | 1000-hPa moisture flux convergence | 300-hPa thickness advection | 500-hPa static stability |\n| 4 | 500-hPa moist potential vorticity | 500-hPa meridional moisture flux | 300-hPa relative vorticity |\n| 5 | conditional probability of ascent (+24 h)* | 30-d WCB ascent climatology** | conditional probability of ascent (-24 h)* |\n\n\\* Calculated on the fly. ** Provided in the ./data/ directory.\n\n## Usage of Jupyter Notebook\nAn example Notebook is provided to calculate probabilities and masks of WCB inflow, ascent, and outflow for 04 October 2016 from ERA-Interim data. The ERA-Interim data for this case study are provided in the ./data/ directory. The 30-d running mean WCB climatology is needed for WCB ascent and is provided in the same ./data/ directory. The decision thresholds which convert the conditional probabilities to dichotomous predictions are provided in netcdf Format in the ./thresholds/ directory. \n",
            "project_id": "155944"
        },
        {
            "software_organization": "https://helmholtz.software/software/beta-faircore4eosc",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/beta-faircore4eosc",
            "readme": "# beta-faircore4eosc\n\n![LARAVEL](https://img.shields.io/badge/LARAVEL-%23CC342D.svg?style=plastic&logo=laravel&logoColor=white) ![Livewire](https://img.shields.io/badge/Livewire-purple?style=plastic&logo=laravel&logoColor=white) ![PHP](https://img.shields.io/badge/PHP-777BB4?style=plastic&logo=php&logoColor=white)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12808833.svg)](https://doi.org/10.5281/zenodo.12808833)\n\n> [!Note]\n>  A demonstrable version can be accessed here: <a href=\"https://1959e979-c58a-4d3c-86bb-09ec2dfcec8a.ka.bw-cloud-instance.org/\" target=\"_blank\">**Demo Version**</a>\n\n#### Sample snapshot of the codemeta generator and converter demo:\n\n![snap.PNG](snap.PNG)\n\n#### Sample archiving repositories demo:\n\n![archive-samp.PNG](archive-samp.PNG)\n\n## Installation Steps:\n\n    1) Clone this project.\n    \n    2) Open a console session and navigate to the cloned directory, then:\n    \n        2.1) Run \"composer install\".\n        \n        2.2) Run \"npm install\".         \n        \n    3) (Optional) Create your local branch.\n    \n    4) (Optional) Acquire SWH tokens for increased SWH-API Rate-Limits.\n    \n    5) Prepare .env file:   \n    \n        5.1) Rename/Copy the cloned \".env.example\" file\n                cp .env.example .env   \n                \n        5.2) ADD these Keys:\n        \n                SWH_TOKEN=Your_TOKEN_FROM_SWH_ACCOUNT                   # As set in step 4)                \n                SWH_API_URL=https://archive.softwareheritage.org                \n                SWH_TOKEN_STAGING=Your_STAGING_TOKEN_FROM_SWH_ACCOUNT   # As set in step 4)                \n                SWH_API_URL_STAGING=https://webapp.staging.swh.network\n\n    You can now proceed to either I) or II)\n\n#### I) SWH API First Steps:\n\n    1) In a console session inside the cloned directory.    \n    \n        - Run 'php artisan tinker' to interact with the API modules.\n        \n    2) Initialise a new API session:\n    \n        - Write:\n                namespace App\\Modules\\SwhApi;                 \n                use App\\Modules\\SwhApi;\n                \n> - You can now proceed to the [SWH API Client documentation](https://github.com/Ramy-Badr-Ahmed/beta-faircore4eosc/blob/dev-cont/app/Modules/SwhApi/README.md)\n> - SWH Client as a standalone php library: https://github.com/Ramy-Badr-Ahmed/swh-client/wiki\n___\n\n#### II) Deployment Steps (Run your own local webserver instance):\n    \n    1) Setup a Database (e.g. MariaDB/MySQL/PostgreSQL) and create a new DB schema relevant for this project.\n    \n    2) Edit .env file\n    \n        2.1) (Optional) Generate an Application Key --> Navigate to the cloned directory and Run \"php artisan key:generate\"\n        \n        2.2) Edit Keys:\n                APP_NAME=beta-faircore4eosc\n                APP_ENV=local \n                APP_DEBUG=true\n                APP_URL=http://localhost\n\n                DB_CONNECTION=mysql             # As set in step 1)\n                DB_HOST=127.0.0.1               # As set in step 1)\n                DB_PORT=3306                    # As set in step 1)\n                DB_DATABASE=beta-faircore4eosc  # As set in step 1): Name of your database schema for this project\n                DB_USERNAME=root                # As set in step 1)\n                DB_PASSWORD=                    # As set in step 1)\n\n    3) Run \"php artisan migrate\".    \n    \n    4) (Optional) Checkout the first Commit: \"Initial Setup\".\n    \n    5) Navigate to the cloned directory and Run \"php artisan serve\" in your console.     \n    \n    6) Visit \"http://127.0.0.1:8000\" from your browser.\n\n#### III) Quick Test After II) Deployment:\n\n    1) Navigate to an Archive page, e.g.: /beta/archival-view-3\n    \n    2) Insert a group of repository URLs.\n    \n    3) Navigate to the previously cloned directory and then Run \"php artisan swh:updateCron\" in your console to synchronise with SWH.\n    \n       Note: you may need to set up a CRON/Scheduler in your OS.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/fairmq",
            "repo_link": "https://github.com/FairRootGroup/FairMQ",
            "readme": "<!-- {#mainpage} -->\n# FairMQ\n\n[![license](https://alfa-ci.gsi.de/shields/badge/license-LGPL--3.0-orange.svg)](COPYRIGHT)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1689985.svg)](https://doi.org/10.5281/zenodo.1689985)\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/6915/badge)](https://bestpractices.coreinfrastructure.org/projects/6915)\n[![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8B%20%20%E2%97%8F%20%20%E2%97%8F-yellow)](https://github.com/FairRootGroup/FairMQ/actions/workflows/fair-software.yml)\n[![Spack package](https://repology.org/badge/version-for-repo/spack/fairmq.svg)](https://repology.org/project/fairmq/versions)\n\nC++ Message Queuing Library and Framework\n\nDocs: [Book](https://github.com/FairRootGroup/FairMQ/blob/dev/README.md#documentation)\n\nFind all FairMQ releases [here](https://github.com/FairRootGroup/FairMQ/releases).\n\n## Introduction\n\nFairMQ is designed to help implementing large-scale data processing workflows needed in next-generation Particle Physics experiments. FairMQ is written in C++ and aims to\n  * provide **an asynchronous message passing abstraction** of different data transport technologies,\n  * provide a reasonably **efficient data transport** service (zero-copy, high throughput),\n  * be **data format agnostic**, and\n  * provide **basic building blocks** that can be used to implement higher level data processing workflows.\n\nThe core of FairMQ provides an abstract asynchronous message passing API with scalability protocols\ninspired by [ZeroMQ](https://github.com/zeromq/libzmq) (e.g. PUSH/PULL, PUB/SUB).\nFairMQ provides multiple implementations for its API (so-called \"transports\",\ne.g. `zeromq` and `shmem` (latest release of the `ofi` transport in v1.4.56, removed since v1.5+)) to cover\na variety of use cases\n(e.g. inter-thread, inter-process, inter-node communication) and machines (e.g. Ethernet, Infiniband).\nIn addition to this core functionality FairMQ provides a framework for creating \"devices\" - actors which\nare communicating through message passing. FairMQ does not only allow the user to use different transport\nbut also to mix them; i.e: A Device can communicate using different transport on different channels at the\nsame time. Device execution is modelled as a simple state machine that shapes the integration points for\nthe user task. Devices also incorporate a plugin system for runtime configuration and control.\nNext to the provided [devices](https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/devices) and\n[plugins](https://github.com/FairRootGroup/FairMQ/tree/master/fairmq/plugins) the user can extend FairMQ\nby developing his own plugins to integrate his devices with external configuration and control services.\n\nFairMQ has been developed in the context of its mother project [FairRoot](https://github.com/FairRootGroup/FairRoot) -\na simulation, reconstruction and analysis framework.\n\n## Installation from Source\n\nRecommended:\n\n```bash\ngit clone https://github.com/FairRootGroup/FairMQ fairmq_source\ncmake -S fairmq_source -B fairmq_build -GNinja -DCMAKE_BUILD_TYPE=Release\ncmake --build fairmq_build\nctest --test-dir fairmq_build --output-on-failure --schedule-random -j<ncpus>\ncmake --install fairmq_build --prefix $(pwd)/fairmq_install\n```\n\nPlease consult the [manpages of your CMake version](https://cmake.org/cmake/help/latest/manual/cmake.1.html) for more options.\n\nIf dependencies are not installed in standard system directories, you can hint the installation location via\n`-DCMAKE_PREFIX_PATH=...` or per dependency via `-D{DEPENDENCY}_ROOT=...` (`*_ROOT` variables can also be environment variables).\n\n\n## Usage\n\nFairMQ ships as a CMake package, so in your `CMakeLists.txt` you can discover it like this:\n\n```cmake\nfind_package(FairCMakeModules 1.0 REQUIRED)\ninclude(FairFindPackage2)\nfind_package2(FairMQ)\nfind_package2_implicit_dependencies()\n```\n\nThe [`FairFindPackage2` module](https://fairrootgroup.github.io/FairCMakeModules/latest/module/FairFindPackage2.html) is part of the [`FairCMakeModules` package](https://fairrootgroup.github.io/FairCMakeModules).\n\nIf FairMQ is not installed in system directories, you can hint the installation:\n\n```cmake\nlist(PREPEND CMAKE_PREFIX_PATH /path/to/fairmq_install)\n```\n\n## Dependencies\n\n  * [Boost](https://www.boost.org/)\n  * [CMake](https://cmake.org/)\n  * [Doxygen](http://www.doxygen.org/)\n  * [FairCMakeModules](https://github.com/FairRootGroup/FairCMakeModules) (optionally bundled)\n  * [FairLogger](https://github.com/FairRootGroup/FairLogger)\n  * [GTest](https://github.com/google/googletest) (optionally bundled)\n  * [ZeroMQ](http://zeromq.org/)\n\n  Which dependencies are required depends on which components are built.\n\n  Supported platform is Linux. macOS is supported on a best-effort basis.\n\n## CMake options\n\nOn command line:\n\n  * `-DDISABLE_COLOR=ON` disables coloured console output.\n  * `-DBUILD_TESTING=OFF` disables building of tests.\n  * `-DBUILD_EXAMPLES=OFF` disables building of examples.\n  * `-DBUILD_DOCS=ON` enables building of API docs.\n  * `-DFAIRMQ_CHANNEL_DEFAULT_AUTOBIND=OFF` disable channel `autoBind` by default\n  * You can hint non-system installations for dependent packages, see the #installation-from-source section above\n\nAfter the `find_package(FairMQ)` call the following CMake variables are defined:\n\n| Variable | Info |\n| --- | --- |\n| `${FairMQ_PACKAGE_DEPENDENCIES}` | the list of public package dependencies |\n| `${FairMQ_<dep>_VERSION}` | the minimum `<dep>` version FairMQ requires |\n| `${FairMQ_<dep>_COMPONENTS}` | the list of `<dep>` components FairMQ depends on |\n| `${FairMQ_PACKAGE_COMPONENTS}` | the list of components FairMQ consists of |\n| `${FairMQ_#COMPONENT#_FOUND}` | `TRUE` if this component was built |\n| `${FairMQ_VERSION}` | the version in format `MAJOR.MINOR.PATCH` |\n| `${FairMQ_GIT_VERSION}` | the version in the format returned by `git describe --tags --dirty --match \"v*\"` |\n| `${FairMQ_PREFIX}` | the actual installation prefix |\n| `${FairMQ_BINDIR}` | the installation bin directory |\n| `${FairMQ_INCDIR}` | the installation include directory |\n| `${FairMQ_LIBDIR}` | the installation lib directory |\n| `${FairMQ_DATADIR}` | the installation data directory (`../share/fairmq`) |\n| `${FairMQ_CMAKEMODDIR}` | the installation directory of shipped CMake find modules |\n| `${FairMQ_BUILD_TYPE}` | the value of `CMAKE_BUILD_TYPE` at build-time |\n| `${FairMQ_CXX_FLAGS}` | the values of `CMAKE_CXX_FLAGS` and `CMAKE_CXX_FLAGS_${CMAKE_BUILD_TYPE}` at build-time |\n\n## Documentation\n\n1. [Device](docs/Device.md#1-device)\n   1. [Topology](docs/Device.md#11-topology)\n   2. [Communication Patterns](docs/Device.md#12-communication-patterns)\n   3. [State Machine](docs/Device.md#13-state-machine)\n   4. [Multiple devices in the same process](docs/Device.md#15-multiple-devices-in-the-same-process)\n2. [Transport Interface](docs/Transport.md#2-transport-interface)\n   1. [Message](docs/Transport.md#21-message)\n      1. [Ownership](docs/Transport.md#211-ownership)\n   2. [Channel](docs/Transport.md#22-channel)\n   3. [Poller](docs/Transport.md#23-poller)\n3. [Configuration](docs/Configuration.md#3-configuration)\n    1. [Device Configuration](docs/Configuration.md#31-device-configuration)\n    2. [Communication Channels Configuration](docs/Configuration.md#32-communication-channels-configuration)\n        1. [JSON Parser](docs/Configuration.md#321-json-parser)\n        2. [SuboptParser](docs/Configuration.md#322-suboptparser)\n    3. [Introspection](docs/Configuration.md#33-introspection)\n4. [Development](docs/Development.md#4-development)\n   1. [Testing](docs/Development.md#41-testing)\n   2. [Static Analysis](docs/Development.md#42-static-analysis)\n      1. [CMake Integration](docs/Development.md#421-cmake-integration)\n      2. [Extra Compiler Arguments](docs/Development.md#422-extra-compiler-arguments)\n5. [Logging](docs/Logging.md#5-logging)\n   1. [Log severity](docs/Logging.md#51-log-severity)\n   2. [Log verbosity](docs/Logging.md#52-log-verbosity)\n   3. [Color for console output](docs/Logging.md#53-color)\n   4. [File output](docs/Logging.md#54-file-output)\n   5. [Custom sinks](docs/Logging.md#55-custom-sinks)\n6. [Examples](docs/Examples.md#6-examples)\n7. [Plugins](docs/Plugins.md#7-plugins)\n   1. [Usage](docs/Plugins.md#71-usage)\n   2. [Development](docs/Plugins.md#72-development)\n   3. [Provided Plugins](docs/Plugins.md#73-provided-plugins)\n       1. [PMIx](docs/Plugins.md#731-pmix)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/fame",
            "repo_link": "https://gitlab.com/fame-framework/fame-io",
            "readme": "<!-- SPDX-FileCopyrightText: 2024 German Aerospace Center <fame@dlr.de>\n\nSPDX-License-Identifier: Apache-2.0 -->\n[![PyPI version](https://badge.fury.io/py/fameio.svg)](https://badge.fury.io/py/fameio)\n[![JOSS](https://joss.theoj.org/papers/10.21105/joss.04958/status.svg)](https://doi.org/10.21105/joss.04958)\n[![Zenodo](https://zenodo.org/badge/DOI/10.5281/zenodo.4314337.svg)](https://doi.org/10.5281/zenodo.4314337)\n[![PyPI license](https://img.shields.io/pypi/l/fameio.svg)](https://badge.fury.io/py/fameio)\n[![pipeline status](https://gitlab.com/fame-framework/fame-io/badges/main/pipeline.svg)](https://gitlab.com/fame-framework/fame-io/commits/main)\n[![coverage report](https://gitlab.com/fame-framework/fame-io/badges/main/coverage.svg)](https://gitlab.com/fame-framework/fame-io/-/commits/main)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![REUSE status](https://api.reuse.software/badge/gitlab.com/fame-framework/fame-io)](https://api.reuse.software/info/gitlab.com/fame-framework/fame-io)\n[![Common Changelog](https://common-changelog.org/badge.svg)](https://common-changelog.org)\n![GitLab last commit](https://img.shields.io/gitlab/last-commit/fame-framework%2Ffame-io)\n![GitLab closed issues by-label](https://img.shields.io/gitlab/issues/closed/fame-framework%2Ffame-io)\n\n# FAME-Io\n\n*Tools for input preparation and output digestion of FAME models*\n\nFAME-Io compiles input for FAME models in protobuf format and extracts model outputs to human-readable files.\nPlease visit the [FAME-Wiki](https://gitlab.com/fame-framework/wiki/-/wikis/home) to get an explanation of FAME and its components.\n\n# Installation\n\nWe recommend installing `fameio` using PyPI:\n\n    pip install fameio\n\nYou may also use `pipx`. For detailed information please refer to the\nofficial `pipx` [documentation](https://github.com/pypa/pipx).\n\n    pipx install fameio\n\n`fameio` is currently developed and tested for Python 3.8 or higher.\nSee the `pyproject.toml` for a complete listing of dependencies.\n\n# Usage\n\nFAME-Io currently offers two main scripts `makeFameRunConfig` and `convertFameResults`.\nBoth are automatically installed with the package.\nThe first one creates a protobuf file for FAME applications using YAML definition files and CSV files.\nThe latter one reads output files from FAME applications in protobuf format and converts them to CSV files.\n\nYou may use the [example data](https://gitlab.com/dlr-ve/esy/amiris/examples) provided for\nthe [AMIRIS](https://gitlab.com/dlr-ve/esy/amiris/amiris) model which can be used to simulate electricity markets\nin [Germany](https://gitlab.com/dlr-ve/esy/amiris/examples/-/tree/main/Germany2019), [Austria](https://gitlab.com/dlr-ve/esy/amiris/examples/-/tree/main/Austria2019),\nand a simple [proof-of-concept model](https://gitlab.com/dlr-ve/esy/amiris/examples/-/tree/main/Simple).\n\n## Make a FAME run configuration\n\nDigests configuration files in YAML format, combines them with CSV data files and creates a single input file for FAME\napplications in protobuf format.\nCall structure:\n\n    makeFameRunConfig -f <path/to/scenario.yaml>\n\nYou may also specify any of the following arguments:\n\n| Command                | Action                                                                                                                                   |\n|------------------------|------------------------------------------------------------------------------------------------------------------------------------------|\n| `-l` or `--log`        | Sets the logging level. Default is `info`. Options are `debug`, `info`, `warning`, `warn`, `error`, `critical`.                          |\n| `-lf` or `--logfile`   | Sets the logging file. Default is `None`. If `None` is provided, all logs get only printed to the console.                               |\n| `-o` or `--output`     | Sets the path of the compiled protobuf output file. Default is `config.pb`.                                                              |\n| `-enc` or `--encoding` | Sets the encoding of all yaml files to the given one (e.g. 'utf8' or 'cp1252'. Default is `None`, i.e. your operating system's standard. |\n\nThis could look as follows:\n\n    makeFameRunConfig -f <path/to/scenario.yaml> -l debug -lf <path/to/scenario.log> -o <path/to/config.pb>\n\nYou may also call the configuration builder from any Python script with\n\n```python\nfrom fameio.scripts.make_config import Options, run as make_config\n\nmake_config({Options.FILE: \"path/to/scenario.yaml\", })\n```\n\nSimilar to the console call you may also specify custom run config arguments and add it in a dictionary to the function\ncall.\n\n```python\nfrom fameio.scripts.make_config import Options, run as make_config\n\nrun_config = {Options.FILE: \"path/to/scenario.yaml\",\n              Options.LOG_LEVEL: \"info\",\n              Options.OUTPUT: \"output.pb\",\n              Options.LOG_FILE: \"scenario.log\",\n              }\n\nmake_config(run_config)\n```\n\nYou can also use the associated argument parser, to extract the run_config dynamically from a string:\n\n```python\nfrom fameio.scripts.make_config import Options, run as make_config\nfrom fameio.cli.make_config import handle_args\n\nmy_defaults = {Options.FILE: \"path/to/scenario.yaml\",\n               Options.LOG_LEVEL: \"info\",\n               Options.OUTPUT: \"output.pb\",\n               Options.LOG_FILE: \"scenario.log\",\n               }\nmy_arg_string = ['-f', 'my/other/scenario.yaml', '-l', 'error']\n\nrun_config = handle_args(my_arg_string, my_defaults)\nmake_config(run_config)\n```\n\n### Scenario YAML\n\nThe \"scenario.yaml\" file contains all configuration options for a FAME-based simulation.\nIt consists of the sections `Schema`, `GeneralProperties`, `Agents` and `Contracts`, and the optional\nsection `StringSets`.\nAll of them are described below.\n\n#### Schema\n\nThe Schema describes a model's components such as its types of agents, their inputs, what data they exchange, etc.\nIt is also used to validate the model inputs provided in the `scenario.yaml`.\nSince the Schema is valid until the model itself is changed, it is recommended to defined it in a separate file and\ninclude the file here.\n\nCurrently, the schema specifies:\n\n* which type of Agents can be created\n* what type of input attributes an Agent uses\n* what type of Products an Agent can send in Contracts, and\n* the names of the Java packages for the classes corresponding to Agents, DataItems and Portables.\n\nThe Schema consists of the sections `JavaPackages` and `AgentTypes`.\n\n##### JavaPackages\n\nThis section defines the name of the Java packages in which the model code is located.\nA similar data set was formerly specified in the `fameSetup.yaml`, but is now specified in the schema.\nEach of the three sections `Agents`, `DataItems`, and `Portables` contain a list of fully qualified java package names\nof your model's classes.\nPackage names can occur in multiple lists and may overlap.\nIt is not necessary (but possible) to specify the nearest enclosing package for each Agent, DataItem or Portable.\nSpecifying any super-package will also work.\nAlso, package names occur on multiple lists for Agent, DataItem or Portable.\n\nFor example, for a project with all its\n\n* Agent-derived java classes located in packages below the package named \"agents\",\n* DataItem implementation classes in a subpackage named \"msg\",\n* Portable implementation classes in a subpackages named \"portableItems\" and \"otherPortables\",\n\nthe corresponding section in the schema would look like this:\n\n```yaml\nJavaPackages:\n  Agents:\n    - \"agents\"\n  DataItems:\n    - \"msg\"\n  Portables:\n    - \"portableItems\"\n    - \"otherPortables\"\n```\n\nOne can leave out the `DataItems` specifications, but `Agents` and `Portables` are required and must not be empty.\n\n##### AgentTypes\n\nHere, each type of agent that can be created in your FAME-based application is listed, its attributes and its available\nProducts for Contracts.\nThe structure of this section\n\n```yaml\nAgentTypes:\n  MyAgentType:\n    Attributes:\n      MyAttribute:\n        ...\n      MyOtherAttribute:\n        ...\n    Products: [ 'Product1', 'Product2', 'Product3' ]\n    Outputs: [ 'Column1', 'Column2', 'Column3' ]\n    Metadata:\n      Some: \"Dict with Metadata that you would like to add\"\n  MyOtherAgentWithoutProductsOrAttributes:\n```\n\n* `MyAgentType` Java's simple class name of the Agent type\n* `Attributes` indicates that beginning of the attribute definition section for this Agent type\n* `MyAttribute` Name of an attribute as specified in the corresponding Java source code of this Agent type (annotated\n  with \"@Input\")\n* `MyOtherAttribute` Name of another attribute derived from Java source code\n* `Products` list or dictionary of Products that this Agent can send in Contracts; derived from Java source code of this\n  Agent type (annotated with \"@Product\")\n* `Outputs` list or dictionary of Output columns that this Agent can write to; derived from Java source code of this\n  Agent type (annotated with \"@Output\")\n* `Metadata` dictionary with any content that is assigned to this Agent type as additional information\n* `MyOtherAgentWithoutProductsOrAttributes` an Agent type that requires neither Attributes nor Products\n\nAttributes, Products, Outputs and Metadata are optional - there may be useful Agents that require none of them.\nProducts and Outputs can both be lists of Strings, or dictionaries with additional Metadata.\nFor example, you could write the above in the following way:\n\n```yaml\nProducts:\n  Product1:\n    Metadata:\n      Any: \"information you would like to add to Product1 using a dictionary form\"\n  Product2:\n  Product3:\nOutputs:\n  Column1:\n  Column2:\n    ThisEntry: \"is ignored, as it is not below the keyword: 'Metadata'\"\n    Metadata:\n      My: \"Metadata\"\n      That: \"will be saved to Column2\"\n  Column3:\n```\n\nHere, \"Product1\" and \"Column2\" have additional, optional Metadata assigned to them (using the keyword \"Metadata\").\nThe other Products and Columns have no metadata assigned to them - which is also ok.\n\nIn the AgentType definition example above attribute definition was not shown explicitly (indicated by `...`).\nThe next example provides details on how to define an attribute:\n\n```yaml\nMySimpleAttribute:\n  AttributeType: enum\n  Mandatory: true\n  List: false\n  Values: [ 'AllowedValue1', 'AllowedValue2' ]\n  Default: 'AllowedValue1'\n  Help: 'My help text'\n  Metadata:\n    Go: \"here\"\n\nMyComplexAttribute:\n  AttributeType: block\n  NestedAttributes:\n    InnerAttributeA:\n      AttributeType: integer\n      Values:\n        1:\n          Metadata:\n            Explain: \"1 is a allowed value\"\n        2:\n          Metadata:\n            Comment: \"2 is also allowed, but consider using 1\"\n    InnerAttributeB:\n      AttributeType: double\n```\n\n* `MySimpleAttribute`, `MyDoubleList`, `MyComplexAttribute` Names of the attributes as specified in the Java enum\n  annotated with \"@Input\"\n* `AttributeType` (required) data type of the attribute; see options in table below\n* `Mandatory` (optional - true by default) if true: the attribute is required for this agent and validation will fail if\n  the attribute is missing in the scenario **and** no default is provided\n* `List` (optional - false by default)\n    * `AttributeType: time_series` cannot be true\n    * `AttributeType: block`\n        * if true: any nested element in the scenario must be part of a list element and thus can appear multiple times\n        * if false: any nested element in the scenario can only appear once\n    * any other AttributeType: the attribute is interpreted as list, i.e. multiple values can be assigned to this\n      attribute in the scenario\n* `NestedAttributes` (required only if `AttributeType: block`, otherwise disallowed) starts an inner Attribute\n  definition block - defined Attributes are sub-elements of `MyComplexAttribute`\n* `Values` (optional - None by default):\n  * if present, defines a list or dictionary of allowed values for this attribute\n  * if a dictionary is used, individual Metadata can be assigned to each allowed value using the `Metadata` keyword\n* `Default` (optional - None by default):\n  * if present, defines a default value to be used if the scenario does not specify one\n  * must match one of the entries in `Values` in case those are defined\n  * can be a list if the attribute is a list\n* `Help` (optional - None by default): if present, defines a help text for your Attribute\n* `Metadata` (optional - None by default): if present, defines additional metadata assigned to the Attribute\n\n| AttributeType | value                                                                                                                   |\n|---------------|-------------------------------------------------------------------------------------------------------------------------|\n| `integer`     | a 32-bit integer value                                                                                                  |\n| `double`      | a 64-bit floating-point value (integers also allowed)                                                                   |\n| `long`        | a 64-bit integer value                                                                                                  |\n| `time_stamp`  | either a FAME time stamp string or 64-bit integer value                                                                 |\n| `string`      | any string                                                                                                              |\n| `string_set`  | a string from a set of allowed `Values` defined in `StringSet` section in `scenario`                                    |\n| `enum`        | a string from a set of allowed `Values` defined in `schema`                                                             |\n| `time_series` | either a path to a .csv-file or a single 64-bit floating-point value; does not support `List: true`                     |\n| `block`       | this attribute has no value of its own but hosts a group of nested Attributes; implies `NestedAttributes` to be defined |\n\n#### GeneralProperties\nSpecifies FAME-specific properties of the simulation. Structure:\n\n```yaml\nGeneralProperties:\n  RunId: 1\n  Simulation:\n    StartTime: 2011-12-31_23:58:00\n    StopTime: 2012-12-30_23:58:00\n    RandomSeed: 1\n```\n\nParameters:\n\n* `RunId` an ID that can be given to the simulation; use at your discretion\n* `StartTime` time stamp in the format YYYY-MM-DD_hh:mm:ss; first moment of the simulation.\n* `StopTime` time stamp in the format YYYY-MM-DD_hh:mm:ss; last moment of the simulation - i.e. simulation terminates\n  after passing that time stamp\n* `RandomSeed` seed to initialise random number generation; each value leads to a unique series of random numbers.\n\n#### Agents\n\nSpecifies all Agents to be created in the simulation in a list. Each Agent has its own entry.\nStructure:\n\n```yaml\nAgents:\n  - Type: MyAgentWithInputs\n    Id: 1\n    Attributes:\n      MyEnum: SAME_SHARES\n      MyInteger: 2\n      MyDouble: 4.2\n      MyTimeSeries: \"./path/to/time_series.csv\"\n    Metadata:\n      Can: \"also be assigned\"\n\n  - Type: MyAgentWithoutInputs\n    Id: 2\n```\n\nAgent Parameters:\n\n* `Type` Mandatory; Java's simple class name of the agent to be created\n* `Id` Mandatory; simulation-unique id of this agent; if two agents have the same ID, the configuration process will\n  stop.\n* `Attributes` Optional; if the agent has any attributes, specify them here in the format \"AttributeName: value\"; please\n  see attribute table above\n* `Metadata` Optional; can be assigned to each instance of an Agent, as well as to each of its Attributes\n\nThe specified `Attributes` for each agent must match the specified `Attributes` options in the linked Schema (see above).\nFor better structure and readability of the `scenario.yaml`, `Attributes` may also be specified in a nested way as demonstrated below.\n\n```yaml\nAgents:\n  - Type: MyAgentWithInputs\n    Id: 1\n    Attributes:\n      Parent:\n        MyEnum: SAME_SHARES\n        MyInteger: 2\n      Parent2:\n        MyDouble: 4.2\n        Child:\n          MyTimeSeries: \"./path/to/time_series.csv\"\n```\n\nIn case Attributes are defined with `List: true` option, lists are assigned to an Attribute or Group:\n\n```yaml\nAttributes:\n  MyDoubleList: [ 5.2, 4.5, 7, 9.9 ]\n  MyListGroup:\n    - IntValueA: 5\n      IntValueB: 42\n    - IntValueA: 7\n      IntValueB: 100\n```\n\nHere, `MyDoubleList` and `MyListGroup` need to specify `List: true` in the corresponding Schema.\nThe shorter `[]`-notation was used to assign a list of floating-point values to `MyDoubleList`.\nNested items `IntValueA` and `IntValueB` of `MyListGroup` are assigned within a list, allowing the specification of\nthese nested items several times.\n\n##### Attribute Metadata\nMetadata can be assigned to any value, list item, or superstructure.\nTo assign Metadata to a primitive value, create a dictionary from it, set the actual value with the inner keyword `Value` and add the keyword `Metadata` like this:\n\n```yaml\nValueWithoutMetadata: 1\nSameValueWithMetadata:\n  Value: 1\n  Metadata: # describe `SameValueWithMetadata` herein\n```\n\nYou can assign Metadata to a list of primitive values using the keyword `Values` like this:\n\n```yaml\nValueListWithoutMetadata: [1,2,3]\nSameValueListWithListMetadata:\n  Values: [1,2,3]\n  Metadata: # describe the whole list of values with Metadata here\n```\n\nor specify Metadata for each (or just some) value individually, like this:\n\n```yaml\nValueListWithoutMetadata: [1,2,3]\nSameValueListWithMetadataAtEachElement:\n  - Value: 1\n    Metadata: # describe this specific value \"1\" with Metadata here\n  - Value: 2  # this value has no Metadata attached, but you can still use the keyword `Value`\n  - 3 # or use in the actual directly since this value has no Metadata anyway\n```\n\nor assign Metadata to both the list and any of its list entries, like this:\n\n```yaml\nValueListWithoutMetadata: [1,2,3]\nSameValueListWithAllMetadata:\n  Metadata: # Recommendation: place the Metadata of the list first if the list of values is extensive, as in this case\n  Values:\n    - Value: 1\n      Metadata: # describe this specific value \"1\" with Metadata here\n    - Value: 2\n      Metadata: # describe this specific value \"2\" with Metadata here\n    - Value: 3\n      Metadata: # describe this specific value \"3\" with Metadata here\n```\n\nYou can assign Metadata directly to a nested element by adding the Metadata keyword:\n\n```yaml\nNestedItemWithoutMetadata:\n  A: 1\n  B: 2\nSameNestedItemWithMetadata:\n  A: 1\n  B: 2\n  Metadata: # These Metadata describe `SameNestedItemWithMetadata`\n```\n\nSimilar to lists of values, you can assign Metadata to a list of nested elements using the `Values` keyword, like this:\n\n```yaml\nListOfNestedItemsWithoutMetadata:\n  - A: 1\n    B: 10\n  - A: 2\n    B: 20\nSameListOfNestedItemsWithGeneralMetadata:\n  Values:\n    - A: 1\n      B: 10\n    - A: 2\n      B: 20\n  Metadata: # These Metadata describe `SameListOfNestedItemsWithGeneralMetadata` as a whole\n```\n\nand, similar to nested elements, you can assign Metadata directly to any list element, like this:\n\n```yaml\nListOfNestedItemsWithoutMetadata:\n  - A: 1\n    B: 10\n  - A: 2\n    B: 20\nSameListOfNestedItemsWithGeneralMetadata:\n  - A: 1\n    B: 10\n    Metadata: # These Metadata describe the first list item\n  - A: 2\n    B: 20\n    Metadata: # These Metadata describe the second list item\n```\n\nAgain, you may apply both variants and apply Metadata to the list and each of its items if you wish.\n\n#### Contracts\nSpecifies all Contracts, i.e. repetitive bilateral transactions in between agents.\nContracts are given as a list.\nWe recommend moving Contracts to separate files and to use the `!include` command to integrate them in the scenario.\n\n```yaml\nContracts:\n  - SenderId: 1\n    ReceiverId: 2\n    ProductName: ProductOfAgent_1\n    FirstDeliveryTime: -25\n    DeliveryIntervalInSteps: 3600\n    Metadata:\n      Some: \"additional information can go here\"\n\n  - SenderId: 2\n    ReceiverId: 1\n    ProductName: ProductOfAgent_2\n    FirstDeliveryTime: -22\n    DeliveryIntervalInSteps: 3600\n    Attributes:\n      ProductAppendix: value\n      TimeOffset: 42\n```\n\nContract Parameters:\n\n* `SenderId` unique ID of agent sending the product\n* `ReceiverId` unique ID of agent receiving the product\n* `ProductName` name of the product to be sent\n* `FirstDeliveryTime` first time of delivery in the format \"seconds after the January 1st 2000, 00:00:00\"\n* `DeliveryIntervalInSteps` delay time in between deliveries in seconds\n* `Metadata` can be assigned to add further helpful information about a Contract\n* `Attributes` can be set to include additional information as `int`, `float`, `enum`, or `dict` data types\n\n##### Definition of Multiple Similar Contracts\nOften, scenarios contain multiple agents of similar type that also have similar chains of contracts.\nTherefore, FAME-Io supports a compact definition of multiple similar contracts.\n`SenderId` and `ReceiverId` can both be lists and support One-to-N, N-to-One and N-to-N relations like in the following\nexample:\n\n```yaml\nContracts:\n  # effectively 3 similar contracts (0 -> 11), (0 -> 12), (0 -> 13)\n  # with otherwise identical ProductName, FirstDeliveryTime & DeliveryIntervalInSteps\n  - SenderId: 0\n    ReceiverId: [ 11, 12, 13 ]\n    ProductName: MyOtherProduct\n    FirstDeliveryTime: 100\n    DeliveryIntervalInSteps: 3600\n\n  # effectively 3 similar contracts (1 -> 10), (2 -> 10), (3 -> 10)\n  # with otherwise identical ProductName, FirstDeliveryTime & DeliveryIntervalInSteps\n  - SenderId: [ 1, 2, 3 ]\n    ReceiverId: 10\n    ProductName: MyProduct\n    FirstDeliveryTime: 100\n    DeliveryIntervalInSteps: 3600\n\n  # effectively 3 similar contracts (1 -> 11), (2 -> 12), (3 -> 13)\n  # with otherwise identical ProductName, FirstDeliveryTime & DeliveryIntervalInSteps\n  - SenderId: [ 1, 2, 3 ]\n    ReceiverId: [ 11, 12, 13 ]\n    ProductName: MyThirdProduct\n    FirstDeliveryTime: 100\n    DeliveryIntervalInSteps: 3600\n```\n\nCombined with YAML anchors complex contract chains can be easily reduced to a minimum of required configuration.\nThe following example is equivalent to the previous one and allows a quick extension of contracts to a new couple of\nagents e.g. (4;14):\n\n```yaml\nGroups:\n  - &agentList1: [ 1,2,3 ]\n  - &agentList2: [ 11,12,13 ]\n\nContracts:\n  - SenderId: 0\n    ReceiverId: *agentList2\n    ProductName: MyOtherProduct\n    FirstDeliveryTime: 100\n    DeliveryIntervalInSteps: 3600\n\n  - SenderId: *agentList1\n    ReceiverId: 10\n    ProductName: MyProduct\n    FirstDeliveryTime: 100\n    DeliveryIntervalInSteps: 3600\n\n  - SenderId: *agentList1\n    ReceiverId: *agentList2\n    ProductName: MyThirdProduct\n    FirstDeliveryTime: 100\n    DeliveryIntervalInSteps: 3600\n```\n\n#### StringSets\n\nThis optional section defines values of type `string_set`.\nIn contrast to `enum` values, which are **statically** defined in the `Schema`, `string_set` values can be **dynamically\n** defined in this section.\nIf an agent attribute is of type `string_set` and the attribute is set in the `scenario`, then\n\n1. the section `StringSets` in the `scenario` must contain an entry named exactly like the attribute, and\n2. the attribute value must be contained in the string set's `Values` declaration.\n\nFor instance:\n\nIn `schema`:\n\n``` yaml\nAgentTypes:\n  FuelsMarket:\n    Attributes:\n      FuelType:\n        AttributeType: string_set\n```\n\nIn `scenario`:\n\n``` yaml\nStringSets:\n  FuelType:\n    Values: ['OIL', 'HARD_COAL', 'LIGNITE']\n\nAgents:\n - Type: FuelsMarket\n   Id: 1\n   Attributes:\n     FuelType: OIL\n```\n\nImportant: If different types of Agents shall refer to the same StringSet, their attributes in schema must have the\n**exact** same name.\n\n### CSV files\n\nTIME_SERIES inputs are not directly fed into the Scenario YAML file.\nInstead, TIME_SERIES reference a CSV file that can be stored some place else.\nThese CSV files follow a specific structure:\n\n* They should contain exactly two columns - any other columns are ignored.\n  A warning is raised if more than two non-empty columns are detected.\n* The first column must be a time stamp in form `YYYY-MM-DD_hh:mm:ss`\n* The second column must be a numerical value (either integer or floating-point)\n* The separator of the two columns is a semicolon\n* The data must **not** have headers, except for comments marked with `#`\n\nYou may add comments using `#`.\nExemplary content of a valid CSV file:\n\n    # If you want an optional header, you must use a comment\n    2012-01-01_00:00:00;400\n    2013-01-01_00:00:00;720.5\n    2014-01-01_00:00:00;650\n    2015-01-01_00:00:00;99.27772\n    2016-01-01_00:00:00;42  # optional comment on this particular data point\n    2017-01-01_00:00:00;0.1\n\nPlease refer also to the detailed article about `TimeStamps` in\nthe [FAME-Wiki](https://gitlab.com/fame-framework/wiki/-/wikis/TimeStamp).\n\n### Split and join multiple YAML files\n\nThe user may include other YAML files into a YAML file to divide the content across files as convenient.\nWe explicitly recommend using this feature for the `Schema` and `Contracts` sections.\nOtherwise, the scenario.yaml may become crowded.\n\n#### Command: !Include\n\nTo hint YAML to load the content of another file use `!include \"path/relative/to/including/yaml/file.yml\"`.\nYou can concatenate !include commands and can use !include in the included file as well.\nThe path to the included file is always relative to the file using the !include command.\nSo with the following file structure\n\n###### file-structure\n\n```\na.yaml\nfolder/b.yaml\nfolder/c.yaml\nfolder/deeper_folder/d.yaml\n```\n\nthe following !include commands work\n\n###### in a.yaml\n\n```\nToBe: !include \"folder/b.yaml\"\nOrNot: !include \"folder/deeper_folder/d.yaml\"\n```\n\n###### in b.yaml\n\n```\nThatIs: !include \"c.yaml\"\nTheQuestion: !include \"deeper_folder/d.yaml\"\n```\n\nProvided that\n\n###### in c.yaml\n\n```\nOr: maybe\n```\n\n###### d.yaml\n\n```\nnot: \"?\"\n```\n\nthe resulting file would look like this:\n\n###### THe Joined file a.yaml\n\n```\nToBe:\n  ThatIs:\n    Or: maybe\n  TheQuestion:\n    not: \"?\"\nOrNot:\n  not: \"?\"\n```\n\nYou may also specify absolute file paths if preferred by starting with a \"/\".\n\nWhen specifying only a file path, the complete content of the file is assigned to the given key.\nYou always need a key to assign the !include command to.\nHowever, you cannot combine the value returned from !include with other values in the same key.\nThus, the following combinations do not work:\n\n###### caveats.yml\n\n```\n!include \"file.yaml\" # no key assigned\n\nKey:\n  Some: OtherItem\n  !include \"file.yaml\" # cannot join with other named items\n\nList:\n  - an: entry\n  !include \"file.yaml\" # cannot directly join with list items, even if !include returns a list\n```\n\n#### Integrate specific nodes of YAML files\n\nInstead of including *all* content in the included file, you may also pick a specific node within that file.\nFor this use `!include [<relative/path/to/file.yaml>, Path:To:Field:In:Yaml]`.\nHere, `:` is used in the node-specifying string to select a sequence of nodes to follow - with custom depth.\nConsider the following two files:\n\n###### file_to_be_included.yaml\n\n```yaml\nSet1:\n  Subset1:\n    Key: Value\nSet2:\n  OtherKey: OtherValue\n```\n\n###### including_file.yaml\n\n```yaml\n- Type: MyAgentWithInputs\n  Id: 1\n  Attributes: !include_node [ file_to_be_included.yaml, Set1:Subset1 ]\n```\n\nCompiling \"including_file.yaml\" results in\n\n###### resulting_file.yaml\n\n```yaml\n- Type: MyAgentWithInputs\n  Id: 1\n  Attributes:\n    Key: Value\n```\n\n#### Load multiple files\n\nUsing wildcards in the given path (e.g. \"path/to/many/*.yaml\") will lead to loading multiple files and assigning their\ncontent to the same key.\nYou can make use of this feature with or without specifying a node selector.\nHowever, the elements to be joined across multiple files must be lists.\nThese lists are then concatenated into a single list and then assigned to the key in the file calling !include.\nThis feature is especially useful for Contracts: You can split the Contracts list into several files and place them in a\nseparate folder.\nThen use !include to re-integrate them into your configuration. An example:\n\n###### my_contract1.yaml\n\n```\nContracts:\n - ContractA\n - ContractB\n```\n\n###### my_contract2.yaml\n\n```\nContracts:\n - ContractC\n - ContractD\n - ContractE\n```\n\n###### including_file.yaml\n\n```\nContracts: [!include \"my_contract*.yaml\", \"Contracts\"]\n```\n\nresults in\n\n###### result.yaml\n\n```\nContracts:\n - ContractA\n - ContractB\n - ContractC\n - ContractD\n - ContractE\n```\n\n#### Ignoring files\n\nFiles that have their name start with \"IGNORE_\" are not included with the !include command.\nYou will see a debug output to notify you that the file was ignored.\nUse this to temporarily take files out ouf your configuration without deleting or moving them.\n\n## Read FAME results\n\nTakes an output file in protobuf format of FAME-based applications and converts it into files in CSV format.\nAn individual file for each type of Agent is created in a folder named after the protobuf input file.\nCall structure:\n\n    convertFameResults -f <./path/to/protobuf_file.pb>\n\nYou may also specify any of the following arguments:\n\n| Command                                       | Action                                                                                                                                                                                                |\n|-----------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `-l` or `--log` <option>                      | Sets the logging level. Default is `WARNING`. Options are `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`.                                                                                            |\n| `-lf` or `--logfile` <file>                   | Sets the logging file. Default is `None`. If `None` is provided, all logs get only printed to the console.                                                                                            |\n| `-a` or `--agents` <list-of-agents>           | If specified, only a subset of agents is extracted from the protobuf file. Default is to extract all agents.                                                                                          |\n| `-o` or `--output`                            | Sets the path to where the generated output files are written to. If not specified, the folder's name is derived from the input file's name. Folder will be created if it does not exist.             |\n| `-se` or `--single-export`                    | Enables export of individual agents to individual files, when present. If not present (the default) one file per `AgentType` is created.                                                              |\n| `-m` or `--memory-saving`                     | When specified, reduces memory usage profile at the cost of runtime. Use only when necessary.                                                                                                         |\n| `-cc` or `--complex-column` <option>          | Defines how to deal with complex indexed output columns (if any). `IGNORE` ignores complex columns. `SPLIT` creates a separate file for each complex indexed output column.                           |\n| `-t` or `--time` <option>                     | Option to define conversion of time steps to given format (default=`UTC`) by `-t/--time {UTC, INT, FAME}`                                                                                             |\n| `--input-recovery` or `--no-input-recovery`   | If True, all input data are recovered in addition to the outputs (default=False).                                                                                                                     |\n| `-mt` or `--merge-times` <list-of-parameters> | Option to merge `TimeSteps` of a certain range of steps in the output files to associate multiple time steps with a common logical time in your simulation and reduce number of lines in output files |\n\nThe option `--merge-times` requires exactly three integer arguments separated by spaces:\n\n| Position | Name         | Meaning                                                                                  |\n|----------|--------------|------------------------------------------------------------------------------------------|\n| First    | Focal point  | TimeStep on which `steps-before` earlier and `steps-after` later TimeSteps are merged on |\n| Second   | Steps before | Range of TimeSteps before the `focal-point` they get merged to, must be Zero or positive |\n| Third    | Steps after  | Range of TimeSteps after the `focal-point` they get merged to, must be Zero or positive  |\n\n\nThis could look as follows:\n\n    convertFameResults -f <./path/to/protobuf_file.pb> -l debug -lf <path/to/output.log> -a AgentType1 AgentType2 -o myCsvFolder -m -cc SPLIT --merge-times 0 1799 1800\n\nMake sure that in the range of time steps you specify for merging, there is only one value per column in the merged time range.\nIf multiple values per column are merged values will get concatenated and might yield unexpected results.\n\nYou may also call the conversion script from any Python script with:\n\n```python\nfrom fameio.scripts.convert_results import Options, run as convert_results\n\nconvert_results({Options.FILE: \"./path/to/protobuf_file.pb\"})\n```\n\nSimilar to the console call you may also specify custom run config arguments and add it in a dictionary to the function\ncall.\n\n```python\nfrom fameio.scripts.convert_results import Options, run as convert_results\n\nrun_config = {Options.FILE: \"./path/to/protobuf_file.pb\",\n              Options.LOG_LEVEL: \"info\",\n              Options.LOG_FILE: \"scenario.log\",\n              Options.OUTPUT: \"Output\",\n              Options.AGENT_LIST: ['AgentType1', 'AgentType2'],\n              Options.MEMORY_SAVING: False,\n              Options.SINGLE_AGENT_EXPORT: False,\n              Options.RESOLVE_COMPLEX_FIELD: \"SPLIT\",\n              Options.TIME: \"INT\",\n              Options.TIME_MERGING: {},\n              }\n\nconvert_results(run_config)\n```\n\nYou can also use the associated argument parser, to extract the run_config dynamically from a string:\n\n```python\nfrom fameio.scripts.convert_results import Options, run as convert_results\nfrom fameio.cli.convert_results import handle_args\n\nmy_defaults = {Options.FILE: \"./path/to/protobuf_file.pb\",\n               Options.LOG_LEVEL: \"info\",\n               Options.LOG_FILE: \"scenario.log\",\n               Options.OUTPUT: \"Output\",\n               Options.AGENT_LIST: ['AgentType1', 'AgentType2'],\n               Options.MEMORY_SAVING: False,\n               Options.SINGLE_AGENT_EXPORT: False,\n               Options.RESOLVE_COMPLEX_FIELD: \"SPLIT\",\n               Options.TIME: \"INT\",\n               Options.TIME_MERGING: {},\n               }\nmy_arg_string = ['-f', 'my/other/scenario.yaml', '-l', 'error']\n\nrun_config = handle_args(my_arg_string, my_defaults)\nconvert_results(run_config)\n```\n\n## Cite FAME-Io\n\nIf you use FAME-Io for academic work, please cite as follows.\n\nBibtex entry:\n\n```\n@article{fameio2023joss,\n  author  = {Felix Nitsch and Christoph Schimeczek and Ulrich Frey and Benjamin Fuchs},\n  title   = {FAME-Io: Configuration tools for complex agent-based simulations},\n  journal = {Journal of Open Source Software},\n  year    = {2023},\n  doi     = {doi: https://doi.org/10.21105/joss.04958}\n}\n```\n\n## Available Support\n\nThis is a purely scientific project by (at the moment) one research group.\nThus, there is no paid technical support available.\nHowever, we will give our best to answer your questions and provide support.\n\nIf you experience any trouble with FAME-Io, you may contact the developers via [fame@dlr.de](mailto:fame@dlr.de).\nPlease report bugs and make feature requests by filing issues following the provided templates (see\nalso [Contribute](CONTRIBUTING.md)).\nFor substantial enhancements, we recommend that you contact us via [fame@dlr.de](mailto:fame@dlr.de) for working\ntogether on the code in common projects or towards common publications and thus further develop FAME-Io.\n",
            "project_id": "17657706"
        },
        {
            "software_organization": "https://helmholtz.software/software/fastscape-toolbox",
            "repo_link": "https://github.com/fastscape-lem/fastscape",
            "readme": "Fastscape\n=========\n\n|Build Status| |Doc Status| |Zenodo|\n\nA fast, versatile and user-friendly landscape evolution model.\n\nFastscape is a Python package that provides a lot a small model\ncomponents (i.e., processes) to use with the xarray-simlab_ modeling\nframework. Those components can readily be combined together in order\nto create custom Landscape Evolution Models (LEMs).\n\nRoutines from the fastscapelib_ library are used for fast model\nexecution.\n\n.. |Build Status| image:: https://github.com/fastscape-lem/fastscape/actions/workflows/tests.yml/badge.svg?branch=master\n   :target: https://github.com/fastscape-lem/fastscape/actions/workflows/tests.yml\n   :alt: Build Status\n.. |Doc Status| image:: https://readthedocs.org/projects/fastscape/badge/?version=latest\n   :target: https://fastscape.readthedocs.io/en/latest/?badge=latest\n   :alt: Documentation Status\n.. |Zenodo| image:: https://zenodo.org/badge/133702738.svg\n   :target: https://zenodo.org/badge/latestdoi/133702738\n   :alt: Citation\n\n.. _xarray-simlab: https://github.com/benbovy/xarray-simlab\n.. _fastscapelib: https://github.com/fastscape-lem/fastscapelib-fortran\n\nDocumentation\n-------------\n\nDocumentation is hosted on ReadTheDocs:\nhttps://fastscape.readthedocs.io\n\nLicense\n-------\n\n3-clause (\"Modified\" or \"New\") BSD license. See the LICENSE file for details.\n\nAcknowledgment\n--------------\n\nFastscape is developed at the `Earth Surface Process Modelling`__ group of\nthe GFZ Helmholtz Centre Potsdam.\n\n__ http://www.gfz-potsdam.de/en/section/earth-surface-process-modelling/\n\nCiting fastscape\n----------------\n\nIf you use xarray-simlab in a scientific publication, we would\nappreciate a `citation`_.\n\n.. _`citation`: http://fastscape.readthedocs.io/en/latest/cite.html\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/fastsurfer",
            "repo_link": "https://github.com/deep-MI/FastSurfer/",
            "readme": "[![DOI](https://zenodo.org/badge/211859022.svg)](https://zenodo.org/badge/latestdoi/211859022)\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deep-MI/FastSurfer/blob/stable/Tutorial/Tutorial_FastSurferCNN_QuickSeg.ipynb)\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deep-MI/FastSurfer/blob/stable/Tutorial/Complete_FastSurfer_Tutorial.ipynb)\n\n<!-- start of content -->\n# Welcome to FastSurfer!\n##  Overview\n\nThis README contains all information needed to run FastSurfer - a fast and accurate deep-learning based neuroimaging pipeline. FastSurfer provides a fully compatible [FreeSurfer](https://freesurfer.net/) alternative for volumetric analysis (within minutes) and surface-based thickness analysis (within only around 1h run time). \nFastSurfer is transitioning to sub-millimeter resolution support throughout the pipeline.\n\nThe FastSurfer pipeline consists of two main parts for segmentation and surface reconstruction.  \n\n- the segmentation sub-pipeline (`seg`) employs advanced deep learning networks for fast, accurate segmentation and volumetric calculation of the whole brain and selected substructures.\n- the surface sub-pipeline (`recon-surf`) reconstructs cortical surfaces, maps cortical labels and performs a traditional point-wise and ROI thickness analysis. \n\n\n### Segmentation Modules \n- approximately 5 minutes (GPU), `--seg_only` only runs this part. \n \nModules (all run by default):\n1. `asegdkt:` [FastSurferVINN](FastSurferCNN/README.md) for whole brain segmentation (deactivate with `--no_asegdkt`)\n   - the core, outputs anatomical segmentation and cortical parcellation and statistics of 95 classes, mimics FreeSurfer’s DKTatlas.\n   - requires a T1w image ([notes on input images](#requirements-to-input-images)), supports high-res (up to 0.7mm, experimental beyond that).\n   - performs bias-field correction and calculates volume statistics corrected for partial volume effects (skipped if `--no_biasfield` is passed).\n2. `cereb:` [CerebNet](CerebNet/README.md) for cerebellum sub-segmentation (deactivate with `--no_cereb`)\n   - requires `asegdkt_segfile`, outputs cerebellar sub-segmentation with detailed WM/GM delineation.\n   - requires a T1w image ([notes on input images](#requirements-to-input-images)), which will be resampled to 1mm isotropic images (no native high-res support).\n   - calculates volume statistics corrected for partial volume effects (skipped if `--no_biasfield` is passed).\n3. `hypothal`: [HypVINN](HypVINN/README.md) for hypothalamus subsegmentation (deactivate with `--no_hypothal`)\n   - outputs a hypothalamic subsegmentation including 3rd ventricle, c. mammilare, fornix and optic tracts.\n   - a T1w image is highly recommended ([notes on input images](#requirements-to-input-images)), supports high-res (up to 0.7mm, but experimental beyond that).\n   - allows the additional passing of a T2w image with `--t2 <path>`, which will be registered to the T1w image (see `--reg_mode` option).\n   - calculates volume statistics corrected for partial volume effects based on the T1w image (skipped if `--no_bias_field` is passed).\n\n### Surface reconstruction\n- approximately 60-90 minutes, `--surf_only` runs only [the surface part](recon_surf/README.md).\n- supports high-resolution images (up to 0.7mm, experimental beyond that).\n\n<!-- start of image requirements -->\n### Requirements to input images\nAll pipeline parts and modules require good quality MRI images, preferably from a 3T MR scanner.\nFastSurfer expects a similar image quality as FreeSurfer, so what works with FreeSurfer should also work with FastSurfer. \nNotwithstanding module-specific limitations, resolution should be between 1mm and 0.7mm isotropic (slice thickness should not exceed 1.5mm). Preferred sequence is Siemens MPRAGE or multi-echo MPRAGE. GE SPGR should also work. See `--vox_size` flag for high-res behaviour.\n<!-- end of image requirements -->\n\n![](doc/images/teaser.png)\n\n<!-- start of getting started -->\n## Getting started\n\n### Installation \nThere are two ways to run FastSurfer (links are to installation instructions):\n\n1. In a container ([Singularity](doc/overview/INSTALL.md#singularity) or [Docker](doc/overview/INSTALL.md#docker)) (OS: [Linux](doc/overview/INSTALL.md#linux), [Windows](doc/overview/INSTALL.md#windows), [MacOS on Intel](doc/overview/INSTALL.md#docker-currently-only-supported-for-intel-cpus)),\n2. As a [native install](doc/overview/INSTALL.md#native-ubuntu-2004-or-ubuntu-2204) (all OS for segmentation part). \n\nWe recommended you use Singularity or Docker on a Linux host system with a GPU. The images we provide on [DockerHub](https://hub.docker.com/r/deepmi/fastsurfer) conveniently include everything needed for FastSurfer. You will also need a [FreeSurfer license](https://surfer.nmr.mgh.harvard.edu/fswiki/License) file for the [Surface pipeline](#surface-reconstruction). We have detailed per-OS Installation instructions in the [INSTALL.md](doc/overview/INSTALL.md) file.\n\n### Usage\n\nAll installation methods use the `run_fastsurfer.sh` call interface (replace `*fastsurfer-flags*` with [FastSurfer flags](doc/overview/FLAGS.md#required-arguments)), which is the general starting point for FastSurfer. However, there are different ways to call this script depending on the installation, which we explain here:\n\n1. For container installations, you need to define the hardware and mount the folders with the input (`/data`) and output data (`/output`):  \n   (a) For __singularity__, the syntax is \n    ```\n    singularity exec --nv \\\n                     --no-home \\\n                     -B /home/user/my_mri_data:/data \\\n                     -B /home/user/my_fastsurfer_analysis:/output \\\n                     -B /home/user/my_fs_license_dir:/fs_license \\\n                     ./fastsurfer-gpu.sif \\\n                     /fastsurfer/run_fastsurfer.sh \n                     *fastsurfer-flags*\n   ```\n   The `--nv` flag is needed to allow FastSurfer to run on the GPU (otherwise FastSurfer will run on the CPU).\n\n   The `--no-home` flag tells singularity to not mount the home directory (see [Singularity documentation](Singularity/README.md#mounting-home) for more info).\n\n   The `-B` flag is used to tell singularity, which folders FastSurfer can read and write to.\n \n   See also __[Example 2](doc/overview/EXAMPLES.md#example-2-fastsurfer-singularity)__ for a full singularity FastSurfer run command and [the Singularity documentation](Singularity/README.md#fastsurfer-singularity-image-usage) for details on more singularity flags.  \n\n   (b) For __docker__, the syntax is\n    ```\n    docker run --gpus all \\\n               -v /home/user/my_mri_data:/data \\\n               -v /home/user/my_fastsurfer_analysis:/output \\\n               -v /home/user/my_fs_license_dir:/fs_license \\\n               --rm --user $(id -u):$(id -g) \\\n               deepmi/fastsurfer:latest \\\n               *fastsurfer-flags*\n    ```\n   The `--gpus` flag is needed to allow FastSurfer to run on the GPU (otherwise FastSurfer will run on the CPU).\n\n   The `-v` flag is used to tell docker, which folders FastSurfer can read and write to.\n \n   See also __[Example 1](doc/overview/EXAMPLES.md#example-1-fastsurfer-docker)__ for a full FastSurfer run inside a Docker container and [the Docker documentation](Docker/README.md#docker-flags) for more details on the docker flags including `--rm` and `--user`.\n\n2. For a __native install__, you need to activate your FastSurfer environment (e.g. `conda activate fastsurfer_gpu`) and make sure you have added the FastSurfer path to your `PYTHONPATH` variable, e.g. `export PYTHONPATH=$(pwd)`. \n\n   You will then be able to run fastsurfer with `./run_fastsurfer.sh *fastsurfer-flags*`.\n\n   See also [Example 3](doc/overview/EXAMPLES.md#example-3-native-fastsurfer-on-subjectx-with-parallel-processing-of-hemis) for an illustration of the commands to run the entire FastSurfer pipeline (FastSurferCNN + recon-surf) natively.\n\n<!-- start of flags -->\n### FastSurfer_Flags\nPlease refer to [FASTSURFER_FLAGS](doc/overview/FLAGS.md).\n\n\n## Examples\nAll the examples can be found here: [FASTSURFER_EXAMPLES](doc/overview/EXAMPLES.md)\n- [Example 1: FastSurfer Docker](doc/overview/EXAMPLES.md#example-1-fastsurfer-docker)\n- [Example 2: FastSurfer Singularity](doc/overview/EXAMPLES.md#example-2-fastsurfer-singularity)\n- [Example 3: Native FastSurfer on subjectX with parallel processing of hemis](doc/overview/EXAMPLES.md#example-3-native-fastsurfer-on-subjectx-with-parallel-processing-of-hemis)\n- [Example 4: FastSurfer on multiple subjects](doc/overview/EXAMPLES.md#example-4-fastsurfer-on-multiple-subjects)\n- [Example 5: Quick Segmentation](doc/overview/EXAMPLES.md#example-5-quick-segmentation)\n- [Example 6: Running FastSurfer on a SLURM cluster via Singularity](doc/overview/EXAMPLES.md#example-6-running-fastsurfer-on-a-slurm-cluster-via-singularity)\n\n\n## Output files\n\nModules output can be found here: [FastSurfer_Output_Files](doc/overview/OUTPUT_FILES.md)\n- [Segmentation module](doc/overview/OUTPUT_FILES.md#segmentation-module)\n- [Cerebnet module](doc/overview/OUTPUT_FILES.md#cerebnet-module)\n- [Surface module](doc/overview/OUTPUT_FILES.md#surface-module)\n\n<!-- start of system requirements -->\n## System Requirements\n\nRecommendation: At least 8 GB system memory and 8 GB NVIDIA graphics memory ``--viewagg_device gpu``  \n\nMinimum: 7 GB system memory and 2 GB graphics memory ``--viewagg_device cpu --vox_size 1``\n\nMinimum CPU-only: 8 GB system memory (much slower, not recommended) ``--device cpu --vox_size 1`` \n\n### Minimum Requirements:\n\n|       | --viewagg_device | Min GPU (in GB) | Min CPU (in GB) |\n|:------|------------------|----------------:|----------------:|\n| 1mm   | gpu              |               5 |               5 |\n| 1mm   | cpu              |               2 |               7 |\n| 0.8mm | gpu              |               8 |               6 |\n| 0.8mm | cpu              |               3 |               9 |\n| 0.7mm | gpu              |               8 |               6 |\n| 0.7mm | cpu              |               3 |               9 |\n\n\n## Expert usage\nIndividual modules and the surface pipeline can be run independently of the full pipeline script documented in this documentation. \nThis is documented in READMEs in subfolders, for example: [whole brain segmentation only with FastSurferVINN](FastSurferCNN/README.md), [cerebellum sub-segmentation](CerebNet/README.md), [hypothalamic sub-segmentation](HypVINN/README.md) and [surface pipeline only (recon-surf)](recon_surf/README.md).\n\nSpecifically, the segmentation modules feature options for optimized parallelization of batch processing.\n\n\n## FreeSurfer Downstream Modules\n\nFreeSurfer provides several Add-on modules for downstream processing, such as subfield segmentation ( [hippocampus/amygdala](https://surfer.nmr.mgh.harvard.edu/fswiki/HippocampalSubfieldsAndNucleiOfAmygdala), [brainstem](https://surfer.nmr.mgh.harvard.edu/fswiki/BrainstemSubstructures), [thalamus](https://freesurfer.net/fswiki/ThalamicNuclei) and [hypothalamus](https://surfer.nmr.mgh.harvard.edu/fswiki/HypothalamicSubunits) ) as well as [TRACULA](https://surfer.nmr.mgh.harvard.edu/fswiki/Tracula). We now provide symlinks to the required files, as FastSurfer creates them with a different name (e.g. using \"mapped\" or \"DKT\" to make clear that these file are from our segmentation using the DKT Atlas protocol, and mapped to the surface). Most subfield segmentations require `wmparc.mgz` and work very well with FastSurfer,  so feel free to run those pipelines after FastSurfer. TRACULA requires `aparc+aseg.mgz` which we now link, but have not tested if it works, given that [DKT-atlas](https://mindboggle.readthedocs.io/en/latest/labels.html) merged a few labels. You should source FreeSurfer 7.3.2 to run these modules. \n\n\n## Intended Use\n\nThis software can be used to compute statistics from an MR image for research purposes. Estimates can be used to aggregate population data, compare groups etc. The data should not be used for clinical decision support in individual cases and, therefore, does not benefit the individual patient. Be aware that for a single image, produced results may be unreliable (e.g. due to head motion, imaging artefacts, processing errors etc). We always recommend to perform visual quality checks on your data, as also your MR-sequence may differ from the ones that we tested. No contributor shall be liable to any damages, see also our software [LICENSE](LICENSE). \n\n<!-- start of references -->\n## References\n\nIf you use this for research publications, please cite:\n\n_Henschel L, Conjeti S, Estrada S, Diers K, Fischl B, Reuter M, FastSurfer - A fast and accurate deep learning based neuroimaging pipeline, NeuroImage 219 (2020), 117012. https://doi.org/10.1016/j.neuroimage.2020.117012_\n\n_Henschel L*, Kuegler D*, Reuter M. (*co-first). FastSurferVINN: Building Resolution-Independence into Deep Learning Segmentation Methods - A Solution for HighRes Brain MRI. NeuroImage 251 (2022), 118933. http://dx.doi.org/10.1016/j.neuroimage.2022.118933_\n\n_Faber J*, Kuegler D*, Bahrami E*, et al. (*co-first). CerebNet: A fast and reliable deep-learning pipeline for detailed cerebellum sub-segmentation. NeuroImage 264 (2022), 119703. https://doi.org/10.1016/j.neuroimage.2022.119703_\n\n_Estrada S, Kuegler D, Bahrami E, Xu P, Mousa D, Breteler MMB, Aziz NA, Reuter M. FastSurfer-HypVINN: Automated sub-segmentation of the hypothalamus and adjacent structures on high-resolutional brain MRI. Imaging Neuroscience 2023; 1 1–32. https://doi.org/10.1162/imag_a_00034_\n\nStay tuned for updates and follow us on [X/Twitter](https://twitter.com/deepmilab).\n\n<!-- start of acknowledgements -->\n## Acknowledgements\n\nThis project is partially funded by:\n- [Chan Zuckerberg Initiative](https://chanzuckerberg.com/eoss/proposals/fastsurfer-ai-based-neuroimage-analysis-package/)\n- [German Federal Ministry of Education and Research](https://www.gesundheitsforschung-bmbf.de/de/deepni-innovative-deep-learning-methoden-fur-die-rechnergestutzte-neuro-bildgebung-10897.php)\n\nThe recon-surf pipeline is largely based on [FreeSurfer](https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/fatsegnet",
            "repo_link": "https://github.com/Deep-MI/FatSegNet",
            "readme": "\n# FatSegNet : A Fully Automated Deep Learning Pipeline for Adipose Segmentation on Abdominal Dixon MRI\n\nThis repository contains the tool  designed for the [Rhineland Study](https://www.rheinland-studie.de/) \nfor segmenting visceral and subcuteneous adipose tissue on fat \nimages from a two-point Dixon sequence. \n\nIf you use this tool please cite:\n\nEstrada, Santiago, et al. \"FatSegNet: A fully automated deep learning pipeline for adipose tissue segmentation on abdominal dixon MRI.\" Magnetic resonance in medicine 83.4 (2020): 1471-1483. [https:// doi.org/10.1002/mrm.28022](https://onlinelibrary.wiley.com/doi/full/10.1002/mrm.28022)\n```\n@article{estrada2020fatsegnet,\n  title={FatSegNet: A fully automated deep learning pipeline for adipose tissue segmentation on abdominal dixon MRI},\n  author={Estrada, Santiago and Lu, Ran and Conjeti, Sailesh and Orozco-Ruiz, Ximena and Panos-Willuhn, Joana and Breteler, Monique MB and Reuter, Martin},\n  journal={Magnetic resonance in medicine},\n  volume={83},\n  number={4},\n  pages={1471--1483},\n  year={2020},\n  publisher={Wiley Online Library}\n}\n```\n\n## Usage\n\nWe wrap our tool on a docker image, so there is no need to install any library dependencies or drivers, \nthe only requirement is to have docker (cpu) or \nnvidia-docker(gpu) installed.\n\nPrerequisites:\n\n* Docker (For running on CPU) (https://docs.docker.com/install/)\n* NVIDIA-Docker (For running on GPU ) (https://github.com/nvidia/nvidia-docker/wiki)\n\n\n\n## Tool installation \n\n If the tool is run for the first time the FatSegNet docker image has to be created. Run the following steps\n \n 1. Run on the terminal `sudo git clone https://github.com/reuter-lab/FatSegNet.git`  or download .zip file from the github repository \n 2. From the download repository directory run on the terminal: \n\n* `bash build_docker_cpu.sh` for CPU (In case GPU is not available)<br/> \n* `bash build_docker_gpu.sh` for GPU <br/>\n\nFor checking that the FatSegNet image was created correctly type on the terminal<br/>\n`docker images`\n\nit should appear a repository with the name **adipose_tool** and the tag v1 for gpu or cpu_v1 for cpu.\n\n**Example** \n``` bash\nREPOSITORY        TAG       IMAGE ID      CREATED     SIZE\nadipose_tool      v1        xxxxxxxx      xxxxxx      xxxx\nadipose_tool      cpu_v1    xxxxxxxx      xxxxxx      xxxx    \n```\n\n**Note:** Both docker images for CPU and GPU can be created on the same machine. \n\n \n## Running the tool \n\n### **Input Data format**\nFor running the tool the input data is expected to be a nifti volume with size of [256,224,72], if the scans have a \ndifferent size they will be crop or padd to the correct size. Additionally \nthe scans have to be arrange as follows(or see [example_data_folder](./example_data_folder), **NOTE** :This folder \ncontain a ilustrative example of how images have to organized for FatSegNet to work.\nThe Fat and water images scans are empty) :\n\n ```\n #Input  Scheme                            \n|-- my_dataset                                                             \n    participants.csv                         \n    |-- Subject_1                                \n        |-- FatImaging_F.nii.gz                      \n        |-- FatImaging_W.nii.gz                                                                  \n    |-- Subject_2                                            \n        |-- FatImaging_F.nii.gz                                         \n        |-- FatImaging_W.nii.gz              \n    |-- Subject_3                            \n        |-- FatImaging_F.nii.gz                  \n        |-- FatImaging_W.nii.gz                      \n    ...........                                     \n    |-- Subject_xx                                    \n        |-- FatImaging_F.nii.gz                      \n        |-- FatImaging_W.nii.gz\n ``` \nThe fat and water scans should have the same name, the name can be defined by the user,  the default names are \n**FatImaging_F.nii.gz (Fat)** and **FatImaging_W.nii.gz(water)**.\n\n**Participants file (participants.csv)** : the purpose of this file is to configure the participants scans \nthat should be process. The file has a one compulsory column  that consist of the name of folder containing \nthe water and fat scans.\n \n`participants.csv` example : \n\n```\nSubject_1\nSubject_2\nSubject_3\nSubject_xx\n```\n\n \n### Running FatSegNet\n\nFor executing FatSegNet  is necesary to configure the docker run options and the script input arguments \nas follows :<br/>\n```\n#For gpu\nnvidia-docker run [OPTIONS] adipose_tool:v1 [ARGUMENTS]\n#For Cpu\ndocker run [OPTIONS] adipose_tool:v1 [ARGUMENTS]\n```\n\n#### Options\nA docker container doesnt have access to the system files so volumes has to be mounted. For our tool \nis necessary to mount  the main data directory `my_dataset` to `/tool/Data` and the desire  local output\n folder to `/tool/Output`. The output folder \nis where all pipeline output are going to be store (the input and output folder can be the same). We additionally recommend to use the following docker flags:<br/>\n * `--rm` : Automatically clean up the container and remove the file system when the container exits\n * `--user , -u `: Username or UID (format: <name|uid>[:<group|gid>])\n * `--name` : Assign a name to the container\n * `--volume , -v`: Bind mount a volume\n \n\n**Example** \n``` bash\n#For Gpu\nnvidia-docker run --rm --name fatsegnet -u $(id -u) -v ../my_dataset/:/tool/Data -v ../my_dataset_output/:/tool/Output  adipose_tool:v1 [Arguments]\n# For CPU\ndocker run -it --rm --name fatsegnet -u $(id -u) -v ../my_dataset/:/tool/Data -v ../my_dataset_output/:/tool/Output  adipose_tool:cpu_v1 [Arguments]\n```\n\n #### Arguments\n * `--file,-f` : csv file containing the participants to process (default: participants.csv)\n * `--output_folder,-outp` : Parent folder for the scripts outputs (see output seccion) \n * `--fat_image,-fat` : Name of the fat image (default :FatImaging_F.nii.gz)\n * `--water_image,-water`: Name of the water image (default :FatImaging_W.nii.gz)\n * `--control_images,-No_QC` : Not to plot subjects predictions for visual quality control\n * `--run_localization,-loc` : run abdominal region localization model , by default the localization model is not run\n * `--axial,-axial` : run only axial segmentation model\n * `--order,-order` : Interpolation order (0=nearest,1=linear(default),2=quadratic,3=cubic),the tool standardizes the input resolutions to [2mm,2mm,5mm]; if the axial flag is selected only the axial plane is sample.  \n * `--compartments,-comp` : Number of equal compartments to calculate the statistics (default=0.0)\n * `--increase_threshold,-AAT` : Warning flag for an increase in AAT over the define threhold between consecutive scans (default=0.4)\n * `--sat_to_vat_threshold,-ratio`: Warning flag for a vat to sat ratio higher than the define threshold (default=2.0)\n * `--runs_stats,-stats` : the AAT segmentations model are not deploy only image biomarkers are calculated,a fat scan and VAT and SAT segmentation map  is required (AAT_pred.nii.gz)\n * `--gpu_id, -gpu_id` :  GPU device ID, the container will only use the specified Gpu  (default `device ID 0`). ***Note*** the script organize the GPU IDs by pci bus IDs.\n \n \n**Example**\n```\n# Run paper implementation \nnvidia-docker run --rm --name fatsegnet -u $(id -u) -v ../my_dataset/:/tool/Data -v ../my_dataset_output/:/tool/Output  adipose_tool:v1 -loc\n\n# Change Participants files \nnvidia-docker run [Options]  adipose_tool:v1 -f new_participants.csv -loc\n\n# Change name of water and fat images to search\nnvidia-docker run [Options]  adipose_tool:v1  -fat fat_image.nii.gz -water water_image.nii.gz -loc\n\n# Select a specific GPU (ex: device ID 2)\nnvidia-docker run [Options]  adipose_tool:v1  -loc -gpu_id 2\n\n# run only the segmentation models on the axial plane and define interpolation order\nnvidia-docker run [Options]  adipose_tool:v1  -axial -order 3\n\n```\n\n### **Output Data format**\n```  bash\n#Output Scheme \n|-- my_dataset_output                                   \n    |-- Subject_1\n        |-- MRI (Only created if the images are resize or sample)\n           |-- FatImaging_F.nii.gz (Fat_Scans)\n           |-- FatImaging_W.nii.gz (Water_Scans)\n        |-- QC\n           |-- QC_[0-3].png (Quality control images)\n        |-- Segmentations                                                 \n           |-- AAT_pred.nii.gz (Only adipose tissues prediction map)\n           |-- ALL_pred.nii.gz (adipose tissues and auxilary classes prediction map)         \n           |-- AAT_variables_summary.json  (Calculated Image Biomarkers) \n    |-- Subject_2\n        |-- MRI (Only created if the images are resize or sample)\n           |-- FatImaging_F.nii.gz (Fat_Scans)\n           |-- FatImaging_W.nii.gz (Water_Scans)\n        |-- QC\n           |-- QC_[0-3].png (Quality control images)\n        |-- Segmentations                                                 \n           |-- AAT_pred.nii.gz (Only adipose tissues prediction map)\n           |-- ALL_pred.nii.gz (adipose tissues and auxilary classes prediction map)          \n           |-- AAT_variables_summary.json  (Calculated Image Biomarkers)                      \n    ...............\n    |-- Subject_xx\n        |-- MRI (Only created if the images are resize or sample)\n           |-- FatImaging_F.nii.gz (Fat_Scans)\n           |-- FatImaging_W.nii.gz (Water_Scans)\n        |-- QC\n           |-- QC_[0-3].png (Quality control images)\n        |-- Segmentations    \n           |-- AAT_pred.nii.gz (Only adipose tissues prediction map)\n           |-- ALL_pred.nii.gz (adipose tissues and auxilary classes prediction map)    \n           |-- AAT_variables_summary.json  (Calculated Image Biomarkers)\n\n ``` \n\n**Image Biomarkers**\n\nFor more information on the pipeline image biomarkers reported in the `AAT_variables_summary.json ` file \nplease check the document [FatSegNet_Variables.pdf](./FatSegNet_Variables.pdf)\n\n**Quality Control Image Example**\n\nBy default the tool creates 4 images for visually control of the input scan and predicted segmentation, as the one shown below.\nTop row fat images from axial, coronal ,sagittal view centered on the red dot; bottom row predicted segmentations \n(blue: SAT, green : VAT).    \n\n![](Images/QC_3.png)\n\n\n\n\n--------\nFor any questions and feedback, feel free to contact santiago.estrada(at).dzne.de<br/>\n\n--------\n\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/fesom",
            "repo_link": "https://github.com/FESOM/fesom2",
            "readme": "The Finite Element Sea Ice-Ocean Model (FESOM2) \n======\n[![Build Status](https://github.com/FESOM/fesom2/workflows/FESOM2%20main%20test/badge.svg)](https://github.com/FESOM/fesom2/actions)\n\nMulti-resolution ocean general circulation model that solves the equations of motion describing the ocean and sea ice using finite-element and finite-volume methods on unstructured computational grids. The model is developed and supported by researchers at the Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research (AWI), in Bremerhaven, Germany.\n\n**Website:** [fesom.de](https://fesom.de/)\n\n**Documentation:** [fesom2.readthedocs.io](https://fesom2.readthedocs.io/en/latest/index.html)\n\n**Basic tutorial:** [Getting started](https://fesom2.readthedocs.io/en/latest/getting_started/getting_started.html)\n\n\nReferences\n----------\n\n[Complete list of references on fesom.de](https://fesom.de/publications/)\n\n* **[Ocean model formulation]** Danilov, S., Sidorenko, D., Wang, Q., and Jung, T.: The Finite-volumE Sea ice–Ocean Model (FESOM2), Geosci. Model Dev., 10, 765–789, https://doi.org/10.5194/gmd-10-765-2017, 2017. \n\n* **[Sea ice model formulation]** Danilov, S., Q. Wang, R. Timmermann, N. Iakovlev, D. Sidorenko, M. Kimmritz, T. Jung, and Schröter, J. (2015), Finite-Element Sea Ice Model (FESIM), version 2, Geosci. Model Dev., 8, 1747–1761, http://www.geosci-model-dev.net/8/1747/2015/\n\n* **[Evaluation of standard sumulations]** Scholz, P., Sidorenko, D., Gurses, O., Danilov, S., Koldunov, N., Wang, Q., Sein, D., Smolentseva, M., Rakowsky, N., and Jung, T.: Assessment of the Finite-volumE Sea ice-Ocean Model (FESOM2.0) – Part 1: Description of selected key model elements and comparison to its predecessor version, Geosci. Model Dev., 12, 4875–4899, https://doi.org/10.5194/gmd-12-4875-2019, 2019.\n\n* **[Evaluation of computational performance]** Koldunov, N. V., Aizinger, V., Rakowsky, N., Scholz, P., Sidorenko, D., Danilov, S., and Jung, T.: Scalability and some optimization of the Finite-volumE Sea ice–Ocean Model, Version 2.0 (FESOM2), Geosci. Model Dev., 12, 3991–4012, https://doi.org/10.5194/gmd-12-3991-2019, 2019. \n\n* **[Version coupled with ECHAM6 atmosphere]** Sidorenko, D., Goessling, H. F., Koldunov, N. V., Scholz, P., Danilov, S., Barbi, D., et al ( 2019). Evaluation of FESOM2.0 coupled to ECHAM6.3: Pre‐industrial and HighResMIP simulations. Journal of Advances in Modeling Earth Systems, 11. https://doi.org/10.1029/2019MS001696\n\n* **[Version with ICEPACK sea ice thermodynamics]** Zampieri, Lorenzo, Frank Kauker, Jörg Fröhle, Hiroshi Sumata, Elizabeth C. Hunke, and Helge Goessling. Impact of Sea-Ice Model Complexity on the Performance of an Unstructured-Mesh Sea-ice/ocean Model Under Different Atmospheric Forcings. Washington: American Geophysical Union, 2020. https://dx.doi.org/10.1002/essoar.10505308.1.\n\n* **[Version coupled with OpenIFS atmosphere]** Streffing, J., Sidorenko, D., Semmler, T., Zampieri, L., Scholz, P., Andrés-Martínez, M., et al ( 2022). AWI-CM3 coupled climate model: description and evaluation experiments for a prototype post-CMIP6 model. Geoscientific Model Development, 15. https://doi.org/10.5194/gmd-15-6399-2022\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/fishinspector",
            "repo_link": "https://github.com/sscholz-UFZ/FishInspector",
            "readme": "# FishInspector\n**Annotation of features from zebrafish embryos**\n\nThe software FishInspector allows annotation of features in images of zebrafish embryos. The recent version requires images of a lateral position. It is important that the position is precise since deviation may confound with feature annotations. Images from any source can be used. However, depending on the image properties parameters may have to be adjusted. Furthermore, images obtained with normal microscope and not using an automated position system with embryos in glass capillaries require conversion using a KNIME workflow (available [here](https://github.com/eteixido/Knime-workflows-FishInspector)). As a result of the analysis the software provides JSON files that contain the coordinates of the features. Coordinates are provided for eye, fish contour, notochord , otoliths, yolk sac, pericard and swimbladder. Furthermore, pigment cells in the notochord area are detected. Additional features can be manually annotated. It is the aim of the software to provide the coordinates, which may then be analysed subsequently to identify and quantify changes in the morphology of zebrafish embryos.\n\n## [Available for Download Here](https://github.com//sscholz-UFZ/FishInspector/releases)\n\n## User Guide\n\nThe complete user guide can be checked [here](https://github.com/sscholz-UFZ/FishInspector/blob/master/docs/Index.md)\n\n## Referencing\n\nCitations can be made using the following DOI:\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1422642.svg)](https://doi.org/10.5281/zenodo.1422642)\n\n*Teixido, E., Kießling, T.R., Krupp, E., Quevedo, C., Muriana, A., Scholz, S., 2018. Automated morphological feature assessment for zebrafish embryo developmental toxicity screens. Tox. Sci. accepted.*\n\n## License\n\nThis project is licensed under a GNU General Public License - see the [LICENSE](LICENSE) file for details and also this [file](License.txt). \n\n\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/fiware-deployment-kit",
            "repo_link": "https://jugit.fz-juelich.de/iek-10/public/ict-platform/deployment",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/fleur",
            "repo_link": "https://iffgit.fz-juelich.de/fleur/fleur",
            "readme": "<div align=\"center\">\n<img src=\"https://www.flapw.de/rel/img/fleur.gif\"  width=\"220\">\n\n\nWelcome to the source code of FLEUR\n=====================\n\n[Report bug](https://iffgit.fz-juelich.de/fleur/fleur/issues/new?template=Bug.md)\n.\n[Request feature](https://iffgit.fz-juelich.de/fleur/fleur/issues/new?template=FeatureRequest.md&labels=feature)\n\n[Homepage and Documentation](https://www.flapw.de)\n</div>\n\n## Table of contents\n\n- [Using the FLEUR git repository](#fleur-git-repository)\n- [Dealing with Bugs and problems](#bugs-and-problems)\n- [Installation of FLEUR](#installation-of-FLEUR)\n- [Contributing](#contributing)\n\n## FLEUR git repository\n\nThe primary git-repository of FLEUR can be found on the [iffgit-Server at FZ-Jülich](https://iffgit.fz-juelich.de/fleur/fleur/).\n\nYou can clone the repository by using:\n```\ngit clone https://iffgit.fz-juelich.de/fleur/fleur.git\n```\n\nIf you are a FLEUR developer you should use\n```\ngit clone gitlab@iffgit.fz-juelich.de:fleur/fleur.git\n```\nto be able to push changes back to the server. If you are not a developer yet but want to contribute, please contact [Gregor](g.michalicek@fz-juelich.de) or [Daniel](d.wortmann@fz-juelich.de).\n\nPlease note, that the default branch you will see after cloning the repository is the 'develop' branch. In general you might find \nthe following branches on the server.\n\n* develop: this is the default branch with the most up-to-date version of FLEUR. Small changes and developments should be committed \ndirectly into this branch. When doing so you should try to keep the code operational. It should still compile and the test should run. \n* release: this branch collects the official releases. You cannot commit to this branch and bugfixes should be handled as [described below](#bugs-and-problems).\n* stable: this branch contains snapshots of the development branch considered \"stable\".\n\nIn addition several other branches can/will be present corresponding to features currently under development. If you start your own larger development\nit can be advisable to create your own branch. In this case you should try to follow changes in 'develop' by frequently merging 'develop' into your branch\nand you should create a merge request with 'develop' as soon as you are finished or reached some usefull state in your development.\n\n## Bugs and Problems\n\nYou might experience bugs in FLEUR :-).\n\nIf you find a bug you should:\n\nA)  [Report this bug by generating an Issue](https://iffgit.fz-juelich.de/fleur/fleur/issues/new?template=Bug.md). Please describe in \ndetail the relevant input and what happens. You should consider using \nthe bug-template for your issue as this will help you providing us with \nthe relevant information.\n\nor/and\n\nB) Provide a bugfix. If the bug is only present in the development branch/ is due\nto a new feature under development simply commit your fix to the development branch.\nIf you are fixing a bug in a release-version, please:\n* check out the git release branch: ```git checkout --track origin/release```\n* create a bugfix branch: ```git checkout -b bugfix_SOME_NAME_HERE```\n* apply your changes, test them and commit them\n* push your bugfix branch to the server: ``` git push -u origin bugfix_SOME_NAME_HERE```\n* create a merge request on the gitlab to have you bugfix merged with the release branch\n* check out the develop branch: ```git checkout develop```\n* merge your fix into the develop branch: ```git merge bugfix_SOME_NAME_HERE```\n\n\n## Installation of FLEUR\n\nTo install and use FLEUR, please check the [Documentation](https://www.flapw.de).\n\n## Contributing\n\nFLEUR is an open source code under the [MIT-license](https://iffgit.fz-juelich.de/fleur/fleur/blob/develop/LICENSE).\n\nYour are very welcome to contribute to its development. If you need help or access to the git repository, \nplease contact [Gregor](g.michalicek@fz-juelich.de) or [Daniel](d.wortmann@fz-juelich.de).\n\nPlease also use the [Wiki](https://iffgit.fz-juelich.de/fleur/fleur/wikis/home) for sharing information relevant for developers. ",
            "project_id": "19"
        },
        {
            "software_organization": "https://helmholtz.software/software/formatfuzzer",
            "repo_link": "https://github.com/uds-se/FormatFuzzer",
            "readme": "README.md"
        },
        {
            "software_organization": "https://helmholtz.software/software/fracspy",
            "repo_link": "https://github.com/FraCSPy/FraCSPy",
            "readme": "# FraCSPy\n\n[![DOI](https://zenodo.org/badge/619447827.svg)](https://zenodo.org/badge/latestdoi/619447827)\n\nFraCSPy stands for Python Framework for Conventional microSeismic Processing.\n\n![FraCSPy logo](logo/fracspy_logo.png)\n\nIt is a single python toolbox for the full microseismic pipeline from modelling to post-event analysis.\nThis library is a single location leveraging the excellent work of other scientists (software developers) and adapts them for the specific use case of microseismic monitoring.\n\nSome functionalities include:\n\n- modelling script generation (for accompanying [SOFI3D](https://docs.csc.fi/apps/sofi3d/))\n- event imaging: detection, location\n- moment tensor inversion\n\nSome python libraries that are utilised include:\n\n- pylops\n- torch\n- obspy\n- and more...\n\n## Requirements\n\nInstallation requires either [pip](https://pypi.org/project/pip/) package installer or [Conda](https://conda.io) package manager, e.g. one can use [miniforge](https://github.com/conda-forge/miniforge).\n\n## Install using pip\n\n```bash\npip install fracspy\n```\n\n## Install using conda\n\n### Linux\n\nSimply run\n\n```bash\nmake install\n```\n\nIt will create a new conda environment `fracspy` with all the required packages:\n\nSimilarly, on Linux you can run:\n\n```bash\n./install.sh\n```\n\n### Windows\n\nOn Windows, the best way is to use [miniforge](https://github.com/conda-forge/miniforge) prompt and run:\n\n```cmd\ninstall.bat\n```\n\nIt will install the package to environment `fracspy` and activate it.\n\nTo install development version use\n\n```cmd\ninstall-dev.bat\n```\n\nNow you are ready to use the package.\n\n### Uninstall\n\nIf you need to add/change packages:\n\n```bash\nconda deactivate\nconda remove -n fracspy -all\n```\n\n## Documentation\n\nThe latest stable documentation based on [Sphinx](https://www.sphinx-doc.org) is available online at: <https://fracspy.github.io/FraCSPy>\n\nOne can also build the documentation locally:\n\n```bash\ncd docs\nmake html\n```\n\nIf you want to rebuild the documentation:\n\n```bash\nmake clean\nmake html\n```\n\nAfter a successful build, one can serve the documentation website locally:\n\n```bash\ncd build/html\npython -m http.server\n```\n\nand open in browser: <http://localhost:8000>\n\nTo build/rebuild documentation on Windows you can simply run\n\n```cmd\nbuild_docs.bat\n```\n\n**Note:** check the exact port number in the output\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/fsqc",
            "repo_link": "https://github.com/Deep-MI/fsqc",
            "readme": "# fsqc toolbox\n\n## Description\n\nThis package provides quality assurance / quality control scripts for FastSurfer- or\nFreeSurfer-processed structural MRI data. It will check outputs of these two software \npackages by means of quantitative and visual summaries. Prior processing of data using \neither FastSurfer or FreeSurfer is required, i.e. the software cannot be used on raw images.\n\nIt is a revision, extension, and translation to the Python language of the\n[Freesurfer QA Tools](https://surfer.nmr.mgh.harvard.edu/fswiki/QATools). It has\nbeen augmented by additional functions from the [MRIQC toolbox](https://github.com/poldracklab/mriqc),\nand with code derived from the [LaPy](https://github.com/Deep-MI/lapy) and\n[BrainPrint](https://github.com/Deep-MI/brainprint) toolboxes.\n\nThis page provides general, usage, and installation information. See [here](https://deep-mi.org/fsqc/dev/index.html)\nfor the full documentation.\n___\n\n## Contents\n\n- [Functionality](#functionality)\n- [Development](#development)\n  - [News](#news)\n  - [Main and development branches](#main-and-development-branches)\n  - [Roadmap](#roadmap)\n- [Usage](#usage)\n  - [As a command line tool](#as-a-command-line-tool)\n  - [As a Python package](#as-a-python-package)\n  - [As a Docker image](#as-a-docker-image)\n- [Installation](#installation)\n   - [Installation as a Python package](#installation-as-a-python-package)\n   - [Installation from GitHub](#installation-from-github)\n   - [Download from GitHub](#download-from-github)\n- [Requirements](#requirements)\n- [Known issues](#known-issues)\n- [Authors](#authors)\n- [Citations](#citations)\n- [License](#license)\n\n___\n\n## Functionality\n\nThe core functionality of this toolbox is to compute the following features:\n\nvariable       |   description\n---------------|----------------------------------------------------------------\nsubject        |   subject ID\nwm_snr_orig    |   signal-to-noise ratio for white matter in orig.mgz\ngm_snr_orig    |   signal-to-noise ratio for gray matter in orig.mgz\nwm_snr_norm    |   signal-to-noise ratio for white matter in norm.mgz\ngm_snr_norm    |   signal-to-noise ratio for gray matter in norm.mgz\ncc_size        |   relative size of the corpus callosum\nlh_holes       |   number of holes in the left hemisphere\nrh_holes       |   number of holes in the right hemisphere\nlh_defects     |   number of defects in the left hemisphere\nrh_defects     |   number of defects in the right hemisphere\ntopo_lh        |   topological fixing time for the left hemisphere\ntopo_rh        |   topological fixing time for the right hemisphere\ncon_lh_snr     |   wm/gm contrast signal-to-noise ratio in the left hemisphere\ncon_rh_snr     |   wm/gm contrast signal-to-noise ratio in the right hemisphere\nrot_tal_x      |   rotation component of the Talairach transform around the x axis\nrot_tal_y      |   rotation component of the Talairach transform around the y axis\nrot_tal_z      |   rotation component of the Talairach transform around the z axis\n\nThe program will use an existing output directory (or try to create it) and\nwrite a csv table into that location. The csv table will contain the above\nmetrics plus a subject identifier.\n\nThe program can also be run on images that were processed with [FastSurfer](https://github.com/Deep-MI/FastSurfer)\n(v1.1 or later) instead of FreeSurfer. In that case, simply add a `--fastsurfer`\nswitch to your shell command. Note that FastSurfer's full processing stream must\nhave been run, including surface reconstruction (i.e. brain segmentation alone\nis not sufficient).\n\nIn addition to the core functionality of the toolbox there are several optional\nmodules that can be run according to need:\n\n- screenshots module\n\nThis module allows for the automated generation of cross-sections of the brain\nthat are overlaid with the anatomical segmentations (asegs) and the white and\npial surfaces. These images will be saved to the 'screenshots' subdirectory\nthat will be created within the output directory. These images can be used for\nquickly glimpsing through the processing results. Note that no display manager\nis required for this module, i.e. it can be run on a remote server, for example.\n\n- surfaces module\n\nThis module allows for the automated generation of surface renderings of the\nleft and right pial and inflated surfaces, overlaid with the aparc annotation.\nThese images will be saved to the 'surfaces' subdirectory that will be created\nwithin the output directory. These images can be used for quickly glimpsing\nthrough the processing results. Note that no display manager is required for\nthis module, i.e. it can be run on a remote server, for example.\n\n- skullstrip module\n\nThis module allows for the automated generation cross-sections of the brain\nthat are overlaid with the colored and semi-transparent brainmask. This allows\nto check the quality of the skullstripping in FreeSurfer. The resulting images\nwill be saved to the 'skullstrip' subdirectory that will be created within the\noutput directory.\n\n- fornix module\n\nThis is a module to assess potential issues with the segmentation of the\ncorpus callosum, which may incorrectly include parts of the fornix. To assess\nsegmentation quality, a screenshot of the contours of the corpus callosum\nsegmentation overlaid on the norm.mgz will be saved as 'cc.png' for each\nsubject within the 'fornix' subdirectory of the output directory.\n\n- modules for the amygdala, hippocampus, and hypothalamus\n\nThese modules evaluate potential missegmentations of the amygdala, hippocampus,\nand hypothalamus. To assess segmentation quality, screenshots will be created\nThese modules require prior processing of the MR images with FreeSurfer's\ndedicated toolboxes for the segmentation of the amygdala and hippocampus, and\nthe hypothalamus, respectively.\n\n- shape module\n\nThe shape module will run a shapeDNA / brainprint analysis to compute distances\nof shape descriptors between lateralized brain structures. This can be used\nto identify discrepancies and irregularities between pairs of corresponding\nstructures. The results will be included in the main csv table, and the output\ndirectory will also contain a 'brainprint' subdirectory.\n\n- outlier module\n\nThis is a module to detect extreme values among the subcortical ('aseg')\nsegmentations as well as the cortical parcellations. If present, hypothalamic\nand hippocampal subsegmentations will also be included.\n\nThe outlier detection is based on comparisons with the\ndistributions of the sample as well as normative values taken from the\nliterature (see References).\n\nFor comparisons with the sample distributions, extreme values are defined in\ntwo ways: nonparametrically, i.e. values that are 1.5 times the interquartile\nrange below or above the 25th or 75th percentile of the sample, respectively,\nand parametrically, i.e. values that are more than 2 standard deviations above\nor below the sample mean. Note that a minimum of 10 supplied subjects is\nrequired for running these analyses, otherwise `NaNs` will be returned.\n\nFor comparisons with the normative values, lower and upper bounds are computed\nfrom the 95% prediction intervals of the regression models given in Potvin et\nal., 2016, and values exceeding these bounds will be flagged. As an\nalternative, users may specify their own normative values by using the\n'--outlier-table' argument. This requires a custom csv table with headers\n`label`, `upper`, and `lower`, where `label` indicates a column of anatomical\nnames. It can be a subset and the order is arbitrary, but naming must exactly\nmatch the nomenclature of the 'aseg.stats' and/or '[lr]h.aparc.stats' file.\nIf cortical parcellations are included in the outlier table for a comparison\nwith aparc.stats values, the labels must have a 'lh.' or 'rh.' prefix. `upper`\nand `lower` are user-specified upper and lower bounds.\n\nThe main csv table will be appended with the following summary variables, and\nmore detailed output about will be saved as csv tables in the 'outliers'\nsubdirectory of the main output directory.\n\nvariable                 |   description\n-------------------------|---------------------------------------------------\nn_outliers_sample_nonpar | number of structures that are 1.5 times the IQR above/below the 75th/25th percentile\nn_outliers_sample_param  | number of structures that are 2 SD above/below the mean\nn_outliers_norms         | number of structures exceeding the upper and lower bounds of the normative values\n\n___\n\n\n## Development\n\n### Current status\n\nWe are happy to announce the release of version 2.0 of the fsqc toolbox. With\nthis release comes a change of the project name from `qatools` to `fsqc`, to\nreflect increased independence from the original FreeSurfer QA tools, and\napplicability to other neuroimaging analysis packages - such as [Fastsurfer](https://github.com/Deep-MI/FastSurfer).\n\nRecent changes include the addition of the hippocampus and hypothalamus modules\nas well as the addition of surface and skullstrip visualization modules.\nTechnical changes include how the package is installed, imported, and run, see\n[below](https://github.com/Deep-MI/fsqc#usage) for details.\n\nA list of changes is available [here](CHANGES.md).\n\n### Main and development branches\n\nThis repository contains multiple branches, reflecting the ongoing\ndevelopment of the toolbox. The two primary branches are the main branch\n(`stable`) and the development branch (`dev`). New features will first be added\nto the development branch, and eventually be merged with the main branch. \n\n### Roadmap\n\nThe goal of the `fsqc` project is to create a modular and extensible software\npackage that provides quantitative metrics and visual information for the\nquality control of FreeSurfer- or Fastsurfer-processed MR images. The package\nis currently under development, and new features are continuously added.\n\nNew features will initially be available in the [development branch](https://github.com/Deep-MI/fsqc/tree/dev)\nof this toolbox and will be included in the [main branch](https://github.com/Deep-MI/fsqc/tree/stable)\nafter a period of testing and evaluation. Unless explicitly announced, all new\nfeatures will preserve compatibility with earlier versions.\n\nFeedback, suggestions, and [contributions](CONTRIBUTINNG.md) are always welcome,\npreferably via [issues](https://github.com/Deep-MI/fsqc/issues) and [pull requests](https://github.com/Deep-MI/fsqc/pulls).\n\n___\n\n## Usage\n\n### As a command line tool\n\n```\nrun_fsqc --subjects_dir <directory> --output_dir <directory>\n    [--subjects SubjectID [SubjectID ...]]\n    [--subjects-file <file>] [--screenshots]\n    [--screenshots-html] [--surfaces] [--surfaces-html]\n    [--skullstrip] [--skullstrip-html]\n    [--fornix] [--fornix-html] [--hippocampus]\n    [--hippocampus-html] [--hippocampus-label ... ]\n    [--hypothalamus] [--hypothalamus-html] [--shape]\n    [--outlier] [--fastsurfer] [--no-group]\n    [--group-only] [--exit-on-error]\n    [--skip-existing] [-h] [--more-help]\n    [...]\n\n\nrequired arguments:\n  --subjects_dir <directory>\n                         subjects directory with a set of Freesurfer- or\n                         Fastsurfer-processed individual datasets.\n  --output_dir <directory>\n                         output directory\n\noptional arguments:\n  --subjects SubjectID [SubjectID ...]\n                         list of subject IDs\n  --subjects-file <file> filename of a file with subject IDs (one per line)\n  --screenshots          create screenshots of individual brains\n  --screenshots-html     create screenshots of individual brains incl.\n                         html summary page\n  --surfaces             create screenshots of individual brain surfaces\n  --surfaces-html        create screenshots of individual brain surfaces\n                         and html summary page\n  --skullstrip           create screenshots of individual brainmasks\n  --skullstrip-html      create screenshots of individual brainmasks and\n                         html summary page\n  --fornix               check fornix segmentation\n  --fornix-html          check fornix segmentation and create html summary\n                         page of fornix evaluation\n  --hypothalamus         check hypothalamic segmentation\n  --hypothalamus-html    check hypothalamic segmentation and create html\n                         summary page\n  --hippocampus          check segmentation of hippocampus and amygdala\n  --hippocampus-html     check segmentation of hippocampus and amygdala\n                         and create html summary page\n  --hippocampus-label    specify label for hippocampus segmentation files\n                         (default: T1.v21). The full filename is then\n                         [lr]h.hippoAmygLabels-<LABEL>.FSvoxelSpace.mgz\n  --shape                run shape analysis\n  --outlier              run outlier detection\n  --outlier-table        specify normative values (only in conjunction with\n                         --outlier)\n  --fastsurfer           use FastSurfer instead of FreeSurfer output\n  --no-group             run script in subject-level mode. will compute\n                         individual files and statistics, but not create\n                         group-level summaries.\n  --group-only           run script in group mode. will create group-level\n                         summaries from existing inputs\n  --exit-on-error        terminate the program when encountering an error;\n                         otherwise, try to continue with the next module or\n                         case\n  --skip-existing        skips processing for a given case if output\n                         already exists, even with possibly different\n                         parameters or settings\n\ngetting help:\n  -h, --help            display this help message and exit\n  --more-help           display extensive help message and exit\n\nexpert options:\n  --screenshots_base <image>\n                        filename of an image that should be used instead of\n                        norm.mgz as the base image for the screenshots. Can be\n                        an individual file (which would not be appropriate for\n                        multi-subject analysis) or can be a file without\n                        pathname and with the same filename across subjects\n                        within the 'mri' subdirectory of an individual\n                        FreeSurfer results directory (which would be appropriate\n                        for multi-subject analysis).\n  --screenshots_overlay <image>\n                        path to an image that should be used instead of aseg.mgz\n                        as the overlay image for the screenshots; can also be\n                        none. Can be an individual file (which would not be\n                        appropriate for multi-subject analysis) or can be a file\n                        without pathname and with the same filename across\n                        subjects within the 'mri' subdirectory of an individual\n                        FreeSurfer results directory (which would be appropriate\n                        for multi-subject analysis).\n  --screenshots_surf <surf> [<surf> ...]\n                        one or more surface files that should be used instead\n                        of [lr]h.white and [lr]h.pial; can also be none. Can be\n                        one or more individual file(s) (which would not be\n                        appropriate for multi-subject analysis) or can be a\n                        (list of) file(s) without pathname and with the same\n                        filename across subjects within the 'surf' subdirectory\n                        of an individual FreeSurfer results directory (which\n                        would be appropriate for multi-subject analysis).\n  --screenshots_views <view> [<view> ...]\n                        one or more views to use for the screenshots in the form\n                        of x=<numeric> y=<numeric> and/or z=<numeric>. Order\n                        does not matter. Default views are x=-10 x=10 y=0 z=0.\n  --screenshots_layout <rows> <columns>\n                        layout matrix for screenshot images.\n\n```\n\n*Examples:*\n\n- Run the QC pipeline for all subjects found in `/my/subjects/directory`:\n\n```bash\nrun_fsqc --subjects_dir /my/subjects/directory --output_dir /my/output/directory\n```\n\n- Run the QC pipeline for two specific subjects that need to be present in `/my/subjects/directory`:\n\n```bash\nrun_fsqc --subjects_dir /my/subjects/directory --output_dir /my/output/directory --subjects mySubjectID1 mySubjectID2\n```\n\n- Run the QC pipeline for all subjects found in `/my/subjects/directory` after full FastSurfer processing:\n\n```bash\nrun_fsqc --subjects_dir /my/subjects/directory --output_dir /my/output/directory --fastsurfer\n```\n\n- Run the QC pipeline plus the screenshots module for all subjects found in `/my/subjects/directory`:\n\n```bash\nrun_fsqc --subjects_dir /my/subjects/directory --output_dir /my/output/directory --screenshots\n```\n\n- Run the QC pipeline plus the fornix pipeline for all subjects found in `/my/subjects/directory`:\n\n```bash\nrun_fsqc --subjects_dir /my/subjects/directory --output_dir /my/output/directory --fornix\n```\n\n- Run the QC pipeline plus the shape analysis pipeline for all subjects found in `/my/subjects/directory`:\n\n```bash\nrun_fsqc --subjects_dir /my/subjects/directory --output_dir /my/output/directory --shape\n```\n\n- Run the QC pipeline plus the outlier detection module for all subjects found in `/my/subjects/directory`:\n\n```bash\nrun_fsqc --subjects_dir /my/subjects/directory --output_dir /my/output/directory --outlier\n```\n\n- Run the QC pipeline plus the outlier detection module with a user-specific table of normative values for all subjects found in `/my/subjects/directory`:\n\n```bash\nrun_fsqc --subjects_dir /my/subjects/directory --output_dir /my/output/directory --outlier --outlier-table /my/table/with/normative/values.csv\n```\n\n- Note that the `--screenshots`, `--fornix`, `--shape`, and `--outlier` (and other) arguments can also be used in conjunction.\n\n### As a Python package\n\nAs an alternative to their command-line usage, the fsqc scripts can also be run\nwithin a pure Python environment, i.e. installed and imported as a Python package.\n\nUse `import fsqc` (or sth. equivalent) to import the package within a\nPython environment, and use the `run_fsqc` function from the `fsqc` module to\nrun an analysis.\n\nIn its most basic form:\n\n```python\nimport fsqc\nfsqc.run_fsqc(subjects_dir='/my/subjects/dir', output_dir='/my/output/dir')\n```\n\nSpecify subjects as a list:\n\n```python\nimport fsqc\nfsqc.run_fsqc(subjects_dir='/my/subjects/dir', output_dir='/my/output/dir', subjects=['subject1', 'subject2', 'subject3'])\n```\n\nAnd as a more elaborate example:\n\n```python\nimport fsqc\nfsqc.run_fsqc(subjects_dir='/my/subjects/dir', output_dir='/my/output/dir', subject_file='/my/subjects/file.txt', screenshots_html=True, surfaces_html=True, skullstrip_html=True, fornix_html=True, hypothalamus_html=True, hippocampus_html=True, hippocampus_label=\"T1.v21\", shape=True, outlier=True)\n```\n\n\nCall `help(fsqc.run_fsqc)` for further usage info and additional options.\n\n### As a Docker image\n\nWe provide configuration files that can be used to create a Docker or\nSingularity image for the fsqc scripts. Documentation can be found on the\n[Docker](docker/Docker.md) and [Singularity](singularity/Singularity.md) pages.\n\n___\n\n## Installation\n\n### Installation as a Python package\n\nUse:\n\n```bash\npip install fsqc\n```\n\nto install the fsqc package and all of its dependencies. This is the recommended\nway of installing the package, and allows for both command-line execution and\nexecution as a Python function. We also recommend to do this installation within\na Python virtual environment, which can be created and activated as follows:\n\n```bash\nvirtualenv /path/to/my/virtual/environment\nsource /path/to/my/virtual/environment/bin/activate\n```\n\n### Installation from GitHub\n\nUse the following code to download, build and install the fsqc package from its\nGitHub repository into your local Python package directory:\n\n```bash\npip install git+https://github.com/deep-mi/fsqc.git\n```\n\nThis can be useful if you want to install a particular branch - such as the `dev`\nbranch in the following example:\n\n```bash\npip install git+https://github.com/deep-mi/fsqc.git@dev\n```\n\n### Download from GitHub\n\nThis software can also be downloaded from its GitHub repository at `https://github.com/Deep-MI/fsqc`,\nor cloned directly via `git clone https://github.com/Deep-MI/fsqc`.\n\nThe `run_fsqc` script will then be executable from the command line, as\ndetailed above. Note, however, that the required dependencies will have to be\ninstalled manually. See the [requirements](#requirements) section for\ninstructions.\n\n\n___\n\n## Requirements\n\n- At least one structural MR image that was processed with Freesurfer 6.0, 7.x,\n  or FastSurfer 1.1 or later (including the surface pipeline).\n\n- A Python version >= 3.8 is required to run this script.\n\n- Required packages include (among others) the nibabel and skimage package for\n  the core functionality, plus the matplotlib, pandas, and transform3d\n  packages for some optional functions and modules. See the `requirements.txt`\n  file for a complete list. Use `pip install -r requirements.txt` to install\n  these packages.\n\n- If installing the toolbox as a Python package or if using the Docker image,\n  all required packages will be installed automatically and manual installation\n  as detailed above will not be necessary.\n\n- This software has been tested on Ubuntu 20.04 and 22.04.\n\n- A working [FreeSurfer](https://freesurfer.net) installation (version 6 or\n  newer) is required for running the 'shape' module of this toolbox. Also make\n  sure that FreeSurfer is sourced (i.e., `FREESURFER_HOME` is set as an\n  environment variable) before running an analysis.\n\n___\n\n## Known issues\n\n- Aborted / restarted recon-all runs: the program will analyze recon-all\n  logfiles, and may fail or return erroneous results if the logfile is\n  appended by multiple restarts of recon-all runs. Ideally, the logfile should\n  therefore consist of just a single, successful recon-all run.\n\n___\n\n## Authors\n\n- fsqc toolbox: Kersten Diers, Tobias Wolff, and Martin Reuter.\n- Freesurfer QA Tools: David Koh, Stephanie Lee, Jenni Pacheco, Vasanth Pappu,\n  and Louis Vinke.\n- lapy and brainprint toolboxes: Martin Reuter.\n\n___\n\n## Citations\n\n- Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; 2017;\n  MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen\n  Sites; PLOS ONE 12(9):e0184661; doi:10.1371/journal.pone.0184661.\n\n- Wachinger C, Golland P, Kremen W, Fischl B, Reuter M; 2015; BrainPrint: a\n  Discriminative Characterization of Brain Morphology; Neuroimage: 109, 232-248;\n  doi:10.1016/j.neuroimage.2015.01.032.\n\n- Reuter M, Wolter FE, Shenton M, Niethammer M; 2009; Laplace-Beltrami\n  Eigenvalues and Topological Features of Eigenfunctions for Statistical Shape\n  Analysis; Computer-Aided Design: 41, 739-755; doi:10.1016/j.cad.2009.02.007.\n\n- Potvin O, Mouiha A, Dieumegarde L, Duchesne S, & Alzheimer's Disease\n  Neuroimaging Initiative; 2016; Normative data for subcortical regional volumes\n  over the lifetime of the adult human brain; Neuroimage: 137, 9-20; doi.org/10.1016/j.neuroimage.2016.05.016\n\n___\n\n## License\n\nThis software is licensed under the MIT License, see associated LICENSE file\nfor details.\n\nCopyright (c) 2019 Image Analysis Group, DZNE e.V.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/gaia",
            "repo_link": "https://gitlab.dlr.de/pf-plp/gaia-group",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/gasnetsim",
            "repo_link": "https://jugit.fz-juelich.de/iek-10/public/simulation/gasnetsim",
            "readme": "![](https://jugit.fz-juelich.de/iek-10/public/simulation/gasnetsim/-/raw/main/docs/GasNetSim_Logo.svg)\n\n[![PyPI version](https://img.shields.io/pypi/v/GasNetSim.svg?color=orange)](https://pypi.org/project/GasNetSim/)\n![Python Versions](https://img.shields.io/badge/python-3.9%20|%203.10%20|%203.11%20|%203.12-blue)\n[![License: MPL 2.0](https://img.shields.io/badge/License-MPL%202.0-brightgreen.svg)](https://opensource.org/licenses/MPL-2.0)\n[![DOI:10.1109/OSMSES54027.2022.9769148](https://zenodo.org/badge/DOI/10.1109/OSMSES54027.2022.9769148.svg)](https://doi.org/10.1109/OSMSES54027.2022.9769148)\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/git/https%3A%2F%2Fjugit.fz-juelich.de%2Fiek-10%2Fpublic%2Fsimulation%2Fgasnetsim/HEAD)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n# **GasNetSim**\n\n*GasNetSim* is a simulation package designed for gas network steady-state simulation.\nIt supports the steady-state natural gas network simulations with different gas mixture\ncompositions, thus enabling accurate analysis of the impacts of hydrogen injection on the gas network.  \nMoreover, users have the flexibility to modify this tool and implement their own desired\ngas mixture modeling approaches.\nFuture work will be carried out to include gas storage units and to take into account\nthe dynamic behavior of the gas network so that short-term simulations can be performed.\n\n## Installation\n\nCurrently, it is only supported using source files. Using following commands to install the package in editable mode.\n\n- ``pip install -e .``\n- ``pip install -r ./requirements.txt``\n\n## License\n\nThe project is released under the terms of the [MPL 2.0](https://mozilla.org/MPL/2.0/).\n\n## Dependencies\n\n<!-- Dependencies -->\n\n- ``numpy``>=1.19.2\n- ``matplotlib``>=3.3.2\n- ``scipy``>=1.5.2\n- ``pandas``>=1.1.3\n- ``pytest``>=6.2.5\n- ``fluids``>=0.1.86\n- ``pint``>=0.18\n- ``setuptools``>=60.9.3\n- ``requests``>=2.25.1\n- ``pyparsing``~=3.0.7\n- ``cantera``~=3.0.0\n- ``thermo``~=0.2.23\n- ``tqdm``>=4.64.1\n- ``seaborn``>=0.12.2\n- ``networkx``~=3.1\n\n<!-- End Dependencies -->\n\nFor the ``thermo`` package, the version used in this repo is 0.1.40. Because there are some changes\nand new features included in the newer versions. The source files of the `thermo` package is directly\nstored in this repo. It will be updated in the future.\n\n[//]: # (## Discussion)\n\n[//]: # ()\n\n[//]: # (You can connect with the community in a variety of ways...)\n\n[//]: # ()\n\n[//]: # (- [Mailing list]&#40;https://lists.lfenergy.org/g/xxxx-discussion&#41;)\n\n[//]: # (- [#{{**PROJECT-NAME**}} channel on LF Energy Slack]&#40;https://slack.lfenergy.org&#41;)\n\n[//]: # (- Other communication channels, e.g. Discord, Slack, Skype, Mattermost, FZJ Rocket Chat, ...)\n\n[//]: # (## Contributing)\n\n[//]: # ()\n\n[//]: # (_**TODO** Provide contributing guidelines here or point to a_)\n\n[//]: # (_[CONTRIBUTING.md]&#40;CONTRIBUTING.md&#41; file if the contributing guidelines require_)\n\n[//]: # (_more than just a few lines._)\n\n## Reporting Issues\n\nTo report a problem, you can open an\n[issue](https://jugit.fz-juelich.de/iek-10/public/simulation/gasnetsim/-/issues)\nin repository against a specific workflow. If the issue is sensitive in nature or\na security related issue, please do not report in the issue tracker but instead\nemail [Yifei Lu](yi.lu@fz-juelich.de).\n",
            "project_id": "5755"
        },
        {
            "software_organization": "https://helmholtz.software/software/geomultisens",
            "repo_link": "https://git.gfz-potsdam.de/geomultisens",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/gfzrnx",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/ginkgo",
            "repo_link": "https://github.com/ginkgo-project/ginkgo/",
            "readme": "  <p align=\"center\"><img src=\"/assets/logo.png\" alt=\"Ginkgo\" width=\"60%\" height=\"60%\"></p>\n\n<div align=\"center\">\n\n[![License](https://img.shields.io/github/license/ginkgo-project/ginkgo.svg)](./LICENSE)|[![c++ standard](https://img.shields.io/badge/c%2B%2B-17-blue.svg)](https://en.wikipedia.org/wiki/C%2B%2B#Standardization)|[![Documentation](https://img.shields.io/badge/Documentation-latest-blue.svg)](https://ginkgo-project.github.io/ginkgo-generated-documentation/doc/develop/)|[![DOI](https://joss.theoj.org/papers/10.21105/joss.02260/status.svg)](https://doi.org/10.21105/joss.02260)\n|:-:|:-:|:-:|:-:|\n\n\n[![Build status](https://gitlab.com/ginkgo-project/ginkgo-public-ci/badges/develop/pipeline.svg)](https://gitlab.com/ginkgo-project/ginkgo-public-ci/-/pipelines?page=1&scope=branches&ref=develop)|[![OSX-build](https://github.com/ginkgo-project/ginkgo/actions/workflows/osx.yml/badge.svg)](https://github.com/ginkgo-project/ginkgo/actions/workflows/osx.yml)|[![codecov](https://codecov.io/gh/ginkgo-project/ginkgo/branch/develop/graph/badge.svg)](https://codecov.io/gh/ginkgo-project/ginkgo)|[![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=ginkgo-project_ginkgo&metric=sqale_rating)](https://sonarcloud.io/dashboard?id=ginkgo-project_ginkgo)|[![Reliability Rating](https://sonarcloud.io/api/project_badges/measure?project=ginkgo-project_ginkgo&metric=reliability_rating)](https://sonarcloud.io/dashboard?id=ginkgo-project_ginkgo)|[![CDash dashboard](https://img.shields.io/badge/CDash-Access-blue.svg)](https://my.cdash.org/index.php?project=Ginkgo+Project)\n|:-:|:-:|:-:|:-:|:-:|:-:|\n\n</div>\n\n\nGinkgo is a high-performance numerical linear algebra library for many-core systems, with a\nfocus on solution of sparse linear systems. It is implemented using modern C++\n(you will need an at least C++17 compliant compiler to build it), with GPU kernels\nimplemented for NVIDIA, AMD and Intel GPUs.\n\n---\n\n**[Prerequisites](#prerequisites)** |\n**[Building Ginkgo](#building-and-installing-ginkgo)** |\n**[Tests, Examples, Benchmarks](#tests-examples-and-benchmarks)** |\n**[Bug reports](#bug-reports-and-support)** |\n**[Licensing](#licensing)** |\n**[Contributing](#contributing-to-ginkgo)** |\n**[Citing](#citing-ginkgo)**\n\n\n# Prerequisites\n\n### Linux and Mac OS\n\nFor Ginkgo core library:\n\n*   _cmake 3.16+_\n*   C++17 compliant compiler, one of:\n    *   _gcc 7+_\n    *   _clang 5+_\n    *   _Intel compiler 2019+_\n    *   _Apple Clang 15.0_ is tested. Earlier versions might also work.\n    *   _Cray Compiler 14.0.1+_\n    *   _NVHPC Compiler 22.7+_\n\nThe Ginkgo CUDA module has the following __additional__ requirements:\n\n*   _cmake 3.18+_ (If CUDA was installed through the NVIDIA HPC Toolkit, we require _cmake 3.22+_)\n*   _CUDA 11.0+_ or _NVHPC Package 22.7+_\n*   Any host compiler restrictions your version of CUDA may impose also apply\n    here. For the newest CUDA version, this information can be found in the\n    [CUDA installation guide for Linux](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html)\n    or [CUDA installation guide for Mac Os X](https://docs.nvidia.com/cuda/cuda-installation-guide-mac-os-x/index.html)\n\nThe Ginkgo HIP module has the following __additional__ requirements:\n\n* _ROCm 4.5+_\n* the HIP, hipBLAS, hipSPARSE, hip/rocRAND and rocThrust packages compiled with the ROCm backend\n* if the hipFFT package is available, it is used to implement the FFT LinOps.\n* _cmake 3.21+_\n\nThe Ginkgo DPC++(SYCL) module has the following __additional__ requirements:\n\n* _oneAPI 2023.1+_\n* Set `dpcpp` or `icpx` as the `CMAKE_CXX_COMPILER`\n* The following oneAPI packages should be available:\n    * oneMKL\n    * oneDPL\n\nThe Ginkgo MPI module has the following __additional__ requirements:\n\n* MPI 3.1+, ideally GPU-Aware, for best performance\n\nIn addition, if you want to contribute code to Ginkgo, you will also need the\nfollowing:\n\n*   _clang-format 14_ (downloaded automatically by `pre-commit`)\n*   _clang-tidy_ (optional, when setting the flag `-DGINKGO_WITH_CLANG_TIDY=ON`)\n*   _iwyu_ (Include What You Use, optional, when setting the flag `-DGINKGO_WITH_IWYU=ON`)\n\n### Windows\n\n*   _cmake 3.16+_\n*   C++17 compliant 64-bit compiler:\n    *   _MinGW : gcc 7+_\n    *   _Microsoft Visual Studio : VS 2019+_\n\nThe Ginkgo CUDA module has the following __additional__ requirements:\n\n*   _CUDA 11.0+_\n*   _Microsoft Visual Studio_\n*   Any host compiler restrictions your version of CUDA may impose also apply\n    here. For the newest CUDA version, this information can be found in the\n    [CUDA installation guide for Windows](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html)\n\nThe Ginkgo OMP module has the following __additional__ requirements:\n*  _MinGW_\n\nIn these environments, two problems can be encountered, the solution for which is described in the\n[windows section in INSTALL.md](INSTALL.md#building-ginkgo-in-windows):\n* `ld: error: export ordinal too large` needs the compilation flag `-O1`\n* `cc1plus.exe: out of memory allocating 65536 bytes` requires a modification of the environment\n\n__NOTE:__ Some restrictions will also apply on the version of C and C++ standard\nlibraries installed on the system. This needs further investigation.\n\n# Building and Installing Ginkgo\n\nTo build Ginkgo, you can use the standard CMake procedure.\n\n```sh\nmkdir build; cd build\ncmake -G \"Unix Makefiles\" .. && cmake --build .\ncmake --install .\n```\n\nBy default, `GINKGO_BUILD_REFERENCE` is enabled. You should be able to run\nexamples with this executor. By default, Ginkgo tries to enable the relevant\nmodules depending on your machine environment (present of CUDA, ...). You can\nalso explicitly compile with the OpenMP, CUDA, HIP or DPC++(SYCL) modules enabled to\nrun the examples with these executors.\n\nPlease refer to the [Installation page](./INSTALL.md) for more details.\n\nTip: After installation, in your CMake project, Ginkgo can be added with `find_package(Ginkgo)` and the the target that is exported is `Ginkgo::ginkgo`.\nAn example can be found in the [`test_install`](test/test_install/CMakeLists.txt).\n\n# Tests, Examples and Benchmarks\n\n### Testing\n\nGinkgo does comprehensive unit tests using Google Tests. These tests are enabled by default and can be disabled if necessary by passing the `-DGINKGO_BUILD_TESTS=NO` to the cmake command. More details about running tests can be found in the [TESTING.md page](./TESTING.md).\n\n### Running examples\n\nVarious examples are available for you to understand and play with Ginkgo within the `examples/` directory. They can be compiled by passing the `-DGINKGO_BUILD_EXAMPLES=ON` to the cmake command. Each of the examples have commented code with explanations and this can be found within the [online documentation](https://ginkgo-project.github.io/ginkgo-generated-documentation/doc/develop/Examples.html).\n\n### Benchmarking\n\nA unique feature of Ginkgo is the ability to run benchmarks and view your results\nwith the help of the [Ginkgo Performance Explorer (GPE)](https://ginkgo-project.github.io/gpe/).\n\nMore details about this can be found in the [BENCHMARKING.md page](./BENCHMARKING.md)\n\n# Bug reports and Support\n\nIf you have any questions about using Ginkgo, please use [Github discussions](https://github.com/ginkgo-project/ginkgo/discussions).\n\nIf you would like to request a feature, or have encountered a bug, please [create an issue](https://github.com/ginkgo-project/ginkgo/issues/new). Please be sure to describe your problem and provide as much information as possible.\n\nYou can also send an email to [Ginkgo's main email address](mailto:ginkgo.library@gmail.com).\n\n# Licensing\n\nGinkgo is available under the [3-clause BSD license](LICENSE). All contributions\nto the project are added under this license.\n\nDepending on the configuration options used when building Ginkgo, third party\nsoftware may be pulled as additional dependencies, which have their own\nlicensing conditions. Refer to [ABOUT-LICENSING.md](ABOUT-LICENSING.md) for\ndetails.\n\n# Contributing to Ginkgo\n\nWe are glad that that you would like to contribute to Ginkgo and we are happy to help you with any questions you may have.\n\nIf you are contributing for the first time, please add yourself to the list of external contributors with the following info\n\n``` text\nName Surname <email@domain> Institution(s)\n```\n\n#### Declaration\n\nGinkgo's source is distributed with a BSD-3 clause license. By contributing to Ginkgo and adding yourself to the contributors list, you agree to the following statement (also in [contributors.txt](contributors.txt)):\n\n``` text\nI hereby place all my contributions in this codebase under a BSD-3-Clause\nlicense, as specified in the repository's LICENSE file.\n```\n\n#### Contribution Guidelines\n\nWhen contributing to Ginkgo, to ease the review process, please follow the guidelines mentioned in [CONTRIBUTING.md](CONTRIBUTING.md).\n\nIt also contains other general recommendations such as writing proper commit messages, understanding Ginkgo's library design, relevant C++ information etc.\n\n\n# Citing Ginkgo\n\nThe main Ginkgo paper describing Ginkgo's purpose, design and interface is\navailable through the following reference:\n\n``` bibtex\n@article{ginkgo-toms-2022,\ntitle = {{Ginkgo: A Modern Linear Operator Algebra Framework for High Performance Computing}},\nvolume = {48},\ncopyright = {All rights reserved},\nissn = {0098-3500},\nshorttitle = {Ginkgo},\nurl = {https://doi.org/10.1145/3480935},\ndoi = {10.1145/3480935},\nnumber = {1},\nurldate = {2022-02-17},\njournal = {ACM Transactions on Mathematical Software},\nauthor = {Anzt, Hartwig and Cojean, Terry and Flegar, Goran and Göbel, Fritz and Grützmacher, Thomas and Nayak, Pratik and Ribizel, Tobias and Tsai, Yuhsiang Mike and Quintana-Ortí, Enrique S.},\nmonth = feb,\nyear = {2022},\nkeywords = {ginkgo, healthy software lifecycle, High performance computing, multi-core and manycore architectures},\npages = {2:1--2:33}\n}\n```\n\nFor more information on topical subjects, please refer to the [CITING.md\npage](CITING.md).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/gipptools",
            "repo_link": "https://git.gfz-potsdam.de/gipp/gipptools",
            "readme": "// GIPPtools - A collection of programs for (seismic) data pre-processing.\n//\n// Copyright (C) 2021-2022 Christof Lendl (GFZ Potsdam, lendl@gfz-potsdam.de)\n//\n// This work is licensed under the Creative Commons Attribution 4.0\n// International License. To view a copy of this license, visit\n// http://creativecommons.org/licenses/by/4.0/./\n\n\n// Note: This README file is displayed by GitLab when people browse the\n//       GIPPtools project. It is not intended for usage elsewhere!\n//\n//       Hence, optimize the AsciiDoc formatting for display by the GitLab\n//       renderer and nothing else. Don't worry about PDF, DocBook, EPUB\n//       or other output formats!\n\n\n:author: Christof Lendl\n:email: lendl@gfz-potsdam.de\n:description: Readme file for the GIPPtools repository\n:keywords: seismology, seismic, GIPP, data logger, EDR, EDL, Cube, miniSEED, SEG-Y\n:!showtitle:\n:imagesdir: ./src/docs/images\n\n\nimage::gipptools-logo.svg[GIPPtools Logo, align=\"center\"]\n\n'''\n\n[.text-center]\n--\nimage:https://img.shields.io/badge/Source-Apache%202.0-blue.svg[link=\"https://opensource.org/licenses/Apache-2.0\"]\nimage:https://img.shields.io/badge/Documentation-CC%20BY%204.0-blue.svg[link=\"https://creativecommons.org/licenses/by/4.0/\"]\nimage:https://zenodo.org/badge/DOI/10.5281/zenodo.4707611.svg[link=\"https://doi.org/10.5281/zenodo.4707611\"]\n--\n\n'''\n\nThe _GIPPtools_ software utilities aid with initial processing of recorded\ndata supporting users that borrow instruments from the Geophysical Instrument\nPool Potsdam (https://www.gfz-potsdam.de/gipp[GIPP]).\nAll programs in the _GIPPtools_ collection are designed to work with native\nfiles produced by _DSS-Cube/Data-Cube^3^_ recorders and with miniSEED files\nwritten by _EDR-209/210_ and _PR6-24_ Portable Field Recorder.\nHowever, the utilities should work with miniSEED or Cube files produced by\nother instruments or software as well!\n\nThe programs can help you to \"`manage`\" your recorded data and to prepare the\ndataset for import into whatever processing system you use for further\nscientific analysis.\nYou can use the utilities, among other things, to convert, re-organize and\ncut out (seismic) data from miniSEED and Cube data files.\n\n\n== Utilities\n\nThe following programs are part of the _GIPPtools_ collection:\n\n[horizontal]\n_cube2ascii_::   Convert Cube recordings to various ASCII text formats.\n_cube2mseed_::   Convert Cube recordings to miniSEED format.\n_cube2segy_::    Convert Cube recordings to SEG-Y format.\n_cubeevent_::    List events captured by the Cube _event recorder_ hardware.\n_cubeinfo_::     Inspect and summarize the content of Cube files.\n_mseed2ascii_::  Convert miniSEED files to various ASCII text formats.\n_mseed2mseed_::  Modify header fields of miniSEED records.\n_mseed2pdas_::   Convert miniSEED files to PDAS format.\n_mseed2segy_::   Convert miniSEED files to SEG-Y format.\n_mseedcut_::     Cut out data segments from miniSEED files.\n_mseedinfo_::    Inspect and summarize the content of miniSEED files.\n_mseedrecover_:: Recover miniSEED records from damaged files and disks.\n_mseedrename_::  Batch rename miniSEED files using a template.\n\n\n== Requirements\n\nTwo requirements must be met before you can use the utilities of the\n_GIPPtools_ package:\n\n1. A working Java virtual machine (also called a _Java Runtime Environment_\n   or simply _JRE_) supporting *Java 8* or newer!\n+\nTIP:  You can download and install a _JRE_ from e.g. the\n      https://adoptium.net/[Adoptium] site if your operating\n      system dos not already provide an adequate runtime.\n\n2. You need some console or terminal window on your computer where you can\n   type commands. None of the _GIPPtools_ programs utilizes a graphical user\n   interface. They all take their parameters and options exclusively from\n   the command line!\n\n\n== Installation\n\nTo get started with the _GIPPtools_, you can either just download a ready-made\nbinary distribution _OR_ you can manually build the release yourself.\n\nMost people are probably fine with just using the ready-made distribution!\n\n\n=== Ready-made Binary Distribution\n\nTwo binary distributions variants available. One is for _Unix_ style\noperating systems such as _Linux_, _macOS_, _Solaris_, etc. The other one\nis for the _Microsoft Windows_ family. You can download either one from\nthe following locations:\n\n* The https://git.gfz-potsdam.de/gipp/gipptools/-/releases[Releases] subpage\n  of this GitLab repository.\n* The _Software_ section of the https://www.gfz-potsdam.de/gipp[GIPP] webpage.\n* Via the _GIPPtools_ https://doi.org/10.5281/zenodo.4707611[DOI].\n\nTIP:  The Unix distribution is provided as gzipped TAR archive file. Use\n      the `gunzip` program to decompress the archive and extract files\n      with the `tar` command afterwards. +\n      The _GIPPtools_ Windows release is published as ZIP file, which should\n      unzip by double-clicking on the icon.\n\nOnce downloaded and unpacked the _GIPPtools_ are pretty much ready for use.\nThe link:src/docs/asciidoc/articles/Install.adoc[Install] document inside\nthe doc subdirectory contains more detailed instructions.\n\n\n=== Manual Build\n\nFor the steps necessary to manually build the _GIPPtools_, please refer to\nthe link:./BUILD.adoc[BUILD] document in the repository.\n\n\n== Documentation\n\nOnce the _GIPPtools_ are installed, all documentation can be found inside the\nlink:src/docs/asciidoc/[doc] subdirectory of the installation directory. It\nis not fully developed yet, nevertheless should get you started.\n\nTIP:  While all documentation is available in _HTML_ and _PDF_ format,\n      the _GIPPtools_ distribution for Unix operating systems contains an\n      additional copy of the documentation set, ready for display by the\n      standard Unix `man` command.\n\nAlso part of the documentation are some link:src/docs/examples/[example]\nfiles you might want to use as templates for your own projects.\n\n\n== Bug Reports or Feature Requests\n\nIf you encounter a bug, misfeature, or missing feature in _GIPPtools_,\nthe preferred reporting method is by filing an\nhttps://git.gfz-potsdam.de/gipp/gipptools/-/issues[issue] in this GitLab\nrepository.\n\nPlease do not hesitate to file a bug report, even if you think the problem\nis already known, or aren’t sure of the details. Just provide as much\ninformation as you have. It would be nice if you could also include the\n_GIPPtools_ release number you are using as well as the computer platform\nyou are running it on.\n\nYou should also file issues if the documentation is out of date or unclear.\n\n\n== License\n\n- The source code and binaries of the _GIPPtools_ project are made available\n  under the terms of the _Apache License Version 2.0_.\n\n- Project documentation and other media files are license under the _Creative\n  Commons Attribution 4.0 International License_.\n\n\n// --- fin --\n",
            "project_id": "1147"
        },
        {
            "software_organization": "https://helmholtz.software/software/glaes",
            "repo_link": "https://github.com/FZJ-IEK3-VSA/geokit",
            "readme": "﻿|                                                          master                                                           |                                                          dev                                                           |\n| :-----------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------: |\n| [![Build Status](https://travis-ci.com/FZJ-IEK3-VSA/geokit.svg?branch=master)](https://travis-ci.com/FZJ-IEK3-VSA/geokit) | [![Build Status](https://travis-ci.com/FZJ-IEK3-VSA/geokit.svg?branch=dev)](https://travis-ci.com/FZJ-IEK3-VSA/geokit) |\n\n---\n\n<a href=\"https://www.fz-juelich.de/en/iek/iek-3\"><img src=\"https://github.com/FZJ-IEK3-VSA/README_assets/blob/main/FJZ_IEK-3_logo.svg?raw=True\" alt=\"Forschungszentrum Juelich Logo\" width=\"300px\"></a> \n\n# GeoKit - **Geo**spatial tool**kit** for Python\n\nGeoKit communicates directly with functions and objects within the Geospatial Data Abstraction Library (<a href=\"www.gdal.org\">GDAL</a>) and exposes them in such a way that is particularly useful for programmatic general purpose geospatial analyses.\nIt gives low overhead control of fundamental operations; such as reading, writing, and mutating geospatial data sets, manipulating and translating geometries, warping and resampling raster data, and much more.\nVia the RegionMask object, GeoKit even allows for seamless integration of information expressed across multiple geospatial datasets in many formats and reference systems into the context of a single region.\n\nGeoKit is not intended to replace the GDAL library, as only very small subset of GDAL's capabilities are exposed. Nor is it intended to compete with other libraries with similar functionalities.\nInstead GeoKit evolved in an ad hoc manner in order to realize the Geospatial Land Eligibility for Energy Systems (<a href=\"https://github.com/FZJ-IEK3-VSA/glaes\">GLAES</a>) model which is intended for rapid land eligibility analyses of renewable energy systems and is also available on GitHub.\nNevertheless, GeoKit quickly emerged as a general purpose GIS toolkit with capabilities far beyond computing land eligibility.\nTherefore, it is our pleasure to offer it to anyone who is interested in its use.\n\n[![DOI](https://zenodo.org/badge/114900977.svg)](https://zenodo.org/badge/latestdoi/114900977)\n\n## Features\n\n- Direct exposure of functions and objects in the GDAL library\n- Reading, writing, and manipulating raster and vector datasets\n- Translation between data formats and projection systems\n- Direct conversion of raster data into NumPy matrices\n\n## Installation\n\n### Installation via conda-forge\nThe easiest way to install GeoKit into a new environment is from `conda-forge` with:\n\n```bash\nconda create -n geokit -c conda-forge geokit\n```\n\nor into an existing environment with:\n```bash\nconda install -c conda-forge geokit\n```\n\n### Installation from a local folder\n\n1. First clone a local copy of the repository to your computer, and move into the created directory\n\n```\ngit clone https://github.com/FZJ-IEK3-VSA/geokit.git\ncd geokit\n```\n\n1. (Alternative) If you want to use the 'dev' branch (or another branch) then use:\n\n```\ngit checkout dev\n```\n\n2. When using [Anaconda](https://www.anaconda.com/) / [(Micro-)Mamba](https://mamba.readthedocs.io/en/latest/) (recommended), GeoKit should be installable to a new environment with:\n\n```\nconda env create --file requirements.yml\nconda activate geokit\npip install . --no-deps\n```\n\n2. (Alternative) Or into an existing environment with:\n\n```\nconda env update --file requirements.yml -n <ENVIRONMENT-NAME>\nconda activate geokit\npip install . --no-deps\n```\n\n2. (Alternative) If you want to install GeoKit in editable mode, and also with jupyter notebook and with testing functionalities use:\n\n```\nconda env create --file requirements-dev.yml\nconda activate geokit\npip install . --no-deps -e\n```\n\n## Examples\n\nSee the [Examples page](Examples/)\n\n## Docker\n\nWe are trying to get GeoKit to work within a Docker container. Try it out!\n\n- First pull the image with:\n\n```bash\ndocker pull sevberg/geokit:latest\n```\n\n- You can then start a basic python interpreter with:\n\n```bash\ndocker run -it sevberg/geokit:latest -c \"python\"\n```\n\n- Or you can start a jupyter notebook using:\n\n```bash\ndocker run -it \\\n    -p 8888:8888 \\\n    sevberg/geokit:latest \\\n    -c \"jupyter notebook --ip='*' --port=8888 --no-browser --allow-root\"\n```\n\n- Which can then be connected to at the address \"localhost:8888:<API-KEY>\"\n- The API Key can be found from the output of the earlier command\n\n* Finally, you might want to mount a volume to access geospatial data. For this you can use:\n\n```bash\ndocker run -it \\\n    --mount target=/notebooks,type=bind,src=<PATH-TO-DIRECTORY> \\\n    -p 8888:8888 \\\n    sevberg/geokit:latest  \\\n    -c \"jupyter notebook --notebook-dir=/notebooks --ip='*' --port=8888 --no-browser --allow-root\"\n```\n\n## License\n\nMIT License\n\nActive Developers: Julian Schönau, Rachel Maier, Christoph Winkler, Shitab Ishmam, David Franzmann, Julian Belina, Noah Pflugradt, Heidi Heinrichs, Jochen Linßen, Detlef Stolten \n\nAlumni: David Severin Ryberg, Martin Robinius, Stanley Risch\n\nYou should have received a copy of the MIT License along with this program.  \nIf not, see <https://opensource.org/licenses/MIT>\n\n## About Us\n\n<a href=\"https://www.fz-juelich.de/en/iek/iek-3\"><img src=\"https://github.com/FZJ-IEK3-VSA/README_assets/blob/main/iek3-square.png?raw=True\" alt=\"Institute image IEK-3\" width=\"280\" align=\"right\" style=\"margin:0px 10px\"/></a>\n\nWe are the <a href=\"https://www.fz-juelich.de/en/iek/iek-3\">Institute of Energy and Climate Research - Techno-economic Systems Analysis (IEK-3)</a> belonging to the <a href=\"https://www.fz-juelich.de/en\">Forschungszentrum Jülich</a>. Our interdisciplinary department's research is focusing on energy-related process and systems analyses. Data searches and system simulations are used to determine energy and mass balances, as well as to evaluate performance, emissions and costs of energy systems. The results are used for performing comparative assessment studies between the various systems. Our current priorities include the development of energy strategies, in accordance with the German Federal Government’s greenhouse gas reduction targets, by designing new infrastructures for sustainable and secure energy supply chains and by conducting cost analysis studies for integrating new technologies into future energy market frameworks.\n\n## Acknowledgment\n\nThis work was supported by the Helmholtz Association under the Joint Initiative [\"Energy System 2050   A Contribution of the Research Field Energy\"](https://www.helmholtz.de/en/research/energy/energy_system_2050/).\n\n<a href=\"https://www.helmholtz.de/en/\"><img src=\"https://www.helmholtz.de/fileadmin/user_upload/05_aktuelles/Marke_Design/logos/HG_LOGO_S_ENG_RGB.jpg\" alt=\"Helmholtz Logo\" width=\"200px\" style=\"float:right\"></a>\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/global-benchmark-database-gbd",
            "repo_link": "https://github.com/Udopia/gbd",
            "readme": "# Global Benchmark Database (GBD)\n\n[![DOI](https://zenodo.org/badge/141396410.svg)](https://zenodo.org/doi/10.5281/zenodo.10213943)\n\nGBD is a comprehensive suite of tools for provisioning and sustainably maintaining benchmark instances and their metadata for empirical research on hard algorithmic problem classes.\nFor an introduction to the GBD concept, the underlying data model, and specific use cases, please refer to our [2024 SAT Tool Paper](https://doi.org/10.4230/LIPIcs.SAT.2024.18).\n\n## GBD contributes data to your algorithmic evaluations\n\nGBD provides benchmark instance identifiers, feature extractors, and instance transformers for hard algorithmic problem domains, now including propositional satisfiability (SAT) and optimization (MaxSAT), and pseudo-Boolean optimization (PBO).\n\n## GBD solves several problems\n\n- benchmark instance identification\n- identification of equivalence classes of benchmark instances\n- distribution of benchmark instances and benchmark metadata\n- initialization and maintenance of instance feature databases\n- transformation algorithms for benchmark instances\n\nGBD provides an extensible set of problem domains, feature extractors, and instance transformers.\nFor a description of those currently supported, see the [GBDC documentation](https://udopia.github.io/gbdc/doc/Index.html).\nGBDC is a Python extension module for GBD's performance-critical code (written in C++), maintained in a separate [repository](https://github.com/Udopia/gbdc).\n\n## Installation and Configuration\n\n- Run `pip install gbd-tools`\n- Run `pip install gbdc` (optional, installation of extension module gbdc)\n- Obtain a GBD database, e.g. download [https://benchmark-database.de/getdatabase/meta.db](https://benchmark-database.de/getdatabase/meta.db).\n- Configure your environment by registering paths to databases like this `export GBD_DB=path/to/database1:path/to/database2`.\n- Test the command line interface with the `gbd info` and `gbd --help` commands.\n\n## GBD Interfaces\n\nGBD provides the command-line tool `gbd`, the web interface `gbd serve`, and the Python interface `gbd_core.api.GBD`.\n\n### GBD Command-Line Interface\n\nCentral commands in gbd are those for data access `gbd get` and database initialization `gbd init`.\nSee `gbd --help` for more commands.\nOnce a database is registered in the environment variable `GBD_DB`, the `gbd get` command can be used to access data.\nSee `gbd get --help` for more information.\n`gbd init` provides access to registered feature extractors, such as those provided by the `gdbc` extension module.\nAll initialization routines can be run in parallel, and resource limits can be set per process.\nSee `gbd init --help` for more information.\n\n### GBD Server\n\nThe GBD server can be started locally with gbd serve. Our instance of the GBD server is hosted at [https://benchmark-database.de/](https://benchmark-database.de/).\nYou can download benchmark instances and prebuilt feature databases from there.\n\n### GBD Python Interface\n\nThe GBD Python interface is used by all programs in the GBD ecosystem. Important here is the query command, which returns GBD data in the form of a Pandas dataframe for further analysis, as shown in the following example.\n\n```Python\nfrom gbd_core.api import GBD\nwith GBD(['path/to/database1', 'path/to/database2', ..] as gbd:\n    df = gbd.query(\"family = hardware-bmc\", resolve=['verified-result', 'runtime-kissat'])\n```\n\nScripts and use cases of GBD's Python interface are available on [https://udopia.github.io/gbdeval/](https://udopia.github.io/gbdeval/).\nThe [evaluation demo](https://udopia.github.io/gbdeval/demo_evaluation.html) demonstrates portfolio analysis and subsequent category-wise performance evaluation using the 2023 SAT competition data.\nThe [prediction demo](https://udopia.github.io/gbdeval/demo_prediction.html) demonstrates category prediction from instance features and subsequent feature importance evaluation.\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/gmgpolar",
            "repo_link": "https://github.com/mknaranja/GMGPolar",
            "readme": "GMGPolar\n=======\n\nGMGPolar is a performant geometric multigrid solver using implicit extrapolation to raise the convergence order. It is based on meshes in tensor- or product-format. GMGPolar's focus applications are geometries that can be described by polar or curvilinear coordinates for which suited smoothing procedures have been developed.\n\nIf using GMGPolar, please cite:\n\nM. J. Kühn, C. Kruse, U. Rüde. Implicitly extrapolated geometric multigrid on disk-like domains for the gyrokinetic Poisson equation from fusion plasma applications. Journal of Scientific Computing, 91 (28). Springer (2022). Link: https://link.springer.com/article/10.1007/s10915-022-01802-1\n\nTested plateforms\n-----------------\n\nWorking\n=======\n\n* Linux x86_64 with GNU 9.3.0  compilers.    \n\nObtaining the source code\n-------------------------\n\nThe GmgPolar Solver does not require any external libraries.\nIt is possible to link the code with the sparse direct solver ``MUMPS``.\n\n* ``MUMPS`` is optional. However, it is absolutely recommended if large grids are considered.\n  Otherwise, the nonoptimal backup solver will be used for factorization of the matrices and will\n  slow down the setup phase significantly. To use it, compile the code with option -DGMGPOLAR_USE_MUMPS. \n  It is recommended to use the latest version (currently 5.4.1) but any version ulterior \n  to 5.1.0 should be okay. MUMPS is available freely on demand on the MUMPS consortium \n  website \"mumps-solver.org\".\n\t\nThe installation can be done by typing the following commands in your terminal\n\n    # download the latest stable version\n    # it will create a directory named GMGPolar\n\n    git clone https://github.com/mknaranja/GMGPolar\n\nNow that everything is ready, we can compile the solver.\nEdit the file ``Makefile.in`` so that it reflects your configuration (path to libraries, file \nnames, etc).\n\n\nBuilding the library\n--------------------\n          \nThe build process is done using CMake:\n\n    # Create build directory\n    mkdir -p build && cd build\n    # Configure\n    cmake ..\n    # Build\n    cmake --build .\n\nCurrently, the default build process only supports gnu compiler although Intel compiler\nhas been successfully tested for some configurations.\n\nRunning GmgPolar\n------------\n\nYou can run the solver without having to write a code (as we do in the next section). After building \nthe library, a binary is created called ``./build/gmgpolar_simulation``, it takes parameters directly from command-line.\n\n   \n    # To try GmgPolar on a small problem size, without having to write any code,\n    # ./build/gmgpolar_simulation uses default parameters with a grid 49 x 64.\n\n    ./build/gmgpolar_simulation\n\n    # For more details on the available parameters, see the main.cpp source code.\n    # You can control the number of OpenMP threads used by changing the environment variable.\n    # Note that only MUMPS is parallelized at the moment.\n\n    export OMP_NUM_THREADS=4\n  \n\nExecuting an example\n-------------------------------------------------\n\nOnce the library is built, you can run the examples:\n\n    # the verbose option defines the extent of the output\n\n    ./build/gmgpolar_simulation --verbose 2\n\n    # the option --debug 1 turns on internal debugging and compares the results of the C++ code \n    # with the results from the previous matlab implementation.\n   \n    ./build/gmgpolar_simulation --debug 1\n\n\nIssue tracker\n-------------\nIf you find any bug, didn't understand a step in the documentation, or if you\nhave a feature request, submit your issue on our\n`Issue Tracker`: https://github.com/mknaranja/GMGPolar/issues\nby giving:\n\n- reproducible parameters\n- computing environment (compiler, etc.)\n\n\nRelease Notes\n-------------\n* GmgPolar 1.0\n1) Working multigrid cycle\n2) In-house solver and possibility to link with MUMPS for the smoothing and coarse grid solution\n3) Extrapolation strategies:\n   \n\ta. No extrapolation (--extrapolation 0)\n\n\tb. Default implicit extrapolation (--extrapolation 1)\n\n\tc. Non-default implicit extrapolation with smoothing of all nodes on the finest level [experimental, use with care, convergence cannot be observed with residual] (--extrapolation 2)\n6) Optimization of apply_A / build_rhs / apply_prolongation / build_Asc / apply_Asc_ortho\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/goac",
            "repo_link": "https://iffgit.fz-juelich.de/k.koester/goac",
            "readme": "# GOAC: Global Optimization of Atomistic Configurations by Coulomb Energies\n\nGOAC is a Python-based command line tool to approach optimization of Coulomb energies for crystall structures with configurational disorders, e.g., partial site occupations. GOAC's core consists of serveral Fortran based heurstics that allow for parallelization by OpenMP. Moreover, GOAC can be used to wrap Atomistic Configuration problems to existing software such as Gurobi. Thereby, GOAC is, to the best of our knowledege, at its publication (2024) among the most powerful software for optimizing atomistic configuration problems by Coulomb energies.\n\nDetails on how to use GOAC as command line tool or directly from own Python code can be found in the Documentation PDF file and scientific details are availabe in the corresponding publication under: https://doi.org/10.48550/arXiv.2409.08808\n\n## Installation\n\nInstall a Python3 environment on your system along with a Fortran compiler (e.g., gfortran) and a corresponding OpenMP library.\n\n### Requirements:\n\nThe required external Python packages can be installed for example via pip by:\n```sh\npip install -r requirements.txt\n```\n\nThe requirements contain the licensed package Gurobi and the license should be checked before installation. GOAC can be used completely without Gurobi (do not using the Gurobi solver option) and relying on the internal solvers only. When using Gurobi for optimization (setting Gurobi solver), please follow the offical licensing options, including free academic licenses, under: https://www.gurobi.com/solutions/licensing/\n\n### Compilation of Fortran Code\n\nIf all requirements are satisfied, clone the repository and run the following commands in your copy (in case you want to use another compiler adjust settings accodingly):\n```sh\ncd GOAC\nFC=\"gfortran\" python3 -m numpy.f2py -c GOAC.f90 -m GOAC --backend meson --dep openmp\nFC=\"gfortran\" python3 -m numpy.f2py -c ABCEwald.f90 -m ABCEwald --backend meson --dep openmp\ncd ..\n```\n\n### Test of Installation\n\nTo test your installation, run the following command:\n```sh\npython3 GOAC/ -f LCO.cif -p \"Li*=1.0\" -p \"Co*=3.5\" -p \"O*=-2.0\" -s \"random-mc\" -n 4 -w 1\n```\nDepending on your system you should obtain an optimized cif \"out-0.cif\" and a file \"out-summary.txt\" within a few seconds. For more advanced usage of the GOAC code please have a look at the Documentation PDF file in this repository.\n\n\n## Citing GOAC for your Research\n\nIf you find GOAC helpful for your research, please considere citing the packages GOAC is working with as well as citing the GOAC code directly by the following reference: https://doi.org/10.48550/arXiv.2409.08808\n\n\n## License\n\nGOAC is released under the MIT License. The terms of the license are as follows:\n\nThe MIT License (MIT) \n\nCopyright 2024 GOAC\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
            "project_id": "2291"
        },
        {
            "software_organization": "https://helmholtz.software/software/golem",
            "repo_link": "https://github.com/ajacquey/golem",
            "readme": "<h1 align=\"center\">\n  <br>\n  <a href=\"https://github.com/ajacquey/Golem\"><img src=\"images/golem_logo.png\" alt=\"GOLEM\" width=\"600\"></a>\n  <br>\n  A MOOSE-based application\n  <br>\n</h1>\n\n<h4 align=\"center\">A numerical simulator for modelling coupled THM processes in faulted geothermal reservoirs based on <a href=\"http://mooseframework.org/\" target=\"blank\">MOOSE</a>.</h4>\n\n<p align=\"center\">\n  <a href=\"LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-GPLv3-blue.svg\"\n         alt=\"GitHub License\">\n  </a>\n  <a href=\"https://gitter.im/Golem-Moose/golem\">\n    <img src=\"https://img.shields.io/gitter/room/nwjs/nw.js.svg\"\n         alt=\"Gitter\">\n  </a>\n  <a href=\"https://zenodo.org/record/999401#.Wc5NqBdx1pg\">\n    <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.999401.svg\"\n         alt=\"DOI\">\n  </a>\n</p>\n\n## About\nGOLEM is a numerical simulator for modelling coupled Thermo-Hydro-Mechanical processes in faulted geothermal reservoirs.\nThe simulator is developed by [Antoine Jacquey](http://www.gfz-potsdam.de/en/staff/antoine-jacquey/) <a href=\"https://orcid.org/0000-0002-6259-4305\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a><a href=\"https://github.com/ajacquey/\" target=\"github.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"images/GitHub-Mark-32px.png\" width=\"16\" margin-right=\".5em;\" alt=\"GitHub icon id\"></a> and [Mauro Cacace](http://www.gfz-potsdam.de/en/section/basin-modeling/staff/profil/mauro-cacace/) <a href=\"https://orcid.org/0000-0001-6101-9918\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a><a href=\"https://github.com/mcacace\" target=\"github.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"images/GitHub-Mark-32px.png\" width=\"16\" margin-right=\".5em;\" alt=\"GitHub icon id\"></a> at the [GFZ German Research Centre for Geosciences](http://www.gfz-potsdam.de/en/home/) from the section [Basin Modelling](http://www.gfz-potsdam.de/en/section/basin-modeling/).\n\n\nGOLEM is a MOOSE-based application. Visit the [MOOSE framework](http://mooseframework.org) page for more information.\n\n## Licence\nGOLEM is distributed under the [GNU GENERAL PUBLIC LICENSE v3](https://github.com/ajacquey/Golem/blob/master/LICENSE).\n\n\n## Getting Started\n\n#### Minimum System Requirements\nThe following system requirements are from the MOOSE framework (see [Getting Started](http://mooseframework.inl.gov/getting_started/) for more information):\n* Compiler: C++11 Compliant GCC 4.8.4, Clang 3.4.0, Intel20130607\n* Python 2.7+\n* Memory: 16 GBs (debug builds)\n* Processor: 64-bit x86\n* Disk: 30 GBs\n* OS: UNIX compatible (OS X, most flavors of Linux)\n\n#### 1. Setting Up a MOOSE Installation\nTo install GOLEM, you need first to have a working and up-to-date installation of the MOOSE framework.  \nTo do so, please visit the [Getting Started](http://mooseframework.inl.gov/getting_started/) page of the MOOSE framework and follow the instructions. If you encounter difficulties at this step, you can ask for help on the [MOOSE-users Google group](https://groups.google.com/forum/#!forum/moose-users).\n\n#### 2. Clone GOLEM\nGOLEM can be cloned directly from [GitHub](https://github.com/ajacquey/Golem) using [Git](https://git-scm.com/). In the following, we refer to the directory `projects` which you created during the MOOSE installation (by default `~/projects`):  \n\n    cd ~/projects\n    git clone https://github.com/ajacquey/Golem.git\n    cd ~/projects/golem\n    git checkout master\n\n*Note: the \"master\" branch of GOLEM is the \"stable\" branch which is updated only if all tests are passing.*\n\n#### 3. Compile GOLEM\nYou can compile GOLEM by following these instructions:\n\n    cd ~/projects/golem\n    make -j4\n\n#### 4. Test GOLEM\nTo make sure that everything was installed properly, you can run the tests suite of GOLEM:\n\n    cd ~/projects/golem\n    ./run_tests -j2\n\nIf all the tests passed, then your installation is working properly. You can now use the GOLEM simulator!\n\n## Usage\nTo run GOLEM from the command line with multiple processors, use the following command:\n\n    mpiexec -n <nprocs> ~/projects/golem/golem-opt -i <input-file>\n\nWhere `<nprocs>` is the number of processors you want to use and `<input-file>` is the path to your input file (extension `.i`).  \n\nInformation about the structure of the GOLEM input files can be found in the documentation (link to follow).\n## Cite\n\nIf you use GOLEM for your work please cite:\n* This repository:  \nAntoine B. Jacquey, & Mauro Cacace. (2017, September 29). GOLEM, a MOOSE-based application. Zenodo. http://doi.org/10.5281/zenodo.999401\n* The publication presenting GOLEM:  \n Cacace, M. and Jacquey, A. B.: Flexible parallel implicit modelling of coupled thermal–hydraulic–mechanical processes in fractured rocks, Solid Earth, 8, 921-941, https://doi.org/10.5194/se-8-921-2017, 2017.  \n\n\nPlease read the [CITATION](https://github.com/ajacquey/Golem/blob/master/CITATION) file for more information.\n\n## Publications using GOLEM\n\n* Freymark, J., Bott, J., Cacace, M., Ziegler, M., Scheck-Wenderoth, M.: Influence of the Main Border Faults on the 3D Hydraulic Field of the Central Upper Rhine Graben, *Geofluids*, 2019.\n* Blöcher, G.,  Cacace, M.,  Jacquey, A. B.,  Zang, A.,  Heidbach, O.,  Hofmann, H.,  Kluge, C.,  Zimmermann, G.: Evaluating Micro-Seismic Events Triggered by Reservoir Operations at the Geothermal Site of Groß Schönebeck (Germany), *Rock Mechanics and Rock Engineering*, 2018.\n* Jacquey, A. B.,  Urpi, L.,  Cacace, M.,  Blöcher, G.,  Zimmermann, G.,  Scheck-Wenderoth, M.: Far field poroelastic response of geothermal reservoirs to hydraulic stimulation treatment: Theory and application at the Groß Schönebeck geothermal research facility, *International Journal of Rock Mechanics and Mining Sciences*, 2018.\n* Peters, E., Blöcher, G., Salimzadeh, S., Egberts, P. J. P., Cacace, M.: Modelling of multi-lateral well geometries for geothermal applications, *Advances in Geosciences*, 2018.\n* Magri, F., Cacace, M., Fischer, T., Kolditz, O., Wang, W., Watanabe, N.: Thermal convection of viscous fluids in a faulted system: 3D benchmark for numerical codes, *Energy Procedia*, 2017.\n* Cacace, M. and Jacquey, A. B.: Flexible parallel implicit modelling of coupled Thermal-Hydraulic-Mechanical processes in fractured rocks, Solid Earth, 2017.\n* Jacquey, A. B.: Coupled Thermo-Hydro-Mechanical Processes in Geothermal Reservoirs: a Multiphysic and Multiscale Approach Linking Geology and 3D Numerical Modelling, PhD thesis, RWTH Aachen, 2017.\n* Jacquey, A. B., Cacace, M., Blöcher, G.: Modelling coupled fluid flow and heat transfer in fractured reservoirs: description of a 3D benchmark numerical case, Energy Procedia, 2017.\n* Jacquey, A. B., Cacace, M., Blöcher, G., Milsch, H., Deon, F., Scheck-Wenderoth, M.: Processes Responsible for Localized Deformation within Porous Rocks: Insights from Laboratory Experiments and Numerical Modelling, 6th Biot Conference on Poromechanics, Paris 2017.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/gravis",
            "repo_link": "https://git.gfz-potsdam.de/gravis",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/gr-framework",
            "repo_link": "https://github.com/sciapp/gr",
            "readme": "GR - a universal framework for visualization applications\n=========================================================\n\n[![MIT license](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE.md)\n[![GitHub tag](https://img.shields.io/github/tag/jheinen/gr.svg)](https://github.com/jheinen/gr/releases)\n[![PyPI version](https://img.shields.io/pypi/v/gr.svg)](https://pypi.python.org/pypi/gr)\n[![DOI](https://zenodo.org/badge/17747322.svg)](https://zenodo.org/badge/latestdoi/17747322)\n\n*GR* is a universal framework for cross-platform visualization applications.\nIt offers developers a compact, portable and consistent graphics library for\ntheir programs. Applications range from publication quality 2D graphs to the\nrepresentation of complex 3D scenes.\n\n*GR* is essentially based on an implementation of a Graphical Kernel System (GKS).\nAs a self-contained system it can quickly and easily be integrated into existing\napplications (i.e. using the `ctypes` mechanism in Python or `ccall` in Julia).\n\nThe *GR* framework can be used in imperative programming systems or integrated\ninto modern object-oriented systems, in particular those based on GUI toolkits.\n*GR* is characterized by its high interoperability and can be used with modern\nweb technologies. The *GR* framework is especially suitable for real-time\nor signal processing environments.\n\n*GR* was developed by the Scientific IT-Systems group at the Peter Grünberg\nInstitute at Forschunsgzentrum Jülich. The main development has been done\nby Josef Heinen who currently maintains the software, but there are other\ndevelopers who currently make valuable contributions. Special thanks to\nFlorian Rhiem (*GR3*) and Christian Felder (qtgr, setup.py).\n\nStarting with release 0.6 *GR* can be used as a backend\nfor [Matplotlib](http://matplotlib.org) and significantly improve\nthe performance of existing Matplotlib or PyPlot applications written\nin Python or Julia, respectively.\nIn [this](http://gr-framework.org/tutorials/matplotlib.html) tutorial\nsection you can find some examples.\n\nBeginning with version 0.10.0 *GR* supports inline graphics which shows\nup in IPython's Qt Console or interactive computing environments for *Python*\nand *Julia*, such as [IPython](http://ipython.org) and\n[Jupyter](https://jupyter.org). An interesting example can be found\n[here](http://pgi-jcns.fz-juelich.de/pub/doc/700K_460.html).\n\n## Installation and Getting Started\n\nTo install *GR* and try it using *Python*, *Julia* or *C*, please see the corresponding documentation:\n\n- [Python package gr](https://gr-framework.org/python.html)\n- [Julia package GR](https://gr-framework.org/julia.html)\n- [C library GR](https://gr-framework.org/c.html)\n- [Ruby package GR](https://github.com/red-data-tools/GR.rb)\n\n## Documentation\n\nYou can find more information about *GR* on the [GR home page](http://gr-framework.org).\n\n## Contributing\n\nIf you want to improve *GR*, please read the [contribution guide](https://github.com/sciapp/gr/blob/develop/CONTRIBUTING.md) for a few notes on how to report issues or submit changes.\n\n## Support\n\nIf you have any questions about *GR* or run into any issues setting up or running GR, please [open an issue on GitHub](https://github.com/sciapp/gr/issues/new), either in this repo or in the repo for the language binding you are using ([Python](https://github.com/sciapp/python-gr/issues/new), [Julia](https://github.com/jheinen/GR.jl/issues/new), [Ruby](https://github.com/red-data-tools/GR.rb/issues/new)).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/gstools",
            "repo_link": "https://github.com/GeoStat-Framework/GSTools",
            "readme": "# Welcome to GSTools\n[![GMD](https://img.shields.io/badge/GMD-10.5194%2Fgmd--15--3161--2022-orange)](https://doi.org/10.5194/gmd-15-3161-2022)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1313628.svg)](https://doi.org/10.5281/zenodo.1313628)\n[![PyPI version](https://badge.fury.io/py/gstools.svg)](https://badge.fury.io/py/gstools)\n[![Conda Version](https://img.shields.io/conda/vn/conda-forge/gstools.svg)](https://anaconda.org/conda-forge/gstools)\n[![Build Status](https://github.com/GeoStat-Framework/GSTools/workflows/Continuous%20Integration/badge.svg?branch=main)](https://github.com/GeoStat-Framework/GSTools/actions)\n[![Coverage Status](https://coveralls.io/repos/github/GeoStat-Framework/GSTools/badge.svg?branch=main)](https://coveralls.io/github/GeoStat-Framework/GSTools?branch=main)\n[![Documentation Status](https://readthedocs.org/projects/gstools/badge/?version=latest)](https://geostat-framework.readthedocs.io/projects/gstools/en/stable/?badge=stable)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/GeoStat-Framework/GSTools/main/docs/source/pics/gstools.png\" alt=\"GSTools-LOGO\" width=\"251px\"/>\n</p>\n\n<p align=\"center\"><b>Get in Touch!</b></p>\n<p align=\"center\">\n<a href=\"https://github.com/GeoStat-Framework/GSTools/discussions\"><img src=\"https://img.shields.io/badge/GitHub-Discussions-f6f8fa?logo=github&style=flat\" alt=\"GH-Discussions\"/></a>\n<a href=\"https://swung.slack.com/messages/gstools\"><img src=\"https://img.shields.io/badge/Swung-Slack-4A154B?style=flat&logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAABoAAAAaCAYAAACpSkzOAAAABmJLR0QA%2FwD%2FAP%2BgvaeTAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAB3RJTUUH5AYaFSENGSa5qgAABmZJREFUSMeFlltsVNcVhr%2B1z5m7Zzy%2BxaBwcQrGQOpgCAkKtSBQIqJepKhPBULpQ6sKBVWVKqXtSy%2BR0qYXqa2qRmlDCzjBEZGKUCK1TWqlNiGIEKDQBtf4Fki4OIxnxrex53LOXn2YwbjEtOvlHG3tvX%2Btf%2B21%2Fl%2BYJ1QVEbn1vwLYBWwCVgG1lW0ZoA%2FoAQ6LSP%2BdZ%2BeGzAMiIqK%2Bem0GpxNYVeBj3j2b4NCfM2QnfAAaa11al4fZuCZK24owQJ9v%2BbLryIVbd9wVSNUaEWNVtQPYfXHmAD0T32ZJeBM1Q8d0zzMDUpMwAFgLJU%2BxClURw9NfqedLWxMAHSKyR1WNiNhPAM0B6c%2FbdPORTLuOeUMSNkmMBHgyeo32bwwRDMh8bDM%2BZVl0j6uvPrdYknFnSESWzwUzt%2BkyVlUHx7zh5j%2BmPkXBjosjLkWdominiMQ%2BoiEZxuq8OFRXGXJ5K5%2Fde5nha8VlqjooIlZVBcBUiqeqemjGppd1ptfhSpS8pmmN7GVf4whPNY4Di9m%2BMcR03nK3sBbCQeFbv7gBsExVOyp3l6nz1VtjcM4fTK3Uok5IXtPsrHuPevcBXk8d4dWPX6I%2BsIB9wf1s%2B2Y%2FVbFynUIBIeDeplIECiXl5Iv3kbLogogRgbWukfNumT%2FnlYszBxj3hwXg0cQvqXcfYNu5tVyYPE%2B1G8dXn%2BfW72fH49U8sSlOPGr4SccoF4cKs3WzFrY%2BFCMUNmz%2Ba0aeWR1l15JwJ7DaVPpk1YnJ7xIxtQRNjDXRvTx%2F9ef0Tl0g6SYQhAlvmkH%2Fgv74qUaiTSG8ewJ0%2FGgRK5aG8Cts5ouWDa1RxoDRovK9i9MAq1S12QA7b5ROUdBxBIeQ1ACG49m%2FEXPis7Qk3ChHbx6Qw1dgXVeWB7uyDOctP%2Fx6w2zdrIVIyFCyiq8wXlJOZzyAXQbY%2FGGhC8EAilJ%2BVg7ufxU6IAHeSvewfQEadiDuCr%2B6NE1LU4hwUFAF1xFGRkvEjVDlgiPwVqoEsNkAq0ZKp3EIYrFM2xGm7Uc8u%2FzXjHkTmHIHoCiDM73E3IIsDCtRV3gn7QHQ0hTCt0ooKLw%2FWCAM1AcNISOcHSsBrDRAbc7eQMQBFFciHM18kaZIMz3r%2F0HO5mazytsiw%2FmTtCYiGGCkQlltwkEVjMDVmyUA6oIGR%2BDGjAWoM3f2giHAhH%2BFI5nPsDrWxqWNE9S4tUz5k1S7cQ5df4k9S6qY9JRipXtr4w5WQYH0eHkWrqxy8FTn3AvpmFmIqj%2B76EiQjNfHH1JNWFKc3vABj9V9npw%2FRXfmBNsaoTRnRAQDAgqqMJr1KBWUtUmHaR8WRgzAqAH6FgYexqd4R2Yuns5wcLSFK4U36bj%2FdbbUbGdoZoCi3uS%2Bqtt73TlNWygpqXGfZTGXnKesrwkA9BmgZ0noMZT5R0tQ4hzLfo4rhS46W%2F%2BCAn3T7%2BhDySiWMl2RkHArP8dAesKjPixYVbbUBwB6DHB4QWADIamuHPtkhE0t3ZP7ANhe9zgvXP2dfK0pymRJmQLiEYNW6mEVljYGuDzlkwwaHq51AQ4bERkAetvjP2XCT6H480AJeZsB4N7QYt7OnuSROtRXJV2wNNS4qIJvlbUtERJxhxcv5%2FlNWwygV0QGyzKBv%2FP%2ByFfZXf%2ButoR3UuXcS95mKNgxSjpN3qZZFHwUgFPjx5n2c9wo9ktrtcOZtMeWB2NEw4b2thivPLuIS1M%2BAzmrTy4O4ys7Zv1B5fsnVdWCr7PxYf7vej73ex2YeU1VVY9nu7ShG63vRo%2Fe%2FK1%2B518FbXkjo3OjO1XU2LFRzRZ9VdWDczFQ1VsCOHgpd1G%2FcG6jHrj2vPbn%2BjVdHNfr%2BRH92eXva2MPuvxEQpe%2BHdEnzm%2FQf4%2BrRo%2BldMUbGd393oS2dWU0cDSlw1OequrALVG9Q8rLsquqg2OlzLL2Myu1N5eShgB4CjEnSMSJYrX8Oj0t8UH7NMnX0iSDwmhBWRl3tKs9IcmgGRSRZqtqzFwpL4uWWKvWiMjyZKC24%2F1HbsrLn95Pwk3gCpS0yIw%2Fg6clPC2RLc3QmzvJupoARQsvrItxZmtSkkFz6E6Q%2F2m3PFta44jbCaw%2BO3GK7uybnJs8xfXC1fLYCdTz9NIfsCS0mYVhAHp9ZYdr5J%2F%2F127dxUA2AzuBzRUDWVfZlq4YyG6gs9ImdzWQ%2FwFNRlgCFdG5bAAAAABJRU5ErkJggg%3D%3D\" alt=\"Slack-Swung\"/></a>\n<a href=\"https://gitter.im/GeoStat-Framework/GSTools\"><img src=\"https://img.shields.io/badge/Gitter-GeoStat--Framework-ed1965?logo=gitter&style=flat\" alt=\"Gitter-GSTools\"/></a>\n<a href=\"mailto:info@geostat-framework.org\"><img src=\"https://img.shields.io/badge/Email-GeoStat--Framework-468a88?style=flat&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbDpzcGFjZT0icHJlc2VydmUiIHdpZHRoPSI1MDAiIGhlaWdodD0iNTAwIj48cGF0aCBkPSJNNDQ4IDg4SDUyYy0yNyAwLTQ5IDIyLTQ5IDQ5djIyNmMwIDI3IDIyIDQ5IDQ5IDQ5aDM5NmMyNyAwIDQ5LTIyIDQ5LTQ5VjEzN2MwLTI3LTIyLTQ5LTQ5LTQ5em0xNiA0OXYyMjZsLTIgNy0xMTUtMTE2IDExNy0xMTd6TTM2IDM2M1YxMzdsMTE3IDExN0wzOCAzNzBsLTItN3ptMjE5LTYzYy0zIDMtNyAzLTEwIDBMNjYgMTIxaDM2OHptLTc5LTIzIDQ2IDQ2YTM5IDM5IDAgMCAwIDU2IDBsNDYtNDYgMTAxIDEwMkg3NXoiIHN0eWxlPSJmaWxsOiNmNWY1ZjU7ZmlsbC1vcGFjaXR5OjEiLz48L3N2Zz4=\" alt=\"Email\"/></a>\n<a href=\"https://twitter.com/GSFramework\"><img alt=\"Twitter Follow\" src=\"https://img.shields.io/twitter/follow/GSFramework?style=social\"></a>\n</p>\n\n<p align=\"center\"><b>Youtube Tutorial on GSTools</b><br></p>\n\n<p align=\"center\">\n<a href=\"http://www.youtube.com/watch?feature=player_embedded&v=qZBJ-AZXq6Q\" target=\"_blank\">\n<img src=\"http://img.youtube.com/vi/qZBJ-AZXq6Q/0.jpg\" alt=\"GSTools Transform 22 tutorial\" width=\"480\" height=\"360\" border=\"0\" />\n</a>\n</p>\n\n## Purpose\n\n<img align=\"right\" width=\"450\" src=\"https://raw.githubusercontent.com/GeoStat-Framework/GSTools/main/docs/source/pics/demonstrator.png\" alt=\"\">\n\nGeoStatTools provides geostatistical tools for various purposes:\n- random field generation, including periodic boundaries\n- simple, ordinary, universal and external drift kriging\n- conditioned field generation\n- incompressible random vector field generation\n- (automated) variogram estimation and fitting\n- directional variogram estimation and modelling\n- data normalization and transformation\n- many readily provided and even user-defined covariance models\n- metric spatio-temporal modelling\n- plotting and exporting routines\n\n\n## Installation\n\n\n### conda\n\nGSTools can be installed via [conda][conda_link] on Linux, Mac, and Windows.\nInstall the package by typing the following command in a command terminal:\n\n    conda install gstools\n\nIn case conda forge is not set up for your system yet, see the easy to follow\ninstructions on [conda forge][conda_forge_link]. Using conda, the parallelized\nversion of GSTools should be installed.\n\n\n### pip\n\nGSTools can be installed via [pip][pip_link] on Linux, Mac, and Windows.\nOn Windows you can install [WinPython][winpy_link] to get Python and pip\nrunning. Install the package by typing the following command in a command terminal:\n\n    pip install gstools\n\nTo install the latest development version via pip, see the\n[documentation][doc_install_link].\nOne thing to point out is that this way, the non-parallel version of GSTools\nis installed. In case you want the parallel version, follow these easy\n[steps][doc_install_link].\n\n\n## Citation\n\nIf you are using GSTools in your publication please cite our paper:\n\n> Müller, S., Schüler, L., Zech, A., and Heße, F.:\n> GSTools v1.3: a toolbox for geostatistical modelling in Python,\n> Geosci. Model Dev., 15, 3161–3182, https://doi.org/10.5194/gmd-15-3161-2022, 2022.\n\nYou can cite the Zenodo code publication of GSTools by:\n\n> Sebastian Müller & Lennart Schüler. GeoStat-Framework/GSTools. Zenodo. https://doi.org/10.5281/zenodo.1313628\n\nIf you want to cite a specific version, have a look at the [Zenodo site](https://doi.org/10.5281/zenodo.1313628).\n\n\n## Documentation for GSTools\n\nYou can find the documentation under [geostat-framework.readthedocs.io][doc_link].\n\n\n### Tutorials and Examples\n\nThe documentation also includes some [tutorials][tut_link], showing the most important use cases of GSTools, which are\n\n- [Random Field Generation][tut1_link]\n- [The Covariance Model][tut2_link]\n- [Variogram Estimation][tut3_link]\n- [Random Vector Field Generation][tut4_link]\n- [Kriging][tut5_link]\n- [Conditioned random field generation][tut6_link]\n- [Field transformations][tut7_link]\n- [Geographic Coordinates][tut8_link]\n- [Spatio-Temporal Modelling][tut9_link]\n- [Normalizing Data][tut10_link]\n- [Miscellaneous examples][tut0_link]\n\nThe associated python scripts are provided in the `examples` folder.\n\n\n## Spatial Random Field Generation\n\nThe core of this library is the generation of spatial random fields. These fields are generated using the randomisation method, described by [Heße et al. 2014][rand_link].\n\n[rand_link]: https://doi.org/10.1016/j.envsoft.2014.01.013\n\n\n### Examples\n\n#### Gaussian Covariance Model\n\nThis is an example of how to generate a 2 dimensional spatial random field with a gaussian covariance model.\n\n```python\nimport gstools as gs\n# structured field with a size 100x100 and a grid-size of 1x1\nx = y = range(100)\nmodel = gs.Gaussian(dim=2, var=1, len_scale=10)\nsrf = gs.SRF(model)\nsrf((x, y), mesh_type='structured')\nsrf.plot()\n```\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/GeoStat-Framework/GSTools/main/docs/source/pics/gau_field.png\" alt=\"Random field\" width=\"600px\"/>\n</p>\n\nGSTools also provides support for [geographic coordinates](https://en.wikipedia.org/wiki/Geographic_coordinate_system).\nThis works perfectly well with [cartopy](https://scitools.org.uk/cartopy/docs/latest/index.html).\n\n```python\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport gstools as gs\n# define a structured field by latitude and longitude\nlat = lon = range(-80, 81)\nmodel = gs.Gaussian(latlon=True, len_scale=777, geo_scale=gs.KM_SCALE)\nsrf = gs.SRF(model, seed=12345)\nfield = srf.structured((lat, lon))\n# Orthographic plotting with cartopy\nax = plt.subplot(projection=ccrs.Orthographic(-45, 45))\ncont = ax.contourf(lon, lat, field, transform=ccrs.PlateCarree())\nax.coastlines()\nax.set_global()\nplt.colorbar(cont)\n```\n\n<p align=\"center\">\n<img src=\"https://github.com/GeoStat-Framework/GeoStat-Framework.github.io/raw/master/img/GS_globe.png\" alt=\"lat-lon random field\" width=\"600px\"/>\n</p>\n\nA similar example but for a three dimensional field is exported to a [VTK](https://vtk.org/) file, which can be visualized with [ParaView](https://www.paraview.org/) or [PyVista](https://docs.pyvista.org) in Python:\n\n```python\nimport gstools as gs\n# structured field with a size 100x100x100 and a grid-size of 1x1x1\nx = y = z = range(100)\nmodel = gs.Gaussian(dim=3, len_scale=[16, 8, 4], angles=(0.8, 0.4, 0.2))\nsrf = gs.SRF(model)\nsrf((x, y, z), mesh_type='structured')\nsrf.vtk_export('3d_field') # Save to a VTK file for ParaView\n\nmesh = srf.to_pyvista() # Create a PyVista mesh for plotting in Python\nmesh.contour(isosurfaces=8).plot()\n```\n\n<p align=\"center\">\n<img src=\"https://github.com/GeoStat-Framework/GeoStat-Framework.github.io/raw/master/img/GS_pyvista.png\" alt=\"3d Random field\" width=\"600px\"/>\n</p>\n\n\n## Estimating and Fitting Variograms\n\nThe spatial structure of a field can be analyzed with the variogram, which contains the same information as the covariance function.\n\nAll covariance models can be used to fit given variogram data by a simple interface.\n\n### Example\n\nThis is an example of how to estimate the variogram of a 2 dimensional unstructured field and estimate the parameters of the covariance\nmodel again.\n\n```python\nimport numpy as np\nimport gstools as gs\n# generate a synthetic field with an exponential model\nx = np.random.RandomState(19970221).rand(1000) * 100.\ny = np.random.RandomState(20011012).rand(1000) * 100.\nmodel = gs.Exponential(dim=2, var=2, len_scale=8)\nsrf = gs.SRF(model, mean=0, seed=19970221)\nfield = srf((x, y))\n# estimate the variogram of the field\nbin_center, gamma = gs.vario_estimate((x, y), field)\n# fit the variogram with a stable model. (no nugget fitted)\nfit_model = gs.Stable(dim=2)\nfit_model.fit_variogram(bin_center, gamma, nugget=False)\n# output\nax = fit_model.plot(x_max=max(bin_center))\nax.scatter(bin_center, gamma)\nprint(fit_model)\n```\n\nWhich gives:\n\n```python\nStable(dim=2, var=1.85, len_scale=7.42, nugget=0.0, anis=[1.0], angles=[0.0], alpha=1.09)\n```\n\n<p align=\"center\">\n<img src=\"https://github.com/GeoStat-Framework/GeoStat-Framework.github.io/raw/master/img/GS_vario_est.png\" alt=\"Variogram\" width=\"600px\"/>\n</p>\n\n\n## Kriging and Conditioned Random Fields\n\nAn important part of geostatistics is Kriging and conditioning spatial random\nfields to measurements. With conditioned random fields, an ensemble of field realizations with their variability depending on the proximity of the measurements can be generated.\n\n### Example\nFor better visualization, we will condition a 1d field to a few \"measurements\", generate 100 realizations and plot them:\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport gstools as gs\n\n# conditions\ncond_pos = [0.3, 1.9, 1.1, 3.3, 4.7]\ncond_val = [0.47, 0.56, 0.74, 1.47, 1.74]\n\n# conditioned spatial random field class\nmodel = gs.Gaussian(dim=1, var=0.5, len_scale=2)\nkrige = gs.krige.Ordinary(model, cond_pos, cond_val)\ncond_srf = gs.CondSRF(krige)\n# same output positions for all ensemble members\ngrid_pos = np.linspace(0.0, 15.0, 151)\ncond_srf.set_pos(grid_pos)\n\n# seeded ensemble generation\nseed = gs.random.MasterRNG(20170519)\nfor i in range(100):\n    field = cond_srf(seed=seed(), store=f\"field_{i}\")\n    plt.plot(grid_pos, field, color=\"k\", alpha=0.1)\nplt.scatter(cond_pos, cond_val, color=\"k\")\nplt.show()\n```\n\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/GeoStat-Framework/GSTools/main/docs/source/pics/cond_ens.png\" alt=\"Conditioned\" width=\"600px\"/>\n</p>\n\n## User Defined Covariance Models\n\nOne of the core-features of GSTools is the powerful\n[CovModel][cov_link]\nclass, which allows to easy define covariance models by the user.\n\n### Example\n\nHere we re-implement the Gaussian covariance model by defining just a\n[correlation][cor_link] function, which takes a non-dimensional distance ``h = r/l``:\n\n```python\nimport numpy as np\nimport gstools as gs\n# use CovModel as the base-class\nclass Gau(gs.CovModel):\n    def cor(self, h):\n        return np.exp(-h**2)\n```\n\nAnd that's it! With ``Gau`` you now have a fully working covariance model,\nwhich you could use for field generation or variogram fitting as shown above.\n\nHave a look at the [documentation ][doc_link] for further information on incorporating\noptional parameters and optimizations.\n\n\n## Incompressible Vector Field Generation\n\nUsing the original [Kraichnan method][kraichnan_link], incompressible random\nspatial vector fields can be generated.\n\n\n### Example\n\n```python\nimport numpy as np\nimport gstools as gs\nx = np.arange(100)\ny = np.arange(100)\nmodel = gs.Gaussian(dim=2, var=1, len_scale=10)\nsrf = gs.SRF(model, generator='VectorField', seed=19841203)\nsrf((x, y), mesh_type='structured')\nsrf.plot()\n```\n\nyielding\n\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/GeoStat-Framework/GSTools/main/docs/source/pics/vec_srf_tut_gau.png\" alt=\"vector field\" width=\"600px\"/>\n</p>\n\n\n[kraichnan_link]: https://doi.org/10.1063/1.1692799\n\n\n## VTK/PyVista Export\n\nAfter you have created a field, you may want to save it to file, so we provide\na handy [VTK][vtk_link] export routine using the `.vtk_export()` or you could\ncreate a VTK/PyVista dataset for use in Python with to `.to_pyvista()` method:\n\n```python\nimport gstools as gs\nx = y = range(100)\nmodel = gs.Gaussian(dim=2, var=1, len_scale=10)\nsrf = gs.SRF(model)\nsrf((x, y), mesh_type='structured')\nsrf.vtk_export(\"field\") # Saves to a VTK file\nmesh = srf.to_pyvista() # Create a VTK/PyVista dataset in memory\nmesh.plot()\n```\n\nWhich gives a RectilinearGrid VTK file ``field.vtr`` or creates a PyVista mesh\nin memory for immediate 3D plotting in Python.\n\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/GeoStat-Framework/GSTools/main/docs/source/pics/pyvista_export.png\" alt=\"pyvista export\" width=\"600px\"/>\n</p>\n\n\n## Requirements:\n\n- [NumPy >= 1.20.0](https://www.numpy.org)\n- [SciPy >= 1.1.0](https://www.scipy.org/scipylib)\n- [hankel >= 1.0.0](https://github.com/steven-murray/hankel)\n- [emcee >= 3.0.0](https://github.com/dfm/emcee)\n- [pyevtk >= 1.1.1](https://github.com/pyscience-projects/pyevtk)\n- [meshio >= 5.1.0](https://github.com/nschloe/meshio)\n\n### Optional\n\n- [GSTools-Core >= 0.2.0](https://github.com/GeoStat-Framework/GSTools-Core)\n- [matplotlib](https://matplotlib.org)\n- [pyvista](https://docs.pyvista.org/)\n\n\n## Contact\n\nYou can contact us via <info@geostat-framework.org>.\n\n\n## License\n\n[LGPLv3][license_link] © 2018-2024\n\n[pip_link]: https://pypi.org/project/gstools\n[conda_link]: https://docs.conda.io/en/latest/miniconda.html\n[conda_forge_link]: https://github.com/conda-forge/gstools-feedstock#installing-gstools\n[conda_pip]: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#installing-non-conda-packages\n[pipiflag]: https://pip-python3.readthedocs.io/en/latest/reference/pip_install.html?highlight=i#cmdoption-i\n[winpy_link]: https://winpython.github.io/\n[license_link]: https://github.com/GeoStat-Framework/GSTools/blob/main/LICENSE\n[cov_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/generated/gstools.covmodel.CovModel.html#gstools.covmodel.CovModel\n[stable_link]: https://en.wikipedia.org/wiki/Stable_distribution\n[doc_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/\n[doc_install_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/#pip\n[tut_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/tutorials.html\n[tut1_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/01_random_field/index.html\n[tut2_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/02_cov_model/index.html\n[tut3_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/03_variogram/index.html\n[tut4_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/04_vector_field/index.html\n[tut5_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/05_kriging/index.html\n[tut6_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/06_conditioned_fields/index.html\n[tut7_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/07_transformations/index.html\n[tut8_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/08_geo_coordinates/index.html\n[tut9_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/09_spatio_temporal/index.html\n[tut10_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/10_normalizer/index.html\n[tut0_link]: https://geostat-framework.readthedocs.io/projects/gstools/en/stable/examples/00_misc/index.html\n[cor_link]: https://en.wikipedia.org/wiki/Autocovariance#Normalization\n[vtk_link]: https://www.vtk.org/\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/habitat-sampler",
            "repo_link": "https://git.gfz-potsdam.de/habitat-sampler/HabitatSampler",
            "readme": ".. figure:: R-package/hasa/vignettes/images/Logo.png\n    :target: https://github.com/carstennh/HabitatSampler/tree/main/demo\n    :align: center\n\n==================================================================================================\nProcedure on Autonomous Sampling and Reductive Learning in Imagery\n==================================================================================================\n\n\nHow to use\n--------------\n1. R package\n-----------------------\n* You need R to install the **HaSa package** that includes all functions and demo data.\n* The installation steps for R version **4.3.2** are defined in `Section 2.0 of the documentation <https://git.gfz-potsdam.de/habitat-sampler/HabitatSampler/-/blob/main/R-package/hasa/vignettes/HabitatSampler.md#2-hasa-installation>`_.\n\n* For Ubuntu systems the following system packages dependencies need to be installed:\n.. code-block::  \n    apt-get install -y libjq-dev protobuf-compiler libprotobuf-dev proj-bin gdal-bin libgdal-dev jq libv8-dev pandoc\n\n* For Windows operating systems the `Rtools <https://cran.r-project.org/bin/windows/Rtools/>`_ are needed\n\n* library(HaSa) and list datasets: data(package=\"HaSa\") and functions: lsf.str(\"package:HaSa\") or use library(help=\"HaSa\")\n* Information about program execution and function behavior is available in Rmarkdown: `HabitatSampler.Rmd <https://git.gfz-potsdam.de/habitat-sampler/HabitatSampler/-/blob/main/R-package/hasa/vignettes/HabitatSampler.Rmd>`_\n\n\n2. Stepwise Procedure\n----------------------------------\n* The **demo** directory provides a step-wised procedure via an R script: **HabitatSampler.r**, but also via a Jupyter notebook **HabitatSampler.ipynb**.\n* All necessary data and information is available under the directory: `demo <https://git.gfz-potsdam.de/habitat-sampler/HabitatSampler/-/blob/main/demo>`_\n* For documentation please check `HabitatSampler.Rmd <https://git.gfz-potsdam.de/habitat-sampler/HabitatSampler/-/blob/main/R-package/hasa/vignettes/HabitatSampler.Rmd>`_.\n\nInput\n----------------\n* **Image File as Raster Layer Stack** (e.g. Satellite Time Series, RGB Drone, Orthophoto)\n* **Reference File** (e.g. spectral-temporal profiles or point shape; one profile or point per class)\n* **Class Names** (the classes that are defined to be delineated in imagery)\n\nOutput\n----------------\n* **Interactive Maps** of class type probabilities\n\n.. image:: R-package/hasa/vignettes/images/figure_1.jpg\n    :width: 700px\n\n           \n* **Classified Image** of chosen class\n* **Sample Distribution** of sampled class\n* **Spatial Statistics** of class distribution\n* the classes are referred to as class types\n\n\n.. image:: R-package/hasa/vignettes/images/figure_2.jpg\n   :width: 450px\n\nKey Features\n----------------\n* the algorithm provides a set of **reference samples** for each class type\n* the algorithm provides an ensemble of calibrated **machine learning classifiers** for each class type\n* the algorithm provides a map of **class type probabilities** \n* the algorithm is optimized for broad-scale **satellite image** time series (pixel size > 10m)\n* the algorithm can be applied on **variable image classes** in complex scenes\n* the algorithm is transferable to **variable input imagery** \n\nCitation\n----------------\nNeumann, C. (2020): Habitat sampler—A sampling algorithm for class type delineation in remote sensing imagery. - Diversity and Distributions, 26 (12), 1752-1766. `<https://doi.org/10.1111/ddi.13165>`__.\n\nCredits\n----------------\n\nHaSa was developed by Carsten Neumann (Helmholtz Centre Potsdam GFZ German Research Centre for Geosciences) within the context of the\n`NaTec - KRH <http://www.heather-conservation-technology.com/>`__ project funded by the German Federal Ministry of Education and Research (BMBF) (grant number: 01 LC 1602A).\n\nThe test data represent pre-processed Copernicus Sentinel-2 satellite imagery (ESA 2018). Pre-processing was done using `GTS2 <https://git.gfz-potsdam.de/gts2>`__ and `AROSICS <https://git.gfz-potsdam.de/danschef/arosics>`__. \n",
            "project_id": "1519"
        },
        {
            "software_organization": "https://helmholtz.software/software/hcocena",
            "repo_link": "https://github.com/MarieOestreich/hCoCena",
            "readme": "# hCoCena - Horizontal integration and analysis of transcriptomics datasets [[paper](https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btac589/6677225)]\n\nhCoCena is an R-package that allows you to integrate and jointly analyse multiple transcriptomic datasets or simply analyse a single dataset if you don't want to do any data integration! hCoCena uses network representations of the data as the basis for integration. You can find more details of how that works in our [paper](https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btac589/6677225) . Below, you will find some info on how to install the package and tips for using it. \n\n## Installation\nTo install hcocena (v1.1.1) from this repo, run the codeline provided in the `install_hcocena.R` script.\nTo install versioned dependencies, use the script `install_versioned_dependecies.R`.\n\n## Usage\n**hCoCena is divided into 2 parts:** \n\n**1.** the main analysis that comprises the mandatory steps to process and integrate the data and\n\n**2.** the satellite functions that offer you a plethora of analysis options in a pick & mix kind of fashion. \n\nThe figure below illustrates this: the main analysis is at the center, while the satellite functions can be found in the orbits around it. \nA step-by-step walkthrough of the main analysis steps can be found in the `hcocena_main.Rmd`, the satellite functions are in the `hcocena_saltellite.Rmd`. \n\nhCoCena was written with user-friendliness and customizability in mind. We are doing our best to provide you with plenty of supplementary information that make the usage of the tool easy for you. You can also always extend the tool's functionalities with your on custom scripts and functions to adapt the analysis to your needs! For more details on hCoCena's object structure and where to find the outputs of different analysis steps for customization, please refer to the overview in the [Wiki](https://github.com/MarieOestreich/hCoCena/wiki/Structure-of-the-hcobject) and the extensive function documentations you can access from within R Studio.\n\n\n![hCoCenaFig1](https://user-images.githubusercontent.com/50077786/158609782-2048c06e-0420-4c3f-8680-5d99f91d6905.jpg)\n*Marie Oestreich, Lisa Holsten, Shobhit Agrawal, Kilian Dahm, Philipp Koch, Han Jin, Matthias Becker, Thomas Ulas, hCoCena: horizontal integration and analysis of transcriptomics datasets, Bioinformatics, Volume 38, Issue 20, 15 October 2022, Pages 4727–4734, https://doi.org/10.1093/bioinformatics/btac589*\n\n## Showcase\nTo rerun the showcase example from our original publication, please refer to the branch of version [1.0.1](https://github.com/MarieOestreich/hCoCena/tree/v-1.0.1).\n\n## Wiki\nFor loads of additional information regarding the [satellite functions](https://github.com/MarieOestreich/hCoCena/wiki/Satellite-Functions), [community detection](https://github.com/MarieOestreich/hCoCena/wiki/Background-Info-on-the-Community-Detection-Algorithms) algorithms etc. please check out our carefully curated Wiki pages!\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/heat",
            "repo_link": "https://github.com/helmholtz-analytics/heat",
            "readme": "<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/helmholtz-analytics/heat/main/doc/images/logo.png\">\n</div>\n\n---\n\nHeat is a distributed tensor framework for high performance data analytics.\n\n# Project Status\n\n[![CPU/CUDA/ROCm tests](https://codebase.helmholtz.cloud/helmholtz-analytics/ci/badges/heat/base/pipeline.svg)](https://codebase.helmholtz.cloud/helmholtz-analytics/ci/-/commits/heat/base)\n[![Documentation Status](https://readthedocs.org/projects/heat/badge/?version=latest)](https://heat.readthedocs.io/en/latest/?badge=latest)\n[![coverage](https://codecov.io/gh/helmholtz-analytics/heat/branch/main/graph/badge.svg)](https://codecov.io/gh/helmholtz-analytics/heat)\n[![license: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![PyPI Version](https://img.shields.io/pypi/v/heat)](https://pypi.org/project/heat/)\n[![Downloads](https://pepy.tech/badge/heat)](https://pepy.tech/project/heat)\n[![Anaconda-Server Badge](https://anaconda.org/conda-forge/heat/badges/version.svg)](https://anaconda.org/conda-forge/heat)\n[![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F-green)](https://fair-software.eu)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/helmholtz-analytics/heat/badge)](https://securityscorecards.dev/viewer/?uri=github.com/helmholtz-analytics/heat)\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/7688/badge)](https://bestpractices.coreinfrastructure.org/projects/7688)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.2531472.svg)](https://doi.org/10.5281/zenodo.2531472)\n[![Benchmarks](https://img.shields.io/badge/Grafana-Benchmarks-2ea44f)](https://57bc8d92-72f2-4869-accd-435ec06365cb.ka.bw-cloud-instance.org:3000/d/adjpqduq9r7k0a/heat-cb?orgId=1)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![JuRSE Code Pick of the Month](https://img.shields.io/badge/JuRSE_Code_Pick-August_2024-blue)](https://www.fz-juelich.de/en/rse/jurse-community/jurse-code-of-the-month/august-2024)\n\n# Table of Contents\n  - [What is Heat for?](#what-is-heat-for)\n  - [Features](#features)\n  - [Getting Started](#getting-started)\n  - [Installation](#installation)\n    - [Requirements](#requirements)\n    - [pip](#pip)\n    - [conda](#conda)\n  - [Support Channels](#support-channels)\n  - [Contribution guidelines](#contribution-guidelines)\n    - [Resources](#resources)\n  - [License](#license)\n  - [Citing Heat](#citing-heat)\n  - [FAQ](#faq)\n  - [Acknowledgements](#acknowledgements)\n\n\n# What is Heat for?\n\nHeat builds on [PyTorch](https://pytorch.org/) and [mpi4py](https://mpi4py.readthedocs.io) to provide high-performance computing infrastructure for memory-intensive applications within the NumPy/SciPy ecosystem.\n\n\nWith Heat you can:\n- port existing NumPy/SciPy code from single-CPU to multi-node clusters with minimal coding effort;\n- exploit the entire, cumulative RAM of your many nodes for memory-intensive operations and algorithms;\n- run your NumPy/SciPy code on GPUs (CUDA, ROCm, coming up: Apple MPS).\n\nFor a example that highlights the benefits of multi-node parallelism, hardware acceleration, and how easy this can be done with the help of Heat, see, e.g., our [blog post on trucated SVD of a 200GB data set](https://helmholtz-analytics.github.io/heat/2023/06/16/new-feature-hsvd.html).\n\nCheck out our [coverage tables](coverage_tables.md) to see which NumPy, SciPy, scikit-learn functions are already supported.\n\n If you need a functionality that is not yet supported:\n  - [search existing issues](https://github.com/helmholtz-analytics/heat/issues) and make sure to leave a comment if someone else already requested it;\n  - [open a new issue](https://github.com/helmholtz-analytics/heat/issues/new/choose).\n\n\nCheck out our [features](#features) and the [Heat API Reference](https://heat.readthedocs.io/en/latest/autoapi/index.html) for a complete list of functionalities.\n\n# Features\n\n* High-performance n-dimensional arrays\n* CPU, GPU, and distributed computation using MPI\n* Powerful data analytics and machine learning methods\n* Seamless integration with the NumPy/SciPy ecosystem\n* Python array API (work in progress)\n\n\n# Getting Started\n\nGo to [Quick Start](quick_start.md) for a quick overview. For more details, see [Installation](#installation).\n\n**You can test your setup** by running the [`heat_test.py`](https://github.com/helmholtz-analytics/heat/blob/main/scripts/heat_test.py) script:\n\n```shell\nmpirun -n 2 python heat_test.py\n```\n\nIt should print something like this:\n\n```shell\nx is distributed:  True\nGlobal DNDarray x:  DNDarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=ht.int32, device=cpu:0, split=0)\nGlobal DNDarray x:\nLocal torch tensor on rank  0 :  tensor([0, 1, 2, 3, 4], dtype=torch.int32)\nLocal torch tensor on rank  1 :  tensor([5, 6, 7, 8, 9], dtype=torch.int32)\n```\n\nCheck out our Jupyter Notebook [**Tutorials**](https://github.com/helmholtz-analytics/heat/blob/main/tutorials/), choose `local` to try things out on your machine, or `hpc` if you have access to an HPC system.\n\nThe complete documentation of the latest version is always deployed on\n[Read the Docs](https://heat.readthedocs.io/).\n\n\n<!-- # Goals\n\nHeat is a flexible and seamless open-source software for high performance data\nanalytics and machine learning. It provides highly optimized algorithms and data structures for tensor computations using CPUs, GPUs, and distributed cluster systems on top of MPI. The goal of Heat is to fill the gap between single-node data analytics and machine learning libraries, and  high-performance computing (HPC). Heat's interface integrates seamlessly with the existing data science ecosystem and makes  writing scalable\nscientific and data science applications as effortless as using NumPy.\n\nHeat allows you to tackle your actual Big Data challenges that go beyond the\ncomputational and memory needs of your laptop and desktop.\n -->\n# Installation\n\n## Requirements\n\n### Basics\n- python >= 3.9\n- MPI (OpenMPI, MPICH, Intel MPI, etc.)\n- mpi4py >= 3.0.0\n- pytorch >= 2.0.0\n\n### Parallel I/O\n- h5py\n- netCDF4\n\n### GPU support\nIn order to do computations on your GPU(s):\n- your CUDA or ROCm installation must match your hardware and its drivers;\n- your [PyTorch installation](https://pytorch.org/get-started/locally/) must be compiled with CUDA/ROCm support.\n\n### HPC systems\nOn most HPC-systems you will not be able to install/compile MPI or CUDA/ROCm yourself. Instead, you will most likely need to load a pre-installed MPI and/or CUDA/ROCm module from the module system. Maybe, you will even find PyTorch, h5py, or mpi4py as (part of) such a module. Note that for optimal performance on GPU, you need to usa an MPI library that has been compiled with CUDA/ROCm support (e.g., so-called \"CUDA-aware MPI\").\n\n\n## pip\nInstall the latest version with\n\n```bash\npip install heat[hdf5,netcdf]\n```\nwhere the part in brackets is a list of optional dependencies. You can omit\nit, if you do not need HDF5 or NetCDF support.\n\n## **conda**\n\nThe conda build includes all dependencies **including OpenMPI**.\n```bash\n conda install -c conda-forge heat\n ```\n\n# Support Channels\n\nGo ahead and ask questions on [GitHub Discussions](https://github.com/helmholtz-analytics/heat/discussions). If you found a bug or are missing a feature, then please file a new [issue](https://github.com/helmholtz-analytics/heat/issues/new/choose). You can also get in touch with us on [Mattermost](https://mattermost.hzdr.de/signup_user_complete/?id=3sixwk9okpbzpjyfrhen5jpqfo) (sign up with your GitHub credentials). Once you log in, you can introduce yourself on the `Town Square` channel.\n\n\n# Contribution guidelines\n\n**We welcome contributions from the community, if you want to contribute to Heat, be sure to review the [Contribution Guidelines](contributing.md) and [Resources](#resources)  before getting started!**\n\nWe use [GitHub issues](https://github.com/helmholtz-analytics/heat/issues) for tracking requests and bugs, please see [Discussions](https://github.com/helmholtz-analytics/heat/discussions) for general questions and discussion. You can also get in touch with us on [Mattermost](https://mattermost.hzdr.de/signup_user_complete/?id=3sixwk9okpbzpjyfrhen5jpqfo) (sign up with your GitHub credentials). Once you log in, you can introduce yourself on the `Town Square` channel.\n\nIf you’re unsure where to start or how your skills fit in, reach out! You can ask us here on GitHub, by leaving a comment on a relevant issue that is already open.\n\n**If you are new to contributing to open source, [this guide](https://opensource.guide/how-to-contribute/) helps explain why, what, and how to get involved.**\n\n\n## Resources\n\n* [Heat Tutorials](https://github.com/helmholtz-analytics/heat/tree/main/tutorials)\n* [Heat API Reference](https://heat.readthedocs.io/en/latest/autoapi/index.html)\n\n### Parallel Computing and MPI:\n\n* David Henty's [course](https://www.archer2.ac.uk/training/courses/200514-mpi/)\n* Wes Kendall's [Tutorials](https://mpitutorial.com/tutorials/)\n* Rolf Rabenseifner's [MPI course material](https://www.hlrs.de/training/self-study-materials/mpi-course-material) (including C, Fortran **and** Python via `mpi4py`)\n\n### mpi4py\n\n* [mpi4py docs](https://mpi4py.readthedocs.io/en/stable/tutorial.html)\n* [Tutorial](https://www.kth.se/blogs/pdc/2019/08/parallel-programming-in-python-mpi4py-part-1/)\n# License\n\nHeat is distributed under the MIT license, see our\n[LICENSE](LICENSE) file.\n\n# Citing Heat\n\n<!-- If you find Heat helpful for your research, please mention it in your publications. You can cite: -->\n\nPlease do mention Heat in your publications if it helped your research. You can cite:\n\n* Götz, M., Debus, C., Coquelin, D., Krajsek, K., Comito, C., Knechtges, P., Hagemeier, B., Tarnawa, M., Hanselmann, S., Siggel, S., Basermann, A. & Streit, A. (2020). HeAT - a Distributed and GPU-accelerated Tensor Framework for Data Analytics. In 2020 IEEE International Conference on Big Data (Big Data) (pp. 276-287). IEEE, DOI: 10.1109/BigData50022.2020.9378050.\n\n```\n@inproceedings{heat2020,\n    title={{HeAT -- a Distributed and GPU-accelerated Tensor Framework for Data Analytics}},\n    author={\n      Markus Götz and\n      Charlotte Debus and\n      Daniel Coquelin and\n      Kai Krajsek and\n      Claudia Comito and\n      Philipp Knechtges and\n      Björn Hagemeier and\n      Michael Tarnawa and\n      Simon Hanselmann and\n      Martin Siggel and\n      Achim Basermann and\n      Achim Streit\n    },\n    booktitle={2020 IEEE International Conference on Big Data (Big Data)},\n    year={2020},\n    pages={276-287},\n    month={December},\n    publisher={IEEE},\n    doi={10.1109/BigData50022.2020.9378050}\n}\n```\n# FAQ\nWork in progress...\n\n  <!-- - Users\n  - Developers\n  - Students\n  - system administrators -->\n\n## Acknowledgements\n\n*This work is supported by the [Helmholtz Association Initiative and\nNetworking Fund](https://www.helmholtz.de/en/about_us/the_association/initiating_and_networking/)\nunder project number ZT-I-0003 and the Helmholtz AI platform grant.*\n\n*This project has received funding from Google Summer of Code (GSoC) in 2022.*\n\n*This work is partially carried out under a [programme](https://activities.esa.int/index.php/4000144045) of, and funded by, the European Space Agency.\nAny view expressed in this repository or related publications can in no way be taken to reflect the official opinion of the European Space Agency.*\n\n---\n\n<div align=\"center\">\n  <a href=\"https://www.dlr.de/EN/Home/home_node.html\"><img src=\"https://raw.githubusercontent.com/helmholtz-analytics/heat/main/doc/images/dlr_logo.svg\" height=\"50px\" hspace=\"3%\" vspace=\"20px\"></a><a href=\"https://www.fz-juelich.de/portal/EN/Home/home_node.html\"><img src=\"https://raw.githubusercontent.com/helmholtz-analytics/heat/main/doc/images/fzj_logo.svg\" height=\"40px\" hspace=\"3%\" vspace=\"20px\"></a><a href=\"http://www.kit.edu/english/index.php\"><img src=\"https://raw.githubusercontent.com/helmholtz-analytics/heat/main/doc/images/kit_logo.svg\" height=\"40px\" hspace=\"3%\" vspace=\"5px\"></a><a href=\"https://www.helmholtz.de/en/\"><img src=\"https://raw.githubusercontent.com/helmholtz-analytics/heat/main/doc/images/helmholtz_logo.svg\" height=\"50px\" hspace=\"3%\" vspace=\"5px\"></a><a href=\"https://www.esa.int/\"><img src=\"https://github.com/user-attachments/assets/2ee251b4-733e-44ea-8d1c-8b75928eef55\" height=\"45px\" hspace=\"3%\" vspace=\"20px\"></a>\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/heatnetsim",
            "repo_link": "https://jugit.fz-juelich.de/iek-10/public/simulation/heatnetsim",
            "readme": "![](docs/HeatNetSim_Logo.svg)\n\n[//]: # ([![PyPI]&#40;https://badge.fury.io/py/GasNetSim.svg&#41;]&#40;https://badge.fury.io/py/GasNetSim&#41;)\n[![Python 3.9](https://img.shields.io/badge/python-3.9-blue.svg)](https://www.python.org/downloads/release/python-390/)\n[![License: MPL 2.0](https://img.shields.io/badge/License-MPL%202.0-brightgreen.svg)](https://opensource.org/licenses/MPL-2.0)\n\n\n# **HeatNetSim**\n\n*HeatNetSim* is a simulation package designed for the simulation of unidirectional and bidirectional networks, such as fifth generation heating and cooling networks. \nIt can be used for both steady-state simulations and additionally enables a dynamic temperature calculation.\nMoreover, users have the flexibility to modify this tool and implement their own modeling approaches.\n\n## Installation\nCurrently, it is only supported using source files.\n\n## License\n\nThe project is released under the terms of the [MPL 2.0](https://mozilla.org/MPL/2.0/).\n\n## Dependencies\n- ``numpy``>=1.19.2\n- ``matplotlib``>=3.3.2\n- ``scipy``>=1.5.2\n- ``pandas``>=1.1.3\n- ``pytest``>=6.2.5\n- ``fluids``>=0.1.86\n- ``pint``>=0.18\n- ``setuptools``>=60.9.3\n- ``requests``>=2.25.1\n- ``pyparsing``~=3.0.7\n- ``cantera``~=2.5.1\n\n[//]: # (## Discussion)\n\n[//]: # ()\n[//]: # (You can connect with the community in a variety of ways...)\n\n[//]: # ()\n[//]: # (- [Mailing list]&#40;https://lists.lfenergy.org/g/xxxx-discussion&#41;)\n\n[//]: # (- [#{{**PROJECT-NAME**}} channel on LF Energy Slack]&#40;https://slack.lfenergy.org&#41;)\n\n[//]: # (- Other communication channels, e.g. Discord, Slack, Skype, Mattermost, FZJ Rocket Chat, ...)\n\n[//]: # (## Contributing)\n\n[//]: # ()\n[//]: # (_**TODO** Provide contributing guidelines here or point to a_)\n\n[//]: # (_[CONTRIBUTING.md]&#40;CONTRIBUTING.md&#41; file if the contributing guidelines require_)\n\n[//]: # (_more than just a few lines._)\n\n## Reporting Issues\n\nTo report a problem, you can open an \n[issue](https://jugit.fz-juelich.de/iek-10/public/simulation/heatnetsim/-/issues)\nin repository against a specific workflow. If the issue is sensitive in nature or\na security related issue, please do not report in the issue tracker but instead\nemail [Sina Dibos](s.dibos@fz-juelich.de).",
            "project_id": "9885"
        },
        {
            "software_organization": "https://helmholtz.software/software/heliport",
            "repo_link": "https://codebase.helmholtz.cloud/heliport/heliport",
            "readme": "",
            "project_id": "1287"
        },
        {
            "software_organization": "https://helmholtz.software/software/hifis-rsd",
            "repo_link": "https://codebase.helmholtz.cloud/research-software-directory/RSD-as-a-service",
            "readme": "",
            "project_id": "7449"
        },
        {
            "software_organization": "https://helmholtz.software/software/higgs-dataset-training",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/Higgs-Dataset-Training",
            "readme": "![Python](https://img.shields.io/badge/Python-3670A0?style=plastic&logo=python&logoColor=ffdd54)  ![Pandas](https://img.shields.io/badge/Pandas-%23150458.svg?style=plastic&logo=pandas&logoColor=white) ![NumPy](https://img.shields.io/badge/Numpy-777BB4.svg?style=plastic&logo=numpy&logoColor=white) ![Matplotlib](https://img.shields.io/badge/Matplotlib-%233F4F75.svg?style=plastic&logo=plotly&logoColor=white) ![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=plastic&logo=Keras&logoColor=white) ![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=plastic&logo=scikit-learn&logoColor=white) ![Dask](https://img.shields.io/badge/Dask-%23870000.svg?style=plastic&logo=dask&logoColor=white) ![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/Higgs-Dataset-Training?style=plastic)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.13133945.svg)](https://doi.org/10.5281/zenodo.13133945)\n\n\n# Model Training and Evaluation for Higgs Dataset\n\n## Overview\n\nThis repository demonstrates training and evaluating a Keras model using the Higgs dataset available from the UCI ML Repository.\n\n> [Higgs Dataset](http://archive.ics.uci.edu/ml/datasets/HIGGS)\n\nThe dataset has been studied in this publication:\n\n> [Searching for Exotic Particles in High-energy Physics with Deep Learning.<br>Baldi, P., P. Sadowski, and D. Whiteson. \nNature Communications 5, 4308 (2014)](https://www.nature.com/articles/ncomms5308)\n\nThe ML pipeline includes downloading the dataset, data preparation, model training, evaluation, feature importance analysis, and visualization of results. Dask is utilised for handling this large datasets for parallel processing.\n\n### Installation\n\n1) Create and source virtual environment:\n```shell\npython -m venv env\nsource env/bin/activate  # On Windows use `env\\Scripts\\activate`\n```\n2) Install the dependencies:\n```shell\npip install -r requirements.txt\n```\n\n### Data\n\nThe Higgs dataset can be downloaded directly from the provided scripts in separate steps\n\n- `download_data.py`  ~ 2.6 GB\n- `data_extraction.py` ~ 7 GB\n- `data_preparation.py` ~ test dataset: 240 MB, trained dataset: 5 GB\n\nAlternatively, you can run directly the main script from the `data/src/main.py`:\n\n```shell\npython data/src/main.py\n```\n\n#### Downloading Data\nDownload a dataset file from the specified URL with a progress bar.\n\n##### Script\n```shell\npython data/download_data.py\n```\n\n##### Example Usage\n```python\nzipDataUrl = 'https://archive.ics.uci.edu/static/public/280/higgs.zip'      # Higgs dataset URL\nzipPath = '../higgs/higgs.zip'\ndownloadDataset(zipDataUrl, zipPath)\ncleanUp(zipPath)        # Clean up downloaded zip file (~ 2.6 GB)\n```\n\n#### Data Extraction\nExtract the contents of a zip dataset and decompress the .gz dataset file to a specified output path.\n\n##### Script\n```shell\npython data/data_extraction.py\n```\n\n##### Example Usage\n```python\nzipDataUrl = 'https://archive.ics.uci.edu/static/public/280/higgs.zip'      # Higgs dataset URL\nextractTo = '../higgs'\nzipPath = os.path.join(extractTo, 'higgs.zip')\ngzCsvPath = os.path.join(extractTo, 'higgs.csv.gz')\nfinalCsvPath = os.path.join(extractTo, 'higgs.csv')\n\nextractZippedData(zipPath, extractTo)\ndecompressGzFile(gzCsvPath, finalCsvPath)\ncleanUp(gzCsvPath)      # Clean up gzipped file (~ 2.6 GB)\n```\n\n#### Data Preparation\nSet column names and separates the test set from the training data based on the dataset description (500,000 test sets).\n\nDataset Description: The first column is the class label (1 for signal, 0 for background), followed by the 28 features (21 low-level features then 7 high-level features). The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features.\n\n##### Script\n```shell\npython data/data_preparation.py\n```\n\n##### Example Usage\n```python\nprepareFrom = '../higgs'\ncsvPath = os.path.join(prepareFrom, 'higgs.csv')\npreparedCsvPath = os.path.join(prepareFrom, 'prepared-higgs.csv')\nprepareData(csvPath, preparedCsvPath)\ncleanUp(csvPath)         # Clean up gzipped file (~ 7.5 GB)\n```\n\n### Loading Data\n\n#### Using Pandas\n\nUse the `dataLoader/data_loader.py` script to load the prepared dataset into a Pandas DataFrame.\n\n##### Script\n```shell\npython data/src/data_loader.py\n```\n\n##### Example Usage\n```python\nfilepath = '../data/higgs/prepared-higgs_train.csv'   # prepared-higgs_test.csv\ndataLoader = DataLoader(filepath)\ndataFrame = dataLoader.loadData()\ndataLoader.previewData(dataFrame)\n```\n\n#### Using Dask\n\nUse the `dataLoader/data_loader_dask.py` script to load the prepared dataset into a Dask DataFrame, which is beneficial for this large dataset.\n\n##### Script\n```shell\npython data/src/data_loader_dask.py\n```\n##### Example Usage:\n```python\nfilepath = '../data/higgs/prepared-higgs_train.csv'   # prepared-higgs_test.csv\ndataLoader = DataLoaderDask(filepath)\ndataFrame = dataLoader.loadData()\ndataLoader.previewData(dataFrame)\n```\n\n### Exploratory Data Analysis (EDA)\n\nProvides various functions for performing EDA, including visualising correlations, checking missing values, and plotting feature distributions.\nThe data analysis plots are saved under `eda/plots`.\n\n##### Script\n```shell\npython exploration/eda.py\n```\n\n##### Example Usage:\n```python\nfilepath = '../data/higgs/prepared-higgs_train.csv'   # prepared-higgs_test.csv\n\n    # using Dask data frame\ndataLoaderDask = DataLoaderDask(filepath)\ndataFrame = dataLoaderDask.loadData()\n\neda = EDA(dataFrame)\neda.describeData()\neda.checkMissingValues()\neda.visualiseFeatureCorrelation()\n\neda.visualizeTargetDistribution()\neda.visualizeFeatureDistribution('feature_1')\neda.visualizeAllFeatureDistributions()\neda.visualizeFeatureScatter('feature_1', 'feature_2')\neda.visualizeTargetDistribution()\neda.visualizeFeatureBoxplot('feature_2')\n```\n\n### Usage\n\n#### Training the Model\nThe model is defined using Keras with the following default architecture for binary classification:\n\n- Input layer with 128 neurons (dense)\n- Hidden layer with 64 neurons (dense)\n- Output layer with 1 neuron (activation function: sigmoid)\n\nYou can customise the model architecture by providing a different `modelBuilder` callable in the ModelTrainer class.\n\nThe trained models and training loss plots are saved under `kerasModel/trainer/trainedModels`.\n\n##### Script\n```shell\npython kerasModel/trainer/model_trainer.py\n```\n\n##### Example Usage:\n```python\nfilePath = '../../data/higgs/prepared-higgs_train.csv'\n\ndef customModel(inputShape: int) -> Model:\n    \"\"\"Example of a custom model builder function for classification\"\"\"\n    model = keras.Sequential([\n        layers.Input(shape=(inputShape,)),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(256, activation='relu'),\n        layers.Dense(128, activation='relu'),\n        layers.Dense(64, activation='relu'),\n        layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n    ])\n    return model\n        \ndataLoaderDask = DataLoaderDask(filePath)\ndataFrame = dataLoaderDask.loadData()\n\n## Optional: Define model training/compiling/defining parameters as a dictionary and pass it to the class constructor\nparams = {\n    \"epochs\": 10,\n    \"batchSize\": 32,\n    \"minSampleSize\": 100000,\n    \"learningRate\": 0.001,\n    \"modelBuilder\": customModel,     # callable\n    \"loss\": 'binary_crossentropy',    \n    \"metrics\": ['accuracy']\n}\ntrainer = ModelTrainer(dataFrame, params)\ntrainer.trainKerasModel()           # optional: Train the Keras model with sampling, Set: trainKerasModel(sample = true, frac = 0.1).\ntrainer.plotTrainingHistory()\n```\n\n#### Evaluating the Model\nThe evaluation script computes metrics like:\n\n- Accuracy\n- Precision\n- Recall (Sensitivity\n- F1 Score\n- Classification Report\n\nThe evaluation includes visualizations such as\n- Confusion Matrix\n- ROC Curve\n\nThe evaluation results are logged and saved to a file under `kerasModel/evaluator/evaluationPlots`.\n\n##### Script\n```shell\npython kerasModel/evaluator/model_evaluator.py\n```\n\n##### Example Usage:\n```python\nmodelPath = '../trainer/trainedModels/keras_model_trained_dataset.keras'\nfilePath = '../../data/higgs/prepared-higgs_train.csv'\n\ndataLoaderDask = DataLoaderDask(filePath)\ndataFrame = dataLoaderDask.loadData()\n\nevaluator = ModelEvaluator(modelPath, dataFrame)\nevaluator.evaluate()\n```\n\n#### Feature Importance Analysis\n\nThe feature importance is computed using permutation importance and visualised using a bar chart. It is implemented once using the Pandas approach (with SciKit) and another using Dask for parallel processing.\n\nThe chart and the result CSV file are saved under `kerasModel/featureImportance/featureImportancePlots`.\n\n##### Script\n```shell\npython kerasModel/featureImportance/feature_importance.py\n```\n\n##### Example Usage:\n```python\nmodelPath = '../trainer/trainedModels/keras_model_test_dataset.keras'\nfilePath = '../../data/higgs/prepared-higgs_test.csv'\n\ndataLoaderDask = DataLoaderDask(filePath)\ndataFrame = dataLoaderDask.loadData()\n\nevaluator = FeatureImportanceEvaluator(modelPath, dataFrame)\nevaluator.evaluate()\n        \n        # Alternatively\nevaluator = FeatureImportanceEvaluator(modelPath, dataFrame, sampleFraction = 0.1, nRepeats=32)  # with sampling\nevaluator.evaluate(withDask = False)        # with pandas\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/hilbertcurve",
            "repo_link": "https://github.com/jokergoo/HilbertCurve",
            "readme": "# HilbertCurve <img width=\"300\" alt=\"image\" src=\"https://github.com/jokergoo/HilbertCurve/assets/449218/e40159f5-bbca-4d61-960b-1ba1d744f9e2\" align=\"right\">\n\n\n\n[![R-CMD-check](https://github.com/jokergoo/HilbertCurve/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/HilbertCurve/actions)\n[![codecov](https://img.shields.io/codecov/c/github/jokergoo/HilbertCurve.svg)](https://codecov.io/github/jokergoo/HilbertCurve) \n[![bioc](https://bioconductor.org/shields/downloads/devel/HilbertCurve.svg)](https://bioconductor.org/packages/stats/bioc/HilbertCurve/)\n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/HilbertCurve.svg)](http://bioconductor.org/packages/devel/bioc/html/HilbertCurve.html)\n\n\n\n\n\n[Hilbert curve](https://en.wikipedia.org/wiki/Hilbert_curve) is a type of space-filling curves\nthat fold one dimensional axis into a two dimensional space, but with still keeping the locality.\nIt has advantages to visualize data with long axis in following two aspects:\n\n1. greatly improve resolution for the visualization;\n2. easy to visualize clusters because generally data points in the cluster will also be close in the Hilbert curve. \n\nThis package aims to provide an easy and flexible way to visualize data through Hilbert curve.\nThe implementation and example figures are based on following sources:\n\n- http://mkweb.bcgsc.ca/hilbert/\n- http://corte.si/posts/code/hilbert/portrait/index.html\n- http://bioconductor.org/packages/devel/bioc/html/HilbertVis.html\n\n### Citation\n\nZuguang Gu, et al., [HilbertCurve: an R/Bioconductor package for high-resolution visualization of genomic data.](https://doi.org/10.1093/bioinformatics/btw161)\nBioinformatics 2016\n\n### Install\n\nThe package is at [Bioconductor](http://bioconductor.org/packages/devel/bioc/html/HilbertCurve.html) now\nand you can install the newest version by:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/ComplexHeatmap\")  # in order to get the newest version of ComplexHeatmap\ninstall_github(\"jokergoo/HilbertCurve\")\n```\n\n### Usage\n\nBasically, there are two steps to make a Hilbert curve.\n\n1. Initialize the curve and also map the one-dimensional axis to the curve.\n2. add low-level graphics by `hc_points()`, `hc_segments()`, ... by giving the positions of the graphics.\n\n```r\nhc = HilbertCurve(1, 100, level = 4)\nhc_points(hc, ...)\nhc_segments(hc, ...)\nhc_rect(hc, ...)\nhc_text(hc, ...)\n```\n\nThere is another 'pixel' mode which provides a high resolution for visualizing genomic data by the Hilbert curve.\n\n```r\nhc = HilbertCurve(1, 100000000000, level = 10)\nhc_layer(hc, ...) # this can be repeated several times to add multiple layers on the curve\nhc_png(hc, ...)\n```\n\n### Examples\n\nRainbow color spectrum:\n\n![](https://cloud.githubusercontent.com/assets/449218/12678993/f184c4de-c6a1-11e5-8c8c-ed3ed938c487.png)\n\nChinese dynasty:\n\n![](https://cloud.githubusercontent.com/assets/449218/12678995/f18981cc-c6a1-11e5-8b66-6222bed67c63.png)\n\nGC percent and genes on chromosome 1:\n\n![](https://cloud.githubusercontent.com/assets/449218/12678996/f18a6646-c6a1-11e5-9e0b-c99cc7a93f0e.png)\n\nAssociation between H3K36me3 histone modification and gene bodies:\n\n![](https://cloud.githubusercontent.com/assets/449218/12678992/f1848320-c6a1-11e5-8225-e6fef169f29b.png)\n\nMethylation on chromosome 1:\n\n![](https://cloud.githubusercontent.com/assets/449218/12678994/f186827e-c6a1-11e5-884a-b9135f24146e.png)\n\nCopy number alterations in 22 chromosomes:\n\n![](https://cloud.githubusercontent.com/assets/449218/12678997/f18e405e-c6a1-11e5-9478-3d8fdc4bc834.png)\n\n### License\n\nMIT @ Zuguang Gu\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/hipsta",
            "repo_link": "https://github.com/Deep-MI/hipsta",
            "readme": "# Hippocampal Shape and Thickness Analysis\n\n\n## Purpose:\n\nThis repository contains the Hipsta package, a collection of scripts for\nhippocampal shape and thickness analysis as described in our recent [publication](https://doi.org/10.1016/j.neuroimage.2023.120182).\n\n\n## Documentation:\n\nPlease see the documentation pages for a general overview, usage information and\nexamples, and output description. Brief usage information is also available [here](hipsta/doc/DOCUMENTATION.md).\nSome suggestions for running the script can be found in the [tutorial](TUTORIAL.md).\n\n\n## Current status:\n\nThe hippocampal shape and thickness analysis package is currently in its beta\nstage, which means that it's open for testing, but may still contain unresolved\nissues. Future changes with regard to the algorithms, interfaces, and package\nstructure are to be expected.\n\n\n## Feedback:\n\nQuestions, suggestions, and feedback are welcome, and should preferably be\nsubmitted as an [issue](https://github.com/Deep-MI/Hipsta/issues).\n\n\n## Installation:\n\nIt is recommended to run this pipeline within its own virtual environment. A\nvirtual environment can, for example, be created using Python's `virtualenv`\ncommand:\n\n`virtualenv /path/to/a/new/directory/of/your/choice`\n\nActivate the virtual environment as follows:\n\n`source /path/to/a/new/directory/of/your/choice/bin/activate`\n\nThe package is available on `pypi.org`, and can be installed as follows \n(including all required dependencies):\n\n`pip install hipsta`\n\nAlternatively, the following code can be used to download this package from its\nGitHub repository (this will create a 'Hipsta' directory within the current\nworking directory):\n\n`git clone https://github.com/Deep-MI/Hipsta.git`\n\n\nUse the following code to install the downloaded files as a Python package\n(after changing into the 'Hipsta' directory). It will also install all required\ndependencies:\n\n`pip install .`\n\nThe above steps are not necessary when running the [Docker](docker/Docker.md) or\n[Singularity](singularity/Singularity.md) versions of the package.\n\n\n## Requirements:\n\nUnless using the [Docker](docker/Docker.md) or [Singularity](singularity/Singularity.md)\nversions of the package, the following conditions need to be met for running an\nanalysis:\n\n1. A FreeSurfer version (6.x or 7.x) must be sourced, i.e. FREESURFER_HOME must\nexist as an environment variable and point to a valid FreeSurfer installation.\n\n2. A hippocampal subfield segmentation created by FreeSurfer 7.11 or later\nor the ASHS software. A custom segmentation is also permissible (some restrictions\nand settings apply; see [Supported Segmentations](https://github.com/Deep-MI/Hipsta#supported-segmentations)).\n\n3. Python 3.8 or higher including the lapy, numpy, scipy, nibabel, pyvista, and\npyacvd libraries, among others. See `requirements.txt` for a full list, and use\n`pip install -r requirements.txt` to install.\n\n4. The gmsh package (version 2.x; http://gmsh.info) must be installed. Can be\ndownloaded e.g. as binaries for [linux](https://gmsh.info/bin/Linux/gmsh-2.16.0-Linux64.tgz) or\n[MacOSX](https://gmsh.info/bin/MacOSX/gmsh-2.16.0-MacOSX.dmg) . The 'gmsh' binary must\nbe on the $PATH:\n\n    `export PATH=${PATH}:/path/to/gmsh-directory/bin`\n\n\n## References:\n\nPlease cite the following publications if you use these scripts in your work:\n\n- Diers, K., Baumeister, H., Jessen, F., Düzel, E., Berron, D., & Reuter, M. (2023). An automated, geometry-based method for hippocampal shape and thickness analysis. Neuroimage, 276:120182. doi: [10.1016/j.neuroimage.2023.120182](https://doi.org/10.1016/j.neuroimage.2023.120182).\n\nPlease also consider citing the these publications:\n\n- Geuzaine, C., & Remacle, J.-F. (2009). Gmsh: a three-dimensional finite element mesh generator with built-in pre- and post-processing facilities. International Journal for Numerical Methods in Engineering, 79, 1309-1331.\n\n- Andreux, M., Rodola, E., Aubry, M., & Cremers, D. (2014). Anisotropic Laplace-Beltrami operators for shape analysis. In European Conference on Computer Vision (pp. 299-312). Springer, Cham.\n\n- Iglesias, J. E., Augustinack, J. C., Nguyen, K., Player, C. M., Player, A., Wright, M., ... & Fischl, B. (2015). A computational atlas of the hippocampal formation using ex vivo, ultra-high resolution MRI: application to adaptive segmentation of in vivo MRI. Neuroimage, 115, 117-137.\n\n- Yushkevich, P. A., Pluta, J., Wang, H., Ding, S.L., Xie, L., Gertje, E., Mancuso, L., Kliot, D., Das, S. R., & Wolk, D.A. (2015). Automated Volumetry and Regional Thickness Analysis of Hippocampal Subfields and Medial Temporal Cortical Structures in Mild Cognitive Impairment. Human Brain Mapping, 36, 258-287.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/holowizard",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/hybridmt",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/icgem",
            "repo_link": "https://git.gfz-potsdam.de/icgem",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/ideal-equilibrium-oxygen-membrane-reactor",
            "repo_link": "https://github.com/KabitGit/Ideal-Equilibrium-Oxygen-Membrane-Reactor",
            "readme": "Prequisites\n--\n- Numpy\n- SciPy\n- Cantera (tested with version 2.6.0)\n- Matplotlib (used for plotting in the examples)\n\n\nDescription\n--\nThe Python script OMR_model.py allows to simulate oxygen membrane reactors with continuous gas flow rates as described in [1]. Model input values are the initial condition of the feed and sweep gas entering the chambers separated by the membrane, while the output values refer to the chemical equilibrium state in both chambers, which is affected by the oxygen flux through the membrane.  \n\nChemical equilibrium and perfect mixing is assumed in the entire sweep and feed chamber on both sides of the membrane. The oxygen flux through the membrane is modelled using the Wagner equation and included into the chemical equilibrium calculation.\nThe entire problem is then solved as a nested problem: The inner problem is the equilibrium calculation including an assumed oxygen flux using Cantera [2]. \nThe outer problem is a root-finding problem to find the oxygen flux satisfying the Wagner equation in the equilibrium state which is solved using SciPy [3].\nA detailed explanation of the assumptions, limitations and equations including experimental validation can be found in [1].\n\nThe implementation published here uses thermodynamic data from the Gri 3.0 mechanism [4] and subsequently considers 53 species. \nNotable species herein include: [O2, H2O, H2, CH4, CO, CO2, N2, AR]\n\n\n\nUsage\n--------------------------------------------------------------------------------------------------------------------------------------\nTo import the script into your Python code, download OMR_model.py and import the function Simulate_OMR at the beginning of the code as:\n\n\n`from OMR_model import Simulate_OMR`\n\nAfter defining the input parameters for the model [T,N_f0,x_f0,P_f,N_s0,x_s0,P_s,A_mem,sigma,L,Lc], a simulation can then be performed by calling:\n\n`N_f, x_f, p_o2_f, N_s, x_s, p_o2_s, N_o2, dH, x_comp, conv = Simulate_OMR(T,N_f0,x_f0,P_f,N_s0,x_s0,P_s,A_mem,sigma,L,Lc)`\n\nExamples for using the function with scalar input parameters, as well as array shaped input parameters are given in the Examples folder.\n\n\n\nInputs and outputs of the model\n--\n\n    Parameters (Inputs)\n    ----------\n    T : Float (scalar or array with length n)\n        Temperature in °C.\n    N_f0 : Float (scalar or array with length n)\n        Initial feed gas molar flow rate in mol/min.\n    x_f0 : String or list of strings with length n\n        Initial feed gas mole fractions specified as a string in the format 'A:x_A_f0, B:x_B_f0, C:x_C_f0, ...', where x_A_f0, x_B_f0, x_C_f0 are the mole fractions of the respective species.\n    P_f : Float (scalar or array with length n)\n        Feed gas pressure in Pa.\n    N_s0 : Float (scalar or array with length n)\n        Initial sweep gas molar flow rate in mol/min.\n    x_s0 : String or list of strings with length n\n        Initial sweep gas mole fractions specified as a string in the format 'A:x_A_s0, B:x_B_s0, C:x_C_s0, ...', where x_A_s0, x_B_s0, x_C_s0 are the mole fractions of the respective species.\n    P_s : Float (scalar or array with length n)\n        Sweep gas pressure in Pa.\n    A_mem : Float (scalar or array with length n)\n        Active membrane area in cm^2.\n    sigma : Float (scalar or array with length n)\n        Ambipolar conductivity in S/m.\n    L : Float (scalar or array with length n)\n        Membrane thickness in mum.\n    Lc : Float (scalar or array with length n)\n        Characteristic length in mum.\n\n    Returns (Outputs)\n    -------\n    N_f : Float (array with length n)\n        Feed gas molar flow rate in mol/min.\n    x_f : List of array of floats with size n*53\n        Mole fraction array, consisting of the mole fractions of the feed gas, related to the composition array.\n    p_o2_f : Float (array with length n)\n        Feed gas oxygen partial pressure in Pa.\n    N_s : Float (array with length n)\n        Sweep gas molar flow rate in mol/min.\n    x_s : List of array of floats with size n*53\n        Mole fraction array, consisting of the mole fractions of the sweep gas, related to the composition array.\n    p_o2_s : Float (array with length n)\n        Sweep gas oxygen partial pressure in Pa.\n    p_o2_f : Float (array with length n)\n        Feed gas oxygen partial pressure in Pa.\n    N_o2 : Float (array with length n)\n        Molar oxygen flux through the membrane in mol/min.\n    dH : List of array of floats with size n*53\n        Outlet-Inlet enthalpy flow difference (reaction heat) in W; If positive: The reaction is endothermic; If negative: The reaction is exothermic.\n    x_comp : List of strings with size 53\n        Composition array consisting of the considered species in the calculation.\n    conv : Integer (array with length n)\n        Check whether convergence was achieved for the respective array index; Equal to 1 if converged.\n\n\n\nReferences\n--\n[1] Bittner, K., Margaritis, N., Schulze-Küppers, F., Wolters, J., & Natour, G. (2023). \n    A mathematical model for initial design iterations and feasibility studies of oxygen membrane reactors by minimizing Gibbs free energy. \n    Journal of Membrane Science, 685, 121955.\n    DOI: https://doi.org/10.1016/j.memsci.2023.121955\n\n[2] David G. Goodwin, Harry K. Moffat, Ingmar Schoegl, Raymond L. Speth, and Bryan W. Weber. Cantera: An object-oriented software toolkit for chemical kinetics, \n    thermodynamics, and transport processes. \n    https://www.cantera.org, 2023. Version 3.0.0. DOI: 10.5281/zenodo.8137090\n\n[3] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson,\n    Warren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, \n    Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, CJ Carey, İlhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, \n    Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E.A. Quintero, Charles R Harris, Anne M. Archibald, Antônio H. Ribeiro,\n    Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. \n    (2020) SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17(3), 261-272.\n    DOI: https://doi.org/10.1038/s41592-019-0686-2\n\n[4] G.P. Smith, D.M. Golden, M. Frenklach, N.W. Moriarty, B. Eiteneer, M. Goldenberg, C.T. Bowman, R.K. Hanson, S. Song, \n    W.C.J. Gardiner, V.V. Lissianski, Z. Qin, Gri-Mech 3.0\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/igmas",
            "repo_link": "https://git.gfz-potsdam.de/igmas/igmas-releases",
            "readme": "# IGMAS+ Releases\n\n[![Release](https://git.gfz-potsdam.de/igmas/igmas-releases/-/badges/release.svg?&key_text=release&key_width=55&value_width=190)](https://git.gfz-potsdam.de/igmas/igmas-releases/-/releases)\\\n[<img src=\"https://img.shields.io/badge/doi-10.5880/GFZ.4.5.IGMAS-blue.svg?style=flat-square\" alt=\"doi:10.5880/GFZ.4.5.IGMAS\">](https://doi.org/10.5880/GFZ.4.5.IGMAS)\n\nWelcome to the official repository for **IGMAS+** releases.\n\n**IGMAS+** (Interactive Gravity and Magnetic Application System) is a software for 3-D numerical modelling, visualization and interdisciplinary interpretation of potential fields and their applications.\n\nPlease read [**IGMAS+** License Terms and Conditions](./LICENSE).\n\nVisit our website for more information:\\\n<https://www.gfz-potsdam.de/igmas>\n",
            "project_id": "919"
        },
        {
            "software_organization": "https://helmholtz.software/software/interactivecomplexheatmap",
            "repo_link": "https://github.com/jokergoo/InteractiveComplexHeatmap",
            "readme": "# Make Interactive Complex Heatmaps\n\n[![R-CMD-check](https://github.com/jokergoo/InteractiveComplexHeatmap/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/InteractiveComplexHeatmap/actions)\n[![bioc](http://www.bioconductor.org/shields/downloads/devel/InteractiveComplexHeatmap.svg)](https://bioconductor.org/packages/stats/bioc/InteractiveComplexHeatmap/) \n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/InteractiveComplexHeatmap.svg)](http://bioconductor.org/packages/devel/bioc/html/InteractiveComplexHeatmap.html)\n\n<img width=\"1150\" alt=\"Screenshot 2021-07-19 at 21 31 14\" src=\"https://user-images.githubusercontent.com/449218/126217251-8eee8ce8-7e7f-4251-b844-800dd72481bd.png\">\n\n\n**InteractiveComplexHeatmap** is an R package that converts static heatmaps produced from\n[**ComplexHeatmap**](https://github.com/jokergoo/ComplexHeatmap) package into an interactive\nShiny app only with one extra line of code.\n\nThe first example is the default layout of the interactive complex heatmap widget.\n\n<img src=\"https://user-images.githubusercontent.com/449218/110212910-e6147e00-7e9d-11eb-94ed-0ac549247888.gif\"  width='100%' border=\"black\" />\n\nThe second example demonstrates a DESeq2 result with integrating the package **shinydashboard**.\n\n<img src=\"https://user-images.githubusercontent.com/449218/111832925-b16ae280-88f1-11eb-8530-290374f9f2c2.gif\" width=\"100%\" border=\"black\" />\n\n\n### Citation\n\nZuguang Gu, et al., Make Interactive Complex Heatmaps in R, 2021, Bioinformatics, https://doi.org/10.1093/bioinformatics/btab806\n\n## Install\n\n**InteractiveComplexHeatmap** is available on\n[Bioconductor](http://bioconductor.org/packages/devel/bioc/html/InteractiveComplexHeatmap.html),\nyou can install it by:\n\n```r\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"InteractiveComplexHeatmap\")\n```\n\nIf you want the latest version, install it directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/InteractiveComplexHeatmap\")\n```\n\n## Documentation\n\nThere are the following vignettes along with the package:\n\n1. [How to visualize heatmaps interactively](https://jokergoo.github.io/InteractiveComplexHeatmap/articles/InteractiveComplexHeatmap.html)\n2. [How interactive complex heatmap is implemented](https://jokergoo.github.io/InteractiveComplexHeatmap/articles/implementation.html)\n3. [Functions for Shiny app development](https://jokergoo.github.io/InteractiveComplexHeatmap/articles/shiny_dev.html)\n4. [Decorations on heatmaps](https://jokergoo.github.io/InteractiveComplexHeatmap/articles/decoration.html)\n5. [Interactivate heatmaps indirectly generated by pheatmap(), heatmap.2() and heatmap()](https://jokergoo.github.io/InteractiveComplexHeatmap/articles/interactivate_indirect.html)\n6. [A Shiny app for visualizing DESeq2 results](https://jokergoo.github.io/InteractiveComplexHeatmap/articles/deseq2_app.html)\n7. [Implement interactive heatmap from scratch](https://jokergoo.github.io/InteractiveComplexHeatmap/articles/from_scratch.html)\n8. [Share interactive heatmaps to collaborators](https://jokergoo.github.io/InteractiveComplexHeatmap/articles/share.html)\n\nA printer-friendly version of the documentation is available at [bioRxiv](https://doi.org/10.1101/2021.03.08.434289).\n\n\n## Usage\n\n### Directly turn heatmaps interactive\n\nWith any `Heatmap`/`HeatmapList` object, directly send to `htShiny()` to create a Shiny app for your heatmap(s):\n\n```r\nhtShiny(ht_list)\n```\n\nIf the heatmaps are already drawn, `ht_list` can be omitted and the last heatmap object is retrieved automatically:\n\n```r\nHeatmap(...) + other_heatmaps_or_annotations # or other functions that internally use Heatmap()\nhtShiny()\n```\n\n### Shiny app development\n\nThere are also two functions for Shiny app development:\n\n- `InteractiveComplexHeatmapOutput()`: for the UI on the client side.\n- `makeInteractiveComplexHeatmap()`: for processing on the sever side.\n\n```r\nlibrary(InteractiveComplexHeatmap)\nlibrary(ComplexHeatmap)\n\nht = Heatmap(m)\nht = draw(ht)\n\nui = fluidPage(\n    InteractiveComplexHeatmapOutput()\n)\n\nserver = function(input, output, session) {\n    makeInteractiveComplexHeatmap(input, output, session, ht)\n}\n\nshiny::shinyApp(ui, server)\n```\n\nYou can also put multiple interactive heatmaps widgets in the same Shiny app:\n\n```r\nht1 = Heatmap(m, col = c(\"white\", \"blue\"))\nht1 = draw(ht1)\nht2 = Heatmap(m, col = c(\"white\", \"red\"))\nht2 = draw(ht2)\n\nui = fluidPage(\n    h3(\"The first heatmap\"),\n    InteractiveComplexHeatmapOutput(\"ht1\"),\n    hr(),\n    h3(\"The second heatmap\"),\n    InteractiveComplexHeatmapOutput(\"ht2\")\n)\n\nserver = function(input, output, session) {\n    makeInteractiveComplexHeatmap(input, output, session, ht1, \"ht1\")\n    makeInteractiveComplexHeatmap(input, output, session, ht2, \"ht2\")\n}\n\nshiny::shinyApp(ui, server)\n```\n\nTwo additional functions to let you dynamically load interactive heatmap widgets:\n\n- `InteractiveComplexHeatmapModal()`: The interactive heatmap widget is inserted as a \"modal\".\n- `InteractiveComplexHeatmapWidget()`: The interactive heatmap widget is inserted into a place defined by users.\n\n```r\nm = matrix(rnorm(100), 10)\nht = Heatmap(m)\n    \nui = fluidPage(\n    actionButton(\"show_heatmap\", \"Generate_heatmap\"),\n)\n\nserver = function(input, output, session) {\n    observeEvent(input$show_heatmap, {\n        InteractiveComplexHeatmapModal(input, output, session, ht)\n    })\n}\nshiny::shinyApp(ui, server)\n\n# or use InteractiveComplexHeatmapWidget()\nui = fluidPage(\n    actionButton(\"show_heatmap\", \"Generate_heatmap\"),\n    htmlOutput(\"heatmap_output\")\n)\n\nserver = function(input, output, session) {\n    observeEvent(input$show_heatmap, {\n        InteractiveComplexHeatmapWidget(input, output, session, ht,\n            output_id = \"heatmap_output\")\n    })\n}\nshiny::shinyApp(ui, server)\n```\n\n## Interactivate pheatmap(), heatmap.2() and heatmap()\n\nIf you directly use these three funtions, simply replace them with\n`ComplexHeatmap::pheatmap()`, `ComplexHeatmap:::heatmap.2()` and\n`ComplexHeatmap:::heatmap()`. If the three functions are used indirectly, e.g.\na function `foo()` (maybe from another packages or other people's functions)\nwhich internally uses these three heatmap functions, check the vignette\n[\"Interactivate indirect use of pheatmap(), heatmap.2() and heatmap()\"](https://jokergoo.github.io/InteractiveComplexHeatmap/articles/interactivate_indirect.html) to find out how.\n\n## Live examples\n\nFollowing lists several live examples of interactive heatmaps. Details\ncan be found in the package vignette.\n\n- https://jokergoo.shinyapps.io/interactive_complexheatmap/\n- https://jokergoo.shinyapps.io/interactive_complexheatmap_vertical/\n- https://jokergoo.shinyapps.io/interactive_densityheatmap/\n- https://jokergoo.shinyapps.io/interactive_oncoprint/\n- https://jokergoo.shinyapps.io/interactive_enrichedheatmap/\n- https://jokergooo.shinyapps.io/interactive_upset/\n- https://jokergooo.shinyapps.io/interactive_pheatmap/\n- https://jokergooo.shinyapps.io/interactive_heatmap/\n- https://jokergooo.shinyapps.io/interactive_heatmap_2/\n- https://jokergooo.shinyapps.io/interactive_tidyheatmap/\n\nThere are also many other examples provided in the package.\n\n```r\nhtShinyExample()\n```\n\n```\nThere are following examples. Individual example can be run by e.g. htShinyExample(1.1).\n\n──────── 1. Simple examples ─────────────────────────────────────────────────────────\n 1.1 A single heatmap with minimal arguments.\n 1.2 A single heatmap from a character matrix.\n 1.3 A single heatmap with annotations on both rows and columns.\n 1.4 A single heatmap where rows and columns are split.\n 1.5 A list of two heatmaps.\n 1.6 A list of two vertically concatenated heatmaps\n 1.7 Use last generated heatmap, an example from cola package.\n 1.8 Use last generated heatmap, an app with three interactive heatmaps\n 1.9 Demonstrate hover, click and dblclick actions to select cells.\n 1.10 Only response to one of click/hover/dblclick/hover events. Please use\n      htShinyExample('1.10') to get this example (quote the index, or else\n      htShinyExample(1.10) will be treated as the same as htShinyExample(1.1)).\n 1.11 Interactive heatmap under compact mode.\n\n──────── 2. On other plots and packages ─────────────────────────────────────────────\n 2.1 A density heatmap.\n 2.2 An oncoPrint.\n 2.3 A UpSet plot.\n 2.4 An interactive heatmap from pheatmap().\n 2.5 An interactive heatmap from heatmap().\n 2.6 An interactive heatmap from heatmap.2().\n 2.7 A heatmap produced from tidyHeatmap package.\n 2.8 Genome-scale heatmap.\n 2.9 A package-dependency heatmap. You can try to control \"Fill figure region\"\n     and \"Remove empty rows and columns\" in the tools under the sub-heatmap.\n\n──────── 3. Enriched heatmaps ───────────────────────────────────────────────────────\n 3.1 A single enriched heatmap.\n 3.2 A list of enriched heatmaps.\n 3.3 An enriched heatmap with discrete signals.\n\n──────── 4. On public datasets ──────────────────────────────────────────────────────\n 4.1 An example from Lewis et al 2019.\n 4.2 Visualize cell heterogeneity from single cell RNASeq.\n 4.3 Correlations between methylation, expression and other genomic features.\n\n──────── 5. Shiny app development ───────────────────────────────────────────────────\n 5.1 A single Shiny app with two interactive heatmap widgets.\n 5.2 Self-define the output. The selected sub-matrix is shown as a text table.\n 5.3 Self-define the output. Additional annotations for the selected genes are\n     shown.\n 5.4 Visualize Gene Ontology similarities. A list of selected GO IDs as well as\n     their descriptions are shown in the output.\n 5.5 Interactive correlation heatmap. Clicking on the cell generates a\n     scatterplot of the two corresponding variables.\n 5.6 A heatmap on Jaccard coefficients for a list of genomic regions. Clicking\n     on the cell generates a Hilbert curve of how the two sets of genomic\n     regions overlap.\n 5.7 Implement interactivity from scratch. Instead of generating the whole\n     interactive heatmap widget, it only returns the information of rows and\n     columns that user have selected on heatmap and users can use this\n     information to build their own interactive heatmap widgets.\n 5.8 Implement interactivity from scratch. A visualization of 2D density\n     distribution. Brushing on heatmap triggers a new 2D density estimation\n     only on the subset of data.\n\n──────── 6. Dynamically generate heatmap widget in Shiny app ────────────────────────\n 6.1 The matrix with different dimensions is dynamically generated.\n 6.2 Reorder by a column that is specified by user.\n 6.3 Dynamically generate the widget with InteractiveComplexHeatmapModal(). The\n     modal is triggered by an action button.\n 6.4 Dynamically select interactive heatmaps. The modal is triggered by radio\n     buttons.\n 6.5 Dynamically generate the widget. A customized Javascript code is inserted\n     after the UI to change the default behavior of the action button.\n 6.6 The widget is generated by InteractiveComplexHeatmapWidget() where the UI\n     is directly put in the place defined by htmlOutput().\n 6.7 The widget is generated by InteractiveComplexHeatmapWidget() and a\n     customized Javascript code is inserted after the UI.\n\n──────── 7. Interactive R markdown document ─────────────────────────────────────────\n 7.1 Integrate in an interactive R Markdown document.\n 7.2 Integrate in an interactive R Markdown document where the heatmap widgets\n     are dynamically generated.\n\n──────── 8. Interactivate heatmaps indirectly generated by heatmap()/heatmap.2()/pheatmap()\n 8.1 Indirect use of pheatmap().\n 8.2 Indirect use of heatmap.2().\n 8.3 Two interactive heatmap widgets from indirect use of pheatmap().\n\n──────── 9. Float output UI along with mouse positions ──────────────────────────────\n 9.1 A simple example that demonstrates output UI floating with the three\n     actions: hover, click and dblclick.\n 9.2 Floating self-defined outputs.\n 9.3 Floating output only from one event on heatmap, i.e.\n     hover/click/dblclick/brush-output.\n\n──────── 10. Work with shinydashboard ────────────────────────────────────────────────\n 10.1 Separate the three UI components into three boxes.\n 10.2 The three UI components are draggable.\n 10.3 A Shiny dashboard with two tabs.\n 10.4 Only contain the original heatmap where output floats.\n 10.5 A complex dashboard that visualizes a DESeq2 results.\n```\n\n## License\n\nMIT @ Zuguang Gu\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/interactivevis",
            "repo_link": "https://github.com/martindyrba/DeepLearningInteractiveVis",
            "readme": "# Deep Learning Interactive Visualization\n\nThis project contains all code to learn a convolutional neural network model to detect Alzheimer's disease and visualize contributing brain regions with high relevance.\n \n**Further details on the procedures including samples, image processing, neural network modeling, evaluation, and validation were published in:**\n\nDyrba et al. (2021) Improving 3D convolutional neural network comprehensibility via interactive visualization of relevance maps: evaluation in Alzheimer’s disease. *Alzheimer's research & therapy* 13. DOI: [10.1186/s13195-021-00924-2](https://doi.org/10.1186/s13195-021-00924-2).\n\n\n![Screenshot of the InteractiveVis app](InteractiveVis.png)*Screenshot of the InteractiveVis app*\n\n\n***\n\n\n\n### Running the interactive visualization\n\nThe interactive Bokeh web application [InteractiveVis](InteractiveVis) can be used for deriving and inspecting the relevance maps overlaid on the original input images.\n\nTo run it, there are three options.\n\n1. **We set up a public web service to quickly try it out:** <https://explaination.net/demo>\n\n2. Alternatively, download the docker container from DockerHub: `sudo docker pull martindyrba/interactivevis`\nThen use the scripts `sudo ./run_docker_intvis.sh` and `sudo ./stop_docker_intvis.sh` to run or stop the Bokeh app. (You find both files above in this repository.)\nAfter starting the docker container, the app will be available from your web browser: <http://localhost:5006/InteractiveVis>\n\n3. Download this Git repository. Install the required Python modules (see below). Then point the Anaconda prompt or terminal console to the DeepLearningInteractiveVis main directory and run the Bokeh app using:\n`bokeh serve InteractiveVis --show`\n\n\n\n### Requirements and installation:\n\nTo be able to run the interactive visualization from the Git sources, you will need Python <3.8, in order to install tensorflow==1.15.\nAlso, we recommend to first create a new Python environment (using [Anaconda](https://www.anaconda.com/download) or [virtualenv/venv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)) to avoid messing up your local Python modules/versions when you have other coding projects or a system shared by multiple users.\n```console\n# for Anaconda:\nconda create -n InteractiveVis python=3.7\nconda activate InteractiveVis\n```\n\nRun pip to install the dependencies:\n```console\npip install -r requirements.txt\n```\n\nThen you can start the Bokeh application:\n```console\nbokeh serve InteractiveVis --show\n```\n\n\n\n***\n\n\n\n### CNN model training and performance evaluation\n\nThe code for training the CNN models and evaluation is provided in this repository in the subdirectory [scripts](scripts).\nThe order of script execution was as follows:\n\n- [1_CreateResiduals_ADNI2_StoreModels.ipynb](scripts/1_CreateResiduals_ADNI2_StoreModels.ipynb) and other scripts for the validation samples [4_CreateResiduals_DELCODE_applying_ADNI2_regr_model.ipynb](scripts/4_CreateResiduals_DELCODE_applying_ADNI2_regr_model.ipynb) (execution time: each 15-30 minutes).\n- [2_Train_3D_CNN_ADNI2_xVal_wb_mwp1_CAT12_MNI_shuffle_checkpoint.ipynb](scripts/2_Train_3D_CNN_ADNI2_xVal_wb_mwp1_CAT12_MNI_shuffle_checkpoint.ipynb) for model training based on tenfold cross-validation to evaluate general model accuracy for the residualized data (execution time: 2-10 hrs with CUDA-GPU) and [3_Train_3D_CNN_ADNI2_whole_dataset_wb_mwp1_CAT12_MNI_shuffle.ipynb](scripts/3_Train_3D_CNN_ADNI2_whole_dataset_wb_mwp1_CAT12_MNI_shuffle.ipynb) for training the model based on the whole ADNI-GO/2 dataset.\n- [5_Validate_3D_CNN_xVal_wb_mwp1_CAT12_MNI_DELCODE.ipynb](scripts/5_Validate_3D_CNN_xVal_wb_mwp1_CAT12_MNI_DELCODE.ipynb) and [6_Validate_3D_CNN_whole_ds_wb_mwp1_CAT12_MNI_DELCODE.ipynb](scripts/6_Validate_3D_CNN_whole_ds_wb_mwp1_CAT12_MNI_DELCODE.ipynb) for the evaluation of the models using the validation data sets (execution time: each 15-30 minutes with CUDA-GPU).\n- [7_Train_3D_CNN_ADNI2_xVal_wb_rawdat_mwp1_CAT12_MNI_shuffle_checkpoint.ipynb](scripts/7_Train_3D_CNN_ADNI2_xVal_wb_rawdat_mwp1_CAT12_MNI_shuffle_checkpoint.ipynb) and [8_Train_3D_CNN_ADNI2_whole_dataset_wb_rawdat_mwp1_CAT12_MNI_shuffle.ipynb](scripts/8_Train_3D_CNN_ADNI2_whole_dataset_wb_rawdat_mwp1_CAT12_MNI_shuffle.ipynb) for training the models for the raw datasets (execution time: each 2-10 hrs with CUDA-GPU).\n- [9_Validate_3D_CNN_whole_ds_wb_rawdat_mwp1_CAT12_MNI_DELCODE.ipynb](scripts/9_Validate_3D_CNN_whole_ds_wb_rawdat_mwp1_CAT12_MNI_DELCODE.ipynb) and [9_Validate_3D_CNN_xVal_wb_mwp1_CAT12_MNI_DELCODE.ipynb](scripts/9_Validate_3D_CNN_xVal_wb_mwp1_CAT12_MNI_DELCODE.ipynb) for the evaluation of the models using the validation data sets (execution time: each 15-30 minutes with CUDA-GPU).\n- [x_extract_hippocampus_relevance_lrpCMP_DELCODE.ipynb](scripts/x_extract_hippocampus_relevance_lrpCMP_DELCODE.ipynb) to extract the hippocampus relevance for all models (execution time: 15-30 minutes with CUDA-GPU).\n- [x_extract_relevance_maps_as_nifti_DELCODE.ipynb](scripts/x_extract_relevance_maps_as_nifti_DELCODE.ipynb) to extract the relevance maps directly as nifti file for all participants/scans (execution time: 30 minutes with CUDA-GPU).\n- [hippocampus_volume_relevance_analysis_DELCODE.html](scripts/hippocampus_volume_relevance_analysis_DELCODE.html) for the baseline group separation analysis of hippocampus volume and the correlation analysis of hippocampus volume and relevance (see also other R/Rmd scripts).\n- [y_occlusion_analysis.ipynb](scripts/y_occlusion_analysis.ipynb) code for the occlusion sensitivity analysis (execution time: 90 minutes with CUDA-GPU).\n- [z_CreateResiduals_demo_dataset_applying_ADNI2_regr_model.ipynb](scripts/z_CreateResiduals_demo_dataset_applying_ADNI2_regr_model.ipynb) to create the example files being used by the InteractiveVis demo. It contains a sample of 15 people per diagnostic group, representatively selected from the ADNI-2 phase based on the criteria: amyloid status (positive for Alzheimer's dementia and amnestic mild cogntive impairment, negative for controls), MRI field strength of 3 Tesla, RID greater than 4000, and age of 65 or older. \n\n\n***\n\n\n\n### InteractiveVis architecture overview\n\n*InteractiveVis UML class diagram (v4)*\n\n![InteractiveVis class diagram (v4)](InteractiveVis_class_diagram_v4.svg)\n\n*Select subject UML sequence diagram (v3)*\n\n![Select subject sequence diagram (v3)](select_subject_sequence_diagram_v3.svg)\n\n\n\n***\n\n\n\n### License:\n\nCopyright (c) 2020 Martin Dyrba martin.dyrba@dzne.de, German Center for Neurodegenerative Diseases (DZNE), Rostock, Germany\n\nThis project and included source code is published under the MIT license. See [LICENSE](LICENSE) for details.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ioproc",
            "repo_link": "https://gitlab.com/dlr-ve/esy/ioproc",
            "readme": "[![PyPI version](https://badge.fury.io/py/ioproc.svg)](https://badge.fury.io/py/ioproc)\n[![PyPI license](https://img.shields.io/pypi/l/ioproc.svg)](https://badge.fury.io/py/ioproc)\n[![pipeline status](https://gitlab.dlr.de/ioproc/ioproc/badges/development/pipeline.svg)](https://gitlab.dlr.de/ioproc/ioproc/-/commits/development)\n[![coverage report](https://gitlab.dlr.de/ioproc/ioproc/badges/development/coverage.svg)](https://gitlab.dlr.de/ioproc/ioproc/-/commits/development) \n\n# The ioProc workflow manager\n`ioproc` is a light-weight workflow manager for Python ensuring robust, scalable and reproducible data pipelines. The tool is developed at the German Aerospace Center (DLR) for and in the scientific context of energy systems analysis, however, it is widely applicable in other scientific fields.\n\n## how-to install\nSetup a new Python environment and install ioProc using \n\n    pip install ioproc   \n\n## how-to configure\n\nConfigure your pipeline in the `user.yaml`. The `workflow` is defined by a list of actions. These must\ncontain the fields `project`, `call` and `data` (with sub fields `read_from_dmgr`, and `write_to_dmgr`). The user\nmay specify additional fields for each action under the optional key `args`.  \nYou may get inspiration from the default actions in `general.py`.\n\nYou may also have a look into the [snippets](https://gitlab.com/dlr-ve/esy/ioproc/-/snippets) section where several basic `ioproc` functionalities are described:\n- [Set up your first workflow](https://gitlab.com/dlr-ve/esy/ioproc/-/snippets/2327213)\n- [Define your first action](https://gitlab.com/dlr-ve/esy/ioproc/-/snippets/2327210)\n- [Make use of checkpoints](https://gitlab.com/dlr-ve/esy/ioproc/-/snippets/2327214)\n- [Define an action making use of the ioproc datamanger](https://gitlab.com/dlr-ve/esy/ioproc/-/snippets/2327212)\n- [Add additional yaml files to your workflow](https://gitlab.com/dlr-ve/esy/ioproc/-/snippets/2327209)\n- [Define global parameters](https://gitlab.com/dlr-ve/esy/ioproc/-/snippets/2327207)\n- [Starting ioproc workflow via command line with additional input parameters](https://gitlab.com/dlr-ve/esy/ioproc/-/snippets/2327208) \n\n## default actions provided by ioProc\n\n### `readExcel`\nThis function is used to parse Excel files and storing it in the Data manager.\n\n```python\n@action('general')\ndef parse_excel(dmgr, config, params):\n    '''\n    Parses given `excelFile` for specified `excelSheets` as dataframe object and stores it in the datamanager by the \n    key specified in `write_to_dmgr`.\n    `excelHeader` can be set to `True` or `False`.\n    \n    The action may be specified in the user.yaml as follows:\n    - action:\n        project: general\n        call: parse_excel\n        data:\n            read_from_dmgr: null\n            write_to_dmgr: parsedData\n        args:  \n            excelFile: spreadsheet.xlsx\n            excelSheet: sheet1\n            excelHeader: True\n    '''\n\n    args = params['args']\n    file = get_field(args, 'excelFile')\n    excel_sheet = get_excel_sheet(args)\n    header = get_header(get_field(args, 'excelHeader'))\n    parsed_excel = pd.read_excel(io=file, sheet_name=excel_sheet, header=header)\n\n    with dmgr.overwrite:\n        dmgr[params['data']['write_to_dmgr']] = parsed_excel\n```\n\n### `checkpoint`\nCheckpoints save the current state and content of the data manger to disk in HDF5 format. The workflow can be resumed at any time from previously created checkpoints.\n\n```python\n@action('general')\ndef checkpoint(dmgr, config, params):\n    '''\n    creates a checkpoint file in the current working directory with name\n    Cache_TAG while TAG is supplied by the action config.\n\n    :param tag: the tag for this checkpoint, this can never be \"start\"\n    '''\n    assert params['tag'] != 'start', 'checkpoints can not be named start'\n    dmgr.toCache(params['tag'])\n    mainlogger.info('set checkpoint \"{}\"'.format(params['tag']))\n```\n\n### `printData`\nThis action prints all data stored in the data manager to the console. It can therefore be used for conveniently debugging a workflow.\n\n```python\n@action('general')\ndef printData(dmgr, config, params):\n    '''\n    simple debugging printing function. Prints all data in the data manager.\n\n    Does not have any parameters.\n    '''\n    for k, v in dmgr.items():\n        mainlogger.info(k+' = \\n'+str(v))\n```\n",
            "project_id": "20310288"
        },
        {
            "software_organization": "https://helmholtz.software/software/iqtools",
            "repo_link": "https://github.com/xaratustrah/iqtools",
            "readme": "# Welcome to `iqtools`\n[![documentation](https://img.shields.io/badge/docs-mkdocs%20material-blue.svg?style=flat)](https://xaratustrah.github.io/iqtools)[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7615693.svg)](https://doi.org/10.5281/zenodo.7615693)\n\n<div style=\"margin-left:auto;margin-right:auto;text-align:center\">\n<img src=\"https://raw.githubusercontent.com/xaratustrah/iqtools/main/docs/img/icon.png\" width=\"128\">\n</div>\n\nCollection of code for working with offline complex valued time series data ([inphase and quadrature](https://en.wikipedia.org/wiki/In-phase_and_quadrature_components) or IQ Data) with numpy written for Python3.\n\n## Installation and usage\n\n### Quick instructions\n\nThere are many ways to install `iqtools` either fully or partly. One way to do a complete install is this:\n\n#### TL;DR (for Linux and Mac):\n\nQuick but full installation if you have `mamba` installed. Tested on Linux and Mac. First clone the repo, then go to the directory and run these commands.\n\n```\nmamba create -n my_env\nmamba activate my_env\nmamba install -y root pyqt pyfftw\npip install -r requirements.txt\npip install .\n```\n\nWhere `my_env` can be any name you like.\n\n\n#### Test your installation\n\nYou can test your installation by typing:\n\n```bash\npython3 -c 'import ROOT;import PyQt5;from iqtools import*'\n```\n\nIf the command returns without any error, then you are good, i.e. you should be able to use the library, or run one of the user interfaces.\n\n### Detailed installation instructions\n\n#### Preparation\n\nIf you do not need to use `iqtools` with ROOT features, you can skip to the next section. If you like to use `iqtools` with ROOT features within PyROOT, please make sure you have a proper installation of ROOT and PyROOT in your python environment. There are several alternatives of how to install ROOT:\n\n* System wide installation on Linux (Please refer to the web site of [PyROOT](https://root.cern/manual/python/) ). This approach is not recommended\n* An easier way is to install ROOT using `conda-forge` as described [here](https://anaconda.org/conda-forge/root/) or [here](https://iscinumpy.gitlab.io/post/root-conda/).\n* Most recommended is to use `mamba`. For that just install [mamba](https://mamba.readthedocs.io/en/latest/installation.html). Before installing, it is recommended to create a new mamba env and do your work there:\n\n```\nmamba create -n my_env\nmamba activate my_env\nmamba install root pyqt\n```\n\nSame goes with the installation of `pyqt`. If you are not interested in the GUI script, you can just ignore the installation of `pyqt` in the previous step. You will not be able to use the GUI, but you can still use the CLI and of course the library itself.\n\n#### Installing packages\n\nClone the repository or download the source from [GitHUB](https://github.com/xaratustrah/iqtools). Then use `pip` for installing and uninstalling `iqtools`.\n\n    pip install -r requirements.txt\n    pip install .\n\n\n### Windows\n\nUnder windows, ROOT / PyROOT needs to be installed in a different manner. Please refer to the installation instructions on the corresponding [web page](https://root.cern/) of the ROOT project. If you do not need the ROOT functions, you can still run the library, CLI and GUI under Windows. Specifically, it is recommended to download the latest version of [WinPython](https://winpython.github.io/) which contains the `PyQt` library. Just unpacking WinPython is enough, no installation is needed. After this, you can just follow the instructions above to install the requirements and packages via `pip`.\n\nSome stand alone static versions of the `iqgui` for windows may be made available in the future in the release section for the corresponding tags.\n\n### Quick usage\n\n`iqtools` is a library that can be embedded in data analysis projects. You can use its full functionality in your own codes by importing it:\n\n```python\nfrom iqtools import *\n```\n\nand use it accordingly.\n\n`iqtools` offers user interface which do not implement the full functionality of the library, but can be useful for quick access or conversions, so it can be run as a command line program for processing data file as well. For example:\n\n    iqtools --help\n\nThe `iqgui` script is a graphical user interface (GUI) written in Qt with limited functionality, but nevertheless interesting features. You can run it by simply typing:\n\n```bash\niqgui\n```\n\nA simple window will appear, where you can accesss some quick feartures. For more information on the GUI frontend please refer to the [documentation page](https://xaratustrah.github.io/iqtools).\n\n<img src=\"https://raw.githubusercontent.com/xaratustrah/iqtools/main/docs/img/iqgui.png\" width=\"512\">\n\n## Documentation\n\nFor more information please refer to the [documentation page](https://xaratustrah.github.io/iqtools).\n\n## Citation for publications\n\nIf you are using this code in your publications, please refer to [DOI:10.5281/zenodo.7615693](https://doi.org/10.5281/zenodo.7615693) for citation, or cite as:\n\n<small>\nShahab Sanjari. (2023). <i>iqtools: Collection of code for working with offline complex valued time series data in Python.</i> Zenodo. <a href=\"https://doi.org/10.5281/zenodo.7615693\">https://doi.org/10.5281/zenodo.7615693</a>\n</small>\n\n\n## Licensing\n\nPlease see the file [LICENSE.md](./LICENSE.md) for further information about how the content is licensed.\n\n\n## Acknowledgements\n\nMany thanks to @tfoerst3r for providing help with the project structure and licensing issues and to @carlkl for helping with creating a static Windows version of the GUI."
        },
        {
            "software_organization": "https://helmholtz.software/software/isaac",
            "repo_link": "https://github.com/ComputationalRadiationPhysics/isaac",
            "readme": "![ISAAC](/isaac.png?raw=true \"ISAAC\")\n\nIn Situ Animation of Accelerated Computations\n=====================================================\n\n![Wakefield visualization from PIConGPU](/example_renderings/picongpu_wakefield_1.png?raw=true \"Wakefield visualization from PIConGPU\")\n\nAbout ISAAC\n-----------\n\nMany computations like physics or biologists simulations these days\nrun on accelerated hardware like CUDA GPUs or Intel Xeon Phi, which are\nitself distributed in a big compute cluster communicating over MPI. The\ngoal of ISAAC is to visualize this data without the need to download it\nto the host while using the high computation speed of the accelerator.\n\nISAAC insists of two parts: The server and the insitu library.\nFurthermore there needs to be a client, which is able to show the\ntransfered stream and meta data. A reference HTML5 client is provided,\nbut needs to be adapted to specific simulations and is not part of ISAAC\nitself (but still in the repository).\n\nSimulation code has just to add some calls and settings to the insitu\ntemplate library. After that the server will notice when a simulation\nis running and give the user some options to observe the computations\n_on the fly_. It is also possible to send meta data back to the\nsimulation, e.g. to restart it with improved settings.\n\nInstalling requirements, building and using in own application\n--------------------------------------------------------------\n\nPlease see in [INSTALL.md](./INSTALL.md) for installing, building and\nusing ISAAC.\nIf you need to install ISAAC on a server not accessible from the outside\nyou need to [tunnel the connections](./TUNNEL.md) of the clients.\nA more detailed __documentation__ about using ISAAC __can be\n[found here](http://computationalradiationphysics.github.io/isaac)__.\n\nClient\n------\n\nInside the client directory lay three files:\n* interface.htm\n* interface_vlc.htm\n* interface_presentation.htm\n\nThe very first uses direct JSON injection, but no real streaming protocol\nlike RTP. The second can use RTP, but needs the (free) vlc browser plugin\ninstalled to work. Furthermore the server most be able to directly send\nUDP packages to you, which are blocked by most firewalls. Last but not\nleast this adds some latency for the h264 encoding. However the stream itself\nwill use way less bandwidth. The last client version is for presentation\npurposes, the table with meta data values is not shown, but some are shown\ndirectly in the stream box. E.g. if you visualize\n__[PIConGPU](https://github.com/ComputationalRadiationPhysics/picongpu)__\nwith ISAAC enabled this will show you the count of particles and cells\nused.\n\nKnown issues\n------------\n\n* If streaming over twitch or another rtmp compatible service is used,\n  but the rtmp port (1935) ist blocked or a wrong url passed, the server\n  will crash because of the underlying gStreamer rtmp implementation.\n\nLicensing\n---------\n\nISAAC is licensed under the LGPLv3.\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/jards",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/jards-user-forum/jards",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/jcuber",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/perftools/jcuber",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/jemris",
            "repo_link": "https://github.com/JEMRIS/jemris",
            "readme": "General Information\n===================\n\nJEMRIS is a general MRI simulation framework.\n\nThe general process of simulation consists of preparation by choice or\nimplementation of sequence, sample and coil setup and the invocation\nof the simulation run itself.  \n\n\nDocumentation\n=============\n\nIt is _highly_ recommended to read the provided documentation online.\nPlease find the build, install, developer and user documentation under\nhttp://www.jemris.org.\n\n\nLicensing\n=========\n\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA \n02110-1301  USA\n\nFor an explicit declaration of licensing refer to the COPYING file in\nthe root directory of this package.\n\n\nContact\n=======\n\nThis package is maintained by Tony Stoecker <tony.stoecker@dzne.de>.\nPlease find problem specific contact addresses on http://www.jemris.org.\n\n\nInstallation\n============\n\nPlease visit http://www.jemris.org for detailed installation instructions.\n\n\nHow to report bugs\n==================\n\nIf you have identified a bug in JEMRIS you are welcome to send a detailed\nbug report to <tony.stoecker@dzne.de>. Please include`\n\n* Information about your system\n\n   - Which operating system and version (uname -a)\n   - Which C compiler and version (gcc --version)\n   \n  And anything else you think is relevant.\n\n* Information about your version of JEMRIS\n\n   - Version and release number\n   \n* How to reproduce the bug\n\n   - If it is a systematical bug in JEMRIS please provide the\n     sequence, the sample, the coils and the outputs from sequence or\n     simulation GUI to help us to reproduce the bug.\n\nPatches are most welcome.  If possible please provide a pull request on github."
        },
        {
            "software_organization": "https://helmholtz.software/software/jplag",
            "repo_link": "https://github.com/jplag/JPlag/",
            "readme": "<p align=\"center\"> \n\t<img alt=\"JPlag logo\" src=\"core/src/main/resources/de/jplag/logo-dark.png\" width=\"350\">\n</p>\n\n# JPlag - Detecting Software Plagiarism\n[![CI Build](https://github.com/jplag/jplag/actions/workflows/maven.yml/badge.svg)](https://github.com/jplag/jplag/actions/workflows/maven.yml)\n[![Latest Release](https://img.shields.io/github/release/jplag/jplag.svg)](https://github.com/jplag/jplag/releases/latest)\n[![Maven Central](https://maven-badges.herokuapp.com/maven-central/de.jplag/jplag/badge.svg)](https://maven-badges.herokuapp.com/maven-central/de.jplag/jplag)\n[![License](https://img.shields.io/github/license/jplag/jplag.svg)](https://github.com/jplag/jplag/blob/main/LICENSE)\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/y/jplag/JPlag)](https://github.com/jplag/JPlag/pulse)\n[![SonarCloud Coverage](https://sonarcloud.io/api/project_badges/measure?project=jplag_JPlag&metric=coverage)](https://sonarcloud.io/component_measures?metric=Coverage&view=list&id=jplag_JPlag)\n[![Report Viewer](https://img.shields.io/badge/report%20viewer-online-b80025)](https://jplag.github.io/JPlag/)\n[![Java Version](https://img.shields.io/badge/java-SE%2021-yellowgreen)](#download-and-installation)\n\n\nJPlag finds pairwise similarities among a set of multiple programs. It can reliably detect software plagiarism and collusion in software development, even when obfuscated. All similarities are calculated locally, and no source code or plagiarism results are ever uploaded to the internet. JPlag supports a large number of programming and modeling languages.\n\n* 📈 [JPlag Demo](https://jplag.github.io/Demo/)\n\n* 🏛️ [JPlag on Helmholtz RSD](https://helmholtz.software/software/jplag)\n\n* 🤩 [Give us Feedback in a **short (<5 min) survey**](https://docs.google.com/forms/d/e/1FAIpQLSckqUlXhIlJ-H2jtu2VmGf_mJt4hcnHXaDlwhpUL3XG1I8UYw/viewform?usp=sf_link)\n\n\n## Supported Languages\n\nAll supported languages and their supported versions are listed below.\n\n| Language                                               |                                                                                Version | CLI Argument Name | [state](https://github.com/jplag/JPlag/wiki/2.-Supported-Languages) |  parser   |\n|--------------------------------------------------------|---------------------------------------------------------------------------------------:|-------------------|:-------------------------------------------------------------------:|:---------:|\n| [Java](https://www.java.com)                           |                                                                                     21 | java              |                               mature                                |   JavaC   |\n| [C](https://isocpp.org)                                |                                                                                     11 | c                 |                               legacy                                |  JavaCC   |\n| [C++](https://isocpp.org)                              |                                                                                     14 | cpp               |                                beta                                 |  ANTLR 4  |\n| [C#](https://docs.microsoft.com/en-us/dotnet/csharp/)  |                                                                                      6 | csharp            |                               mature                                |  ANTLR 4  |\n| [Python](https://www.python.org)                       |                                                                                    3.6 | python3           |                                beta                                 |  ANTLR 4  |\n| [JavaScript](https://www.javascript.com/)              |                                                                                    ES6 | javascript        |                                beta                                 |  ANTLR 4  |\n| [TypeScript](https://www.typescriptlang.org/)          | [~5](https://github.com/antlr/grammars-v4/tree/master/javascript/typescript/README.md) | typescript        |                                beta                                 |  ANTLR 4  |\n| [Go](https://go.dev)                                   |                                                                                   1.17 | golang            |                                beta                                 |  ANTLR 4  |\n| [Kotlin](https://kotlinlang.org)                       |                                                                                    1.3 | kotlin            |                                beta                                 |  ANTLR 4  |\n| [R](https://www.r-project.org/)                        |                                                                                  3.5.0 | rlang             |                                beta                                 |  ANTLR 4  |\n| [Rust](https://www.rust-lang.org/)                     |                                                                                 1.60.0 | rust              |                                beta                                 |  ANTLR 4  |\n| [Swift](https://www.swift.org)                         |                                                                                    5.4 | swift             |                                beta                                 |  ANTLR 4  |\n| [Scala](https://www.scala-lang.org)                    |                                                                                 2.13.8 | scala             |                                beta                                 | Scalameta |\n| [LLVM IR](https://llvm.org)                            |                                                                                     15 | llvmir            |                                beta                                 |  ANTLR 4  |\n| [Scheme](http://www.scheme-reports.org)                |                                                                                      ? | scheme            |                               legacy                                |  JavaCC   |\n| [EMF Metamodel](https://www.eclipse.org/modeling/emf/) |                                                                                 2.25.0 | emf               |                                beta                                 |    EMF    |\n| [EMF Model](https://www.eclipse.org/modeling/emf/)     |                                                                                 2.25.0 | emf-model         |                                alpha                                |    EMF    |\n| [SCXML](https://www.w3.org/TR/scxml/)                  |                                                                                    1.0 | scxml             |                                alpha                                |    XML    |\n| Text (naive)                                           |                                                                                      - | text              |                               legacy                                |  CoreNLP  |\n\n## Download and Installation\nYou need Java SE 21 to run or build JPlag.\n\n### Downloading a release\n* Download a [released version](https://github.com/jplag/jplag/releases).\n* In case you depend on the legacy version of JPlag we refer to the [legacy release v2.12.1](https://github.com/jplag/jplag/releases/tag/v2.12.1-SNAPSHOT) and the [legacy branch](https://github.com/jplag/jplag/tree/legacy).\n\n### Via Maven\nJPlag is released on [Maven Central](https://search.maven.org/search?q=de.jplag), it can be included as follows:\n```xml\n<dependency>\n  <groupId>de.jplag</groupId>\n  <artifactId>jplag</artifactId>\n  <version><!--desired version--></version>\n</dependency>\n```\n\n### Building from sources \n1. Download or clone the code from this repository.\n2. Run `mvn clean package` from the root of the repository to compile and build all submodules.\n   Run `mvn clean package assembly:single` instead if you need the full jar which includes all dependencies.\n   Run `mvn -P with-report-viewer clean package assembly:single` to build the full jar with the report viewer. In this case, you'll need [Node.js](https://nodejs.org/en/download) installed.\n3. You will find the generated JARs in the subdirectory `cli/target`.\n\n## Usage\nJPlag can either be used via the CLI or directly via its Java API. For more information, see the [usage information in the wiki](https://github.com/jplag/JPlag/wiki/1.-How-to-Use-JPlag). If you are using the CLI, you can display your results via [jplag.github.io](https://jplag.github.io/JPlag/). No data will leave your computer!\n\n### CLI\n*Note that the [legacy CLI](https://github.com/jplag/jplag/blob/legacy/README.md) is varying slightly.*\nThe language can either be set with the -l parameter or as a subcommand (`jplag [jplag options] <language name> [language options]`). A subcommand takes priority over the -l option.\nWhen using the subcommand, language-specific arguments can be set. A list of language-specific options can be obtained by requesting the help page of a subcommand (e.g. `jplag java -h`).\n\n```\nParameter descriptions: \n      [root-dirs[,root-dirs...]...]\n                        Root-directory with submissions to check for plagiarism.\n      -bc, --bc, --base-code=<baseCode>\n                        Path to the base code directory (common framework used in all submissions).\n  -l, --language=<language>\n                        Select the language of the submissions (default: java). See subcommands below.\n  -M, --mode=<{RUN, VIEW, RUN_AND_VIEW}>\n                        The mode of JPlag: either only run analysis, only open the viewer, or do both (default: null)\n  -n, --shown-comparisons=<shownComparisons>\n                        The maximum number of comparisons that will be shown in the generated report, if set to -1 all comparisons will be shown (default: 500)\n      -new, --new=<newDirectories>[,<newDirectories>...]\n                        Root-directories with submissions to check for plagiarism (same as root).\n      --normalize       Activate the normalization of tokens. Supported for languages: Java, C++.\n      -old, --old=<oldDirectories>[,<oldDirectories>...]\n                        Root-directories with prior submissions to compare against.\n  -r, --result-file=<resultFile>\n                        Name of the file in which the comparison results will be stored (default: results). Missing .zip endings will be automatically added.\n  -t, --min-tokens=<minTokenMatch>\n                        Tunes the comparison sensitivity by adjusting the minimum token required to be counted as a matching section. A smaller value increases the sensitivity but might lead to more\n                          false-positives.\n\nAdvanced\n      --csv-export      Export pairwise similarity values as a CSV file.\n  -d, --debug           Store on-parsable files in error folder.\n  -m, --similarity-threshold=<similarityThreshold>\n                        Comparison similarity threshold [0.0-1.0]: All comparisons above this threshold will be saved (default: 0.0).\n  -p, --suffixes=<suffixes>[,<suffixes>...]\n                        comma-separated list of all filename suffixes that are included.\n  -P, --port=<port>     The port used for the internal report viewer (default: 1996).\n  -s, --subdirectory=<subdirectory>\n                        Look in directories <root-dir>/*/<dir> for programs.\n  -x, --exclusion-file=<exclusionFileName>\n                        All files named in this file will be ignored in the comparison (line-separated list).\n\nClustering\n      --cluster-alg, --cluster-algorithm=<{AGGLOMERATIVE, SPECTRAL}>\n                        Specifies the clustering algorithm (default: spectral).\n      --cluster-metric=<{AVG, MIN, MAX, INTERSECTION}>\n                        The similarity metric used for clustering (default: average similarity).\n      --cluster-skip    Skips the cluster calculation.\n\nSubsequence Match Merging\n      --gap-size=<maximumGapSize>\n                        Maximal gap between neighboring matches to be merged (between 1 and minTokenMatch, default: 6).\n      --match-merging   Enables merging of neighboring matches to counteract obfuscation attempts.\n      --neighbor-length=<minimumNeighborLength>\n                        Minimal length of neighboring matches to be merged (between 1 and minTokenMatch, default: 2).\n\nSubcommands (supported languages):\n  c\n  cpp\n  csharp\n  emf\n  emf-model\n  go\n  java\n  javascript\n  kotlin\n  llvmir\n  python3\n  rlang\n  rust\n  scala\n  scheme\n  scxml\n  swift\n  text\n  typescript\n```\n\n### Java API\n\nThe new API makes it easy to integrate JPlag's plagiarism detection into external Java projects:\n\n<!-- To assure that the code example is always correct, it must be kept in sync\nwith [`ReadmeCodeExampleTest#testReadmeCodeExample`](core/src/test/java/de/jplag/special/ReadmeCodeExampleTest.java). -->\n```java\nLanguage language = new JavaLanguage();\nSet<File> submissionDirectories = Set.of(new File(\"/path/to/rootDir\"));\nFile baseCode = new File(\"/path/to/baseCode\");\nJPlagOptions options = new JPlagOptions(language, submissionDirectories, Set.of()).withBaseCodeSubmissionDirectory(baseCode);\n\ntry {\n    JPlagResult result = JPlag.run(options);\n\n    // Optional\n    ReportObjectFactory reportObjectFactory = new ReportObjectFactory(new File(\"/path/to/output\"));\n    reportObjectFactory.createAndSaveReport(result);\n} catch (ExitException e) {\n    // error handling here\n} catch (FileNotFoundException e) {\n    // handle IO exception here\n}\n```\n\n## Contributing\nWe're happy to incorporate all improvements to JPlag into this codebase. Feel free to fork the project and send pull requests.\nPlease consider our [guidelines for contributions](https://github.com/jplag/JPlag/wiki/3.-Contributing-to-JPlag).\n\n## Contact\nIf you encounter bugs or other issues, please report them [here](https://github.com/jplag/jplag/issues).\nFor other purposes, you can contact us at jplag@ipd.kit.edu .\nIf you are doing research related to JPlag, we would love to know what you are doing. Feel free to contact us!\n\n### More information can be found in our [Wiki](https://github.com/jplag/JPlag/wiki)!\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/jtrack",
            "repo_link": "https://github.com/Biomarker-Development-at-INM7",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/jube",
            "repo_link": "https://github.com/FZJ-JSC/JUBE",
            "readme": "<div align=\"center\">\n<img src=\"docs/logo/JUBE-Logo.svg\" alt=\"JUBE\" height=\"170em\"/>\n</div>\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7534372.svg)](https://doi.org/10.5281/zenodo.7534372)\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n\n# What is JUBE?\n\nThe JUBE benchmarking environment provides a script-based framework for easily\ncreating benchmark and workflow sets, running those sets on different computer\nsystems, and evaluating the results.\nIt is actively developed by the [Juelich Supercomputing Centre](https://www.fz-juelich.de/en/ias/jsc).\nIt focuses on managing the complexity of combinatorial benchmarks and ensuring reproducibility of the benchmarks.\nJUBE provides support for different workflows and the ability to use vendor-supplied platform configurations.\nThe benchmark configuration and scripts can be specified in either YAML or XML format.\nJUBE is primarily designed for use on supercomputers with *scheduding* systems\nlike Slurm or PBS, but also works on laptops running Linux or MacOS operating systems.\n\n## Documentation\n\nJUBE is not (yet) available on `pypi` (it is work in progress).\nThe source code can be downloaded from any of the following places:\n- [GitHub](https://github.com/FZJ-JSC/JUBE)\n- [JSC JUBE Webpage](https://www.fz-juelich.de/en/ias/jsc/services/user-support/software-tools/jube/download)\n\nJUBE can be installed using `pip` or `setup.py` and needs *python 3.2* or higher.\nYou will also need *SQLite* version 3.35.0 (or higher) to use the database as a result output.\nInstallation instructions can be found [here](https://apps.fz-juelich.de/jsc/jube/docu/tutorial.html#installation).\n\nThe documentation for JUBE is split into Beginner Tutorial, Advanced Tutorial, \nFAQ, CLI, and Glossary and can be found in the \n**[User Guide](https://apps.fz-juelich.de/jsc/jube/docu/index.html)**.\n\nIn addition to the documentation, there are also \n[tutorial examples](examples)\nwhich are described in the tutorials of the user guide and \n[benchmark examples](https://github.com/FZJ-JSC/jube-configs), which are curated\nexamples of JUBE benchmarks (the latter will be either replaced or \nupdated/extended soon).\n\nFor more information on the design and architecture of JUBE, please refer to\nthis [paper](https://ebooks.iospress.nl/DOI/10.3233/978-1-61499-621-7-431).\n\n\n## Community and Contributing\n\nJUBE is an open-source project and we welcome your questions, discussions and contributions.\nQuestions can be asked directly to the JSC JUBE developers via mail to\n[jube.jsc@fz-juelich.de](mailto:jube.jsc@fz-juelich.de) and issues can be\nreported in the issue tracker.\nWe also welcome contributions in the form of pull requests.\nContributions can include anything from bug fixes and documentation to new features.\n\nJUBE development is currently still taking place on an internal GitLab instance.\nHowever, we are in a transition phase to move development to GitHub. The complete\nmove will take some time. In the meantime, we will decide individually how to\nproceed with Pull Requests opened on GitHub. Before you start implementing new\nfeatures, we would recommended to contact us, as we still have several open\nbranches in GitLab.\n\n- **[GitHub Issue Tracker](https://github.com/FZJ-JSC/JUBE/issues)**\n- **[Github Discussions](https://github.com/FZJ-JSC/JUBE/discussions)**\n- **[GitHub Pull Requests](https://github.com/FZJ-JSC/JUBE/pulls)**\n\nPlease ensure that your contributions to JUBE are compliant with the \n[contribution](CONTRIBUTING.md), \n[developer](https://apps.fz-juelich.de/jsc/jube/docu/devel.html) and\n[community](CODE_OF_CONDUCT.md) guidelines.\n\n# Citing JUBE\n\nIf you use JUBE in your work, please cite the\n[software release](https://zenodo.org/records/7534372)\nand the [paper](https://ebooks.iospress.nl/DOI/10.3233/978-1-61499-621-7-431).\n\n# Acknowledgments\n\nWe gratefully acknowledge the support of the following research projects and \ninstitutions in the development of JUBE and for granting compute time to develop JUBE. \n\n- UNSEEN (BMWi project, ID: 03EI1004A-F)\n- Gauss Centre for Supercomputing e.V. (www.gauss-centre.eu) and the John von\nNeumann Institute for Computing (NIC) on the GCS Supercomputer JUWELS at\nJülich Supercomputing Centre (JSC)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/jukkr",
            "repo_link": "https://iffgit.fz-juelich.de/kkr/jukkr",
            "readme": "# The Jülich KKR codes\n\n## Description\n\nThe Korringa-Kohn-Rostoker (KKR) Greens function method is a highly accurate all-electron method to perform density functional theory calculations. The most important features of the Jülich KKR codes include the possibility to perform relativistic calculations, predict scattering effects, and treat finite-sized clusters or very large systems.\n\n## Installation\n\n### Dependencies\n- a Fortran compiler (tested with `gfortran` and `ifort` but `ifort` is recommended)\n- [cmake](https://cmake.org)\n- an installation of [LAPACK](http://www.netlib.org/lapack/)\n- a compiler supporting MPI (optional but strongly recommended)\n\n### Compiling the code\n\nThe easiest way to set up the code is to execute the `install.py` script which will guide you through the installation. Afterwards you shoud go to the `build` directory and execute `make` which will start the compilation of the code. The compiled executable will then be placed in the `build` directory.\n\n## Further reading\n\n- The code's [wiki page](https://iffgit.fz-juelich.de/kkr/jukkr/wikis/home)\n\n- The [source code documentation](https://kkr.iffgit.fz-juelich.de/jukkr/)\n\n## Development\n\nCode development is done on the main [gitlab server hosted at the FZ Jülich](https://iffgit.fz-juelich.de/kkr/jukkr) (and not on the [mirrored repository on github](https://github.com/JuDFTteam/JuKKR)).\n\nCreating / editing issues, branches etc. is only supported on the [gitlab version hosted at the FZ Jülich](https://iffgit.fz-juelich.de/kkr/jukkr) which requires sign in (possible with free github account).\n\n## Found a bug?\n\nIf you find any bugs, please file a new issue on the [gitlab issues page](https://iffgit.fz-juelich.de/kkr/jukkr/issues).\n\n\n",
            "project_id": "403"
        },
        {
            "software_organization": "https://helmholtz.software/software/julearn",
            "repo_link": "https://github.com/juaml/julearn",
            "readme": "# julearn\n\n![PyPI](https://img.shields.io/pypi/v/julearn?style=flat-square)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/julearn?style=flat-square)\n![PyPI - Wheel](https://img.shields.io/pypi/wheel/julearn?style=flat-square)\n[![Anaconda-Server Badge](https://anaconda.org/conda-forge/julearn/badges/version.svg)](https://anaconda.org/conda-forge/julearn)\n![GitHub](https://img.shields.io/github/license/juaml/julearn?style=flat-square)\n![Codecov](https://img.shields.io/codecov/c/github/juaml/julearn?style=flat-square)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v2.json)](https://github.com/charliermarsh/ruff)\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit)](https://github.com/pre-commit/pre-commit)\n\n## About\n\nThe Forschungszentrum Jülich Machine Learning Library\n\nCheck our full documentation here: https://juaml.github.io/julearn/index.html\n\nIt is currently being developed and maintained at the [Applied Machine Learning](https://www.fz-juelich.de/en/inm/inm-7/research-groups/applied-machine-learning-aml) group at [Forschungszentrum Juelich](https://www.fz-juelich.de/en), Germany.\n\n## Installation\n\nUse `pip` to install from PyPI like so:\n\n```\npip install julearn\n```\n\nYou can also install via `conda`, like so:\n\n```\nconda install -c conda-forge julearn\n```\n\n## Licensing\n\njulearn is released under the AGPL v3 license:\n\njulearn, FZJuelich AML machine learning library.\nCopyright (C) 2020, authors of julearn.\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n## Citing\n\nIf you use julearn in a scientific publication, please use the following reference\n\n> Hamdan, Sami, Shammi More, Leonard Sasse, Vera Komeyer, Kaustubh R. Patil, and Federico Raimondo. ‘Julearn: An Easy-to-Use Library for Leakage-Free Evaluation and Inspection of ML Models’. arXiv, 19 October 2023. https://doi.org/10.48550/arXiv.2310.12568.\n\nSince julearn is also heavily reliant on scikit-learn, please also cite them: https://scikit-learn.org/stable/about.html#citing-scikit-learn\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/jumpdiff",
            "repo_link": "https://github.com/LRydin/jumpdiff",
            "readme": "![PyPI - License](https://img.shields.io/pypi/l/jumpdiff)\n![PyPI](https://img.shields.io/pypi/v/jumpdiff)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/jumpdiff)\n[![Build Status](https://github.com/LRydin/jumpdiff/actions/workflows/CI.yml/badge.svg)](https://github.com/LRydin/jumpdiff/actions/workflows/CI.yml)\n[![codecov](https://codecov.io/gh/LRydin/jumpdiff/branch/master/graph/badge.svg)](https://codecov.io/gh/LRydin/jumpdiff)\n[![Documentation Status](https://readthedocs.org/projects/jumpdiff/badge/?version=latest)](https://jumpdiff.readthedocs.io/en/latest/?badge=latest)\n\n# jumpdiff\n`jumpdiff` is a `python` library with non-parametric Nadaraya─Watson estimators to extract the parameters of jump-diffusion processes.\nWith `jumpdiff` one can extract the parameters of a jump-diffusion process from one-dimensional timeseries, employing both a kernel-density estimation method combined with a set on second-order corrections for a precise retrieval of the parameters for short timeseries.\n\n## Installation\nTo install `jumpdiff`, run\n\n```\n   pip install jumpdiff\n```\n\nThen on your favourite editor just use\n\n```python\n   import jumpdiff as jd\n```\n\n## Dependencies\nThe library parameter estimation depends on `numpy` and `scipy` solely. The mathematical formulae depend on `sympy`. It stems from [`kramersmoyal`](https://github.com/LRydin/KramersMoyal) project, but functions independently from it<sup>3</sup>.\n\n## Documentation\nYou can find the documentation [here](https://jumpdiff.readthedocs.io/).\n\n# Jump-diffusion processes\n## The theory\nJump-diffusion processes<sup>1</sup>, as the name suggest, are a mixed type of stochastic processes with a diffusive and a jump term.\nOne form of these processes which is mathematically traceable is given by the [Stochastic Differential Equation](https://en.wikipedia.org/wiki/Stochastic_differential_equation)\n\n<img src=\"/Others/SDE_1.png\" title=\"A jump diffusion process\" height=\"25\"/>\n\nwhich has 4 main elements: a drift term <img src=\"/Others/a_xt.png\" title=\"drift term\" height=\"18\"/>, a diffusion term <img src=\"/Others/b_xt.png\" title=\"diffusion term\" height=\"18\"/>, and jump amplitude term <img src=\"/Others/xi.png\" title=\"jump amplitude term\" height=\"18\"/>, which is given by a Gaussian distribution, and finally a jump rate <img src=\"/Others/lambda.png\" title=\"jump rate term\" height=\"14\"/>.\nYou can find a good review on this topic in Ref. 2.\n\n## Integrating a jump-diffusion process\nLet us use the functions in `jumpdiff` to generate a jump-difussion process, and subsequently retrieve the parameters. This is a good way to understand the usage of the integrator and the non-parametric retrieval of the parameters.\n\nFirst we need to load our library. We will call it `jd`\n```python\nimport jumpdiff as jd\n```\nLet us thus define a jump-diffusion process and use `jd_process` to integrate it. Do notice here that we need the drift <img src=\"/Others/a_xt.png\" title=\"drift term\" height=\"18\"/> and diffusion <img src=\"/Others/b_xt.png\" title=\"diffusion term\" height=\"18\"/> as functions.\n\n```python\n# integration time and time sampling\nt_final = 10000\ndelta_t = 0.001\n\n# A drift function\ndef a(x):\n    return -0.5*x\n\n# and a (constant) diffusion term\ndef b(x):\n    return 0.75\n\n# Now define a jump amplitude and rate\nxi = 2.5\nlamb = 1.75\n\n# and simply call the integration function\nX = jd.jd_process(t_final, delta_t, a=a, b=b, xi=xi, lamb=lamb)\n```\n\nThis will generate a jump diffusion process `X` of length `int(10000/0.001)` with the given parameters.\n\n<img src=\"/Others/X_trajectory.png\" title=\"A jump-difussion process\" height=\"200\"/>\n\n## Using `jumpdiff` to retrieve the parameters\n### Moments and Kramers─Moyal coefficients\nTake the timeseries `X` and use the function `moments` to retrieve the conditional moments of the process.\nFor now let us focus on the shortest time lag, so we can best approximate the Kramers─Moyal coefficients.\nFor this case we can simply employ\n\n```python\nedges, moments = jd.moments(timeseries = X)\n```\nIn the array `edges` are the limits of our space, and in our array `moments` are recorded all 6 powers/order of our conditional moments.\nLet us take a look at these before we proceed, to get acquainted with them.\n\nWe can plot the first moment with any conventional plotter, so lets use here `plotly` from `matplotlib`\n\n```python\nimport matplotlib.plotly as plt\n\n# we want the first power, so we need 'moments[1,...]'\nplt.plot(edges, moments[1,...])\n```\nThe first moment here (i.e., the first Kramers─Moyal coefficient) is given solely by the drift term that we have selected `-0.5*x`\n\n<img src=\"/Others/1_moment.png\" title=\"The 1st Kramers─Moyal coefficient\" height=\"200\"/>\n\nAnd the second moment (i.e., the second Kramers─Moyal coefficient) is a mixture of both the contributions of the diffusive term <img src=\"/Others/b_xt.png\" title=\"diffusion term\" height=\"18\"/> and the jump terms <img src=\"/Others/xi.png\" title=\"jump amplitude term\" height=\"18\"/> and <img src=\"/Others/lambda.png\" title=\"jump rate term\" height=\"14\"/>.\n\n<img src=\"/Others/2_moment.png\" title=\"The 2nd Kramers─Moyal coefficient\" height=\"200\"/>\n\nYou have this stored in `moments[2,...]`.\n\n### Retrieving the jump-related terms\nNaturally one of the most pertinent questions when addressing jump-diffusion processes is the possibility of recovering these same parameters from data. For the given jump-diffusion process we can use the `jump_amplitude` and `jump_rate` functions to non-parametrically estimate the jump amplitude <img src=\"/Others/xi.png\" title=\"jump amplitude term\" height=\"18\"/> and jump rate <img src=\"/Others/lambda.png\" title=\"jump rate term\" height=\"18\"/> terms.\n\nAfter having the `moments` in hand, all we need is\n\n```python\n# first estimate the jump amplitude\nxi_est = jd.jump_amplitude(moments = moments)\n\n# and now estimated the jump rate\nlamb_est = jd.jump_rate(moments = moments)\n```\nwhich resulted in our case in `(xi_est) ξ = 2.43 ± 0.17` and `(lamb_est) λ = 1.744 * delta_t` (don't forget to divide `lamb_est` by `delta_t`)!\n\n### Other functions and options\nInclude in this package is also the [Milstein scheme](https://en.wikipedia.org/wiki/Milstein_method) of integration, particularly important when the diffusion term has some spacial `x` dependence. `moments` can actually calculate the conditional moments for different lags, using the parameter `lag`.\n\nIn `formulae` the set of formulas needed to calculate the second order corrections are given (in `sympy`).\n\n# Contributions\nWe welcome reviews and ideas from everyone. If you want to share your ideas, upgrades, doubts, or simply report a bug, open an [issue](https://github.com/LRydin/jumpdiff/issues) here on GitHub, or contact us directly.\nIf you need help with the code, the theory, or the implementation, drop us an email.\nWe abide to a [Conduct of Fairness](contributions.md).\n\n# Changelog\n- Version 0.4 - Designing a set of self-consistency checks, the documentation, examples, and a trial code. Code at PyPi.\n- Version 0.3 - Designing a straightforward procedure to retrieve the jump amplitude and jump rate functions, alongside with a easy `sympy` displaying the correction.\n- Version 0.2 - Introducing the second-order corrections to the moments\n- Version 0.1 - Design an implementation of the `moments` functions, generalising `kramersmoyal` `km`.\n\n# Literature and Support\n\n### History\nThis project was started in 2017 at the [neurophysik](https://www.researchgate.net/lab/Klaus-Lehnertz-Lab-2) by Leonardo Rydin Gorjão, Jan Heysel, Klaus Lehnertz, and M. Reza Rahimi Tabar, and separately by Pedro G. Lind, at the Department of Computer Science, Oslo Metropolitan University. From 2019 to 2021, Pedro G. Lind, Leonardo Rydin Gorjão, and Dirk Witthaut developed a set of corrections and an implementation for python, presented here.\n\n### Funding\nHelmholtz Association Initiative _Energy System 2050 - A Contribution of the Research Field Energy_ and the grant No. VH-NG-1025 and *STORM - Stochastics for Time-Space Risk Models* project of the Research Council of Norway (RCN) No. 274410.\n\n---\n##### Bibliography\n\n<sup>1</sup> Tabar, M. R. R. *Analysis and Data-Based Reconstruction of Complex Nonlinear Dynamical Systems.* Springer, International Publishing (2019), Chapter [*Stochastic Processes with Jumps and Non-vanishing Higher-Order Kramers–Moyal Coefficients*](https://doi.org/10.1007/978-3-030-18472-8_11).\n\n<sup>2</sup> Friedrich, R., Peinke, J., Sahimi, M., Tabar, M. R. R. *Approaching complexity by stochastic methods: From biological systems to turbulence,* [Physics Reports 506, 87–162 (2011)](https://doi.org/10.1016/j.physrep.2011.05.003).\n\n<sup>3</sup> Rydin Gorjão, L., Meirinhos, F. *kramersmoyal: Kramers–Moyal coefficients for stochastic processes.* [Journal of Open Source Software, **4**(44) (2019)](https://doi.org/10.21105/joss.01693).\n\n##### Extended Literature\nYou can find further reading on SDE, non-parametric estimatons, and the general principles of the Fokker–Planck equation, Kramers–Moyal expansion, and related topics in the classic (physics) books\n\n- Risken, H. *The Fokker–Planck equation.* Springer, Berlin, Heidelberg (1989).\n- Gardiner, C.W. *Handbook of Stochastic Methods.* Springer, Berlin (1985).\n\nAnd an extensive review on the subject [here](http://sharif.edu/~rahimitabar/pdfs/80.pdf)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/jumper",
            "repo_link": "https://go.fzj.de/jumper",
            "readme": "",
            "project_id": "9879"
        },
        {
            "software_organization": "https://helmholtz.software/software/jupedsim",
            "repo_link": "https://github.com/PedestrianDynamics/jupedsim",
            "readme": "[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1293771.svg)](https://doi.org/10.5281/zenodo.1293771)\n[![GitHub license](https://img.shields.io/badge/license-LGPL-blue.svg)](https://raw.githubusercontent.com/PedestrianDynamics/jupedsim/master/LICENSE)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/jupedsim)\n![PyPI - Version](https://img.shields.io/pypi/v/jupedsim)\n\n# Jülich Pedestrian Simulator - JuPedSim\n\nJuPedSim is a library to simulate pedestrian dynamics. This software is mainly\ndeveloped at the Institute for Civil Safety\n[IAS-7](https://www.fz-juelich.de/en/ias/ias-7) of the Jülich Research Center\n(Forschungszentrum Jülich) in Germany.\n\n## Installation\n\nIt is easiest to install directly with pip from\n[PyPi.org](https://pypi.org/project/jupedsim/)\n\n```\npip install jupedsim\n```\n\n## Usage\n\nPlease consult our [documentation.](http://jupedsim.org)\n\n## Contributing\n\nJuPedSim is licensed under [GNU LGPLv3](LICENSE) hence we are looking forward\nto your contributions and would be happy to see questions, issues and pull\nrequests.\n\n### Questions\n\nIf you have a question or a problem please open a new topic in [GitHub\ndiscussions](https://github.com/PedestrianDynamics/jupedsim/discussions).\n\n### Issues\n\nIf you found a bug and want to give us a chance to fix it we would be very\nhappy to hear from you. To make it easy for us to help you please include the\nfollowing information when you open a [new\nissue](https://github.com/PedestrianDynamics/jupedsim/issues):\n\n* What did JuPedSim do?\n* What did you expect JuPedSim to do?\n* How can we reproduce the issue?\n\n### Pull Requests\n\nIf you encounter a bug and are would like to submit a fix feel free to open a\nPR, we will look into it.\n\nBefore embarking on larger work it is a good idea to\n[discuss](https://github.com/PedestrianDynamics/jupedsim/discussions) what you\nplan.\n\nWhile we are very happy if you contribute we reserve us the right to\ndecline your PR because it may not fit into our vision of JuPedSim.\n\n## License\n\n[GNU LGPLv3](LICENSE)\n\n## Building from source\n\nHere you have two options.\n\n### With setuptools\n\nYou will need a C++20 capable compiler and CMake >= 3.19 installed on your\nsystem. Then install our python dependencies via pip. Our python package\ndependencies are listed in `requirements.txt` in the root of this repository.\nNow you can call `pip install .`\n\nE.g.:\n\n```bash\ncd jupedsim\npip install -r requirements.txt\npip install .\n```\n\n### Compile yourself\n\nYou will need a C++20 capable compiler and CMake >= 3.19 installed on your\nsystem. Then install our python dependencies via pip. Our python package\ndependencies are listed in `requirements.txt` in the root of this repository.\nNow you can generate makefiles with CMake, then compile and run the python\nlibrary.\n\n```bash\npip install -r jupedsim/requirements.txt\nmkdir jupedsim-build\ncd jupedsim-build\ncmake ../jupedsim\nmake -j\nsource ./environment\n```\n\nThe last line in the above description will populate the python path with the\nlocation of our python code and the native library.\n\n> [!WARNING]\n>\n> When sourcing `./environment` from the build folder you need to ensure JuPedSim\n> is not installed in the current python environment. Otherwise there will be\n> erroneous calls to the wrong python code, resulting in crashes and/or\n> exceptions.\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/jupyterhub-outpost",
            "repo_link": "https://github.com/kreuzert/jupyterhub-outpost",
            "readme": "[![Documentation Status](https://readthedocs.org/projects/jupyterhub-outpost/badge/?version=latest)](https://jupyterhub-outpost.readthedocs.io/en/latest/?badge=latest)\n[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/jupyterhub-outpost)](https://artifacthub.io/packages/search?repo=jupyterhub-outpost)\n\n# JupyterHub Outpost\n\nJupyterHub Outpost can be used as an additional, external source to start and manage single-user servers. Like in JupyterHub itself, different Spawners can be configured at the Outpost. It's best used together with the [jupyterhub-outpostspawner](https://pypi.org/project/jupyterhub-outpostspawner/) configured at JupyterHub.\n\n## Documentation\n\nLink to [documentation](https://jupyterhub-outpost.readthedocs.io).  \n\n## Overview  \n  \nThe JupyterHub community created many useful [JupyterHub Spawner](https://jupyterhub.readthedocs.io/en/latest/reference/spawners.html#examples) over the past years, to allow JupyterHub to use the specific resources of different systems. For most of these Spawners JupyterHub has to run at the system itself. The JupyterHub Outpost service allows the use of these Spawners on remote systems, if JupyterHub uses the [OutpostSpawner](https://github.com/kreuzert/jupyterhub-outpostspawner/)..\n\nOther Spawners like [SSHSpawner](https://github.com/NERSC/sshspawner) can spawn single-user servers on remote systems, but are not able to use system-specific features like [KubeSpawner](https://github.com/jupyterhub/kubespawner) or [BatchSpawner](https://github.com/jupyterhub/batchspawner).\n\nThe JupyterHub Outpost service in combination with the OutpostSpawner enables a single JupyterHub to offer multiple remote systems of different types.  \n  \n- Use one JupyterHub to offer single-user servers on multiple systems.\n- Each system may use a different JupyterHub Spawner.\n- Integrated SSH port forwarding solution to reach remote single-user server.\n- supports the JupyterHub `internal_ssl` feature.\n- shows events gathered by the remote Spawner to the user.\n- Users can override the configuration of the remote Spawner at runtime (e.g. to select a different Docker Image).\n- One JupyterHub Outpost can be connected to multiple JupyterHubs, without interfering with each other.\n  \n## Requirements  \n  \nJupyterHub must run on a Kubernetes Cluster (recommended is the use of Zero2JupyterHub).  \nThe JupyterHub Outpost must fulfill the requirements of the configured Spawner class. \n"
        },
        {
            "software_organization": "https://helmholtz.software/software/jupyterhub-outpostspawner",
            "repo_link": "https://github.com/kreuzert/jupyterhub-outpostspawner",
            "readme": "\n[![Documentation Status](https://readthedocs.org/projects/jupyterhub-outpostspawner/badge/?version=latest)](https://jupyterhub-outpostspawner.readthedocs.io/en/latest/?badge=latest)\n\n# OutpostSpawner\n\nThe OutpostSpawner in combination with the [JupyterHub Outpost service](https://github.com/kreuzert/jupyterhub-outpost) enables JupyterHub to spawn single-user notebook servers on multiple remote resources.\n\n## Documentation\n\nLink to [documentation](https://jupyterhub-outpostspawner.readthedocs.io).\n\n## Overview  \n  \nThe JupyterHub community created many useful [JupyterHub Spawner](https://jupyterhub.readthedocs.io/en/latest/reference/spawners.html#examples) over the past years, to allow JupyterHub to use the specific resources of different systems. For most of these Spawners JupyterHub has to run at the system itself. The OutpostSpawner enables the use of these Spawners on remote systems.\n\nOther Spawners like [SSHSpawner](https://github.com/NERSC/sshspawner) can spawn single-user servers on remote systems, but are not able to use system-specific features like [KubeSpawner](https://github.com/jupyterhub/kubespawner) or [BatchSpawner](https://github.com/jupyterhub/batchspawner).\n\nThe JupyterHub Outpost service in combination with the OutpostSpawner enables a single JupyterHub to offer multiple remote systems of different types.  \n  \n- Use one JupyterHub to offer single-user servers on multiple systems.\n- Each system may use a different JupyterHub Spawner.\n- Integrated SSH port forwarding solution to reach remote single-user server.\n- supports the JupyterHub `internal_ssl` feature.\n- shows events gathered by the remote Spawner to the user.\n- Users can override the configuration of the remote Spawner at runtime (e.g. to select a different Docker Image).\n- One JupyterHub Outpost can be connected to multiple JupyterHubs, without interfering with each other.\n  \n## Requirements  \n  \nJupyterHub must run on a Kubernetes Cluster (recommended is the use of Zero2JupyterHub).  \nThe JupyterHub Outpost must fulfill the requirements of the configured Spawner class. \n"
        },
        {
            "software_organization": "https://helmholtz.software/software/jurassic",
            "repo_link": "https://github.com/slcs-jsc/jurassic",
            "readme": "# Juelich Rapid Spectral Simulation Code\n\nThe Juelich Rapid Spectral Simulation Code (JURASSIC) is a fast infrared radiative transfer model for the analysis of atmospheric remote sensing measurements.\n\n![logo](https://github.com/slcs-jsc/jurassic/blob/master/docs/logo/JURASSIC_320px.png)\n\n[![release (latest by date)](https://img.shields.io/github/v/release/slcs-jsc/jurassic)](https://github.com/slcs-jsc/jurassic/releases)\n[![commits since latest release (by SemVer)](https://img.shields.io/github/commits-since/slcs-jsc/jurassic/latest)](https://github.com/slcs-jsc/jurassic/commits/master)\n[![last commit](https://img.shields.io/github/last-commit/slcs-jsc/jurassic.svg)](https://github.com/slcs-jsc/jurassic/commits/master)\n[![top language](https://img.shields.io/github/languages/top/slcs-jsc/jurassic.svg)](https://github.com/slcs-jsc/jurassic/tree/master/src)\n[![code size in bytes](https://img.shields.io/github/languages/code-size/slcs-jsc/jurassic.svg)](https://github.com/slcs-jsc/jurassic/tree/master/src)\n[![codacy](https://api.codacy.com/project/badge/Grade/aaba414eaf9e4e6784f13458a285ec2f)](https://app.codacy.com/gh/slcs-jsc/jurassic?utm_source=github.com&utm_medium=referral&utm_content=slcs-jsc/jurassic&utm_campaign=Badge_Grade_Settings)\n[![codecov](https://codecov.io/gh/slcs-jsc/jurassic/branch/master/graph/badge.svg?token=TYGWEJMOLI)](https://codecov.io/gh/slcs-jsc/jurassic)\n[![tests](https://img.shields.io/github/actions/workflow/status/slcs-jsc/jurassic/tests.yml?branch=master&label=tests)](https://github.com/slcs-jsc/jurassic/actions)\n[![docs](https://img.shields.io/github/actions/workflow/status/slcs-jsc/jurassic/docs.yml?branch=master&label=docs)](https://slcs-jsc.github.io/jurassic)\n[![license](https://img.shields.io/github/license/slcs-jsc/jurassic.svg)](https://github.com/slcs-jsc/jurassic/blob/master/COPYING)\n[![doi](https://zenodo.org/badge/DOI/10.5281/zenodo.4572889.svg)](https://doi.org/10.5281/zenodo.4572889)\n\n## Features\n\n* JURASSIC uses the emissivity growth approximation (EGA) or the Curtis-Godson approximation (CGA) to conduct infrared radiative transfer calculations. Band transmittances are obtained from pre-calculated look-up tables from line-by-line calculations.\n* The model was carefully tested in intercomparisons with the Karlsruhe Optimized and Precise Radiative Transfer Algorithm (KOPRA), the Reference Forward Model (RFM), and the Stand-alone AIRS Radiative Transfer Algorithm (SARTA).\n* JURASSIC features an MPI-OpenMP hybrid parallelization for efficient use on HPC systems.\n* Distributed open source under the terms and conditions of the GNU GPL.\n\n## Getting started\n\n### Prerequisites\n\nThis documentation describes the installation of JURASSIC on a Linux system. A number of standard tools (gcc, git, make) and software libraries are needed to install JURASSIC. The [GNU Scientific Library](https://www.gnu.org/software/gsl) is required for numerical calculations. A copy of this library can be found in the git repository.\n\nStart by downloading the source code from the git repository:\n\n    git clone https://github.com/slcs-jsc/jurassic.git\n\nTo update an existing installation use:\n\n    git pull https://github.com/slcs-jsc/jurassic.git\n\n### Installation\n\nFirst, compile the GSL library needed for JURASSIC by using the build script:\n\n    cd jurassic/lib\n    ./build.sh\n\nNext, change to the source directory, edit the Makefile according to your needs, and try to compile the code:\n\n    cd jurassic/src\n    emacs Makefile\n    make\n\nThe binaries will be linked statically, i.e., they can be copied and run on other machines. Sometimes this causes problems. In this case remove the '-static' flag from the CFLAGS in the Makefile and compile again.\n\nBy default we use rather strict compiler warnings. All warning messages will be turned into errors and no binaries will be produced. This behavior is enforced by the flag '-Werror'.\n\nThe binaries will remain in the jurassic/src/ directory.\n\nTo run the test cases to check the installation, please use:\n\n    make check\n\nThis will run sequentially through a set of tests. The execution of the tests will stop if any of the tests fails. Please inspect the log messages.\n\n### Run the examples\n\nJURASSIC provides a project directory for testing the examples and also to store other experiments:\n\n    cd jurassic/projects\n\nThis shows how to run the example for the nadir sounder:\n\n    cd nadir\n    ./run.sh\n\nThis shows how to run the example for the limb sounder:\n\n    cd ../limb\n    ./run.sh\n\nIn both examples, we generate an observation geometry file,\n\n    cat obs.tab\n\na standard atmosphere for mid-latitudes,\n\n    cat atm.tab\n\nand conduct radiative transfer calculations for two or three detector channels:\n\n    cat rad.tab\n\nThe output of the simulation is verified by comparing it to reference data.\nAdditionally, gnuplot is used to create plots of the radiance data:\n\n<p align=\"center\"><img src=\"projects/limb/plot_rad.png\" width=\"45%\"/> &emsp; <img src=\"projects/nadir/plot_rad.png\" width=\"45%\"/></p>\n\nKernel functions are calculated using a finite difference method:\n\n<p align=\"center\"><img src=\"projects/limb/plot_kernel_temperature_792.png\" width=\"45%\"/> &emsp; <img src=\"projects/nadir/plot_kernel_temperature_668.5410.png\" width=\"45%\"/></p>\n\n<p align=\"center\"><img src=\"projects/limb/plot_kernel_H2O_792.png\" width=\"45%\"/> &emsp; <img src=\"projects/nadir/plot_kernel_CO2_668.5410.png\" width=\"45%\"/></p>\n\n## Further information\n\nMore detailed information for new users and developers of JURASSIC is collected in the [GitHub wiki](https://github.com/slcs-jsc/jurassic/wiki).\n\nThese are the main references for citing the JURASSIC model in scientific publications:\n\n* Baumeister, P. F. and Hoffmann, L.: Fast infrared radiative transfer calculations using graphics processing units: JURASSIC-GPU v2.0, Geosci. Model Dev., 15, 1855–1874, https://doi.org/10.5194/gmd-15-1855-2022, 2022.\n\n* Hoffmann, L., and M. J. Alexander, Retrieval of stratospheric temperatures from Atmospheric Infrared Sounder radiance measurements for gravity wave studies, J. Geophys. Res., 114, D07105, https://doi.org/10.1029/2008JD011241, 2009.\n\n* Hoffmann, L., Kaufmann, M., Spang, R., Müller, R., Remedios, J. J., Moore, D. P., Volk, C. M., von Clarmann, T., and Riese, M.: Envisat MIPAS measurements of CFC-11: retrieval, validation, and climatology, Atmos. Chem. Phys., 8, 3671-3688, https://doi.org/10.5194/acp-8-3671-2008, 2008.\n\n* You can cite the source code of JURASSIC by using the DOI https://doi.org/10.5281/zenodo.4572889. This DOI represents all versions, and will always resolve to the latest one. Specific DOIs for each release of JURASSIC can be found on the zenodo web site.\n\nPlease see the [citation file](https://github.com/slcs-jsc/jurassic/blob/master/CITATION.cff) for further information.\n\n## Contributing\n\nWe are interested in sharing JURASSIC for operational or research applications. Please do not hesitate to contact us, if you have any further questions or need support.\n\n## License\n\nJURASSIC is distributed under the [GNU General Public License v3.0](https://github.com/slcs-jsc/jurassic/blob/master/COPYING).\n\n## Contact\n\nDr. Lars Hoffmann\n\nJülich Supercomputing Centre, Forschungszentrum Jülich\n\ne-mail: l.hoffmann@fz-juelich.de\n\nwebsite: https://www.fz-juelich.de/ias/jsc/slcs\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/juri",
            "repo_link": "https://github.com/FZJ-JSC/JURI",
            "readme": "# JURI - Jülich Reporting Interface\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10232352.svg)](https://doi.org/10.5281/zenodo.10232352)\n\nJURI provides a template driven fully client based web framework to visualize data lists\nand associated data graphs.\n\nJURI is currently used for the [LLview Job Reporting](https://github.com/FZJ-JSC/LLview) and Kontview @JSC. \n\n## Installation\n\nInstallation instructions can be currently found on [LLview's documentation page](https://apps.fz-juelich.de/jsc/llview/docu/install/).\n\n## Further Information\n\nFor further information please see: https://www.fz-juelich.de/jsc/llview\n\nContact: [llview.jsc@fz-juelich.de](mailto:llview.jsc@fz-juelich.de)\n\n## Copyright, License and CLA\n\nCopyright (c) 2023 Forschungszentrum Juelich GmbH, Juelich Supercomputing Centre  \nhttps://www.fz-juelich.de/jsc/llview  \n\nThis is an open source software distributed under the GPLv3 license. More information see the LICENSE file at the top level.\n\nContributions must follow the Contributor License Agreement. More information see the CONTRIBUTING.md file at the top level.\n\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/kaapana",
            "repo_link": "https://github.com/kaapana/kaapana",
            "readme": "\n<p align=\"center\">\n <img src=\"https://www.kaapana.ai/kaapana-downloads/kaapana-docs/stable/img/kaapana_logo_2.png\" height=170 alt=\"kaapana\" border=\"0\" />\n</p>\n\n[![Documentation Status](https://readthedocs.org/projects/kaapana/badge/?version=latest)](https://kaapana.readthedocs.io/en/latest/?badge=latest)\n<a href=\"https://join.slack.com/t/kaapana/shared_invite/zt-hilvek0w-ucabihas~jn9PDAM0O3gVQ/\"><img src=\"https://img.shields.io/badge/chat-slack-blueviolet\" /></a>\n\n## What is Kaapana?\n\n<p>\n  <a href=\"https://www.kaapana.ai/kaapana-downloads/kaapana-docs/stable/gif/kaapana-v0.2.1-showcase.mp4\" target=\"_blank\">\n    <img src=\"https://www.kaapana.ai/kaapana-downloads/kaapana-docs/stable/img/thumbnail_kaapana_vid.png\" />\n  </a>\n</p>\n\nKaapana (from the hawaiian word kaʻāpana, meaning \"distributor\" or \"part\") is an open-source toolkit for state-of-the-art platform provisioning in the field of medical data analysis. The applications comprise  AI-based workflows and federated learning scenarios with a focus on radiological and radiotherapeutic imaging. \n\nObtaining large amounts of medical data necessary for developing and training modern machine learning methods is an extremely challenging effort that often fails in a multi-center setting, e.g. due to technical, organizational and legal hurdles. A federated approach where the data remains under the authority of the individual institutions and is only processed on-site is, in contrast, a promising approach ideally suited to overcome these difficulties.\n\nFollowing this federated concept, the goal of Kaapana is to provide a framework and a set of tools for sharing data processing algorithms, for standardized workflow design and execution as well as for performing distributed method development. This will facilitate data analysis in a compliant way enabling researchers and clinicians to perform large-scale multi-center studies.\n\nBy adhering to established standards and by adopting widely used open technologies for private cloud development and containerized data processing, Kaapana integrates seamlessly with the existing clinical IT infrastructure, such as the Picture Archiving and Communication System (PACS), and ensures modularity and easy extensibility.\n\nCore components of Kaapana:\n* **Workflow management:** Large-scale image processing with SOTA deep learning algorithms, such as [nnU-Net](https://github.com/MIC-DKFZ/nnunet) image segmentation and [TotalSegmentator](https://github.com/wasserth/TotalSegmentator)\n* **Datasets:** Exploration, visualization and curation of medical images\n* **Extensions:** Simple integration of new, customized algorithms and applications into the framework\n* **Storage:** An integrated PACS system and Minio for other types of data\n* **System monitoring:** Extensive resource and system monitoring for administrators\n* **User management** Simple user management via [Keycloak](https://www.keycloak.org/)\n\nCore technologies used in Kaapana:\n* [Kubernetes](https://kubernetes.io/): Container orchestration system\n* [Helm](https://helm.sh/): The package manager for Kubernetes\n* [Airflow](https://airflow.apache.org/): Workflow management system enabling complex and flexible data processing workflows\n* [OpenSearch](https://opensearch.org/): Search engine for DICOM metadata-based searches\n* [dcm4chee](https://www.dcm4che.org/): Open source PACS system serving as a central DICOM data storage\n* [Prometheus](https://github.com/prometheus/prometheus): Collecting metrics for system monitoring\n* [Grafana](https://github.com/grafana/grafana): Visualization for monitoring metrics\n* [Keycloak](https://www.keycloak.org/): User authentication\n\n\nCurrently, Kaapana is used in multiple projects in which a Kaapana-based platform is deployed at multiple clinical sites with the objective of distributed radiological image analysis and quantification. The projects include [RACOON](https://racoon.network/) initiated by [NUM](https://www.netzwerk-universitaetsmedizin.de) with all 38 German university clinics participating, the Joint Imaging Platform ([JIP](https://jip.dktk.dkfz.de/jiphomepage/)) initiated by the German Cancer Consortium ([DKTK](https://dktk.dkfz.de/)) with 11 university clinics participating as well as [DART](https://cce-dart.com) initiated by the [Cancer Core Europe](https://cancercoreeurope.eu/) with 7 cancer research centers participating.\n\nFor more information, please also take a look at our publication of the Kaapana-based [Joint Imaging Platform in JCO Clinical Cancer Informatics](https://ascopubs.org/doi/full/10.1200/CCI.20.00045).\n\n## Documentation\n\nCheck out the [documentation](https://kaapana.readthedocs.io/en/latest/) for further information about how Kaapana works, for instructions on how to build, deploy, use and further develop the platform.\n\n## Where to find us\n* [GitLab](https://gitlab.hzdr.de/kaapana/kaapana/): The main Kaapana repository, mirrored on GitHub.\n* [Slack](https://kaapana.slack.com/): Join the community for discussions and updates.\n* [YouTube](https://www.youtube.com/@KaapanaAI): Tutorials, demos and more in-depth presentations.\n* [Website](https://kaapana.ai/)\n\n## Versioning\n\nAs of Kaapana 0.2.0 we follow strict [SemVer](https://semver.org/) approach to versioning.\n\n## Citations\nPlease [cite](https://ascopubs.org/action/showCitFormats?doi=10.1200/CCI.20.00045) the [following paper](https://ascopubs.org/doi/full/10.1200/CCI.20.00045) when using Kaapana:\n\n    Jonas Scherer, Marco Nolden, Jens Kleesiek, Jasmin Metzger, Klaus Kades, Verena Schneider, Michael Bach, Oliver Sedlaczek, Andreas M. Bucher, Thomas J. Vogl, ...Klaus Maier-Hein. Joint Imaging Platform for Federated Clinical Data Analytics. JCO Clinical Cancer Informatics, 4:10271038, November 2020. doi: 10.1200/CCI.20.00045. URL https://ascopubs.org/doi/full/10.1200/CCI.20.00045.\n\nWhen using Kapaana for federated learning please also [cite](https://link.springer.com/chapter/10.1007/978-3-031-18523-6_13#citeas) the [following paper](https://link.springer.com/book/10.1007/978-3-031-18523-6):\n\n    Klaus Kades, Jonas Scherer, Maximilian Zenk, Marius Kempf, and Klaus MaierHein. Towards Real-World Federated Learning in Medical Image Analysis Using Kaapana. In Distributed, Collaborative, and Federated Learning, and Affordable AI and Healthcare for Resource Diverse Global Health, pages 130140, Cham, 2022b. Springer Nature Switzerland. ISBN 978-3-031-18523-6. doi: 10.1007/978-3-031-18523-6_13. URL https://doi.org/10.1007/978-3-031-18523-6_13.\n\n## Licence\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Affero General Public License as published\nby the Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Affero General Public License for more details.\n\nYou should have received a copy of the GNU Affero General Public License\nalong with this program (see file LICENCE).  \nIf not, see <https://www.gnu.org/licenses/>.\n\n## Considerations on our license choice\n\nYou can use Kaapana to build any product you like, including commercial closed-source ones since it is a highly modular system. Kaapana is licensed under the [GNU Affero General Public License](https://www.gnu.org/licenses/agpl-3.0.en.html) for now since we want to ensure that we can integrate all developments and contributions to its core system for maximum benefit to the community and give everything back. We consider switching to a more liberal license in the future. This decision will depend on how our project develops and what the feedback from the community is regarding the license. \n\nKaapana is built upon the great work of many other open-source projects, see the documentation for details. For now, we only release source code we created ourselves since providing pre-built docker containers and licensing for highly modular container-based systems is [a complex task](https://www.linuxfoundation.org/blog/2020/04/docker-containers-what-are-the-open-source-licensing-considerations/). We have done our very best to fulfill all requirements, and the choice of AGPL was motivated mainly to make sure we can improve and advance Kaapana in the best way for the whole community. If you have thoughts about this or if you disagree with our way of using a particular third-party toolkit or miss something please let us know and get in touch. We are open to any feedback and advice on this challenging topic.\n\n## Acknowledgments\n\n### Supporting projects\n\n**Building Data Rich Clinical Trials - CCE_DART**: This project has received funding from the European Union’s Horizon 2020 research and innovation program under grant agreement No 965397. Website: <https://cce-dart.com/>\n\n**Capturing Tumor Heterogeneity in Hepatocellular Carcinoma - A Radiomics Approach Systematically Tested in Transgenic Mice** This project is partially funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – 410981386. Website: <https://gepris.dfg.de/gepris/projekt/410981386>\n\n**Data Science Driven Surgical Oncology Project**: This work was partially supported by the Data Science Driven Surgical Oncology Project (DSdSO), funded by the Surgical Oncology Program at the National Center for Tumor Diseases (NCT), Heidelberg, a partnership by DKFZ, UKHD, Heidelberg University. Website: <https://www.nct-heidelberg.de/forschung/precision-local-therapy-and-image-guidance/surgical-oncology.html>\n\n**Joint Imaging Platform**: This work was partially supported by Joint Imaging Platform, funded by the German Cancer Consortium. Website: <https://jip.dktk.dkfz.de/jiphomepage/>\n\n**HiGHmed**: This work was partially supported by the HiGHmed Consortium, funded by the German Federal Ministry of Education and Research (BMBF, funding code 01ZZ1802A). Website: <https://highmed.org/>\n\n**RACOON**: This work was partially supported by RACOON, funded by the German Federal Ministry of Education and ResearchDieses in the Netzwerk Universitätsmedizin (NUM; funding code 01KX2021). Website: <https://www.netzwerk-universitaetsmedizin.de/projekte/racoon>\n\n**Trustworthy Federated Data Analysis - TFDA**: This work is partially funded by the Helmholtz Association within the project \"Trustworthy Federated Data Analytics” (TFDA) (funding number\nZT-I-OO1 4). Website: <https://tfda.hmsp.center/>\n\nCopyright (C) 2024  German Cancer Research Center (DKFZ)"
        },
        {
            "software_organization": "https://helmholtz.software/software/kadi4mat",
            "repo_link": "https://gitlab.com/iam-cms/kadi",
            "readme": "# Kadi4Mat\n\n**Kadi4Mat**, or **Kadi** for short, is a generic and open source virtual\nresearch environment. Originally developed in the context of materials science,\nKadi4Mat can be used for the management of any type of research data within\ndifferent research disciplines and use cases. For more information about the\nproject, please see its [website](https://kadi.iam.kit.edu) and\n[documentation](https://kadi.readthedocs.io/en/stable).\n\n## Installation\n\nWhile the packaged code of Kadi4Mat can easily be installed as a Python package\nvia [pip](https://pypi.org/project/kadi), a complete installation requires a\nfew additional dependencies and considerations. Please refer to the [stable\ndocumentation](https://kadi.readthedocs.io/en/stable) for full installation\ninstructions.\n\n## Development\n\nContributions to the code are always welcome. However, please consider creating\nan issue first, as described below, if you are planning to make larger changes.\nPlease refer to the [latest\ndocumentation](https://kadi.readthedocs.io/en/latest) for instructions on how\nto set up a development environment of Kadi4Mat as well as other useful\ninformation, such as how to set up a separate fork of the [main\nrepository](https://gitlab.com/iam-cms/kadi).\n\nIn order to merge any contributions back into the main repository, please open\na corresponding [merge\nrequest](https://gitlab.com/iam-cms/kadi/-/merge_requests). Typically, the\nsource branch of the merge request would be a separate (feature) branch of your\nforked repository containing the changes to merge, while the target branch\nshould correspond to the `master` branch of the main repository. Depending on\nthe changes, please make sure to add appropriate tests, documentation,\ntranslations, etc. and also add a corresponding entry to the changelog in\n[`HISTORY.md`](https://gitlab.com/iam-cms/kadi/-/blob/master/HISTORY.md), if\nnecessary. Furthermore, you can add yourself as a contributor to\n[`AUTHORS.md`](https://gitlab.com/iam-cms/kadi/-/blob/master/AUTHORS.md).\n\n## Issues\n\nFor any issues regarding Kadi4Mat (bugs, suggestions, discussions, etc.) please\nuse the [issue tracker](https://gitlab.com/iam-cms/kadi/-/issues) of this\nproject. Make sure to add one or more fitting labels to each issue in order to\nkeep them organized. Before creating a new issue, please also check whether a\nsimilar issue is already open. Note that creating or interacting with issues\nrequires a GitLab account.\n\nFor **bugs** in particular, please use the provided [`Bug`\ntemplate](https://gitlab.com/iam-cms/kadi/-/issues/new?issuable_template=Bug)\nwhen creating a new issue, which also adds the `Bug` label to the issue\nautomatically. For **security-related** issues or concerns, please see\n[`SECURITY.md`](https://gitlab.com/iam-cms/kadi/-/blob/master/SECURITY.md).\n",
            "project_id": "18483189"
        },
        {
            "software_organization": "https://helmholtz.software/software/kagen-communication-free-massively-distributed-graph-generators",
            "repo_link": "https://github.com/KarlsruheGraphGeneration/KaGen",
            "readme": "# Communication-free Graph Generators (+ others)\n\nThis is the code to accompany our eponymous paper: *Funke, D., Lamm, S., Sanders, P., Schulz, C., Strash, D. and von Looz, M., 2017. Communication-free Massively Distributed Graph Generation. arXiv preprint arXiv:1710.07565.*\nYou can find a freely accessible online version [in the arXiv](https://arxiv.org/abs/1710.07565).\n\nIf you use this library in the context of an academic publication, we ask that you cite our paper:\n\n```bibtex\n@inproceedings{funke2017communication,\n  title={Communication-free Massively Distributed Graph Generation},\n  author={Funke, Daniel and Lamm, Sebastian and Sanders, Peter and Schulz, Christian and Strash, Darren and von Looz, Moritz},\n  booktitle={2018 {IEEE} International Parallel and Distributed Processing Symposium, {IPDPS} 2018, Vancouver, BC, Canada, May 21 -- May 25, 2018},\n  year={2018},\n}\n```\n\nAdditionally, if you use the Barabassi-Albert generator, we ask that you cite the [paper](https://arxiv.org/abs/1602.07106):\n\n```bibtex\n@article{sanders2016generators,\n  title={Scalable generation of scale-free graphs},\n  journal={Information Processing Letters},\n  volume={116},\n  number={7},\n  pages={489 -- 491},\n  year={2016},\n  author={Sanders, Peter and Schulz, Christian},\n}\n```\n\nIf you use the R-MAT generator, we ask that you cite the [paper](https://www.cambridge.org/core/journals/network-science/article/linear-work-generation-of-rmat-graphs/68A0DDA58A7B84E9B3ACA2DBB123A16C):\n\n```bibtex\n@article{HubSan2020RMAT, \n  title={Linear Work Generation of {R-MAT} Graphs}, \n  volume={8}, \n  number={4}, \n  journal={Network Science}, \n  publisher={Cambridge University Press}, \n  author={H{\\\"u}bschle-Schneider, Lorenz and Sanders, Peter}, \n  year={2020}, \n  pages={543 -- 550},\n}\n```\n\n## Introduction \n\nNetwork generators serve as a tool to alleviate the need for synthethic instances with controllable parameters by algorithm developers and researchers. \nHowever, many generators fail to provide instances on a massive scale due to their sequential nature or resource constraints.\n\nIn our work, we present novel generators for a variety of network models commonly found in practice.\nBy making use of pseudorandomization and divide-and-conquer schemes, our generators follow a communication-free paradigm.\nThe resulting generators are often embarrassingly parallel and have a near optimal scaling behavior.\nThis allows us to generate instances of up to $2^{43}$ vertices and $2^{47}$ edges in less than 22 minutes on 32,768 cores.\nTherefore, our generators allow new graph families to be used on an unprecedented scale.\n\n## Requirements \n\nIn order to compile the generators, you require: \n\n* A modern, C++17-ready compiler such as `g++` version 9 or higher or `clang` version 11 or higher. \n  * Note: Apple Clang is **not** supported. \n* OpenMPI\n* [Google Sparsehash](https://github.com/sparsehash/sparsehash)\n* CGAL (optional, only required for the Delaunay generators)\n\nYou can install these dependencies via your package manager:\n\n```shell\n# Ubuntu, Debian \napt-get install gcc-12 g++-12 libopenmpi-dev libcgal-dev libsparsehash-dev \n\n# Arch Linux, Manjaro\npacman -S gcc sparsehash openmpi cgal\n\n# Fedora \ndnf install gcc openmpi sparsehash-devel CGAL-devel\n\n# macOS using Homebrew \nbrew install gcc open-mpi google-sparsehash cgal\n\n# macOS using MacPorts \nport install gcc12 openmpi sparsehash cgal5\n```\n\n## Building KaGen \n\nTo compile the code either run `compile.sh` or use the following instructions:\n\n```shell\ngit submodule update --init --recursive\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build --parallel\n```\n\n## Running KaGen \n\nAfter building KaGen, the standalone application is located at `build/app/KaGen`. \nA list of all command line options is available using the `./KaGen --help` option. \nTo view the options of a specific graph generator, use:\n\n```shell \n./KaGen <gnm-undirected|gnm-directed|gnp-undirected|gnp-directed|rgg2d|rgg3d|grid2d|grid3d|rdg2d|rdg3d|rhg|ba|kronecker|rmat> --help\n```\n\nBy default, the generated graph is written to a single file `out` (`-o` option) in DIMACS edge list format (`-f` option).\nOther output formats include:\n\n- `-f edgelist`: DIMACS edge list format (default)\n- `-f binary-edgelist`: DIMACS binary edge list format, use `--32` to write the file with 32 bit data types \n- `-f metis`: Metis graph format\n- `-f hmetis`: hMetis hypergraph format; **note:** KaGen still generates a graph, i.e., every hyperedge will contain two pins\n- `-f dot`: GraphViz dot file (add `-C` to include vertex coordinates for 2D graph generators)\n- `-f coordinates`: Text file containing vertex coordinates \n- `-f parhip`: Binary graph format used by [ParHIP](https://github.com/KaHIP/KaHIP)\n- `-f xtrapulp`: Binary graph format used by [XtraPuLP](https://github.com/HPCGraphAnalysis/PuLP), use `--32` to write the file with 32 bit data types\n\nExperimental output formats include:\n\n- `-f experimental/hmetis-ep`: hMetis hypergraph format, but the graph is transformed s.t. a partition of the hypergraph is an edge partition of the generated graph\n- `-f experimental/freight-netl`: hypergraph format used by FREIGHT; **note:** KaGen still generates a graph, i.e., every hyperedge will contain two pins\n- `-f experimental/freight-netl-ep`: hypergraph format used by FREIGHT, but the graph is transformed s.t. a partition of the hypergraph is an edge partition of the generated graph\n\nOne graph can be stored in multiple formats by passing the `-f` repeatedly, e.g., `-o out -f metis -f coordinates` will write two files `out.metis` and `out.xyz`.\nIf you want each PE to write its edges to a seperate file, use the `--distributed-output` flag.\n\n## Using the KaGen Library\n\nThe KaGen library is located at `build/library/libkagen.a` (use `-DBUILD_SHARED_LIBS=On` to build a shared library instead) and can be used in C++ and C projects.\nIf you are using CMake, you can use KaGen by adding this repository as a Git submodule to your project and including it in your CMake configuration:\n\n```cmake \nadd_subdirectory(external/KaGen)\ntarget_link_libraries(<your-target> PUBLIC KaGen::KaGen)\n```\n\nAlternatively, you can use `FetchContent`: \n\n```cmake \ninclude(FetchContent)\nFetchContent_Declare(KaGen \n  GIT_REPOSITORY https://github.com/sebalamm/KaGen.git \n  GIT_TAG master)\nFetchContent_MakeAvailable(KaGen)\nset_property(DIRECTORY \"${KaGen_SOURCE_DIR}\" PROPERTY EXCLUDE_FROM_ALL YES) # optional\n\ntarget_link_libraries(<your-target> PUBLIC KaGen::KaGen)\n```\n\nExamples on how to use the C and C++ interfaces are available in the `examples/` directory.\nThe examples given below only show the C++ interface.\n\n**Note**: Instead of calling the library functions listed below, you can also use `KaGen::GenerateFromOptionString()` \nto pass the generator options as a string (documentation is available in `kagen/kagen.h`).\n\nThe library functions return the generated graph as an instance of type `kagen::Graph`. \nBy default, the graph is represented as an edge list, i.e., a vector `kagen::Graph::edges[]` containing pairs of vertices.\nTo generate a graph in compressed sparse row (CSR) format, call `kagen::KaGen::UseCSRRepresentation()` before generating the graph. \nThen, access the graph via `kagen::Graph::xadj[]` and `kagen::Graph::adjncy[]`.\n\n## General Graph Format\n\nUnless noted otherwise, KaGen generates **simple**, **undirected** graphs, i.e.,\ngraphs without self-loops, without multi-edges and where for every edge (u, v),\nthere is also a reverse edge (v, u).\n\nWhen using KaGen in a distributed setting, each PE owns an equally sized range of consecutive vertices.\nAn edge is owned by the PE that owns its tail vertex.\nThus, an edge (u, v) is in the edge list of the PE that owns vertex u, while the reverse edge \n(v, u) is in the edge list of the PE owning vertex v.\n\n## Communication-free Graph Generators\n\n### Erdos-Renyi Graphs with Fixed Number of Edges\nGenerate a random Erdos-Renyi graph with a fixed number of edges.\nThe graph can either be directed or undirected and can contain self-loops.\n\n#### Application\n```\nmpirun -n <nproc> ./KaGen <gnm-directed|gnm-undirected> \n  -n <number of vertices>\n  [-N <number of vertices as a power of two>]\n  -m <number of edges>\n  [-M <number of edges as a power of two>]\n  [--self-loops]\n  [-k <number of chunks>]\n  [-s <seed>]\n```\n\n#### Library\n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph_directed = gen.GenerateDirectedGNM(n, m, self_loops = false);\nGraph graph_undirected = gen.GenerateUndirectedGNM(n, m, self_loops = false);\n```\n\n---\n\n### Erdos-Renyi graphs with Fixed Edge Probability\nGenerate a random Erdos-Renyi graph with a fixed edge probability.\nThe graph can either be directed or undirected and can contain self-loops.\n\n#### Application\n```\nmpirun -n <nproc> ./KaGen <gnp_directed|gnp_undirected> \n  -n <number of vertices>\n  [-N <number of vertices as a power of two>]\n  -p <edge probability>\n  [--self-loops]\n  [-k <number of chunks>]\n  [-s <seed>]\n```\n\n#### Library\n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph_directed = gen.GenerateDirectedGNP(n, p, self_loops = false);\nGraph graph_undirected = gen.GenerateUndirectedGNP(n, p, self_loops = false);\n```\n\n---\n\n### Random Geometric Graphs\nGenerate an undirected random geometric graph.\n\n**Note:** This generator is parameterized by the number of vertices in the graph and its edge radius. \nEither parameter can be omitted in favor of the desired number of edges, in which case the omitted \nparameter is approximated such that the expected number of edges matches the desired number of edges.\n\n#### Application\n```\nmpirun -n <nproc> ./KaGen <rgg2d|rgg3d> \n  -n <number of vertices>\n  [-N <number of vertices as a power of two>]\n  -r <edge radius>\n  -m <number of edges>                     # only if -n or -r are omitted\n  [-M <number of edges as a power of two>] # only if -n or -r are omitted\n  [-k <number of chunks>] \n  [-s <seed>]\n```\n\n#### Library\n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph = gen.GenerateRGG2D(n, r, coordinates = false);\nGraph graph = gen.GenerateRGG2D_NM(n, m, coordinates = false); // deduce r s.t. E[# edges] = m\nGraph graph = gen.GenerateRGG2D_MR(m, r, coordinates = false); // deduce n s.t. E[# edges] = m\n\nGraph graph = gen.GenerateRGG3D(n, r, coordinates = false);\nGraph graph = gen.GenerateRGG3D_NM(n, m, coordinates = false); // deduce r s.t. E[# edges] = m\nGraph graph = gen.GenerateRGG3D_MR(m, r, coordinates = false); // deduce n s.t. E[# edges] = m\n```\n\n--- \n\n### Random Delaunay Graphs\nGenerate an undirected random delaunay graph.\n\n**Note:** The graph can be generated with periodic boundary conditions to avoid long edges at the border using the `-p` flag. \nHowever, this can yield unexpected results when using less than 9 PEs (2D) / 27 PEs (3D) to generate the graph.\n\n#### Application\n```\nmpirun -n <nproc> ./KaGen <rdg2d|rdg3d>\n  -n <number of vertices>\n  [-N <number of vertices as a power of two>]\n  [--periodic]\n  [-s <seed>]\n```\n\n#### Library\n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph = gen.GenerateRDG2D(n, periodic, coordinates = false);\nGraph graph = gen.GenerateRDG2D_M(m, periodic, coordinates = false);\n\nGraph graph = gen.GenerateRDG3D(n, coordinates = false);\nGraph graph = gen.GenerateRDG3D_M(m, coordinates = false);\n```\n\n---\n\n### Random Grid Graphs\nGenerate an undirected random grid graph. \n\n#### Application \n```\nmpirun -n <nproc> ./KaGen <grid2d|grid3d>\n  -x <width of grid>\n  [-X <width of grid as a power of two>]\n  -y <height of grid>\n  [-Y <height of grid as a power of two>]\n  -z <depth of grid (grid3d only)>\n  [-Z <depth of grid as a power of two (grid3d only)>]\n  -p <edge probability>\n  -m <number of edges>                     # only if -p is omitted\n  [-M <number of edges as a power of two>] # only if -p is omitted\n  [--periodic]\n  [-k <number of cunks>]\n  [-s <seed>]\n```\n\n#### Library \n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph = gen.GenerateGrid2D(x, y, p, periodic, coordinates = false);\nGraph graph = gen.GenerateGrid2D_N(n, p, periodic, coordinates = false); // x, y = sqrt(n)\nGraph graph = gen.GenerateGrid2D_NM(n, m, periodic, coordinates = false); // x, y = sqrt(n)\n\nGraph graph = gen.GenerateGrid3D(x, y, z, p, periodic, coordinates = false);\nGraph graph = gen.GenerateGrid3D_N(n, p, periodic, coordinates = false); // x, y, z = cbrt(n) \nGraph graph = gen.GenerateGrid3D_NM(n, m, periodic, coordinates = false); // x, y, z = cbrt(n) \n```\n\n--- \n\n### Random Hyperbolic Graphs \nGenerate a two dimensional undirected random hyperbolic graph.\n\n**Note:** On x86 systems, the generator can use 64 bit or 80 bit floating point numbers.\nThis can be controlled explicitly by using the `--hp-floats` or `--no-hp-floats` flags. \nIf neither flag is set, KaGen switches to 80 bit precision automatically if the generated graph has more than 2^29 vertices.\n\n**Note:** Due to floating point inaccuracies, this generator performs communication in a post-processing step.\n\n#### Application\n```\nmpirun -n <nproc> ./KaGen rhg\n  -n <number of vertices>\n  [-N <number of vertices as a power of two>]\n  -g <power-law exponent>\n  -d <average vertex degree>\n  [-k <number of chunks>]\n  [--hp-floats]\n  [--no-hp-floats]\n  [-s <seed>]\n```\n\n#### Library\n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph = gen.GenerateRHG(gamma, n, d, coordinates = false);\nGraph graph = gen.GenerateRHG_NM(gamma, n, m, coordinates = false); // deduce d s.t. E[# edges] = m\nGraph graph = gen.GenerateRHG_MD(gamma, m, d, coordinates = false); // deduce n s.t. E[# edges] = m\n```\n\n## Non-communication-free Graph Generators \n\nSince the original publication, several other graph generators have been integrated into the KaGen framework. \n\n### Barabassi-Albert Graphs \n\nGenerate a random Barabassi-Albert graph.\nThe graph may contain self-loops and multi edges.\n\n#### Application\n```\nmpirun -n <nproc> ./KaGen ba \n  -n <number of vertices>\n  [-N <number of vertices as a power of two>]\n  -d <minimum degree for each vertex>\n  [--directed]\n  [--self-loops]\n  [-k <number of chunks>]\n  [-s <seed>]\n```\n\n#### Library\n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph = gen.GenerateBA(n, d, directed = false, self_loops = false);\nGraph graph = gen.GenerateBA_NM(n, m, directed = false, self_loops = false);\nGraph graph = gen.GenerateBA_MD(m, d, directed = false, self_loops = false);\n```\n\n---\n\n### R-MAT Graphs\nGenerate a random RMAT graph.\n\nEach PE generates a random R-MAT graph with n vertices and m/\\<nproc\\> edges.\nAfterwards, the vertices are assigned to PEs round-robin style and edges are distributed accordingly.\n\n#### Application\n```\nmpirun -n <nproc> ./KaGen rmat \n  -n <number of vertices> # should be a power of two\n  [-N <number of vertices as a power of two>]\n  -m <number of edges>\n  [-M <number of edges as a power of two>]\n  -a <probability for an edge to land in block a>\n  -b <probability for an edge to land in block b>\n  -c <probability for an edge to land in block c>\n  [--directed]\n  [--self-loops]\n  [-s <seed>]\n```\n\n#### Library \n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph = gen.GenerateRMAT(n, m, a, b, c, directed = false, self_loops = false);\n```\n\n---\n\n### Kronecker Graphs \nGenerate a random Kronecker graph.\n\nEach PE generates a random Kronecker graph with n vertices and m/\\<nproc\\> edges.\nAfterwards, the vertices are assigned to PEs round-robin style and edges are distributed accordingly.\n\n#### Application \n```\nmpirun -n <nproc> ./KaGen kronecker \n  -n <number of vertices> # should be a power of two \n  [-N <number of vertices as a power of  two>]\n  -m <number of edges> \n  [-M <number of edges as a power of two>]\n  [--directed]\n  [--self-loops]\n  [-s <seed>]\n```\n\n#### Library \n\n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph = gen.GenerateKronecker(n, m, directed = false, self_loops = false);\n```\n\n## Static Graph Generators\n\n### Image Graph Generator\nGenerates a graph based on an input image.\nEach pixel is represented by a vertex with edges to its neighboring vertices.\nThe image has to be converted to KARGB format first (a simple binary file containing the uncompressed R, G, B channels of the image) by \nusing the `img2kargb` or `upsb2kargb` tool shipped with KaGen.\n\n#### Application\n```\nmpirun -n <nproc> ./KaGen image\n  --filename=<path to kargb file>\n  [--weight-model=<l2, inv-l2, inv-ratio>]\n  [--weight-multiplier=1]\n  [--weight-offset=0]\n  [--min-weight-threshold=1]\n  [--max-weight-threshold=inf]\n  [--neighborhood=<4, 8, 24>]\n  [--max-grid-x=<...>]\n  [--max-grid-y=<...>]\n  [--grid-x=<...>]\n  [--grid-y=<...>]\n  [--cols-per-pe=<...>]\n  [--rows-per-pe=<...>]\n```\n\n#### Library \n\n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph = gen.GenerateFromOptionString(\"image;filename=<...>;...\");\n```\n\n--- \n\n### File Graph Generator\nPseudo-generator that loads a static graph from disk.\nCan be used to convert input formats to output format, or to load static graphs when using KaGen as a library.\n\n#### Application \n```\nmpirun -n <nproc> ./KaGen file\n  --filename=<path to graph>\n  --input-format=<metis|parhip>\n  [--distribution=<balance-vertices|balance-edges>]\n```\n\n#### Library \n\n```c++\nKaGen gen(MPI_COMM_WORLD);\n\nGraph graph = gen.GenerateFromOptionString(\"file;filename=<...>;input_format=<...>;distribution=<...>\");\n```\n\n## Tools\n\nTools can be installed via `cmake --install build --component tools`. The following tools are included: \n\n```shell\n# graphstats: compute some basic statistics for the given graphs\nmpirun ./app/tools/graphstats <path to graph(s), ...>\n  [-f <format, e.g., metis, parhip, plain-edgelist>]\n\n# chkgraph: validate a graph file in any supported input format\nmpirun -n <nproc> ./app/tools/chkgraph <path to graph>\n  [-f <format, e.g., metis, parhip, plain-edgelist>] \n  [--64bits]                  # allow 64 bit weights and IDs\n  [--self-loops]              # allow self loops\n  [--directed]                # allow directed graphs (i.e., not all reverse edges are present)\n  [--multi-edges]             # allow multi edges\n  [--negative-edge-weights]   # allow negative edge weights\n  [--negative-vertex-weights] # allow negative vertex weights\n  \n# pangraph: convert a graph file between supported formats in external memory\n./app/tools/pangraph --input-format=<...> --input-filename=<...> --output-format=<...> --output-filename=<...>\n  [-C <num chunks = 1>]       # split the graph into <num chunks> chunks; only one chunk has to fit into internal memory at a time\n  [-T <tmp directory = /tmp>] # directory to be used for temporary files (requires free space roughly the size of the input graph)\n  [--remove-self-loops]       # remove any self-loops during convertion\n  [--add-reverse-edges]       # make all edges undirected by adding potentially missing reverse edges\n  [--sort-edges]              # sort the outgoing edges by destination vertex ID\n  [-n <num vertices>]         # provide the number of vertices in the graph -- currently only used for the plain-edgelist input format\n```\n\n---\n\n**[License](/LICENSE):** 2-clause BS\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/kahypar",
            "repo_link": "https://github.com/kahypar/",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/kaminpar",
            "repo_link": "https://github.com/KaHIP/KaMinPar",
            "readme": "# KaMinPar\n\nKaMinPar is a shared-memory parallel tool to heuristically solve the graph partitioning problem: divide a graph into k disjoint blocks of roughly equal weight while\nminimizing the number of edges between blocks.\nCompeting algorithms are mostly evaluated for small values of k. If k is large, they often compute highly imbalance solutions, solutions of low quality or suffer excessive running time.\nKaMinPar substantially mitigates these problems.\nIt computes partitions of comparable quality to other high-quality graph partitioning tools while guaranteeing the balance constraint for unweighted input graphs.\nMoreover, for large values of k, it is an order of magnitude faster than competing algorithms.\n\n## Installation Notes\n\n### Requirements\n\n* **Compiler:** C++20-ready GCC or Clang compiler\n* **Dependencies:** CMake, Intel TBB, MPI (optional)\n* **System:** Linux (x86, ARM) or macOS (ARM)\n\n### Quickstart\n\nAfter cloning the repository, make sure to initialize the submodules:\n\n```shell\ngit submodule update --init --recursive\n```\n\nThen, follow the standard CMake build procedure:\n\n```shell\ncmake -B build --preset=default\ncmake --build build --parallel\n```\n\nTo partition a graph in METIS format (see, e.g., the [KaHIP manual](https://github.com/KaHIP/KaHIP/raw/master/manual/kahip.pdf)), run:\n\n```shell\n# KaMinPar: shared-memory partitioning\n./build/apps/KaMinPar [-P default|terapart|strong|largek] -G <graph filename> -k <number of blocks> -t <nproc> [-o <output partition>]\n\n# dKaMinPar: distributed partitioning\nmpirun -n <nproc> ./build/apps/dKaMinPar [-P default|strong|xterapart] -G <graph filename> -k <number of blocks> [-o <output partition>]\n```\n\nThe computed partition is written to a text file, where the n-th line contains the block ID (0-based) of the n-th vertex.\n\nThere are multiple configuration presets that tune the algorithm for different scenarios:\n\n* `-P default`: fast partitioning with quality comparable to Metis\n* `-P terapart`: same partition quality as `default`, but with reduced memory consumption (slightly slower)\n* `-P strong`: better quality than `default` at the cost of increased runtime\n* `-P largek`: faster for large values of k (e.g., k > 1024); may reduce partition quality for smaller k\n\nConfiguration presets can be inspected using the `--dump-config` flag.\nTo build a custom configuration, dump one of the presets to a file, modify it and load it using `-C <filename>`:\n\n```shell\n./build/KaMinPar -P terapart --dump-config > custom.ini\n# ... modify custom.ini ...\n./build/KaMinPar -C custom.ini <...>\n```\n\n## Using the Library Interface\n\nIf you are using CMake, you can use the partitioners as libraries by adding this repository as a Git submodule to your project and including it in your CMake configuration:\n\n```cmake\nadd_subdirectory(external/KaMinPar)\n\ntarget_link_libraries(<your-target> PUBLIC KaMinPar::KaMinPar)  # Shared-memory partitioning\ntarget_link_libraries(<your-target> PUBLIC KaMinPar::dKaMinPar) # Distributed partitioning\n```\n\nAlternatively, you can use `FetchContent`:\n\n```cmake\ninclude(FetchContent)\nFetchContent_Declare(KaMinPar\n  GIT_REPOSITORY https://github.com/KaHIP/KaMinPar.git\n  GIT_TAG main)\nFetchContent_MakeAvailable(KaMinPar)\nset_property(DIRECTORY \"${KaMinPar_SOURCE_DIR}\" PROPERTY EXCLUDE_FROM_ALL YES) # optional\n\ntarget_link_libraries(<your-target> PUBLIC KaMinPar::KaMinPar)  # Shared-memory partitioning\ntarget_link_libraries(<your-target> PUBLIC KaMinPar::dKaMinPar) # Distributed partitioning\n```\n\nThen, call the libraries as follows:\n\n```c++\n#include <kaminpar-shm/kaminpar.h>\n#include <kaminpar-dist/dkaminpar.h>\n\nusing namespace kaminpar;\n\n// Call the shared-memory partitioner:\nKaMinPar shm(int num_threads, shm::create_default_context());\n// KaMinPar::reseed(int seed);\nshm.borrow_and_mutate_graph(NodeID n, EdgeID *xadj, NodeID *adjncy, NodeWeight *vwgt = nullptr, EdgeWeight *adjwgt = nullptr);\n// alternatively: shm.copy_graph(n, xadj, adjncy, vwgt, adjwgt); will work on a copy of the graph\nshm.compute_partition(BlockID number_of_blocks, double epsilon, std::span<BlockID> out_partition);\n// alternatively: shm.compute_partition(std::vector<BlockWeight> max_block_weights, std::span<BlockID> out_partition);\n// Note: you must ensure that the total max block weight is larger than the total node weight of the graph\n\n// Call the distributed partitioner:\ndKaMinPar dist(MPI_Comm comm, int num_threads, dist::create_default_context());\n// dKaMinPar::reseed(int seed); \ndist.import_graph(GlobalNodeID *vtxdist, GlobalEdgeID *xadj, GlobalNodeID *adjncy, GlobalNodeWeight *vwvgt = nullptr, GlobalEdgeWeight *adjwgt = nullptr);\ndist.compute_partition(BlockID number_of_blocks, BlockID *out_partition);\n```\n\nMore examples can be found in the `examples/` directory. \n\n## Licensing\n\nKaMinPar is free software provided under the MIT license.\nIf you use KaMinPar in an academic setting, please cite the appropriate publication(s) listed below.\n\n```\n// KaMinPar\n@InProceedings{DeepMultilevelGraphPartitioning,\n  author    = {Lars Gottesb{\\\"{u}}ren and\n               Tobias Heuer and\n               Peter Sanders and\n               Christian Schulz and\n               Daniel Seemaier},\n  title     = {Deep Multilevel Graph Partitioning},\n  booktitle = {29th Annual European Symposium on Algorithms, {ESA} 2021},\n  series    = {LIPIcs},\n  volume    = {204},\n  pages     = {48:1--48:17},\n  publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\\\"{u}}r Informatik},\n  year      = {2021},\n  url       = {https://doi.org/10.4230/LIPIcs.ESA.2021.48},\n  doi       = {10.4230/LIPIcs.ESA.2021.48}\n}\n\n// dKaMinPar (distributed KaMinPar)\n@InProceedings{DistributedDeepMultilevelGraphPartitioning,\n  author    = {Sanders, Peter and Seemaier, Daniel},\n  title     = {Distributed Deep Multilevel Graph Partitioning},\n  booktitle = {Euro-Par 2023: Parallel Processing},\n  year      = {2023},\n  publisher = {Springer Nature Switzerland},\n  pages     = {443--457},\n  isbn      = {978-3-031-39698-4}\n}\n\n// [x]TeraPart (memory-efficient [d]KaMinPar)\n@misc{TeraPart,\n      title={Tera-Scale Multilevel Graph Partitioning}, \n      author={Daniel Salwasser and Daniel Seemaier and Lars Gottesbüren and Peter Sanders},\n      year={2024},\n      eprint={2410.19119},\n      archivePrefix={arXiv},\n      primaryClass={cs.DS},\n      url={https://arxiv.org/abs/2410.19119}, \n}\n```\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/kamping-karlsruhe-mpi-next-generation",
            "repo_link": "https://github.com/kamping-site/kamping",
            "readme": "[![C/C++ CI](https://github.com/kamping-site/kamping/actions/workflows/build.yml/badge.svg)](https://github.com/kamping-site/kamping/actions/workflows/build.yml)\n![GitHub](https://img.shields.io/github/license/kamping-site/kamping)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10949647.svg)](https://doi.org/10.5281/zenodo.10949647)\n\n# KaMPIng: Karlsruhe MPI next generation :rocket:\n\n![KaMPIng logo](./docs/images/logo.svg)\n\nThis is KaMPIng [kampɪŋ], a (near) zero-overhead MPI wrapper for modern C++.\n\nIt covers the whole range of abstraction levels from low-level MPI calls to\nconvenient STL-style bindings, where most parameters are inferred from a small\nsubset of the full parameter set. This allows for both rapid prototyping and\nfine-tuning of distributed code with predictable runtime behavior and memory\nmanagement.\n\nUsing template-metaprogramming, only code paths required for computing\nparameters not provided by the user are generated at compile time, which results in (near) zero-overhead\nbindings.\n\n**:running: Quick Start:**\nKaMPIng is header-only, compatible with all major MPI implementations and requires a C++17-ready compiler.\nThe easiest way to get started is to include KaMPIng using CMake's FetchContent module.\n```cmake\ninclude(FetchContent)\nFetchContent_Declare(\n  kamping\n  GIT_REPOSITORY https://github.com/kamping-site/kamping.git\n  GIT_TAG v0.1.1\n)\n\nFetchContent_MakeAvailable(kamping)\ntarget_link_libraries(myapp PRIVATE kamping::kamping)\n```\nIt is fully compatible with your existing MPI code and you can start using it right away. Just include the headers for the main communicator class and the MPI call that you want to use.\n\n``` c++\n\n#include <kamping/communicator.hpp>\n#include <kamping/collectives/allgather.hpp>\n \nkamping::Communicator comm;\n \nstd::vector<int> input(comm.rank(), comm.rank_signed());\nauto const result = comm.allgatherv(kamping::send_buf(input));\n```\n\nWe provide a wide range of [usage](./examples/usage) and [simple applications](./examples/applications) examples (start with [`allgatherv`](./examples/usage/allgatherv_example.cpp)). Or checkout the [documentation](https://kamping-site.github.io/kamping/) for a description of KaMPIng's core concepts and a full reference.\n\nKaMPIng is developed at the [Algorithm Engineering\nGroup](https://ae.iti.kit.edu/english/index.php) at Karlsruhe Institute of\nTechnology.\n\nIf you use KaMPIng in the context of an academic publication, we kindly ask you to cite [our technical report](https://arxiv.org/abs/2404.05610):\n\n``` bibtex\n@misc{kamping2024,\n  title={KaMPIng: Flexible and (Near) Zero-overhead C++ Bindings for MPI},\n  author={Demian Hespe and Lukas Hübner and Florian Kurpicz and Peter Sanders and Matthias Schimek and Daniel Seemaier and Christoph Stelz and Tim Niklas Uhl},\n  year={2024},\n  eprint={2404.05610},\n  archivePrefix={arXiv},\n  primaryClass={cs.DC}\n}\n```\n\n## Features :sparkles:\n### Named Parameters :speech_balloon:\nUsing plain MPI, operations like `MPI_Allgatherv` often lead to verbose and error-prone boilerplate code:\n\n``` c++\nstd::vector<T> v = ...; // Fill with data\nint size;\nMPI_Comm_size(comm, &size);\nint n = static_cast<int>(v.size());\nstd::vector<int> rc(size), rd(size);\nMPI_Allgather(&n, 1, MPI_INT, rc.data(), 1, MPI_INT, comm);\nstd::exclusive_scan(rc.begin(), rc.end(), rd.begin(), 0);\nint n_glob = rc.back() + rd.back();\nstd::vector<T> v_glob(v_global_size);\nMPI_Allgatherv(v.data(), v_size, MPI_TYPE, v_glob.data(), rc.data(), rd.data(), MPI_TYPE, comm);\n\n```\n\nIn contrast, KaMPIng introduces a streamlined syntax inspired by Python's named parameters. For example, the `allgatherv` operation becomes more intuitive and concise:\n\n```c++\nstd::vector<T> v = ...; // Fill with data\nstd::vector<T> v_glob = comm.allgatherv(send_buf(v));\n```\n\nEmpowered by named parameters, KaMPIng allows users to name and pass parameters in arbitrary order, computing default values only for the missing ones. This not only improves readability but also streamlines the code, providing a user-friendly and efficient way of writing MPI applications.\n\n### Controlling memory allocation :floppy_disk:\nKaMPIng's *resize policies* allow for fine-grained control over when allocation happens:\n\n| resize policy            |                                                                         |\n|--------------------------|-------------------------------------------------------------------------|\n| `kamping::resize_to_fit` | resize the container to exactly accommodate the data                    |\n| `kamping::no_resize`     | assume that the container has enough memory available to store the data |\n| `kamping::grow_only`     | only resize the container if it not large enough                        |\n\n\n``` c++\n// easy to use with sane defaults\nstd::vector<int> v = comm.recv<int>(source(kamping::rank::any));\n\n// flexible memory control\nstd::vector<int> v_out;\nv_out.resize(enough_memory_to_fit);\n// already_known_counts are the recv_counts that may have been computed already earlier and thus do not need to be computed again\ncomm.recv<int>(recv_buf<kamping::no_resize>(v_out), recv_count(i_know_already_know_that), source(kamping::rank::any));\n```\n\n### STL support :books:\n- KaMPIng works with everything that is a `std::contiguous_range`, everywhere.\n- Builtin C++ types are automatically mapped to their corresponding MPI types. \n- All internally used containers can be altered via template parameters.\n### Expandability :jigsaw:\n- Don't like the performance of your MPI implementation's reduce algorithm? Just override it using our plugin architecture.\n- Add additional functionality to communicator objects, without altering any application code.\n- Easy to integrate with existing MPI code.\n- Flexible core library for a new toolbox :toolbox: of distributed datastructures and algorithms\n\n### And much more ... :arrow_upper_right:\n- Safety guarantees for non-blocking communication and easy handling of multiple requests via request pools\n- Compile time and runtime error checking (which can be completely deactivated).\n- Collective hierarchical timers to speed up your evaluation workflow.\n- ...\n\nDive into the [documentation](https://kamping-site.github.io/kamping/) or [tests](https://github.com/kamping-site/kamping/tree/main/tests) to find out more ...\n\n### (Near) zero overhead - for development and performance :chart_with_upwards_trend:\nUsing template-metaprogramming, KaMPIng only generates the code paths required for computing parameters not provided by the user. \nThe following shows a complete implementation of distributed sample sort with KaMPIng. \n\n```c++\nvoid sort(MPI_Comm comm_, std::vector<T>& data, size_t seed) {\n    Communicator<> comm(comm_);\n    size_t const   oversampling_ratio = 16 * static_cast<size_t>(std::log2(comm.size())) + 1;\n    std::vector<T> local_samples(oversampling_ratio);\n    std::sample(data.begin(), data.end(), local_samples.begin(), oversampling_ratio, std::mt19937{seed});\n    auto global_samples = comm.allgather(send_buf(local_samples)).extract_recv_buffer();\n    std::sort(global_samples.begin(), global_samples.end());\n    for (size_t i = 0; i < comm.size() - 1; i++) {\n        global_samples[i] = global_samples[oversampling_ratio * (i + 1)];\n    }\n    global_samples.resize(num_splitters);\n    std::vector<std::vector<T>> buckets(global_samples.size() + 1);\n    for (auto& element: data) {\n        auto const bound = std::upper_bound(global_samples.begin(), global_samples.end(), element);\n        buckets[static_cast<size_t>(bound - global_samples.begin())].push_back(element);\n    }\n    data.clear();\n    std::vector<int> scounts;\n    for (auto& bucket: buckets) {\n        data.insert(data.end(), bucket.begin(), bucket.end());\n        scounts.push_back(static_cast<int>(bucket.size()));\n    }\n    data = comm.alltoallv(send_buf(data), send_counts(scounts)).extract_recv_buffer();\n    std::sort(data.begin(), data.end());\n}\n```\nIt is a lot more concise than the [(verbose) plain MPI implementation](./examples/applications/sample-sort/mpi.hpp), but also introduces no additional overhead to achieve this, as can be seen the following experiment. There we compare the sorting implementation in KaMPIng to other MPI bindings.\n\n![](./plot.svg)\n## Platform :desktop_computer:\n- intensively tested with GCC and Clang and OpenMPI\n- requires a C++17 ready compiler\n- easy integration into other projects using modern CMake\n   \n## Other MPI bindings\n|                                                      | [MPI](https://www.mpi-forum.org/) | [Boost.MPI](https://www.boost.org/doc/libs/1_84_0/doc/html/mpi.html) | [RWTH MPI](https://github.com/VRGroupRWTH/mpi) | [MPL](https://github.com/rabauke/mpl) | ![KaMPIng](./docs/images/icon.svg) |\n|------------------------------------------------------|:---------------------------------:|:--------------------------------------------------------------------:|:----------------------------------------------:|:-------------------------------------:|:-----------------------------------------------:|\n| STL support                                          | :x:                               | :heavy_check_mark:[^2]                                               | :heavy_check_mark:[^3]                         | :heavy_check_mark:[^2]                | :white_check_mark:                              |\n| computation of defaults via additional communication | :x:                               | :x:                                                                  | :white_check_mark:                             | :x:                                   | :white_check_mark:                              |\n| custom reduce operations via lambdas                 | :x:                               | :white_check_mark:                                                   | :x:                                            | :heavy_check_mark:[^4]                | :white_check_mark:                              |\n| containers can be resized automatically              | :x:                               | :heavy_check_mark:[^1]                                               | :heavy_check_mark:[^3]                         | :x:                                   | :white_check_mark:                              |\n| error handling                                       | :white_check_mark:                | :white_check_mark:                                                   | :white_check_mark:                             | :x:                                   | :white_check_mark:                              |\n| actively maintained                                  | :white_check_mark:                | :x:                                                                  | :heavy_check_mark:                             | :white_check_mark:                    | :white_check_mark:                              |\n\n[^1]: partial \n\n[^2]: only `std::vector` \n\n[^3]: only for send and receive buffers\n\n[^4]: not mapped to builtin operations\n\n## LICENSE\nKaMPIng is released under the GNU Lesser General Public License. See [COPYING](COPYING) and [COPYING.LESSER](COPYING.LESSER) for details\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/karri",
            "repo_link": "https://github.com/molaupi/karri",
            "readme": "# KaRRi\n\nThis repository contains the C++17 implementation of KaRRi, a state-of-the-art dispatcher for the dynamic \ntaxi sharing problem with meeting points. \nKaRRi uses engineered on-the-fly shortest path queries based on bucket contraction hierarchies (BCHs) \nto allow for fast query times with maximum flexibility. \nFor more information on KaRRi's novel techniques, we refer to the related publication:\n\n* Moritz Laupichler, and Peter Sanders. Fast Many-to-Many Routing for Dynamic Taxi Sharing with\n  Meeting Points. 2024 Proceedings of the Symposium on Algorithm Engineering and Experiments (ALENEX),\n  2024\\. https://doi.org/10.1137/1.9781611977929.6\n\nIf you use KaRRi in your scientific publication, we ask that you cite the paper above.\n\n## License\n\nAll files in this repository except the files in the directory `External` are licensed under the MIT\nlicense. External libraries are licensed under their respective licenses.\n\nThis source code is based on a fork of https://github.com/vbuchhold/routing-framework.\nLarge parts of the project structure as well as basic data structures and shortest path algorithms\nare directly taken or adapted from the original framework.\nThe copyright statements in each file state the respective author or authors of the file.\n\n## Prerequisites\n\nTo build KaRRi, you need to have some tools and libraries installed. On Debian and its derivatives\n(such as Ubuntu) the `apt-get` tool can be used:\n\n```\n$ sudo apt-get install build-essential\n$ sudo apt-get install cmake\n$ sudo apt-get install python3 python3-pip; pip3 install -r python_requirements.txt\n$ sudo apt-get install sqlite3 libsqlite3-dev\n$ sudo apt-get install zlib1g-dev\n```\n\nNext, you need to clone the libraries in the `External` subdirectory and build the `RoutingKit` library. To do so,\ntype the following commands at the top-level directory of the framework:\n\n```\n$ git submodule update --init\n$ make -C External/RoutingKit lib/libroutingkit.so\n```\n\n\n## Constructing KaRRi Input\nWe provide bash scripts to generate the input data for the `Berlin-1pct`, `Berlin-10pct`,\n`Ruhr-1pct`, and `Ruhr-10pct` problem instances for the KaRRi algorithm.\nInputs are generated based on OpenStreetMap (OSM) data, which requires the [osmium tool](https://osmcode.org/osmium-tool/). \nOn Debian and its derivatives osmium can be installed using\n```\nsudo apt-get install osmium-tool\n```\n\nAs an example, you can generate the input data for the `Berlin-1pct` instance by typing the following commands\nat the top-level directory: (Downloads multiple GiB of raw OSM data and requires at least 10 GiB of RAM.)\n\n```\n$ cd Publications/KaRRi\n$ bash DownloadGermanyOSMData.sh .\n$ bash FilterGermanyOSMData.sh .\n$ bash PreprocessOSMData.sh . Germany Berlin BoundaryPolygons\n$ bash GenerateKnownInstanceInputData.sh . Berlin-1pct pedestrian\n```\n\nTo generate the input data for the other instances, simply replace `Berlin-1pct` with the instance name\n(`Berlin-10pct`, `Ruhr-1pct`, `Ruhr-10pct`) and replace `Berlin` with `Ruhr` for the\nRuhr instances.\n\n\n## Running KaRRi\nTo run KaRRi in its default configuration (using collective last stop searches, sorted buckets, and\nSIMD instructions), use the provided bash script by typing the following commands at the top-level directory:\n\n```\n$ cd Publications/KaRRi\n$ bash RunKaRRiDefault.sh . <instance-name> <output-dir>\n```\n\nwhere `<instance-name>` can be any of `Berlin-1pct`, `Berlin-10pct`, `Ruhr-1pct`,\nand `Ruhr-10pct`,  and `<output-dir>` is the path to the directory where the output files\nwill be stored.\n\nWe provide functions for a basic evaluation of results in `Publications/KaRRi/eval.R`.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/kd-tree-python",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/KD-Tree-Python",
            "readme": "![Python](https://img.shields.io/badge/Python-3670A0?style=plastic&logo=python&logoColor=ffdd54) ![NumPy](https://img.shields.io/badge/Numpy-777BB4.svg?style=plastic&logo=numpy&logoColor=white) ![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/KD-Tree-Python?style=plastic&cached)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.13384095.svg)](https://doi.org/10.5281/zenodo.13384095)\n\n# KD-Tree Implementation in Python\n\nThis repository contains Python implementation of the kd-tree data structure and performing k-nearest neighbour search.\n\nIts Matlab implementation is located here: [KD-Tree-Matlab](https://github.com/Ramy-Badr-Ahmed/KD-Tree-Matlab)\n\n### About\nThe kd-tree is a space-partitioning data structure for organizing points in a k-dimensional space.\n\n> [Mathematica Link](https://reference.wolfram.com/language/ref/datastructure/KDTree.html)\n\n### Scripts\n\n1. `build_kdtree.py`\n\n   > Builds a kd-tree from a set of points.\n\n2. `nearest_neighbour_search.py`\n\n   > Performs nearest neighbour search using the built kd-tree.\n\n3. `hypercube_points.py`\n\n   > Generates n-Dimensional Points Uniformly in an n-Dimensional Hypercube.\n\n### Example Usage\n\n```python\nfrom kdtree.build_kdtree import build_kdtree\nfrom kdtree.nearest_neighbor_search import nearest_neighbor_search\nfrom examples.hypercube_points import hypercube_points\n\nnum_points = 5000\ncube_size = 10\nnum_dimensions = 10\n\npoints = hypercube_points(num_points, cube_size, num_dimensions)\nhypercube_kdtree = build_kdtree(points.tolist())\n\nquery_point = np.random.rand(num_dimensions).tolist()\n\nnearest_point, nearest_dist, nodes_visited = nearest_neighbor_search(hypercube_kdtree, query_point)\n\nprint(f\"Query point: {query_point}\")\nprint(f\"Nearest point: {nearest_point}\")\nprint(f\"Distance: {nearest_dist:.4f}\")\nprint(f\"Nodes visited: {nodes_visited}\")\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/key",
            "repo_link": "https://github.com/keyproject/key",
            "readme": "# KeY -- Deductive Java Program Verifier\n\n[![Tests](https://github.com/KeYProject/key/actions/workflows/tests.yml/badge.svg)](https://github.com/KeYProject/key/actions/workflows/tests.yml) [![CodeQL](https://github.com/KeYProject/key/actions/workflows/codeql.yml/badge.svg)](https://github.com/KeYProject/key/actions/workflows/codeql.yml) [![CodeQuality](https://github.com/KeYProject/key/actions/workflows/code_quality.yml/badge.svg)](https://github.com/KeYProject/key/actions/workflows/code_quality.yml) \n\nThis repository is the home of the interactive theorem prover KeY for formal verification and analysis of Java programs. KeY comes as a standalone GUI application, which allows you to verify the functional correctness of Java programs with respect to formal specifications formulated in the Java Modeling Language JML. Moreover, KeY can also be used as a library e.g. for symbolic program execution, first order reasoning, or test case generation.\n\nFor more information, refer to\n\n* [The KeY homepage](https://key-project.org) \n* [The KeY book](https://www.key-project.org/thebook2/)\n* [The KeY developer documentation](https://keyproject.github.io/key-docs/)\n* KeY's success stories:\n  * [Severe bug discovered in JDK sorting routine (TimSort)](http://www.envisage-project.eu/proving-android-java-and-python-sorting-algorithm-is-broken-and-how-to-fix-it/),  \n  * [Verification of `java.util.IdentityHashMap`](https://doi.org/10.1007/978-3-031-07727-2_4),\n  * [Google Award for analysing a bug in `LinkedList`](https://www.key-project.org/2023/07/23/cwi-researchers-win-google-award-for-finding-a-bug-in-javas-linkedlist-using-key/)\n\nThe current version of KeY is 2.12.2, licensed under GPL v2.\n\n\nFeel free to use the project templates to get started using KeY:\n* [For Verification Projects](https://github.com/KeYProject/verification-project-template)\n* [Using as a Library](https://github.com/KeYProject/key-java-example)\n* [Using as a Symbolic Execution Backend](https://github.com/KeYProject/symbex-java-example)\n\n## Requirements\n\n* Hardware: >=2 GB RAM\n* Operating System: Linux/Unix, MacOSX, Windows\n* Java 17 or newer\n* Optionally, KeY can make use of the following binaries:\n  * SMT Solvers:\n    * [Z3](https://github.com/Z3Prover/z3#z3)\n    * [cvc5](https://cvc5.github.io/)\n    * [CVC4](https://cvc4.github.io/)\n    * [Princess](http://www.philipp.ruemmer.org/princess.shtml)\n\n## Content of the KeY folder\n\nThis folder provides a [gradle](https://gradle.org)-managed project following\n[Maven's standard folder layout](https://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html).\nThere are several subprojects in this folder. In general, every `key.*/` subproject contains a core component of KeY.\nAdditional and optional components are in `keyext.*/` folders. The file `build.gradle` is the root build script\ndescribing the dependencies and common build tasks for all subprojects.\n\n`key.util`, `key.core` and `key.ui` are the base for the product \"KeY Prover\". Special care is needed\nif you plan to make changes here.\n\n\n## Compile and Run KeY\n\nAssuming you are in the directory of this README file, you can create a runnable and deployable version with one of these commands:\n\n1. With `./gradlew key.ui:run` you can run the user interface of KeY directly from the repository. \n   Use `./gradlew key.ui:run --args='--experimental'` to enable experimental features.\n\n2. Use `./gradlew classes` to compile KeY, which includes running JavaCC and Antlr.\n   Likewise, use `./gradlew testClasses` if you also want to compile the JUnit test classes.\n\n3. Test your installation with `./gradlew test`. Be aware that this will usually take multiple hours to complete.\n   With `./gradlew testFast`, you can run a more lightweight test suite that should complete in a few minutes.\n\n   You can select a specific test case with the `--tests` argument. Wildcards are allowed.\n   ```sh\n   ./gradlew :key.<subproject>:test --tests \"<class>.<method>\"\n   ```\n\n   You can debug KeY by adding the `--debug-jvm` option, then attaching a debugger at `localhost:5005`.\n\n4. You can create a single jar-version, aka *fat jar*, of KeY with\n   ```sh\n   ./gradlew :key.ui:shadowJar\n   ```\n   The file is generated in `key.ui/build/libs/key-*-exe.jar`.\n\n5. A distribution is build with\n   ```sh\n   ./gradlew :key.ui:installDist :key.ui:distZip\n   ```\n   The distribution can be tested by calling `key.ui/install/key/bin/key.ui`\n   and is zipped in `key.ui/build/distributions`.\n\n   The distribution gives you potential of using single jar files.\n\n# Developing KeY\n\n* Quality is automatically assessed using [SonarQube](https://sonarqube.org) on each pull request.\n  The results of the assessments (pass/fail) can be inspected in the checks section of the PR.\n\n  The rules and quality gate are maintained by Alexander Weigl\n  <weigl@kit.edu> currently.\n\n* More guideline and documentation for the KeY development can be found under\n[key-docs](https://keyproject.github.io/key-docs/devel/).\n\n\n\n# Issues and Bug Reports\n\n* For bug reports, please use the [issue tracker](https://github.com/KeYProject/key/issues) or send a mail to support@key-project.org. \n\n* For discussions, you may want to subscribe and use the mailing list <key-all@lists.informatik.kit.edu> or use [GitHub discussions](https://github.com/KeYProject/key/discussions).\n\n# Contributing to KeY\n\nFeel free to submit [pull requests](https://github.com/KeYProject/key/pulls) via GitHub. Pull requests are assessed using automatic tests, formatting and static source checkers, as well as a manual review by one of the developers. More guidelines and documentation for the KeY development can be found under [key-docs](https://keyproject.github.io/key-docs/devel/).\n\n\n\n# License Remark\n\n```\nThis is the KeY project - Integrated Deductive Software Design\nCopyright (C) 2001-2011 Universität Karlsruhe, Germany\n\t\t\t\t\t\tUniversität Koblenz-Landau, Germany\n\t\t\t\t\t\tand Chalmers University of Technology, Sweden\nCopyright (C) 2011-2024 Karlsruhe Institute of Technology, Germany\n\t\t\t\t\t\tTechnical University Darmstadt, Germany\n\t\t\t\t\t\tChalmers University of Technology, Sweden\n\nThe KeY system is protected by the GNU General Public License.\nSee LICENSE.TXT for details.\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/keymaera-x",
            "repo_link": "https://github.com/LS-Lab/KeYmaeraX-release",
            "readme": "# KeYmaera X Theorem Prover for Hybrid Systems\n\nSelf-driving cars, autonomous robots, modern airplanes, or robotic surgery:\nwe increasingly entrust our lives to computers and therefore should strive\nfor nothing but the highest safety standards - mathematical correctness proof.\nProofs for such cyber-physical systems can be constructed with the KeYmaera X prover.\nAs a _hybrid systems_ theorem prover,\nKeYmaera X analyzes the control program and the physical behavior\nof the controlled system together in _differential dynamic logic_.\n\nKeYmaera X features a minimal core of just about 2000 lines of code\nthat isolates all soundness-critical reasoning.\nSuch a small and simple prover core makes it much easier to trust verification results.\nPre-defined and custom tactics built on top of the core drive automated proof search.\nKeYmaera X comes with a web-based front-end that provides a clean interface\nfor both interactive and automated proving,\nhighlighting the most crucial parts of a verification activity.\nBesides hybrid systems,\nKeYmaera X also supports the verification of _hybrid games_ in _differential game logic_.\n\n**More information** and precompiled binaries are available at [keymaerax.org](https://keymaerax.org/):\n\n* The [KeYmaera X Tutorial](https://keymaeraX.org/Xtutorial.html)\n* The [Logical Foundations of Cyber-Physical Systems](http://lfcps.org/lfcps/) textbook\n* The [KeYmaera X API Documentation](https://keymaerax.org/scaladoc)\n\n## Installation\n\n1. Install Java Runtime Environment version 11 or later, for example from [OpenJDK](https://openjdk.org/)\n\n2. Optionally, install and set up\n  [Wolfram Mathematica](https://www.wolfram.com/mathematica/) (version 10 or later)\n  or [Wolfram Engine](http://www.wolfram.com/engine/).\n  See below for more details on the different arithmetic solvers.\n\n3. Download the file [keymaerax.jar](https://keymaerax.org/keymaerax.jar)\n\n4. Configure KeYmaera X according to the **Configuration** section below.\n\n5. Launch KeYmaera X by opening the console in the same directory as `keymaerax.jar`\n  and running `java -jar keymaerax.jar`.\n  You might need to specify additional arguments as explained in the **Configuration** section.\n\nFor more details on installation, usage, and for troubleshooting steps,\nsee the [Install section of the website](https://keymaerax.org/download.html).\n\n## Configuration\n\nKeYmaera X requires a decision procedure for real arithmetic to finalize proofs.\nIt is compatible with these arithmetic solvers:\n- Wolfram Mathematica\n- Wolfram Engine, a free alternative to Mathematica that requires an active internet connection.\n- The Z3 Theorem Prover, for which built-in binaries are included.\n  This is the fallback when no other solver is configured.\n\nKeYmaera X is extensively tested with Mathematica and some features are only available when using Mathematica.\nAfter starting KeYmaera X you can configure arithmetic tools in the _KeYmaera X->Preferences_ menu.\n\nDepending on the operating system, Mathematica is installed in different locations.\nIf KeYmaera X can't find your Mathematica installation,\nyou need to manually specify the kernel and jlink paths when starting KeYmaera X\nusing the `-mathkernel` and `-jlink` parameters.\n\nIf you installed Mathematica at the\n[default path](https://reference.wolfram.com/language/tutorial/WolframSystemFileOrganization.html),\nthe required values on the different platforms are:\n\n- Linux\n  - `-mathkernel /usr/local/Wolfram/Mathematica/13.0/Executables/MathKernel`\n  - `-jlink /usr/local/Wolfram/Mathematica/13.0/SystemFiles/Links/JLink/SystemFiles/Libraries/Linux-x86-64`\n- macOS\n  - `-mathkernel /Applications/Mathematica.app/Contents/MacOS/MathKernel`\n  - `-jlink /Applications/Mathematica.app/Contents/SystemFiles/Links/JLink/SystemFiles/Libraries/MacOSX-x86-64`\n- Windows\n  - `-mathkernel \"C:\\Program Files\\Wolfram Research\\Mathematica\\13.0\\MathKernel.exe\"`\n  - `-jlink \"C:\\Program Files\\Wolfram Research\\Mathematica\\13.0\\SystemFiles\\Links\\JLink\\SystemFiles\\Libraries\\Windows-x86-64\"`\n\n## Building\n\nTo compile KeYmaera X from source or set up a development environment, see [procedures.md](doc/procedures.md).\nMore detailed but outdated instructions are available\n[in the wiki on GitHub](https://github.com/LS-Lab/KeYmaeraX-release/wiki/Building-Instructions).\n\n## Publications\n\nKeYmaera X implements the uniform substitution calculus for differential dynamic logic\nin order to enable soundness assurance by way of a small trusted LCF-style kernel\nwhile still being amenable to automatic theorem proving.\n\nhttps://www.ls.cs.cmu.edu/publications.html\n\n1. André Platzer.\n  [A complete uniform substitution calculus for differential dynamic logic](https://doi.org/10.1007/s10817-016-9385-1).\n  Journal of Automated Reasoning 59(2), pp. 219-266, 2017.\n  Extended version of [CADE-25](https://doi.org/10.1007/978-3-319-21401-6_32).\n\n2. André Platzer.\n  [Logics of dynamical systems](https://doi.org/10.1109/LICS.2012.13).\n  ACM/IEEE Symposium on Logic in Computer Science, LICS 2012, June 25–28, 2012, Dubrovnik, Croatia, pages 13-24. IEEE 2012.\n\n3. Nathan Fulton, Stefan Mitsch, Jan-David Quesel, Marcus Völp and André Platzer.\n  [KeYmaera X: An axiomatic tactical theorem prover for hybrid systems](https://doi.org/10.1007/978-3-319-21401-6_36).\n  In Amy P. Felty and Aart Middeldorp, editors, International Conference on Automated Deduction, CADE-25, Berlin, Germany, Proceedings, LNCS. Springer, 2015.\n\n4. Nathan Fulton, Stefan Mitsch, Brandon Bohrer and André Platzer.\n  [Bellerophon: Tactical theorem proving for hybrid systems](https://doi.org/10.1007/978-3-319-66107-0_14).\n  In Mauricio Ayala-Rincón and César Muñoz, editors, Interactive Theorem Proving, International Conference, ITP 2017, volume 10499 of LNCS, pp. 207-224. Springer, 2017.\n\n5. André Platzer.\n  [Logical Foundations of Cyber-Physical Systems](http://lfcps.org/lfcps/).\n  Springer, Cham, 2018.\n  [DOI](https://doi.org/10.1007/978-3-319-63588-0), [Videos](http://video.lfcps.org/)\n\nThe soundness assurances provided by a small LCF-style kernel are further strengthened\nby a cross-verification of the soundness theorem for the uniform substitution calculus.\n\n6. Brandon Bohrer, Vincent Rahli, Ivana Vukotic, Marcus Völp and André Platzer.\n  [Formally verified differential dynamic logic](https://doi.org/10.1145/3018610.3018616).\n  ACM SIGPLAN Conference on Certified Programs and Proofs, CPP 2017, Jan 16-17, 2017, Paris, France, pages 208-221, ACM, 2017.\n  [Isabelle/HOL](https://github.com/LS-Lab/Isabelle-dL) and [Coq](https://github.com/LS-Lab/Coq-dL)\n\nA secondary goal of KeYmaera X is to also make it possible to implement extensions of differential dynamic logic,\nsuch as differential game logic for hybrid games\nas well as quantified differential dynamic logic for distributed hybrid systems:\n\n7. André Platzer.\n  [Differential game logic](https://doi.org/10.1145/2817824).\n  ACM Trans. Comput. Log. 17(1), 2015.\n\n8. André Platzer.\n  [Differential hybrid games](https://doi.org/10.1145/3091123).\n  ACM Trans. Comput. Log. 18(3), 2017.\n\n9. André Platzer.\n  [A complete axiomatization of quantified differential dynamic logic for distributed hybrid systems](https://doi.org/10.2168/LMCS-8(4:17)2012).\n  Logical Methods in Computer Science 8(4), pages 1-44, 2012.\n\nKeYmaera X implements fast generalized uniform substitution algorithms, also cross-verified:\n\n10. André Platzer.\n  [Uniform substitution for differential game logic](https://doi.org/10.1007/978-3-319-94205-6_15).\n  In Didier Galmiche, Stephan Schulz and Roberto Sebastiani, editors, Automated Reasoning, 9th International Joint Conference, IJCAR 2018, volume 10900 of LNCS, pp. 211-227. Springer 2018.\n\n11. André Platzer.\n  [Uniform substitution at one fell swoop](https://doi.org/10.1007/978-3-030-29436-6_25).\n  In Pascal Fontaine, editor, International Conference on Automated Deduction, CADE-27, volume 11716 of LNCS, pp. 425-441. Springer, 2019.\n  [Isabelle/HOL](http://isa-afp.org/entries/Differential_Game_Logic.html)\n\nAutomatic proofs for differential equation invariants are based on:\n\n12. André Platzer and Yong Kiam Tan.\n  [Differential equation invariance axiomatization](https://doi.org/10.1145/3380825).\n  J. ACM 67(1), 6:1-6:66, 2020.\n  Extended version of [LICS'18](https://doi.org/10.1145/3209108.3209147).\n\nLiveness proofs for differential equations are based on:\n\n13. Yong Kiam Tan and André Platzer.\n  Yong Kiam Tan and André Platzer.\n  [An axiomatic approach to existence and liveness for differential equations](https://doi.org/10.1007/s00165-020-00525-0).\n  Formal Aspects of Computing 33(4), pp 461-518, 2021.\n  Special issue for selected papers from [FM'19](https://doi.org/10.1007/978-3-030-30942-8_23).\n\nKeYmaera X uses the [Pegasus](http://pegasus.keymaeraX.org/) tool\nfor invariant generation (which gets better when additional software is installed):\n\n14. Andrew Sogokon, Stefan Mitsch, Yong Kiam Tan, Katherine Cordwell and André Platzer.\n  [Pegasus: Sound continuous invariant generation](https://doi.org/10.1007/s10703-020-00355-z).\n  Formal Methods in System Design, 58(1), pp. 5-41, 2022.\n  Special issue for selected papers from [FM'19](https://doi.org/10.1007/978-3-030-30942-8_10).\n\nKeYmaera X implements the [ModelPlex](http://modelplex.net) method\nto ensure that verification results about models apply to cyber-physical system implementations.\nModelPlex generates provably correct monitor conditions that, if checked to hold at runtime,\nare provably guaranteed to imply that the offline safety verification results about the CPS model\napply to the present run of the actual CPS implementation.\n\n15. Stefan Mitsch and André Platzer.\n  [ModelPlex: Verified runtime validation of verified cyber-physical system models](https://doi.org/10.1007/s10703-016-0241-z).\n  Formal Methods in System Design 49(1), pp. 33-74. 2016.\n  Special issue for selected papers from [RV'14](https://doi.org/10.1007/978-3-319-11164-3_17).\n\n16. Yong Kiam Tan, Stefan Mitsch and André Platzer.\n  [Verifying switched system stability with logic](https://doi.org/10.1145/3501710.3519541)\n  In Ezio Bartocci and Sylvie Putot, editors, Hybrid Systems: Computation and Control (part of CPS Week 2022), HSCC'22. Article No. 2, pp. 1-11. ACM, 2022.\n\nThe design principles for the user interface of KeYmaera X are described in:\n\n17. Stefan Mitsch and André Platzer.\n  [The KeYmaera X proof IDE: Concepts on usability in hybrid systems theorem proving](https://doi.org/10.4204/EPTCS.240.5).\n  In Catherine Dubois, Paolo Masci and Dominique Méry, editors, 3rd Workshop on Formal Integrated Development Environment F-IDE 2016, volume 240 of EPTCS, pp. 67-81, 2017.\n\nModel and proof management techniques are described in:\n\n18. Stefan Mitsch.\n  [Implicit and Explicit Proof Management in KeYmaera X](https://doi.org/10.4204/EPTCS.338.8)\n  In José Proença and Andrei Paskevich, editors, 6th Workshop on Formal Integrated Development Environment F-IDE 2021, volume 338 of EPTCS 338, pp. 53-67, 2021.\n\nA comparison of KeYmaera X with its predecessor provers is described in:\n\n19. Stefan Mitsch and André Platzer.\n  [A Retrospective on Developing Hybrid System Provers in the KeYmaera Family: A Tale of Three Provers](https://doi.org/10.1007/978-3-030-64354-6_2).\n  In Wolfgang Ahrendt et al., editors, Deductive Software Verification: Future Perspectives, volume 12345 of LNCS, pp. 21-64. Springer, 2020.\n\n## Copyright and Licenses\n\nCopyright (C) 2014-2024 Carnegie Mellon University, Karlsruhe Institute of Technology\n\nDeveloped by Andre Platzer, Stefan Mitsch, Nathan Fulton, Brandon Bohrer,\nYong Kiam Tan, Andrew Sogokon, Fabian Immler, Katherine Cordwell,\nEnguerrand Prebet, Joscha Mennicken, Tobias Erthal.\nWith previous contributions by Nathan Fulton, Jan-David Quesel,\nMarcus Voelp, Ran Ji.\nSee [COPYRIGHT.txt](COPYRIGHT.txt) for details.\n\nSee [LICENSE.txt](LICENSE.txt) for the conditions of using this software.\n\nThe KeYmaera X distribution contains external tools.\nA list of tools and their licenses can be found in [LICENSES_THIRD_PARTY.txt](LICENSES_THIRD_PARTY.txt).\n\n## Contact\n\nKeYmaera X developers: keymaerax@keymaerax.org\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/kinfit",
            "repo_link": "https://github.com/KinFit/KinFit.git",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/kramersmoyal",
            "repo_link": "https://github.com/LRydin/KramersMoyal",
            "readme": "[![DOI](https://joss.theoj.org/papers/10.21105/joss.01693/status.svg)](https://doi.org/10.21105/joss.01693)\n![PyPI - License](https://img.shields.io/pypi/l/kramersmoyal) ![PyPI](https://img.shields.io/pypi/v/kramersmoyal) ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/kramersmoyal)\n[![Build Status](https://github.com/LRydin/KramersMoyal/actions/workflows/CI.yml/badge.svg)](https://github.com/LRydin/KramersMoyal/actions/workflows/CI.yml)\n[![codecov](https://codecov.io/gh/LRydin/KramersMoyal/branch/master/graph/badge.svg)](https://codecov.io/gh/LRydin/KramersMoyal) [![Documentation Status](https://readthedocs.org/projects/kramersmoyal/badge/?version=latest)](https://kramersmoyal.readthedocs.io/en/latest/?badge=latest)\n\n# KramersMoyal\n`kramersmoyal` is a python package designed to obtain the Kramers–Moyal coefficients, or conditional moments, from stochastic data of any dimension. It employs kernel density estimations, instead of a histogram approach, to ensure better results for low number of points as well as allowing better fitting of the results.\n\nThe [paper](https://doi.org/10.21105/joss.01693) is now officially published on [JOSS](https://joss.theoj.org/). The paper is also available [here](/paper/paper.pdf), or you can find it in the [ArXiv](https://arxiv.org/abs/1912.09737).\n\n# Installation\nTo install `kramersmoyal`, just use `pip`\n\n```\npip install kramersmoyal\n```\nThen on your favourite editor just use\n```python\nfrom kramersmoyal import km\n```\n\n## Dependencies\nThe library depends on `numpy` and `scipy`.\n\n# A one-dimensional stochastic process\n\nA Jupyter notebook with this example can be found [here](/examples/kmc.ipynb)\n\n## The theory\nTake, for example, the well-documented one-dimension Ornstein–Uhlenbeck process, also known as Va&#353;&#237;&#269;ek process, see [here](https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process). This process is governed by two main parameters: the mean-reverting parameter &theta; and the diffusion parameter &sigma;\n\n<img src=\"/other/OU_eq.png\" title=\"Ornstein–Uhlenbeck process\" height=\"25\"/>\n\nwhich can be solved in various ways. For our purposes, recall that the drift coefficient, i.e., the first-order Kramers–Moyal coefficient, is given by ![](/other/inline_KM_1.png) and the second-order Kramers–Moyal coefficient is ![](/other/inline_KM_2.png), i.e., the diffusion.\n\nGenerate an exemplary Ornstein–Uhlenbeck process with your favourite integrator, e.g., the [Euler–Maruyama](https://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method) or with a more powerful tool from [`JiTCSDE`](https://github.com/neurophysik/jitcsde) found on GitHub.\nFor this example let's take &theta;=.3 and &sigma;=.1, over a total time of 500 units, with a sampling of 1000 Hertz, and from the generated data series retrieve the two parameters, the drift -&theta;y(t) and diffusion &sigma;.\n\n## Integrating an Ornstein–Uhlenbeck process\nHere is a short code on generating a Ornstein–Uhlenbeck stochastic trajectory with a simple Euler–Maruyama integration method\n\n```python\n# integration time and time sampling\nt_final = 500\ndelta_t = 0.001\n\n# The parameters theta and sigma\ntheta = 0.3\nsigma = 0.1\n\n# The time array of the trajectory\ntime = np.arange(0, t_final, delta_t)\n\n# Initialise the array y\ny = np.zeros(time.size)\n\n# Generate a Wiener process\ndw = np.random.normal(loc=0, scale=np.sqrt(delta_t), size=time.size)\n\n# Integrate the process\nfor i in range(1,time.size):\n    y[i] = y[i-1] - theta*y[i-1]*delta_t + sigma*dw[i]\n```\n\nFrom here we have a plain example of an Ornstein–Uhlenbeck process, always drifting back to zero, due to the mean-reverting drift &theta;. The effect of the noise can be seen across the whole trajectory.\n\n<img src=\"/other/fig1.png\" title=\"Ornstein–Uhlenbeck process\" height=\"200\"/>\n\n## Using `kramersmoyal`\nTake the timeseries `y` and let's study the Kramers–Moyal coefficients. For this let's look at the drift and diffusion coefficients of the process, i.e., the first and second Kramers–Moyal coefficients, with an `epanechnikov` kernel\n```python\n\n# The kmc holds the results, where edges holds the binning space\nkmc, edges = km(y, powers=2)\n```\n\nThis results in\n\n<img src=\"/other/fig2.png\" title=\"Drift and diffusion terms of an Ornstein–Uhlenbeck process\" height=\"200\"/>\n\nNotice here that to obtain the Kramers–Moyal coefficients you need to divide `kmc` by the timestep `delta_t`. This normalisation stems from the Taylor-like approximation, i.e., the Kramers–Moyal expansion (`delta t` &rarr; 0).\n\n# A two-dimensional diffusion process\n\nA Jupyter notebook with this example can be found [here](/examples/kmc.ipynb)\n\n## Theory\n\nA two-dimensional diffusion process is a stochastic process that comprises two ![](/other/inline_W.png) and allows for a mixing of these noise terms across its two dimensions.\n\n<img src=\"/other/2D-diffusion.png\" alt=\"2D-diffusion\" title=\"A 2-dimensional diffusion process\" height=\"60\" />\n\nwhere we will select a set of state-dependent parameters obeying\n\n<img src=\"/other/parameters_2D-diffusion.png\" alt=\"2D-diffusion\" title=\"Specific parameters for the diffusion process\" height=\"70\" />\n\nwith ![](/other/inline_parameters_2D-diffusion_1.png) and ![](/other/inline_parameters_2D-diffusion_2.png).\n\n## Choice of parameters\nAs an example, let's take the following set of parameters for the drift vector and diffusion matrix\n\n```python\n# integration time and time sampling\nt_final = 2000\ndelta_t = 0.001\n\n# Define the drift vector N\nN = np.array([2.0, 1.0])\n\n# Define the diffusion matrix g\ng = np.array([[0.5, 0.0], [0.0, 0.5]])\n\n# The time array of the trajectory\ntime = np.arange(0, t_final, delta_t)\n```\n\n## Integrating a 2-dimensional process\nIntegrating the previous stochastic trajectory with a simple Euler–Maruyama integration method\n\n```python\n# Initialise the array y\ny = np.zeros([time.size, 2])\n\n# Generate two Wiener processes with a scale of np.sqrt(delta_t)\ndW = np.random.normal(loc=0, scale=np.sqrt(delta_t), size=[time.size, 2])\n\n# Integrate the process (takes about 20 secs)\nfor i in range(1, time.size):\n    y[i,0] = y[i-1,0]  -  N[0] * y[i-1,0] * delta_t + g[0,0]/(1 + np.exp(y[i-1,0]**2)) * dW[i,0]  +  g[0,1] * dW[i,1]\n    y[i,1] = y[i-1,1]  -  N[1] * y[i-1,1] * delta_t + g[1,0] * dW[i,0]  +  g[1,1]/(1 + np.exp(y[i-1,1]**2)) * dW[i,1]\n```\n\nThe stochastic trajectory in 2 dimensions for `10` time units (`10000` data points)\n\n<img src=\"/other/fig3.png\" alt=\"2D-diffusion\" title=\"2-dimensional trajectory\" height=\"280\" />\n\n## Back to `kramersmoyal` and the Kramers–Moyal coefficients\nFirst notice that all the results now will be two-dimensional surfaces, so we will need to plot them as such\n\n```python\n# Choose the size of your target space in two dimensions\nbins = [100, 100]\n\n# Introduce the desired orders to calculate, but in 2 dimensions\npowers = np.array([[0,0], [1,0], [0,1], [1,1], [2,0], [0,2], [2,2]])\n# insert into kmc:   0      1      2      3      4      5      6\n\n# Notice that the first entry in [,] is for the first dimension, the\n# second for the second dimension...\n\n# Choose a desired bandwidth bw\nbw = 0.1\n\n# Calculate the Kramers−Moyal coefficients\nkmc, edges = km(y, bw=bw, bins=bins, powers=powers)\n\n# The K−M coefficients are stacked along the first dim of the\n# kmc array, so kmc[1,...] is the first K−M coefficient, kmc[2,...]\n# is the second. These will be 2-dimensional matrices\n```\n\nNow one can visualise the Kramers–Moyal coefficients (surfaces) in green and the respective theoretical surfaces in black. (Don't forget to normalise: `kmc / delta_t`).\n\n<img src=\"/other/fig4.png\" alt=\"2D-diffusion\" title=\"2-dimensional Kramers–Moyal surfaces (green) and the theoretical surfaces (black)\" height=\"480\" />\n\n# Contributions\nWe welcome reviews and ideas from everyone. If you want to share your ideas or report a bug, open an [issue](https://github.com/LRydin/KramersMoyal/issues) here on GitHub, or contact us directly.\nIf you need help with the code, the theory, or the implementation, do not hesitate to contact us, we are here to help.\nWe abide to a [Conduct of Fairness](contributions.md).\n\n# TODOs\nNext on the list is\n- Include more kernels\n- Work through the documentation carefully\n\n# Changelog\n- Version 0.4.1 - Changing CI. Correcting `kmc[0,:]` normalisation. Various Simplifications. Bins as ints, powers as ints.\n- Version 0.4.0 - Added the documentation, first testers, and the Conduct of Fairness\n- Version 0.3.2 - Adding 2 kernels: `triagular` and `quartic` and extending the documentation and examples.\n- Version 0.3.1 - Corrections to the fft triming after convolution.\n- Version 0.3.0 - The major breakthrough: Calculates the Kramers–Moyal coefficients for data of any dimension.\n- Version 0.2.0 - Introducing convolutions and `gaussian` and `uniform` kernels. Major speed up in the calculations.\n- Version 0.1.0 - One and two dimensional Kramers–Moyal coefficients with an `epanechnikov` kernel.\n\n# Literature and Support\n\n### Literature\nThe study of stochastic processes from a data-driven approach is grounded in extensive mathematical work. From the applied perspective there are several references to understand stochastic processes, the Fokker–Planck equations, and the Kramers–Moyal expansion\n\n- Tabar, M. R. R. (2019). *Analysis and Data-Based Reconstruction of Complex Nonlinear Dynamical Systems.* Springer, International Publishing\n- Risken, H. (1989). *The Fokker–Planck equation.* Springer, Berlin, Heidelberg.\n- Gardiner, C.W. (1985). *Handbook of Stochastic Methods.* Springer, Berlin.\n\nYou can find and extensive review on the subject [here](http://sharif.edu/~rahimitabar/pdfs/80.pdf)<sup>1</sup>\n\n### History\nThis project was started in 2017 at the [neurophysik](https://www.researchgate.net/lab/Klaus-Lehnertz-Lab-2) by Leonardo Rydin Gorjão, Jan Heysel, Klaus Lehnertz, and M. Reza Rahimi Tabar. Francisco Meirinhos later devised the hard coding to python. The project is now supported by Dirk Witthaut and the [Institute of Energy and Climate Research Systems Analysis and Technology Evaluation](https://www.fz-juelich.de/iek/iek-ste/EN/Home/home_node.html).\n\n### Funding\nHelmholtz Association Initiative _Energy System 2050 - A Contribution of the Research Field Energy_ and the grant No. VH-NG-1025 and *STORM - Stochastics for Time-Space Risk Models* project of the Research Council of Norway (RCN) No. 274410.\n\n---\n\n<sup>1</sup> Friedrich, R., Peinke, J., Sahimi, M., Tabar, M. R. R. *Approaching complexity by stochastic methods: From biological systems to turbulence,* [Phys. Rep. 506, 87–162 (2011)](https://doi.org/10.1016/j.physrep.2011.05.003).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/lapy",
            "repo_link": "https://github.com/Deep-MI/lapy",
            "readme": "[![PyPI version](https://badge.fury.io/py/lapy.svg)](https://pypi.org/project/lapy/)\r\n# LaPy\r\n\r\nLaPy is an open-source Python package for differential geometry on triangle\r\nand tetrahedra meshes. It includes an FEM solver to estimate the Laplace,\r\nPoisson or Heat equations. Further functionality includes the computations\r\nof gradients, divergence, mean-curvature flow, conformal mappings, \r\ngeodesics, ShapeDNA (Laplace spectra), and IO and plotting methods. \r\n\r\nLaPy is written purely in Python 3 without sacrificing speed as almost all\r\nloops are vectorized, drawing upon efficient and sparse mesh data structures.\r\n\r\n## Contents:\r\n\r\n- **TriaMesh**: a class for triangle meshes offering various operations, such as\r\n  fixing orientation, smoothing, curvature, boundary, quality, normals, and\r\n  various efficient mesh datastructures (edges, adjacency matrices). IO from\r\n  OFF, VTK and other formats.\r\n- **TetMesh**: a class for tetrahedral meshes (orientation, boundary, IO ...)\r\n- **Solver**: a class for linear FEM computation (Laplace stiffness and mass\r\n  matrix, fast and sparse eigenvalue solver, anisotropic Laplace, Poisson)\r\n- **io**: module for IO of vertex functions and eigenvector files\r\n- **diffgeo**: module for gradients, divergence, mean curvature flow, etc.\r\n- **heat**: module for heat kernel and diffusion\r\n- **shapedna**: module for the ShapeDNA descriptor of surfaces and solids\r\n- **plot**: module for interactive visualizations (wrapping plotly)\r\n\r\n## Usage:\r\n\r\nThe LaPy package is a comprehensive collection of scripts, so we refer to the\r\n'help' function and docstring of each module / function / class for usage info.\r\nFor example:\r\n\r\n```\r\nimport lapy as lp\r\nhelp(lp.TriaMesh)\r\nhelp(lp.Solver)\r\n```\r\n\r\nIn the `examples` subdirectory, we provide several Jupyter notebooks that\r\nillustrate prototypical use cases of the toolbox.\r\n\r\n## Installation:\r\n\r\nUse the following code to install the latest release of LaPy into your local\r\nPython package directory:\r\n\r\n`python3 -m pip install lapy`\r\n\r\nUse the following code to install the dev package in editable mode to a location of\r\nyour choice:\r\n\r\n`python3 -m pip install --user --src /my/preferred/location --editable git+https://github.com/Deep-MI/Lapy.git#egg=lapy`\r\n\r\nSeveral functions, e.g. the Solver, require a sparse matrix decomposition, for which either the LU decomposition (from scipy sparse, default) or the faster Cholesky decomposition (from scikit-sparse cholmod, recommended) can be used. If the parameter flag use_cholmod is True, the code will try to import cholmod from the scikit-sparse package. If this fails, an error will be thrown. If you would like to use cholmod, you need to install scikit-sparse separately, as pip currently cannot install it (conda can). scikit-sparse requires numpy and scipy to be installed separately beforehand.\r\n\r\n## API Documentation\r\n\r\nThe API Documentation can be found at https://deep-mi.org/LaPy .\r\n\r\n## References:\r\n\r\nIf you use this software for a publication please cite both these papers:\r\n\r\n**[1]** Laplace-Beltrami spectra as 'Shape-DNA' of surfaces and solids. Reuter M, Wolter F-E, Peinecke N. Computer-Aided Design. 2006;38(4):342-366. http://dx.doi.org/10.1016/j.cad.2005.10.011\r\n\r\n**[2]** BrainPrint: a discriminative characterization of brain morphology. Wachinger C, Golland P, Kremen W, Fischl B, Reuter M. Neuroimage. 2015;109:232-48. http://dx.doi.org/10.1016/j.neuroimage.2015.01.032 http://www.ncbi.nlm.nih.gov/pubmed/25613439\r\n\r\nShape-DNA [1] introduces the FEM methods and the Laplace spectra for shape analysis, while BrainPrint [2] focusses on medical applications.\r\n\r\nFor Geodesics please also cite:\r\n\r\n[3] Crane K, Weischedel C, Wardetzky M. Geodesics in heat: A new approach to computing distance based on heat flow. ACM Transactions on Graphics. https://doi.org/10.1145/2516971.2516977\r\n\r\nFor non-singular mean curvature flow please cite:\r\n\r\n[4] Kazhdan M, Solomon J, Ben-Chen M. 2012. Can Mean-Curvature Flow be Modified to be Non-singular? Comput. Graph. Forum 31, 5, 1745–1754.\r\nhttps://doi.org/10.1111/j.1467-8659.2012.03179.x\r\n\r\nFor conformal mapping please cite:\r\n\r\n[5] Choi PT, Lam KC, Lui LM. FLASH: Fast Landmark Aligned Spherical Harmonic Parameterization for Genus-0 Closed Brain Surfaces. SIAM Journal on Imaging Sciences, vol. 8, no. 1, pp. 67-94, 2015. https://doi.org/10.1137/130950008\r\n\r\nWe invite you to check out our lab webpage at https://deep-mi.org\r\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/libertem",
            "repo_link": "https://github.com/LiberTEM/LiberTEM/",
            "readme": "|docs|_ |gitter|_ |azure|_ |github|_ |codeclimate|_ |precommit|_ |joss|_ |zenodo|_ |pypi|_ |condaforge|_\n\n.. |docs| image:: https://img.shields.io/badge/%F0%9F%95%AE-docs-green.svg\n.. _docs: https://libertem.github.io/LiberTEM/\n\n.. |gitter| image:: https://badges.gitter.im/join_chat.svg\n.. _gitter: https://gitter.im/LiberTEM/Lobby\n\n.. |azure| image:: https://dev.azure.com/LiberTEM/LiberTEM/_apis/build/status/LiberTEM.LiberTEM-data?branchName=master\n.. _azure: https://dev.azure.com/LiberTEM/LiberTEM/_build/latest?definitionId=4&branchName=master\n\n.. |zenodo| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.1477847.svg\n.. _zenodo: https://doi.org/10.5281/zenodo.1477847\n\n.. |github| image:: https://img.shields.io/badge/GitHub-MIT-informational\n.. _github: https://github.com/LiberTEM/LiberTEM/\n\n.. |codeclimate| image:: https://api.codeclimate.com/v1/badges/dee042f64380f64737e5/maintainability\n.. _codeclimate: https://codeclimate.com/github/LiberTEM/LiberTEM\n\n.. |joss| image:: https://joss.theoj.org/papers/10.21105/joss.02006/status.svg\n.. _joss: https://doi.org/10.21105/joss.02006\n\n.. |precommit| image:: https://results.pre-commit.ci/badge/github/LiberTEM/LiberTEM/master.svg\n.. _precommit: https://results.pre-commit.ci/latest/github/LiberTEM/LiberTEM/master\n\n.. |pypi| image:: https://badge.fury.io/py/libertem.svg\n.. _pypi: https://pypi.org/project/libertem/\n\n.. |condaforge| image:: https://anaconda.org/conda-forge/libertem/badges/version.svg\n.. _condaforge: https://anaconda.org/conda-forge/libertem\n\nLiberTEM is an open source platform for high-throughput distributed processing\nof large-scale binary data sets and live data streams using a modified\n`MapReduce programming model <https://en.wikipedia.org/wiki/MapReduce>`_. The\ncurrent focus is `pixelated\n<https://en.wikipedia.org/wiki/Scanning_transmission_electron_microscopy#Universal_detectors>`_\nscanning transmission electron microscopy (`STEM\n<https://en.wikipedia.org/wiki/Scanning_transmission_electron_microscopy>`_)\n\\[`MacLaren et al. (2016) <https://doi.org/10.1002/9783527808465.EMC2016.6284>`_,\n`Ophus (2019) <https://doi.org/10.1017/s1431927619000497>`_\\] and scanning electron\nbeam diffraction data.\n\nMapReduce-like processing allows to specify an algorithm through two functions:\nOne function that is mapped on portions of the input data, and another function\nthat merges (reduces) a partial result from this mapping step into the complete\nresult. A wide range of TEM and 4D STEM processing tasks can be expressed in\nthis fashion, see `Applications`_.\n\nThe UDF interface of LiberTEM offers a standardized, versatile API to decouple\nthe mathematical core of an algorithm from details of data source, parallelism,\nand use of results. Mapping and merging can be performed in any order and with\ndifferent subdivisions of the input data, including running parts of the\ncalculation concurrently. That means the same implementation can be used in a\nwide range of modalities, including massive scaling on clusters. Since each\nmerge step produces an intermediate result, this style of processing is suitable\nfor displaying live results from a running calculation in a GUI application and\nfor `processing live data streams <https://github.com/LiberTEM/LiberTEM-live>`_.\nA closed-loop feedback between processing and instrument control can be realized\nas well. See `User-defined functions\n<https://libertem.github.io/LiberTEM/udf.html>`_ for more details on the\nLiberTEM UDF interface.\n\nThe LiberTEM back-end offers `high throughput and scalability\n<https://libertem.github.io/LiberTEM/architecture.html>`_ on PCs, single server\nnodes, clusters and cloud services. On clusters it can use fast distributed\nlocal storage on high-performance SSDs. That way it achieves `very high\naggregate IO performance\n<https://libertem.github.io/LiberTEM/performance.html>`_ on a compact and\ncost-efficient system built from stock components. All CPU cores and CUDA\ndevices in a system can be used in parallel.\n\nLiberTEM is supported on Linux, Mac OS X and Windows. Other platforms that allow\ninstallation of Python 3.7+ and the required packages will likely work as well. The\nGUI is running in a web browser.\n\nInstallation\n------------\n\nThe short version:\n\n.. code-block:: shell\n\n    $ virtualenv -p python3 ~/libertem-venv/\n    $ source ~/libertem-venv/bin/activate\n    (libertem-venv) $ python -m pip install \"libertem[torch]\"\n\n    # optional for GPU support\n    # See also https://docs.cupy.dev/en/stable/install.html\n    (libertem-venv) $ python -m pip install cupy\n\nPlease see `our documentation\n<https://libertem.github.io/LiberTEM/install.html>`_ for details!\n\nAlternatively, to run the `LiberTEM Docker image\n<https://libertem.github.io/LiberTEM/deployment/clustercontainer.html>`_:\n\n.. code-block:: shell\n\n    $ docker run -p localhost:9000:9000 --mount type=bind,source=/path/to/your/data/,dst=/data/,ro ghcr.io/libertem/libertem\n\nor\n\n.. code-block:: shell\n\n    $ singularity exec docker://ghcr.io/libertem/libertem /venv/bin/libertem-server\n\nDeployment for offline data processing on a single-node system for a local user\nis thoroughly tested and can be considered stable. Deployment on a cluster is\nexperimental and still requires some additional work, see `Issue #105\n<https://github.com/LiberTEM/LiberTEM/issues/105>`_. Back-end support for live data processing\nis still experimental as well, see https://github.com/LiberTEM/LiberTEM-live.\n\nApplications\n------------\n\nSince LiberTEM is programmable through `user-defined functions (UDFs)\n<https://libertem.github.io/LiberTEM/udf.html>`_, it can be used for a wide\nrange of processing tasks on array-like data and data streams. The following\napplications have been implemented already:\n\n- Virtual detectors (virtual bright field, virtual HAADF, center of mass\n  \\[`Krajnak et al. (2016) <https://doi.org/10.1016/j.ultramic.2016.03.006>`_\\],\n  custom shapes via masks)\n- `Analysis of amorphous materials <https://libertem.github.io/LiberTEM/app/amorphous.html>`_\n- `Strain mapping <https://libertem.github.io/LiberTEM-blobfinder/>`_\n- `Off-axis electron holography reconstruction <https://libertem.github.io/LiberTEM-holo/>`_\n- `Single Side Band ptychography <https://ptychography-4-0.github.io/ptychography/>`_\n\nSome of these applications are available through an `interactive web GUI\n<https://libertem.github.io/LiberTEM/usage.html#gui-usage>`_. Please see `the\napplications section <https://libertem.github.io/LiberTEM/applications.html>`_\nof our documentation for details!\n\nThe Python API and user-defined functions (UDFs) can be used for complex\noperations such as arbitrary linear operations and other features like data\nexport. Example Jupyter notebooks are available in the `examples directory\n<https://github.com/LiberTEM/LiberTEM/tree/master/examples>`_. If you are having\ntrouble running the examples, please let us know by filing an issue or\nby `joining our Gitter chat <https://gitter.im/LiberTEM/Lobby>`_.\n\nLiberTEM is suitable as a high-performance processing backend for other\napplications, including live data streams. `Contact us\n<https://gitter.im/LiberTEM/Lobby>`_ if you are interested!\n\nLiberTEM is evolving rapidly and prioritizes features following user demand and\ncontributions. Currently we are working on `live data processing\n<https://github.com/LiberTEM/LiberTEM-live>`_, improving application support for sparse\ndata and event-based detectors, performance improvements for GPU processing, and implementing\nanalysis methods for various applications of pixelated\nSTEM and other large-scale detector data. If you like to influence the direction\nthis project is taking, or if you'd like to `contribute\n<https://libertem.github.io/LiberTEM/contributing.html>`_, please join our\n`gitter chat <https://gitter.im/LiberTEM/Lobby>`_ and our `general mailing list\n<https://groups.google.com/forum/#!forum/libertem>`_.\n\nFile formats\n------------\n\nLiberTEM currently opens most file formats used for pixelated STEM. See `our\ngeneral information on loading data\n<https://libertem.github.io/LiberTEM/formats.html>`_ and `format-specific\ndocumentation\n<https://libertem.github.io/LiberTEM/reference/dataset.html#formats>`_ for more\ninformation!\n\n- Raw binary files\n- NumPy .npy binary files\n- Thermo Fisher EMPAD detector \\[`Tate et al. (2016) <https://doi.org/10.1017/S1431927615015664>`_\\] files\n- `Quantum Detectors MIB format <https://quantumdetectors.com/products/merlinem/>`_\n- Nanomegas .blo block files\n- Direct Electron DE5 files (HDF5-based) and Norpix SEQ files for `DE-Series <https://directelectron.com/de-series-cameras/>`_ detectors\n- `Gatan K2 IS <https://web.archive.org/web/20180809021832/http://www.gatan.com/products/tem-imaging-spectroscopy/k2-camera>`_ raw format\n- Stacks of Gatan DM3 and DM4 files (via `openNCEM <https://github.com/ercius/openNCEM>`_)\n- Single-file Gatan DM4 scans when saved using C-ordering\n- FRMS6 from PNDetector pnCCD cameras \\[`Simson et al. (2015) <https://doi.org/10.1017/s1431927615011836>`_\\]\n  (currently alpha, gain correction still needs UI changes)\n- FEI SER files (via `openNCEM <https://github.com/ercius/openNCEM>`_)\n- MRC (via `openNCEM <https://github.com/ercius/openNCEM>`_)\n- HDF5-based formats such as HyperSpy files, NeXus and EMD\n- TVIPS binary files\n- Sparse data in Raw CSR (compressed sparse row) format, as is possible\n  to generate from event-based detectors\n- Please contact us if you are interested in support for an additional format!\n\nLive processing and detectors (experimental)\n--------------------------------------------\n\nSee `LiberTEM-live <https://libertem.github.io/LiberTEM-live/>`_!\n\nLicense\n-------\n\nLiberTEM is licensed under the MIT license.\n\nAcknowledgements\n----------------\n\nWe are very grateful for your continuing support for LiberTEM!\n\nSee `the acknowledgement page\n<https://libertem.github.io/acknowledgements.html>`_ for a list of authors and\ncontributors to LiberTEM and its subprojects. See also our info on `funding\n<https://libertem.github.io/#funding>`_ and `industry partners\n<https://libertem.github.io/#industry-partners>`_.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/lightning-uq-box",
            "repo_link": "https://github.com/lightning-uq-box/lightning-uq-box",
            "readme": "<p align=\"center\">\n<img src=\"https://github.com/lightning-uq-box/lightning-uq-box/blob/main/docs/_static/lettering.jpeg?raw=true\" alt=\"Lightning-UQ-Box logo\" width=\"600\" height=\"auto\" />\n</p>\n\n[![docs](https://readthedocs.org/projects/lightning-uq-box/badge/?version=latest)](https://lightning-uq-box.readthedocs.io/en/latest/)\n[![style](https://github.com/lightning-uq-box/lightning-uq-box/actions/workflows/style.yaml/badge.svg)](https://github.com/lightning-uq-box/lightning-uq-box/actions/workflows/style.yaml)\n[![tests](https://github.com/lightning-uq-box/lightning-uq-box/actions/workflows/tests.yaml/badge.svg)](https://github.com/lightning-uq-box/lightning-uq-box/actions/workflows/tests.yaml)\n[![codecov](https://codecov.io/gh/lightning-uq-box/lightning-uq-box/branch/main/graph/badge.svg?token=oa3Z3PMVOg)](https://app.codecov.io/gh/lightning-uq-box/lightning-uq-box)\n[![license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/lightning-uq-box/lightning-uq-box/blob/main/LICENSE)\n<a href=\"https://pytorch.org/get-started/locally/\"><img alt=\"PyTorch\" src=\"https://img.shields.io/badge/PyTorch-ee4c2c?logo=pytorch&logoColor=white\"></a>\n<a href=\"https://pytorchlightning.ai/\"><img alt=\"Lightning\" src=\"https://img.shields.io/badge/-Lightning-792ee5?logo=pytorchlightning&logoColor=white\"></a> &emsp;\n\n# lightning-uq-box\n\nThe lightning-uq-box is a PyTorch library that provides various Uncertainty Quantification (UQ) techniques for modern neural network architectures.\n\nWe hope to provide the starting point for a collaborative open source effort to make it easier for practitioners to include UQ in their workflows and\nremove possible barriers of entry. Additionally, we hope this can be a pathway to more easily compare methods across UQ frameworks and potentially enhance the development of new UQ methods for neural networks.\n\n*The project is currently under active development, but we nevertheless hope for early feedback, feature requests, or contributions. Please check the [Contribution Guide](https://lightning-uq-box.readthedocs.io/en/latest/contribute.html) for further information.*\n\nThe goal of this library is threefold:\n\n1. Provide implementations for a variety of Uncertainty Quantification methods for Modern Deep Neural Networks that work with a range of neural network architectures and have different theoretical underpinnings\n2. Make it easy to compare UQ methods on a given dataset\n3. Focus on reproducibility of experiments with minimum boiler plate code and standardized evaluation protocols\n\nTo this end, each UQ-Method is essentially just a [Lightning Module](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html) which can be used with a [Lightning Data Module](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) and a [Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html) to execute training, evaluation and inference for your desired task. The library also utilizes the [Lightning Command Line Interface (CLI)](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.cli.LightningCLI.html) for better reproducibility of experiments and setting up experiments at scale.\n\n# Theory Guide\n\nFor a comprehensive document that provides more mathematical details for each method and generally forms the basis of our implementations, please see the [Theory Guide](./docs/api/Lightning_UQ_Box_Theory_Guide.pdf). As a living document, we plan to update it as the library encompasses more methods. If you have any questions, or find typos or errors, feel free to open an issue.\n\n# Installation\n\nThe recommended way to install the latest released version is via pip,\n\n```console\npip install lightning-uq-box\n```\n\nFor the latest development version you can run,\n\n```console\npip install git+https://github.com/lightning-uq-box/lightning-uq-box.git\n```\n\nThe package is also available for installation via conda or spack. You can find instructions in the [documention](https://lightning-uq-box.readthedocs.io/en/latest/installation.html)\n\n# UQ-Methods\n\nIn the tables that follow below, you can see what UQ-Method/Task combination is currently supported by the Lightning-UQ-Box via these indicators:\n\n- ✅ supported\n- ❌ not designed for this task\n- ⏳ in progress\n\nThe implemented methods are of course not exhaustive, as the number of new methods keeps increasing. For an overview of methods that we are tracking or are planning to support, take a look at [this issue](https://github.com/lightning-uq-box/lightning-uq-box/issues/43).\n\n## Classification of UQ-Methods\n\nThe following sections aims to give an overview of different UQ-Methods by grouping them according to some commonalities. We agree that there could be other groupings as well and welcome suggestions to improve this overview. We also follow this grouping for the API documentation in the hopes to make navigation easier.\n\n### Single Forward Pass Methods\n\n| UQ-Method                                     | Regression | Classification | Segmentation | Pixel Wise Regression |\n|-----------------------------------------------|:----------:|:--------------:|:------------:|:---------------------:|\n| Quantile Regression (QR)                      |     ✅     |       ❌       |      ❌      |          ✅           |\n| Deep Evidential (DE)                          |     ✅     |       ⏳       |      ⏳      |          ✅           |\n| Mean Variance Estimation (MVE)                |     ✅     |       ❌       |      ❌      |          ✅           |\n| ZigZag                                        |     ✅     |       ✅       |      ❌      |          ❌           |\n| Mixture Density Networks                      |     ✅     |       ❌       |      ❌      |          ⏳           |\n\n### Approximate Bayesian Methods\n\n| UQ-Method                                     | Regression | Classification | Segmentation | Pixel Wise Regression |\n|-----------------------------------------------|:----------:|:--------------:|:------------:|:---------------------:|\n| Bayesian Neural Network VI ELBO (BNN_VI_ELBO) |     ✅     |       ✅       |      ✅      |          ⏳           |\n| Bayesian Neural Network VI (BNN_VI)           |     ✅     |       ⏳       |      ⏳      |          ⏳           |\n| Deep Kernel Learning (DKL)                    |     ✅     |       ✅       |      ❌      |          ❌           |\n| Deterministic Uncertainty Estimation (DUE)    |     ✅     |       ✅       |      ❌      |          ❌           |\n| Laplace Approximation (Laplace)               |     ✅     |       ✅       |      ❌      |          ❌           |\n| Monte Carlo Dropout (MC-Dropout)              |     ✅     |       ✅       |      ✅      |          ✅           |\n| Stochastic Gradient Langevin Dynamics (SGLD)  |     ✅     |       ✅       |      ⏳      |          ⏳           |\n| Spectral Normalized Gaussian Process (SNGP)   |     ✅     |       ✅       |      ❌      |          ❌           |\n| Stochastic Weight Averaging Gaussian (SWAG)   |     ✅     |       ✅       |      ✅      |          ✅           |\n| Variational Bayesian Last Layer (VBLL)        |     ✅     |       ✅       |      ❌      |          ❌           |\n| Deep Ensemble                                 |     ✅     |       ✅       |      ✅      |          ✅           |\n| Masked Ensemble                               |     ✅     |       ✅       |      ⏳      |          ⏳           |\n| Density Uncertainty Layer                     |     ✅     |       ✅       |      ❌      |          ❌           |\n\n### Generative Models\n\n| UQ-Method                                     | Regression | Classification | Segmentation | Pixel Wise Regression |\n|-----------------------------------------------|:----------:|:--------------:|:------------:|:---------------------:|\n| Classification And Regression Diffusion (CARD)|     ✅     |       ✅       |      ❌      |          ❌           |\n| Probabilistic UNet                            |     ❌     |       ❌       |      ✅      |          ❌           |\n| Hierarchical Probabilistic UNet               |     ❌     |       ❌       |      ✅      |          ❌           |\n| Variational Auto-Encoder (VAE)                |     ❌     |       ❌       |      ❌      |          ✅           |\n\n### Post-Hoc methods\n\n| UQ-Method                                     | Regression | Classification | Segmentation | Pixel Wise Regression |\n|-----------------------------------------------|:----------:|:--------------:|:------------:|:---------------------:|\n| Test Time Augmentation (TTA)                  |     ✅     |       ✅       |      ⏳      |          ⏳           |\n| Temperature Scaling                           |     ❌     |       ✅       |      ⏳      |          ❌           |\n| Conformal Quantile Regression (Conformal QR)  |     ✅     |       ❌       |      ❌      |          ⏳           |\n| Regularized Adaptive Prediction Sets (RAPS)   |     ❌     |       ✅       |      ❌      |          ❌           |\n| Image to Image Conformal                      |     ❌     |       ❌       |      ❌      |          ✅           |\n\n# Tutorials\n\nWe try to provide many different tutorials so that users can get a better understanding of implemented methods and get a feel for how they apply to different problems.\nHead over to the [tutorials](https://lightning-uq-box.readthedocs.io/en/latest/tutorial_overview.html) page to get started. These tutorials can also be launched in google colab if you navigate to the rocket icon at the top of a tutorial page.\n\n# Documentation\nWe aim to provide an extensive documentation on all included UQ-methods that provide some theoretical background, as well as tutorials that illustrate these methods on toy datasets.\n\n# Citation\n\nIf you use this software in your work, please cite our [paper](https://arxiv.org/abs/2410.03390):\n\n```bibtex\n@article{Lehmann_Lightning_UQ_Box_2024,\n  author = {Lehmann, Nils and Gawlikowski, Jakob and Stewart, Adam J. and Jancauskas, Vytautas and Depeweg, Stefan and Nalisnick, Eric and Gottschling, Nina M.},\n  journal = {arXiv preprint arXiv:2410.03390},\n  title = {{Lightning UQ Box}: A Comprehensive Framework for Uncertainty Quantification in Deep Learning},\n  year = {2024}\n}\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/linmog",
            "repo_link": "https://jugit.fz-juelich.de/iek-10/public/optimization/linmog",
            "readme": "# LinMOG\n\nLinMOG is a collection of tools for the generation of linear models for \nunivariate and multivariate functions. Furthermore, the linear model can be \nautomatically transformed into a MILP optimization formulation. \n\n\nThe packages in LinMoG are briefly described in the following.\n\n## Hinging_Hyperplanes\n\nThe hinging hyperplane package can be utilized for data driven model generation and visualization of multivariate\nfunctions with one output variable\n\n## Opt_model\n\nUsing this package, piecewise linear models can be transformed into different MILP formulations.\n\n## Univariate_model\n\nPackage for data-driven modeling of univariate functions.\n\n## Documentation\nYou can also build the documentation locally, following the [instructions in the docs directory](docs/README.md).\n\n## Referencing\n\nWhen using LinMOG in an academic context please cite\n\n```bibtex\n@inproceedings{holtwerth2022data,\n  title={Data-Driven Generation of Mixed-Integer Linear Programming Formulations for Model Predictive Control of Hybrid Energy Storage Systems Using Detailed Nonlinear Simulation Models},\n  author={Holtwerth, Alexander and Xhonneux, Andr{\\'e} and M{\\\"u}ller, Dirk},\n  booktitle={2022 Open Source Modelling and Simulation of Energy Systems (OSMSES)},\n  pages={1--6},\n  year={2022},\n  organization={IEEE}\n}\n```\n\n## License\n\nThis project is licensed under the MIT License, for more information please refer to the [LICENSE](LICENSE) file.\n\n## Installation\nCurrently, it is only supported using source files.",
            "project_id": "8837"
        },
        {
            "software_organization": "https://helmholtz.software/software/llama",
            "repo_link": "https://github.com/alpaka-group/llama",
            "readme": "LLAMA – Low-Level Abstraction of Memory Access\n==============================================\n\n[![ReadTheDocs](https://img.shields.io/badge/Docs-Read%20the%20Docs-blue.svg)](https://llama-doc.readthedocs.io)\n[![Doxygen](https://img.shields.io/badge/API-Doxygen-blue.svg)](https://alpaka-group.github.io/llama)\n[![Language](https://img.shields.io/badge/Language-C%2B%2B17-blue.svg)](https://isocpp.org/)\n[![Paper](https://img.shields.io/badge/Paper-Wiley%20Online%20Library-blue.svg)](https://doi.org/10.1002/spe.3077)\n[![Preprint](https://img.shields.io/badge/Preprint-arXiv-blue.svg)](https://arxiv.org/abs/2106.04284)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5901241.svg)](https://doi.org/10.5281/zenodo.5901241)\n[![codecov](https://codecov.io/gh/alpaka-group/llama/branch/develop/graph/badge.svg?token=B94D9G96FA)](https://codecov.io/gh/alpaka-group/llama)\n\n![LLAMA](docs/images/logo_400x169.png)\n\nLLAMA is a cross-platform C\\++17/C\\++20 header-only template library for the abstraction of data layout and memory access.\nIt separtes the view of the algorithm on the memory and the real data layout in the background.\nThis allows for performance portability in applications running on heterogeneous hardware with the very same code.\n\nDocumentation\n-------------\n\nOur extensive user documentation is available on [Read the Docs](https://llama-doc.rtfd.io).\nIt includes:\n\n* Installation instructions\n* Motivation and goals\n* Overview of concepts and ideas\n* Descriptions of LLAMA's constructs\n\nAn API documentation is generated by [Doxygen](https://alpaka-group.github.io/llama/) from the C++ source.\nPlease read the documentation on Read the Docs first!\n\nSupported compilers\n-------------------\n\nLLAMA tries to stay close to recent developments in C++ and so requires fairly up-to-date compilers.\nThe following compilers are supported by LLAMA and tested as part of our CI:\n\n\n| Linux                                                                                         | Windows                                             | MacOS                            |\n|-----------------------------------------------------------------------------------------------|-----------------------------------------------------|----------------------------------|\n| g++ 10 - 13 </br> clang++ 12 - 17 </br> icpx (latest) </br> nvc++ 23.5 </br> nvcc 11.6 - 12.3 | Visual Studio 2022 </br> (latest on GitHub actions) | clang++ </br> (latest from brew) |\n\n\nSingle header\n-------------\n\nWe create a single-header version of LLAMA on each commit,\nwhich you can find on the [single-header branch](https://github.com/alpaka-group/llama/tree/single-header).\n\nThis also useful, if you would like to play with LLAMA on Compiler explorer:\n```c++\n#include <https://raw.githubusercontent.com/alpaka-group/llama/single-header/llama.hpp>\n```\n\nContributing\n------------\n\nWe greatly welcome contributions to LLAMA.\nRules for contributions can be found in [CONTRIBUTING.md](CONTRIBUTING.md).\n\nScientific publications\n-----------------------\n\nWe published an [article](https://doi.org/10.1002/spe.3077) on LLAMA in the journal of Software: Practice and Experience.\nWe gave a talk on LLAMA at CERN's Compute Accelerator Forum on 2021-05-12.\nThe video recording (starting at 40:00) and slides are available here on [CERN's Indico](https://indico.cern.ch/event/975010/).\nMind that some of the presented LLAMA APIs have been renamed or redesigned in the meantime.\n\nWe presented recently added features to LLAMA at the ACAT22 workshop as a [poster](https://indico.cern.ch/event/1106990/contributions/5096939/)\nand a contribution to the [proceedings](https://arxiv.org/abs/2302.08251).\nAdditionally, we gave a [talk](https://indico.cern.ch/event/1106990/contributions/4991259/) at ACAT22 on LLAMA's instrumentation capabilities during a case study on [AdePT](https://github.com/apt-sim/AdePT),\nagain, with a contribution to the [proceedings](https://arxiv.org/abs/2302.08252).\n\nAttribution\n-----------\n\nIf you use LLAMA for scientific work, please consider citing this project.\nWe upload all releases to [Zenodo](https://zenodo.org/record/4911494),\nwhere you can export a citation in your preferred format.\nWe provide a DOI for each release of LLAMA.\nAdditionally, consider citing the [LLAMA paper](https://doi.org/10.1002/spe.3077).\n\nLicense\n-------\n\nLLAMA is licensed under the [MPL-2.0](LICENSE).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/llview",
            "repo_link": "https://github.com/FZJ-JSC/LLview",
            "readme": "<div align=\"left\">\n  <img src=\"docs/docs/images/LLview_logo.svg\" alt=\"LLview\" height=\"150em\"/>\n</div>\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10221407.svg)](https://doi.org/10.5281/zenodo.10221407)\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n\n# LLview\n\n<div align=\"center\">\n  <img src=\"docs/docs/images/LLview_thumbnail.png\" alt=\"LLview thumbnail\" width=\"100%\"/>\n</div>\n\nLLview is a set of software components to monitor clusters that are controlled by a resource manager and a scheduler system. Within its Job Reporting module, it provides detailed information of all the individual jobs running on the system. To achieve this, LLview connects to different sources in the system and collects data to present to the user via a web portal. For example, the resource manager provides information about the jobs, while additional daemons may be used to acquire extra information from the compute nodes, keeping the overhead at a minimum, as the metrics are obtained in the range of minutes apart. The LLview portal establishes a link between performance metrics and individual jobs to provide a comprehensive job reporting interface.\n\n## Installation\n\n[Installation instructions](https://apps.fz-juelich.de/jsc/llview/docu/install/) can be found on LLview's [documentation page](https://llview.fz-juelich.de/docs).\n\nLLview presents its gathered data in a Web Portal created by [JURI](https://github.com/FZJ-JSC/JURI).\n\n## Further Information\n\nFor further information please see: http://llview.fz-juelich.de/docs\n\nContact: [llview.jsc@fz-juelich.de](mailto:llview.jsc@fz-juelich.de)\n\n## Copyright, License and CLA\n\nCopyright (c) 2023 Forschungszentrum Juelich GmbH, Juelich Supercomputing Centre  \nhttp://llview.fz-juelich.de/\n\nThis is an open source software distributed under the GPLv3 license. More information see the LICENSE file at the top level.\n\nContributions must follow the Contributor License Agreement. More information see the CONTRIBUTING.md file at the top level.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/lynx",
            "repo_link": "https://github.com/ajacquey/lynx",
            "readme": "<h1 align=\"center\">\n  <br>\n  <a href=\"https://gitext.gfz-potsdam.de/ajacquey/lynx\">LYNX</a>\n  <br>\n  Lithosphere dYnamic Numerical toolboX\n  <br>\n  A MOOSE-based application\n  <br>\n</h1>\n\n<h4 align=\"center\">A numerical simulator for modelling deformation of the lithosphere, based on <a href=\"http://mooseframework.org/\" target=\"blank\">MOOSE</a>.</h4>\n\n<p align=\"center\">\n  <a href=\"LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-GPLv3-blue.svg\"\n         alt=\"GPL License\">\n  </a>\n  <a href=\"https://zenodo.org/record/3355376#.XUA2qi2Q1PU\">\n    <img src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.3355376.svg\"\n         alt=\"DOI\">\n  </a>\n</p>\n\n## About\nLYNX (Lithosphere dYnamic Numerical toolboX) is a numerical simulator for modelling coupled Thermo-Hydro-Mechanical processes in the porous rocks of the lithosphere.\nThe simulator is developed by [Antoine Jacquey](http://www.gfz-potsdam.de/en/staff/antoine-jacquey/) <a href=\"https://orcid.org/0000-0002-6259-4305\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a> and [Mauro Cacace](http://www.gfz-potsdam.de/en/section/basin-modeling/staff/profil/mauro-cacace/) <a href=\"https://orcid.org/0000-0001-6101-9918\" target=\"orcid.widget\" rel=\"noopener noreferrer\" style=\"vertical-align:top;\"><img src=\"https://orcid.org/sites/default/files/images/orcid_16x16.png\" style=\"width:1em;margin-right:.5em;\" alt=\"ORCID iD icon\"></a> at the [GFZ Potsdam, German Research Centre for Geosciences](http://www.gfz-potsdam.de/en/home/) from the section [Basin Modelling](http://www.gfz-potsdam.de/en/section/basin-modeling/).\n\n\nLYNX is a MOOSE-based application. Visit the [MOOSE framework](http://mooseframework.org) page for more information.\n\n## Licence\nLYNX is distributed under the [GNU GENERAL PUBLIC LICENSE v3](https://gitext.gfz-potsdam.de/ajacquey/lynx/blob/master/LICENSE).\n\n\n## Getting Started\n\n#### Minimum System Requirements\nThe following system requirements are from the MOOSE framework (see [Getting Started](http://mooseframework.org/getting-started/) for more information):\n* Compiler: C++11 Compliant GCC 4.8.4, Clang 3.4.0, Intel20130607\n* Python 2.7+\n* Memory: 16 GBs (debug builds)\n* Processor: 64-bit x86\n* Disk: 30 GBs\n* OS: UNIX compatible (OS X, most flavors of Linux)\n\n#### 1. Setting Up a MOOSE Installation\nTo install LYNX, you need first to have a working and up-to-date installation of the MOOSE framework.  \nTo do so, please visit the [Getting Started](http://mooseframework.org/getting-started/) page of the MOOSE framework and follow the instructions. If you encounter difficulties at this step, you can ask for help on the [MOOSE-users Google group](https://groups.google.com/forum/#!forum/moose-users).\n\n#### 2. Clone LYNX\nLYNX can be cloned directly from [GitLab](https://gitext.gfz-potsdam.de/ajacquey/lynx) using [Git](https://git-scm.com/). In the following, we refer to the directory `projects` which you created during the MOOSE installation (by default `~/projects`):  \n\n    cd ~/projects\n    git clone https://gitext.gfz-potsdam.de/ajacquey/lynx.git\n    cd ~/projects/lynx\n    git checkout master\n\n*Note: the \"master\" branch of LYNX is the \"stable\" branch which is updated only if all tests are passing.*\n\n#### 3. Compile LYNX\nYou can compile LYNX by following these instructions:\n\n    cd ~/projects/lynx\n    make -j4\n\n#### 4. Test LYNX\nTo make sure that everything was installed properly, you can run the tests suite of LYNX:\n\n    cd ~/projects/lynx\n    ./run_tests -j2\n\nIf all the tests passed, then your installation is working properly. You can now use the LYNX simulator!\n\n## Usage\nTo run LYNX from the command line with multiple processors, use the following command:\n\n    mpiexec -n <nprocs> ~/projects/lynx/lynx-opt -i <input-file>\n\nWhere `<nprocs>` is the number of processors you want to use and `<input-file>` is the path to your input file (extension `.i`).  \n\nInformation about the structure of the LYNX input files can be found in the documentation (link to follow).\n\n## Cite\n\nIf you use LYNX for your work please cite:\n* This repository:  \nJacquey, Antoine B., & Cacace, Mauro. (2019, July 30). LYNX: Lithosphere dYnamic Numerical toolboX, a MOOSE-based application (Version 1.0). Zenodo. http://doi.org/10.5281/zenodo.3355376\n\n* The following research articles:\nJacquey, Antoine B., & Cacace, Mauro. (2020). Multiphysics Modeling of a Brittle‐Ductile Lithosphere: 1. Explicit Visco‐Elasto‐Plastic Formulation and Its Numerical Implementation. Journal of Geophysical Research: Solid Earth. http://doi.org/10.1029/2019jb018474\nJacquey, Antoine B., & Cacace, Mauro. (2020). Multiphysics Modeling of a Brittle‐Ductile Lithosphere: 2. Semi‐brittle, Semi‐ductile Deformation and Damage Rheology. Journal of Geophysical Research: Solid Earth. http://doi.org/10.1029/2019jb018475\n\n\nPlease read the [CITATION](https://gitext.gfz-potsdam.de/ajacquey/lynx//blob/master/CITATION) file for more information.\n\n## Publications using LYNX\n\n* Jacquey, Antoine B., & Cacace, Mauro. (2020). Multiphysics Modeling of a Brittle‐Ductile Lithosphere: 1. Explicit Visco‐Elasto‐Plastic Formulation and Its Numerical Implementation. Journal of Geophysical Research: Solid Earth. http://doi.org/10.1029/2019jb018474\n\n* Jacquey, Antoine B., & Cacace, Mauro. (2020). Multiphysics Modeling of a Brittle‐Ductile Lithosphere: 2. Semi‐brittle, Semi‐ductile Deformation and Damage Rheology. Journal of Geophysical Research: Solid Earth. http://doi.org/10.1029/2019jb018475\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/maftools",
            "repo_link": "https://github.com/PoisonAlien/maftools",
            "readme": "<img src=\"vignettes/maftools_hex.svg\" align=\"left\" height=\"140\" /></a>\n\n## maftools - An R package to summarize, analyze and visualize MAF files\n\n[![GitHub closed issues](https://img.shields.io/github/issues-closed-raw/poisonalien/maftools.svg)](https://github.com/poisonalien/maftools/issues)\n[![R-CMD-check](https://github.com/PoisonAlien/maftools/workflows/R-CMD-check/badge.svg)](https://github.com/PoisonAlien/maftools/actions)\n\n## Introduction\n\nmaftools is a comprehensive toolkit for processing somatic variants from cohort-based cancer genomic studies. maftools offers over 80 functions to perform the most commonly required tasks in cancer genomics, using [MAF](https://docs.gdc.cancer.gov/Data/File_Formats/MAF_Format/) as the only input file type.\n\n## Installation\n\n```{r}\n#Install from Bioconductor repository\nBiocManager::install(\"maftools\")\n\n#Install from GitHub repository\nBiocManager::install(\"PoisonAlien/maftools\")\n```\n\n## Getting started: Vignette and a case study\n\nA complete documentation of maftools using [TCGA LAML](https://www.nejm.org/doi/full/10.1056/nejmoa1301689) as a case study can be found [here](http://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html).\n\n<p align=\"left\">\n<img src=\"https://user-images.githubusercontent.com/8164062/97981605-d8a59500-1dd2-11eb-9f5e-cc808f7b3f91.gif\" height=\"320\" height=\"400\">\n</p>\n\n## Primary applications \n\nmaftools is extremely easy to use, starting with importing an [MAF](https://docs.gdc.cancer.gov/Data/File_Formats/MAF_Format/) file along with the associated clinical data. Once the data is successfully imported, the resulting MAF object can be passed to various functions. Key applications include:\n\n- [Cohort summarization using oncoplots](https://bioconductor.org/packages/devel/bioc/vignettes/maftools/inst/doc/oncoplots.html#08_Combining_everything)\n- [Identify co-occurring and mutually exclusive events](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#91_Somatic_Interactions)\n- [Clinical enrichment analysis](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#96_Clinical_enrichment_analysis)\n- [Detect cancer driver genes](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#92_Detecting_cancer_driver_genes_based_on_positional_clustering)\n- [Infer tumor heterogeneity](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#99_Tumor_heterogeneity_and_MATH_scores)\n- [Analyze known cancer signaling pathways](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#98_Oncogenic_Signaling_Pathways)\n- [De-novo somatic signature analysis with NMF](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#9103_Signature_analysis)\n- [Compare two cohorts to identify differentially mutated genes](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#95_Comparing_two_cohorts_(MAFs))\n- [Perform survival analysis and predict genesets associated with survival](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#942_Predict_genesets_associated_with_survival)\n- [Drug-gene interactions](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#97_Drug-Gene_Interactions)\n\nBesides the MAF files, maftools can handle sequencing alignment BAM files, copy number output from GISTIC and mosdepth. Please refer to the package documentation sections below to learn more.\n\n- [Generate personalized cancer report](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/cancer_hotspots.html) for known somatic [hotspots](https://www.cancerhotspots.org/)\n- [Sample mismatch and relatedness analysis](https://bioconductor.org/packages/devel/bioc/vignettes/maftools/inst/doc/maftools.html#12_Sample_swap_identification)\n- [Copy number analysis](https://bioconductor.org/packages/devel/bioc/vignettes/maftools/inst/doc/cnv_analysis.html) with [ASCAT](https://github.com/VanLoo-lab/ascat) and [mosdepth](https://github.com/brentp/mosdepth)\n\nMoreover, analyzing all 33 TCGA cohorts along with the harmonized clinical data is a breeze. \n\n- A single command [tcgaLoad](https://bioconductor.org/packages/release/bioc/vignettes/maftools/inst/doc/maftools.html#13_TCGA_cohorts) will import the desired TCGA cohort thereby avoiding costly time spent on data mining from public databases. \n- Please refer to an associated software package [TCGAmutations](https://github.com/PoisonAlien/TCGAmutations) that provides ready to use `MAF` objects for 33 TCGA cohorts and 2427 cell line profiles from CCLE - along with relevant clinical information for all sequenced samples.\n\n## Citation\n\n**_Mayakonda A, Lin DC, Assenov Y, Plass C, Koeffler HP. 2018. Maftools: efficient and comprehensive analysis of somatic variants in cancer. [Genome Research](https://doi.org/10.1101/gr.239244.118). PMID: [30341162](https://www.ncbi.nlm.nih.gov/pubmed/?term=30341162)_**\n\n\n## Useful links\n\n| File Fomats                                                                                                        | Data portals                                                                                    | Annotation tools                                                                                                                       |\n|--------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n| [Mutation Annotation Format](https://docs.gdc.cancer.gov/Data/File_Formats/MAF_Format/)                            | [TCGA](http://cancergenome.nih.gov)                                                             | [vcf2maf](https://github.com/mskcc/vcf2maf) - for converting your VCF files to MAF                                                     |\n| [Variant Call Format](https://en.wikipedia.org/wiki/Variant_Call_Format)                                           | [ICGC](https://docs.icgc.org/)                                                                  | [annovar2maf](https://github.com/PoisonAlien/annovar2maf) - for converting annovar output files to MAF                                 |\n| ICGC [Simple Somatic Mutation Format](https://docs.icgc.org/submission/guide/icgc-simple-somatic-mutation-format/) | [Broad Firehose](https://gdac.broadinstitute.org/)                                              | [bcftools csq](https://samtools.github.io/bcftools/howtos/csq-calling.html) - Rapid annotations of VCF files with variant consequences |\n|                                                                                                                    | [cBioPortal](https://www.cbioportal.org/)                                                       | [Annovar](https://annovar.openbioinformatics.org/en/latest/)                                                              |\n|                                                                                                                    | [PeCan](https://pecan.stjude.cloud/)                                                            | [Funcotator](https://gatk.broadinstitute.org/hc/en-us/articles/360037224432-Funcotator)                                                |\n|                                                                                                                    | [CIViC](https://civicdb.org/home) - Clinical interpretation of variants in cancer               |                                                                                                                                        |\n|                                                                                                                    | [DGIdb](http://www.dgidb.org/) - Information on drug-gene interactions and the druggable genome |                                                                                                                                        |\n\n\n## Useful packages/tools\n\nBelow are some more useful software packages for somatic variant analysis\n\n* [TRONCO](https://github.com/BIMIB-DISCo/TRONCO) - Repository of the TRanslational ONCOlogy library (R)\n* [dndscv](https://github.com/im3sanger/dndscv) - dN/dS methods to quantify selection in cancer and somatic evolution (R)\n* [cloneevol](https://github.com/hdng/clonevol) - Inferring and visualizing clonal evolution in multi-sample cancer sequencing (R)\n* [sigminer](https://github.com/ShixiangWang/sigminer) - Primarily for signature analysis and visualization in R. Supports `maftools` output (R)\n* [GenVisR](https://github.com/griffithlab/GenVisR) - Primarily for visualization (R)\n* [comut](https://github.com/vanallenlab/comut) - Primarily for visualization (Python)\n* [TCGAmutations](https://github.com/PoisonAlien/TCGAmutations) - pre-compiled curated somatic mutations from TCGA cohorts (from Broad Firehose and TCGA MC3 Project) that can be loaded into `maftools` (R)\n* [somaticfreq](<https://github.com/PoisonAlien/somaticfreq>) - rapid genotyping of known somatic hotspot variants from the tumor BAM files. Generates a browsable/sharable HTML report. (C)\n\n***\n\n#### Powered By\n\n* [data.table](https://github.com/Rdatatable/data.table/wiki) at [warp speed](https://en.wikipedia.org/wiki/Warp_drive)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mainzelliste",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/mallob",
            "repo_link": "https://github.com/domschrei/mallob",
            "readme": "[![status](https://joss.theoj.org/papers/700e9010c4080ffe8ae4df21cf1cc899/status.svg)](https://joss.theoj.org/papers/700e9010c4080ffe8ae4df21cf1cc899)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6890239.svg)](https://doi.org/10.5281/zenodo.6890239)\n\n# Mallob\n\nThe platform **Mallob** (**Mal**leable **Lo**ad **B**alancer, or **Ma**ssively P**a**ra**ll**el **Lo**gic **B**ackend) is a distributed platform for processing automated reasoning tasks in modern large-scale HPC and cloud environments. Mallob primarily solves instances of the NP-complete _propositional satisfiability_ (SAT) problem – an essential building block at the core of automated reasoning and Symbolic AI. Mallob's flexible and decentralized approach to job scheduling allows to concurrently process many tasks of varying priority by different users. As such, Mallob can drastically improve your academic or industrial workflows tied to automated reasoning.\n\nMallob's tightly integrated distributed general-purpose SAT solving engine, which we refer to as MallobSat, has received a large amount of attention, five gold medals of the International SAT Competition's Cloud Track in a row, and Amazon's proposition that our system is, \"by a _wide_ margin, the most powerful SAT solver on the planet\" (Byron Cook, [Amazon Science blog post](https://www.amazon.science/blog/automated-reasonings-scientific-frontiers)).\nMallob is also the first distributed system that supports _incremental SAT solving_, i.e., interactive solving procedures over evolving formulas. Most recently, Mallob spearheaded the adoption of unsatisfiability proof checking in parallel and distributed SAT solving. Since proofs can serve as crucial witnesses for a result’s correctness, Mallob is suitable even for the most critical use cases.\n\n<hr/>\n\n# Setup\n\n## Prerequisites\n\nNote that we only support Linux as an operating system.\n(Some people have been developing and experimenting with Mallob within the WSL, but there seem to be issues related to inotify.)\n\n* CMake ≥ 3.11.4\n* Open MPI (or another MPI implementation)\n* GDB\n* [jemalloc](https://github.com/jemalloc/jemalloc)\n\n## Building\n\n```bash\n# Only needed if building with MALLOB_APP_SAT (enabled by default).\n# For non-x86-64 architectures (ARM, POWER9, etc.), prepend `DISABLE_FPU=1` to \"bash\".\n( cd lib && bash fetch_and_build_sat_solvers.sh )\n\n# Build Mallob\nmkdir -p build\ncd build\nCC=$(which mpicc) CXX=$(which mpicxx) cmake -DCMAKE_BUILD_TYPE=RELEASE -DMALLOB_APP_SAT=1 -DMALLOB_USE_JEMALLOC=1 -DMALLOB_LOG_VERBOSITY=4 -DMALLOB_ASSERT=1 -DMALLOB_SUBPROC_DISPATCH_PATH=\\\"build/\\\" ..\nmake; cd ..\n\n# Optional - only needed for on-the-fly LRAT checking\n( cd lib && bash fetch_and_build_impcheck.sh && cp impcheck/build/impcheck_* ../build/ )\n```\n\nSpecify `-DCMAKE_BUILD_TYPE=RELEASE` for a release build or `-DCMAKE_BUILD_TYPE=DEBUG` for a debug build.\nYou can use the following Mallob-specific build options:\n\n| Usage                                       | Description                                                                                                |\n| ------------------------------------------- | ---------------------------------------------------------------------------------------------------------- |\n| -DMALLOB_ASSERT=<0/1>                       | Turn on assertions (even on release builds). Setting to 0 limits assertions to debug builds.               |\n| -DMALLOB_JEMALLOC_DIR=path                  | If necessary, provide a path to a local installation of `jemalloc` where `libjemalloc.*` is located.       |\n| -DMALLOB_LOG_VERBOSITY=<0..6>               | Only compile logging messages of the provided maximum verbosity and discard more verbose log calls.        |\n| -DMALLOB_SUBPROC_DISPATCH_PATH=\\\\\"path\\\\\"   | Subprocess executables must be located under <path> for Mallob to find. (Use `\\\"build/\\\"` by default.)     |\n| -DMALLOB_USE_ASAN=<0/1>                     | Compile with Address Sanitizer for debugging purposes.                                                     |\n| -DMALLOB_USE_GLUCOSE=<0/1>                  | Compile with support for Glucose SAT solver (disabled by default for licensing reasons, see below).        |\n| -DMALLOB_USE_JEMALLOC=<0/1>                 | Compile with Scalable Memory Allocator `jemalloc` instead of default `malloc`.                             |\n| -DMALLOB_APP_KMEANS=<0/1>                   | Compile with K-Means clustering engine.                                                                    |\n| -DMALLOB_APP_SAT=<0/1>                      | Compile with SAT solving engine.                                                                           |\n| -DMALLOB_MAX_N_APPTHREADS_PER_PROCESS=<N>   | Max. number of application threads (solver threads for SAT) per process to support. (max: 128)             |\n| -DMALLOB_BUILD_LRAT_MODULES=<0/1>           | Also build standalone LRAT checker                                                                         |\n\n## Docker\n\nWe also provide a setup based on Docker containerization. Please consult the documentation in the `docker/` directory.\n\n## Bash Autocompletion\n\nMallob features bash auto-completion by pressing TAB. To enable this, execute this command from Mallob's base directory:\n\n  source scripts/run/autocomplete.sh\n\nFrom this directory you can now autocomplete program options by pressing TAB once or twice.\n\n<hr/>\n\n# Testing\n\n**Note:** In its current state, the test suite expects that Mallob is built and run with OpenMPI, i.e., that `mpicc` and `mpicxx` (for building) and `mpirun` (for execution) link to OpenMPI executables on your system. For other MPI implementations, you may still be able to run the tests by removing or replacing the option `--oversubscribe` from the function `run()` in `scripts/run/systest_commons.sh`.\n\nIn order to test that the system has been built and set up correctly, run the following command.\n```\nbash scripts/run/systest.sh mono drysched sched osc\n```\nThis will locally run a suite of automated tests which cover the basic functionality of Mallob as a scheduler and as a SAT solving engine. \nTo include Glucose in the tests, prepend the above command with \"GLUCOSE=1\".\nRunning the tests takes a few minutes and in the end \"All tests done.\" should be output.\n\n<hr/>\n\n# Usage\n\nWe first explain how to execute Mallob in general, then detail how to solve an isolated problem and then turn to solving many instances in a row or at the same time.\n\n## General\n\nGiven a single machine with two hardware threads per core, the following command executed in Mallob's base directory assigns one MPI process to each set of four physical cores (eight hardware threads) and then runs four solver threads on each MPI process.\n\n```\nRDMAV_FORK_SAFE=1; NPROCS=\"$(($(nproc)/8))\"; mpirun -np $NPROCS --bind-to core --map-by ppr:${NPROCS}:node:pe=4 build/mallob -t=4 $MALLOB_OPTIONS\n```\n\nGiven a machine with `$nthreads` cores (and twice the number of hardware threads), the following command spawns a single process with one solver thread per core (per hardware thread):\n\n```\nRDMAV_FORK_SAFE=1; mpirun -np 1 --bind-to core --map-by ppr:1:node:pe=$nthreads build/mallob -t=$nthreads $MALLOB_OPTIONS\nRDMAV_FORK_SAFE=1; mpirun -np 1 --bind-to hwthread --map-by ppr:1:node:pe=$((2*$nthreads)) build/mallob -t=$((2*$nthreads)) $MALLOB_OPTIONS\n```\n\nAlternatively, only executing `build/mallob -t=$nthreads $MALLOB_OPTIONS` works as well in this case but does not pin threads to cores.\n\nYou can always stop Mallob via Ctrl+C (interrupt signal) or by executing `killall mpirun` (or `killall build/mallob`). \nYou can also specify the number of jobs to process (with `-J=$NUM_JOBS`) and/or the time to pass (with `-T=$TIME_LIMIT_SECS`) before Mallob terminates on its own.\n\nFor exact and clean logging, you should not rely on a textfile in which you piped Mallob's output.\nInstead, specify a logging directory with `-log=<log-dir>` where separate sub-directories and files will be created for each worker / thread. \nThis can be combined with the `-q` option to suppress Mallob's output to STDOUT. \nVerbosity of logging can be set with the `-v` option (as long as Mallob was compiled with the respective verbosity or higher, see `-DMALLOB_LOG_VERBOSITY` above).\nAll further options of Mallob can be seen by executing Mallob with the `-h` option. (This also works without the `mpirun` prefix.)\n\nFor running Mallob on distributed clusters, please also consult [our quickstart guide for clusters](docs/clusters.md) and/or the user documentation of your particular cluster.\n\n## SAT Solving\n\nIn general, in order to let Mallob process only a single instance, use option `-mono=$PROBLEM_FILE` where `$PROBLEM_FILE` is the path and file name of the problem to solve (DIMACS CNF format, possibly with .xz or .lzma compression, for SAT; whitespace-separated plain text file for K-Means). Specify the application of this instance with `-mono-app=sat` or `-mono-app=kmeans`.\n\nIn this mode, all processes participate in solving, overhead is minimal, and Mallob terminates immediately after the job has been processed.\nUse option `-s2f=path/to/output.txt` (\"solution to file\") to write the result and (if applicable) the found satisfying assignment to a text file.\n\n### Producing Proofs of Unsatisfiability\n\nTo enable proof production, just set the option `-proof=path/to/final/compressed/prooffile.lrat` together with `-mono=path/to/input.cnf`. You also need to set a log directory with `-proof-dir=path/to/dir` where intermediate files will be written to on each machine. The final proof is output in compressed LRAT format.\n\nCaDiCaL is currently the only supported solver backend for parallel/distributed proof production. However, it is possible to employ other solvers as long as their only purpose is to find a satisfying assignment (i.e., exported clauses and unsatisfiability results from these solvers are discarded). See *Portfolio Tweaking* below.\n\nFor instance, you can check the output proof with the standalone LRAT checker that comes with Mallob if you set `-DMALLOB_BUILD_LRAT_MODULES=1` at build time:\n```bash\nbuild/standalone_lrat_checker path/to/input.cnf path/to/final/compressed/prooffile.lrat\n```\nFurther synergies are possible; you can set `-uninvert=0` for Mallob and `--reversed` for the checker to avoid one entire I/O pass over the proof that \"uninverts\" its lines.\nYou can use the [`drat-trim`](https://github.com/marijnheule/drat-trim) tool suite to decompress a proof; note that you need to `#define MODE 2` (1=DRAT, 2=LRAT) in `decompress.c` before building.\n\n### Trusted solving *without* explicit proof production\n\nProof production can be costly and bottlenecked by the I/O bandwidth of the single process which needs to write the entire proof. A more scalable approach is to check all proof information on-the-fly, without writing it to disk, and to transfer clause soundness guarantees across machines via cryptographic signatures. This is explained in detail in our [2024 SAT publication](https://dominikschreiber.de/papers/2024-sat-trusted-pre.pdf).\n\nExecute the command chain fetching and building [ImpCheck](https://github.com/domschrei/impcheck) in the above *Building* section. Then just use Mallob's option `-otfc=1` (without any `-proof*` options) to enable on-the-fly checking. Again, only CaDiCaL is supported for UNSAT whereas any solver can be employed for boosting satisfying assignments. By default, found satisfying assignments are also validated, which can be disabled via `-otfcm=0`.\n\nLog lines of the following shape are reporting a trusted result from a proof checking process:\n```\nc 0.851 0 <#11606> S0.0 TRUSTED checker reported UNSAT - sig c6c0a823f35ce38cdb31c9483dc98143\n```\n```\nc 0.242 0 <#11607> S0.0 TRUSTED checker reported SAT - sig a43e47d81715035d79290d1a6acf05e8\n```\nTo be extra safe (e.g., if you are suspecting garbled or tampered-with logging output), execute the following command to validate the output signature:\n```bash\nbuild/impcheck_confirm -formula-input=path/to/input.cnf -result=X -result-sig=SIG\n```\nwhere `X` is either 10 (for SAT) or 20 (for UNSAT), and `SIG` is the reported signature.\n\n**Note:** On-the-fly checking can also be used in Mallob's scheduled mode of operation. Globally unique clause IDs are ensured by adding a large offset times $x$ to a new solver thread's clause ID counter if the job has already experienced $x$ _balancing epochs_, i.e., received $x$ volume updates, since its initialization. The offset is chosen in such a way that 10,000 solvers each producing 10,000 clauses per second can run for 10,000 seconds before they may begin overlapping with clause IDs from the next balancing epoch. `ImpCheck` notices and reports any errors that would result from such a corner case.\n\n### Portfolio Tweaking\n\nMallob allows to customize the employed SAT solver backends and some of their flavors. This is done with the `-satsolver` option, which expects a string representing the solver backends to cycle over. The option also allows for a limited set of regular expression symbols. Here are some examples:\n```bash\n... -satsolver='c' # CaDiCaL only.\n... -satsolver='kcl' # Kissat, CaDiCaL, Lingeling, Kissat, CaDiCaL, Lingeling, Kissat, ...\n... -satsolver='k(c)*' # One Kissat, then only CaDiCaL (always put brackets around the argument of '*')\n... -satsolver='kCLCLcl' # Capital letters indicate using truly incremental SAT solving for incremental jobs\n... -satsolver='l+(c!){37}' # One Lingeling configured for satisfiable instances (+), then 37 LRAT-producing (!) CaDiCaLs, repeat\n... -satsolver='(c!){37}k+((c!){37}l+)*' # As above, but replacing the 1st Lingeling with Kissat\n```\n\n## Solve multiple instances in an orchestrated manner\n\nIf you want to solve a fixed set of $n$ formulae or wish to evaluate Mallob's scheduling behavior with simulated jobs, follow these steps:\n\n* Write the set of formulae into a text file `$INSTANCE_FILE` (one line per path).\n* Configure the base properties of a job with a JSON file `$JOB_TEMPLATE`. For a plain job with default properties you can use `templates/job-template.json`.\n* Configure the behavior of each job-introducing process (\"client\") with a JSON file `$CLIENT_TEMPLATE`. You can find the simplest possible configuration in `templates/client-template.json` and a more complex randomized configuration in `templates/client-template-random.json`. Both files contain all necessary documentation to adjust them as desired.\n\nThen use these Mallob options:\n```\n-c=1 -ajpc=$MAX_PAR_JOBS -ljpc=$((2*$MAX_PAR_JOBS)) -J=$NUM_JOBS -job-desc-template=$INSTANCE_FILE -job-template=$JOB_TEMPLATE -client-template=$CLIENT_TEMPLATE -pls=0\n```\nwhere `$NUM_JOBS` is set to $n$ (if it is larger than $n$, a client cycles through the provided job descriptions indefinitely). You can set `-sjd=1` to shuffle the provided job descriptions. You can also increase the number of client processes introducing jobs by increasing the value of `-c`. However, note that the provided configuration for active jobs in the system is applied to each of the clients independently, hence the formulae provided in the instance file are not split up among the clients but rather duplicated.\n\n## Process jobs on demand\n\nThis is the default and most general configuration of Mallob, i.e., without `-mono` or `-job-template` options.\nYou can manually set the number of worker processes (`-w`) and the number of client processes introducing jobs (`-c`). By default, all processes are workers (`-w=-1`) and a single process is additionally a client (`-c=1`). The $k$ client processes are always the $k$ processes of the highest ranks, and they open up file system interfaces for introducing jobs and retrieving results at the directories `.api/jobs.0/` through `.api/jobs.`$k-1$`/`.\n\n### Introducing a Job\n\nTo introduce a job to the system, drop a JSON file in `.api/jobs.`$i$`/in/` (e.g., `.api/jobs.0/in/`) on the filesystem of the according PE structured like this:  \n```\n{\n    \"application\": \"SAT\",\n    \"user\": \"admin\", \n    \"name\": \"test-job-1\", \n    \"files\": [\"/path/to/difficult/formula.cnf\"], \n    \"priority\": 0.7, \n    \"wallclock-limit\": \"5m\", \n    \"cpu-limit\": \"10h\",\n    \"arrival\": 10.3,\n    \"dependencies\": [\"admin.prereq-job1\", \"admin.prereq-job2\"],\n    \"incremental\": false\n}\n```    \n\nHere is a brief overview of all required and optional fields in the JSON API:\n\n| Field name        | Required? | Value type   | Description                                                                                                    |\n| ----------------- | :-------: | -----------: | -------------------------------------------------------------------------------------------------------------- |\n| user              | **yes**   | String       | A string specifying the user who is submitting the job                                                         |\n| name              | **yes**   | String       | A user-unique name for this job (increment)                                                                    |\n| files             | **yes***  | String array | File paths of the input to solve. For SAT, this must be a single (text file or compressed file or named pipe). |\n| priority          | **yes***  | Float > 0    | Priority of the job (higher is more important)                                                                 |\n| application       | **yes**   | String       | Which kind of problem is being solved; currently either of \"SAT\" or \"DUMMY\" (default: DUMMY)                   |\n| wallclock-limit   | no        | String       | Job wallclock limit: combination of a number and a unit (ms/s/m/h/d)                                           |\n| cpu-limit         | no        | String       | Job CPU time limit: combination of a number and a unit (ms/s/m/h/d)                                            |\n| arrival           | no        | Float >= 0   | Job's arrival time (seconds) since program start; ignore job until then                                        |\n| max-demand        | no        | Int >= 0     | Override the max. number of MPI processes this job should receive at any point in time (0: no limit)           |\n| dependencies      | no        | String array | User-qualified job names (using \".\" as a separator) which must exit **before** this job is introduced          |\n| interrupt         | no        | Bool         | If `true`, the job given by \"user\" and \"name\" is interrupted (for incremental jobs, just the current revision).|\n| incremental       | no        | Bool         | Whether this job has multiple _increments_ / _revisions_ and should be treated as such                         |\n| literals          | no        | Int array    | You can specify the set of SAT literals (for this increment) directly in the JSON.                             |\n| precursor         | no        | String       | _(Only for incremental jobs)_ User-qualified job name (`<user>.<jobname>`) of this job's previous increment    |\n| assumptions       | no        | Int array    | _(Only for incremental jobs)_ You can specify the set of assumptions for this increment directly in the JSON.  |\n| done              | no        | Bool         | _(Only for incremental jobs)_ If `true`, the incremental job given by \"precursor\" is finalized and cleaned up. |\n\n*) Not needed if `done` is set to `true`.\n\nIn the above example, a job is introduced with priority 0.7, with a wallclock limit of five minutes and a CPU limit of 10 CPUh.\n\nFor SAT solving, the input can be provided (a) as a plain file, (b) as a compressed (.lzma / .xz) file, or (c) as a named (UNIX) pipe.\nIn each case, you have the option of providing the payload (i) in text form (i.e., a valid CNF description), or, with field `content-mode: \"raw\"`, in binary form (i.e., a sequence of bytes representing integers).  \nFor text files, Mallob uses the common iCNF extension for incremental formulae: The file may contain a single line of the form `a <lit1> <lit2> ... 0` where `<lit1>`, `<lit2>` etc. are assumption literals.   \nFor binary files, Mallob reads clauses as integer sequences with separation zeroes in between.\nTwo zeroes in a row (i.e., an \"empty clause\") signal the end of clause literals, after which a number of assumption integers may be specified. Another zero signals that the description is complete.  \nIf providing a named pipe, make sure that (a) the named pipe is already created when submitting the job and (b) your application pipes the formula _after_ submitting the job (else it will hang indefinitely except if this is done in a separate thread).\n\nAssumptions can also be specified directly in the JSON describing the job via the `assumptions` field (without any trailing zero). This way, an incremental application could maintain a single text file with a monotonically growing set of clauses.\n\nThe \"arrival\" and \"dependencies\" fields are useful to test a particular preset scenario of jobs: The \"arrival\" field ensures that the job will be scheduled only after Mallob ran for the specified amount of seconds. The \"dependencies\" field ensures that the job is scheduled only if all specified other jobs are already processed.\n\nMallob is notified by the kernel as soon as a valid file is placed in `.api/jobs.0/in/` and will immediately remove the file and schedule the job.\n\n### Retrieving a Job Result\n\nUpon completion of a job, Mallob writes a result JSON file under `.api/jobs.0/out/<user-name>.<job-name>.json` (you can repeatedly query the directory contents or employ a kernel-level mechanism like `inotify`).\nSuch a file may look like this:\n```\n{\n    \"application\": \"SAT\",\n    \"cpu-limit\": \"10h\",\n    \"file\": \"/path/to/difficult/formula.cnf\",\n    \"name\": \"test-job-1\",\n    \"priority\": 0.7,\n    \"result\": {\n        \"resultcode\": 10,\n        \"resultstring\": \"SAT\",\n        \"solution\": [0, 1, 2, 3, 4, 5]\n    },\n    \"stats\": {\n        \"time\": {\n            \"parsing\": 0.03756427764892578,\n            \"processing\": 0.07197785377502441,\n            \"scheduling\": 0.0002980232238769531,\n            \"total\": 0.11040472984313965\n        },\n        \"used_cpu_seconds\": 0.2633516788482666,\n        \"used_wallclock_seconds\": 0.06638360023498535\n    },\n    \"user\": \"admin\",\n    \"wallclock-limit\": \"5m\"\n}\n```\nThe result code is 0 is unknown, 10 if SAT (solved successfully), and 20 if UNSAT (no solution exists).\nThe `solution` field is application-dependent.\nFor SAT solving, in case of SATISFIABLE, the solution field contains the found satisfying assignment; in case of UNSAT, the result for an incremental job contains the set of failed assumptions.\nInstead of the \"solution\" field, the response may also contain the fields \"solution-size\" and \"solution-file\" if the solution is large and if option `-pls` is set. In that case, your application has to read `solution-size` integers (as bytes) representing the solution from the named pipe located at `solution-file`.\n\n<hr/>\n\n# Debugging\n\nDebugging of distributed applications can be difficult, especially in Mallob's case where message passing goes hand in hand with multithreading and inter-process communication. Please take a look at [docs/debugging.md](docs/debugging.md) for some notes on how Mallob runs can be diagnosed and debugged appropriately.\n\n<hr/>\n\n# Programming Interfaces\n\nMallob can be extended in the following ways:\n\n* New options for Mallob can be added in `src/optionslist.hpp`.\n    - Options which are specific to a certain application can be found and edited in `src/app/$APPKEY/options.hpp`.\n* To add a new SAT solver to be used in a SAT solver engine, do the following:\n    - Add a subclass of `PortfolioSolverInterface`. (You can use the existing implementation for any of the existing solvers and adapt it to your solver.)\n    - Add your solver to the portfolio initialization in `src/app/sat/execution/engine.cpp`.\n* To extend Mallob by adding another kind of application (like combinatorial search, planning, SMT, ...), please read [docs/application_engines.md](docs/application_engines.md).\n* To add a unit test, create a class `test_*.cpp` in `src/test` and then add the test case to the bottom of `CMakeLists.txt`.\n* To add a system test, consult the files `scripts/systest_commons.sh` and/or `scripts/systest.sh`.\n\n<hr/>\n\n# Licensing and remarks\n\nThe source code of Mallob can be used, changed and redistributed under the terms of the **Lesser General Public License (LGPLv3)**, one exception being the Glucose interface which is excluded from compilation by default (see below).\n**Please approach us if you require a deviating license.**\n\nThe used versions of Lingeling, YalSAT, CaDiCaL, and Kissat are MIT-licensed, as is HordeSat (the massively parallel solver system our SAT engine was based on) and the proof-related tools which are included and/or fetched in the `tools/` directory.\n\nThe Glucose interface of Mallob, unfortunately, is non-free software due to the [non-free license of (parallel-ready) Glucose](https://github.com/mi-ki/glucose-syrup/blob/master/LICENCE). Notably, its usage in competitive events is restricted. So when compiling Mallob with `-DMALLOB_USE_GLUCOSE=1` make sure that you have read and understood these restrictions.\n\nWithin our codebase we make thankful use of the following liberally licensed projects:\n\n* [robin-map](https://github.com/Tessil/robin-map) by Thibaut Goetghebuer-Planchon, for efficient unordered maps and sets\n* [libcuckoo](https://github.com/efficient/libcuckoo) by Manu Goyal et al., for concurrent hash tables\n* [JSON for Modern C++](https://github.com/nlohmann/json) by Niels Lohmann, for reading and writing JSON files\n* [Compile Time Regular Expressions](https://github.com/hanickadot/compile-time-regular-expressions) by Hana Dusíková, for matching particular user inputs\n* [robin_hood hashing](https://github.com/martinus/robin-hood-hashing) by Martin Ankerl, for efficient unordered maps and sets\n\n## Bibliography\n\nIf you make use of Mallob in an academic setting or in a competitive event, please cite the most relevant among the following publications.\n\n#### SAT'21: Focus on SAT solving\n```bibtex\n@inproceedings{schreiber2021scalable,\n  title={Scalable SAT Solving in the Cloud},\n  author={Schreiber, Dominik and Sanders, Peter},\n  booktitle={International Conference on Theory and Applications of Satisfiability Testing},\n  pages={518--534},\n  year={2021},\n  organization={Springer},\n  doi={10.1007/978-3-030-80223-3_35}\n}\n```\n#### Euro-Par'22: Focus on decentralized scheduling\n```bibtex\n@inproceedings{sanders2022decentralized,\n  title={Decentralized Online Scheduling of Malleable {NP}-hard Jobs},\n  author={Sanders, Peter and Schreiber, Dominik},\n  booktitle={International European Conference on Parallel and Distributed Computing},\n  pages={119--135},\n  year={2022},\n  organization={Springer},\n  doi={10.1007/978-3-031-12597-3_8}\n}\n```\n#### TACAS'23: Proofs of unsatisfiability\n```bibtex\n@InProceedings{michaelson2023unsatisfiability,\n  author={Michaelson, Dawn and Schreiber, Dominik and Heule, Marijn J. H. and Kiesl-Reiter, Benjamin and Whalen, Michael W.},\n  title={Unsatisfiability proofs for distributed clause-sharing SAT solvers},\n  booktitle={Tools and Algorithms for the Construction and Analysis of Systems (TACAS)},\n  year={2023},\n  organization={Springer},\n  pages={348--366},\n  doi={10.1007/978-3-031-30823-9_18},\n}\n```\n#### SAT Competition TRs\n```bibtex\n@article{schreiber2020engineering,\n  title={Engineering HordeSat Towards Malleability: mallob-mono in the {SAT} 2020 Cloud Track},\n  author={Schreiber, Dominik},\n  journal={SAT Competition 2020},\n  pages={45--46}\n}\n@article{schreiber2021mallob,\n  title={Mallob in the {SAT} Competition 2021},\n  author={Schreiber, Dominik},\n  journal={SAT Competition 2021},\n  pages={38--39}\n}\n@article{schreiber2022mallob,\n  title={Mallob in the {SAT} Competition 2022},\n  author={Schreiber, Dominik},\n  journal={SAT Competition 2022},\n  pages={46--47}\n}\n@article{schreiber2023mallob,\n  title={Mallob\\{32,64,1600\\} in the {SAT} Competition 2023},\n  author={Schreiber, Dominik},\n  journal={SAT Competition 2023},\n  pages={46--47}\n}\n```\n#### Doctoral thesis (featuring all of the above + new content)\n```bibtex\n@phdthesis{schreiber2023scalable,\n  author={Dominik Schreiber},\n  title={Scalable {SAT} Solving and its Application},\n  year={2023},\n  school={Karlsruhe Institute of Technology},\n  doi={10.5445/IR/1000165224}\n}\n```\n\nFurther references:\n\n* **[Mallob IPASIR Bridge for incremental SAT solving](https://github.com/domschrei/mallob-ipasir-bridge)**\n* **[ImpCheck - Immediate Massively Parallel Propositional Proof Checking](https://github.com/domschrei/impcheck)**\n* **[Experimental data at Zenodo](https://zenodo.org/doi/10.5281/zenodo.10184679)**\n* **[Mallob at Helmholtz Research Software Directory (RSD)](https://helmholtz.software/software/mallob)**\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mallocmc",
            "repo_link": "https://github.com/alpaka-group/mallocMC",
            "readme": "mallocMC\n=============\n\nmallocMC: *Memory Allocator for Many Core Architectures*\n\nThis project provides a framework for **fast memory managers** on **many core\naccelerators**. It is based on [alpaka](https://github.com/alpaka-group/alpaka)\nto run on many different accelerators and comes with multiple allocation\nalgorithms out-of-the-box. Custom ones can be added easily due to the\npolicy-based design.\n\nUsage\n-------\n\nFollow the step-by-step instructions in [Usage.md](Usage.md) to replace your\n`new`/`malloc` calls with a *blacingly fast* mallocMC heap! :rocket:\n\nInstall\n-------\n\nmallocMC is header-only, but requires a few other C++ libraries to be\navailable. Our installation notes can be found in [INSTALL.md](INSTALL.md).\n\nContributing\n------------\n\nRules for contributions are found in [CONTRIBUTING.md](./CONTRIBUTING.md).\n\nOn the Algorithms\n-----------------------------\n\nThis library was originally inspired by the *ScatterAlloc* algorithm,\n[forked](https://en.wikipedia.org/wiki/Fork_%28software_development%29)\nfrom the **ScatterAlloc** project, developed by the\n[Managed Volume Processing](http://www.icg.tugraz.at/project/mvp)\ngroup at [Institute for Computer Graphics and Vision](http://www.icg.tugraz.at),\nTU Graz (kudos!). The currently shipped algorithms are using similar ideas but\ndiffer from the original one significantly.\n\nFrom the original project page (which is no longer existent to the best of our\nknowledge):\n\n```quote\nScatterAlloc is a dynamic memory allocator for the GPU. It is\ndesigned concerning the requirements of massively parallel\nexecution.\n\nScatterAlloc greatly reduces collisions and congestion by\nscattering memory requests based on hashing. It can deal with\nthousands of GPU-threads concurrently allocating memory and its\nexecution time is almost independent of the thread count.\n\nScatterAlloc is open source and easy to use in your CUDA projects.\n```\n\nOur Homepage: <https://www.hzdr.de/crp>\n\nVersions and Releases\n---------------------\n\nOfficial releases can be found in the\n[Github releases](https://github.com/alpaka-group/mallocMC/releases).\nWe try to stick to [semantic versioning](https://semver.org/) but we'll bump\nthe major version number for major features.\nDevelopment happens on the `dev` branch.\nChanges there have passed the CI and a code review but we make no guarantees\nabout API or feature stability in this branch.\n\nLiterature\n----------\n\nJust an incomplete link collection for now:\n\n- [Paper](https://doi.org/10.1109/InPar.2012.6339604) by\n  Markus Steinberger, Michael Kenzel, Bernhard Kainz and Dieter Schmalstieg\n\n- 2012, May 5th: [Presentation](http://innovativeparallel.org/Presentations/inPar_kainz.pdf)\n        at *Innovative Parallel Computing 2012* by *Bernhard Kainz*\n\n- Junior Thesis [![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.34461.svg)](http://dx.doi.org/10.5281/zenodo.34461) by\n  Carlchristian Eckert (2014)\n\nLicense\n-------\n\nWe distribute the modified software under the same license as the\noriginal software from TU Graz (by using the\n[MIT License](https://en.wikipedia.org/wiki/MIT_License)).\nPlease refer to the [LICENSE](LICENSE) file.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mapman",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/massbank",
            "repo_link": "https://github.com/MassBank",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/materials-learning-algorithms",
            "repo_link": "https://github.com/mala-project/mala",
            "readme": "![image](./docs/source/img/logos/mala_horizontal.png)\n\n# MALA\n\n[![CPU](https://github.com/mala-project/mala/actions/workflows/cpu-tests.yml/badge.svg)](https://github.com/mala-project/mala/actions/workflows/cpu-tests.yml)\n[![image](https://github.com/mala-project/mala/actions/workflows/gh-pages.yml/badge.svg)](https://mala-project.github.io/mala/)\n[![image](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5557255.svg)](https://doi.org/10.5281/zenodo.5557255)\n\n\nMALA (Materials Learning Algorithms) is a data-driven framework to generate surrogate models of density functional theory calculations based on machine learning. Its purpose is to enable multiscale modeling by bypassing computationally expensive steps in state-of-the-art density functional simulations.\n\nMALA is designed as a modular and open-source python package. It enables users to perform the entire modeling toolchain using only a few lines of code. MALA is jointly developed by the Sandia National Laboratories (SNL) and the Center for Advanced Systems Understanding (CASUS). See [Contributing](docs/source/CONTRIBUTE.md) for contributing code to the repository.\n\nThis repository is structured as follows:\n```\n├── examples : contains useful examples to get you started with the package\n├── install : contains scripts for setting up this package on your machine\n├── mala : the source code itself\n├── test : test scripts used during development, will hold tests for CI in the future\n└── docs : Sphinx documentation folder\n```\n\n## Installation\n\n> **WARNING**: Even if you install MALA via PyPI, please consult the full installation instructions afterwards. External modules (like the QuantumESPRESSO bindings) are not distributed via PyPI!\n\nPlease refer to [Installation of MALA](docs/source/install/installing_mala.rst).\n\n## Running\n\nYou can familiarize yourself with the usage of this package by running\nthe examples in the `example/` folder.\n\n## Contributors\n\nMALA is jointly maintained by \n\n- [Sandia National Laboratories](https://www.sandia.gov/) (SNL), USA.\n    - Scientific supervisor: Sivasankaran Rajamanickam, code maintenance: \nJon Vogel\n- [Center for Advanced Systems Understanding](https://www.casus.science/) (CASUS), Germany.\n    - Scientific supervisor: Attila Cangi, code maintenance: Lenz Fiedler\n\nA full list of contributors can be found [here](docs/source/CONTRIBUTE.md).\n\n## Citing MALA\n\nIf you publish work which uses or mentions MALA, please cite the following paper:\n\nJ. A. Ellis, L. Fiedler, G. A. Popoola, N. A. Modine, J. A. Stephens, A. P. Thompson,\nA. Cangi, S. Rajamanickam (2021). Accelerating Finite-temperature\nKohn-Sham Density Functional Theory with Deep Neural Networks.\n[Phys. Rev. B 104, 035120 (2021)](https://doi.org/10.1103/PhysRevB.104.035120)\n\nalongside this repository.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/matrad",
            "repo_link": "https://github.com/e0404/matRad",
            "readme": "[![Current Release](https://img.shields.io/github/v/release/e0404/matRad)](https://github.com/e0404/matRad/releases) \n[![Downloads](https://img.shields.io/github/downloads/e0404/matRad/total)](https://github.com/e0404/matRad/releases) \n[![Contributors](https://img.shields.io/github/contributors/e0404/matRad)](https://github.com/e0404/matRad/graphs/contributors)\n\n[![GitHub Build Status](https://github.com/e0404/matRad/actions/workflows/tests.yml/badge.svg)](https://github.com/e0404/matRad/actions/workflows/tests.yml)\n[![codecov](https://codecov.io/gh/e0404/matRad/graph/badge.svg?token=xQhUQLu4FK)](https://codecov.io/gh/e0404/matRad)\n\nCitable DOIs:\n- General DOI: [![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.3879615.svg)](https://doi.org/10.5281/zenodo.3879615)\n- Latest Release: [![DOI](https://zenodo.org/badge/29671667.svg)](https://zenodo.org/badge/latestdoi/29671667)\n\n# General information\n\n---\n\nmatRad is an open source treatment planning system for radiation therapy written in Matlab. It supports planning of intensity-modulated radiation therapy for mutliple modalities and is meant **for educational and research purposes**. **IT IS NOT SUITABLE FOR CLINICAL USE** (also see the no-warranty clause in the GPL license). The source code is maintained by a development team at the German Cancer Reserach Center - DKFZ in Heidelberg, Germany, and other contributors around the world. We are always looking for more people willing to help improve matRad. Do not hesitate and [get in touch](mailto:contact@matRad.org).\n\nMore information can be found on the project page  at <http://e0404.github.io/matRad/>; a wiki documentation is under constant development at <https://github.com/e0404/matRad/wiki>.\n\n# Getting Started\nIf you want to quickly run matRad, start with the Quick Start below. Some information on the structure of matRad for more sustainable use is given afterwards.\n\n## Quick Start\nIt’s the first time you want to use matRad?\n\nFirst, get a local copy of matRad by download or git cloning. Having done that, we recommend you navigate into the folder in Matlab and execute \n```\nmatRad_rc\n```\nwhich will setup the path & configuration and tell you the current version.\n\nThen there’re three options for a pleasant start with matRad. Choose one or try out each of them.\n\n### Option 1: Using the GUI\n\nFor an intuitive workflow with the graphical user interface, type \n```\nmatRadGUI\n```\nin your command window. An empty GUI should be opened. Click the _*Load.mat_ data-Button in the Workflow-section to load a patient. Set the plan and optimization parameters, calculate the dose influence matrix and execute the fluence optimization in the GUI.\n\n### Option 2: Using the main script\n\nIf you prefer scripting, open the default script *matRad.m* from the main matRad folder:\n```\nedit matRad.m\n```\nUse it to learn something about the code structure and execute it section by section.\n\nYou can also run the full script for an example photon plan by just typing\n```\nmatRad\n``` \nin your command window.\n\n### Option 3: Using the examples\n\nThe most time consuming but also most educational approach to matRad. \n\nWhen in the main matRad folder, navigate to the folder *examples*. Open one of the examples given there. Execute it section by section. Move on to the next example afterwards.\n\n## Advanced information for new users\n### Folder Structure\n#### Core Source Code\nMost of the source code of matRad is located in the \"matRad\" subfolder. Within the first level of matRad, you find the functions handling the basic workflow steps. These functions have simple interfaces relying on matRad's main data structures ct, cst, stf, dij, resultGUI, and pln.\nAdditionally, it contains MatRad_Config.m which is a singleton class implementation to handle global configuration of matRad. Check out the infos further below. \n\nWe try to keep the main workflow functions as consistent as possible, while the fine-grained implementation in the subfolders within matRad/* may undergo larger changes.\n#### User Directory\nBy default, matRad adds the \"userdata\" folder to the path. It is the place to put your custom scripts, machine data, imported patients etc. Just follow the README files in the folders. Contents of this folder are added to the .gitignore and will thus be ignored during your development efforts, keeping your repository clean.\n#### Third-Party & Submodules\nOur ThirdParty-Tools used in matRad are stored in the thirdParty folder including licenses. Submodules contains references to used git repositories, and you might recognize that some dependencies appear both in submodules and thirdParty. This is mainly to maintain operation if the code is downloaded (and not cloned), and also helps us to maintain the build process of mex files built from source in the submodules (and then added to ThirdParty). \n#### Tests\nThe \"test\" folder contains xUnit-Style tests based on the MOxUnit framework. You can run those tests by running matRad_runTests from the root directory. Check the README file within the test folder for more information.\n\n### MatRad_Config / matRad_cfg\nmatRad maintains its global configuration, including some default parameters, as well as a logging mechanism with different levels, in the MatRad_Config.m class serving as a \"singleton\" throughout matRad. You will see many functions using a call like `matRad_cfg = MatRad_Config.instance();`, which will get you the global configuration anywhere in the code or in the command window. Alternatively, `matRad_rc` will return matRad_cfg as well.\n\n# Need help?\nIf you encounter problems with matRad, please consider the following guidelines **before** submitting issues on our github page. \n\n* Check you are using the newest version of matRad.\n* Please check the description of how to set up matRad and its technical documentation in the [wiki](https://github.com/e0404/matRad/wiki).\n* Go through the relevant examples and see if they answer your question (see *Option 3* above!)\n* Check open and closed issues for your question.\n\nStill having problems? Then create an issue, provide a **minimum example** of your attempted workflow / what causes the problems and be patient!\n\n# Citing matRad\n\n### Scientific papers\n\nIf you use matRad in a scientific publication, consider citing the following paper:\n\nWieser, Hans-Peter, et al. \"Development of the open-source dose calculation and optimization toolkit matRad.\" Medical Physics 44.6 (2017): 2556-2568. \n\n[![DOI](https://img.shields.io/badge/DOI-10.1002%2Fmp.12251-blue)](https://doi.org/10.1002/mp.12251) \n\nBibTex entry:\n```\n@article{wieser2017development,\n  title={Development of the open-source dose calculation and optimization toolkit matRad},\n  author={Wieser, Hans-Peter and Cisternas, Eduardo and Wahl, Niklas and Ulrich, Silke and Stadler, Alexander and Mescher, Henning and M{\\\"u}ller, Lucas-Raphael and Klinge, Thomas and Gabrys, Hubert and Burigo, Lucas and others},\n  journal={Medical Physics},\n  volume={44},\n  number={6},\n  pages={2556--2568},\n  year={2017},\n  publisher={Wiley Online Library},\n  doi={10.1002/mp.12251}\n}\n```\n\n### Citing as Software\n\nmatRad's code also has its own general DOI with Zenodo: \n\n[![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.3879615.svg)](https://doi.org/10.5281/zenodo.3879615)\n\nYou can cite specific versions of matRad in your work! For example, Here is the badge that lead's to the latest release of matRad:\n\n[![DOI](https://zenodo.org/badge/29671667.svg)](https://zenodo.org/badge/latestdoi/29671667)\n\n# Funding Sources\nmatRad developments (on this branch) were (in parts) funded by:\n- The German Research Foundation (DFG), Project No. 265744405 & 443188743\n- The German Cancer Aid, Project No. 70113094\n- The German Federal Ministry of Education and Research (BMBF), Project No. 01DN17048\n- Mathworks Academic Research Support\n\n---\n\nCopyright 2022 the matRad development team. \n\nmatrad@dkfz.de\n\nAll the elements of the compilation of matRad and Ipopt are free software. You can redistribute and/or modify matRad's source code version provided as files with .m and .mat extension under the terms of the GNU GENERAL PUBLIC LICENSE Version 3 (GPL v3). You can also add to matRad the Ipopt functionality by using the precompiled mex files of the Ipopt optimizer in object code version which are licensed under the Eclipse Public License Version 1.0 (EPL v1.0), also made available for download via https://projects.coin-or.org/Ipopt.\nmatRad also contains interfaces to an open-source photon Monte Carlo dose calculation engine developed by Edgardo Dörner hosted on GitHub (http://github.com/edoerner/ompMC) and to the open-source proton Monte Carlo project MCsquare (www.openmcsquare.org) from UCLouvain, Louvain-la-Neuve, Belgium. Both interfaces are integrated into matRad as submodules.\n\nIn addition, we provide a matlab standalone version of the compilation of matRad and Ipopt, where the files of matRad and Ipopt are licensed under GPL v3 and EPL v1.0 respectively. The matlab standalone version is meant to be used by students for learning and practicing scientific programming and does not yet contain the interfaces to the aforementioned Monte Carlo dose calculation engines.\n\nmatRad is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n\nPlease note that we treat the compilation of matRad and Ipopt as separate and independent works (or modules, components, programs). Therefore, to the best of our understanding, the compilation of matRad and Ipopt is subject to the \"Mere Aggregation\" exception in section 5 of the GNU v3 and the exemption from \"Contributions\" in section 1. b) ii) of the EPL v1.0. Should this interpretation turn out to be not in compliance with the applicable laws in force, we have provided you with an additional permission under GNU GPL version 3 section 7 to allow you to use the work resulting from combining matRad with Ipopt.\n\nYou will receive a copy of the GPL v3  and a copy of the EPL v1.0 in the file LICENSE.md along with the compilation. If not, see http://www.gnu.org/licenses/ and/or http://opensource.org/licenses/EPL-1.0/.\n\n---\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mcodac",
            "repo_link": "https://gitlab.com/dlr-sy/mcodac",
            "readme": "[![PyPi](https://img.shields.io/static/v1?label=PyPi&message=1.2.0&color=informational&logo=pypi)](https://pypi.org/project/mcodac/)\n[![doi](https://img.shields.io/badge/DOI-10.5281%2Fzenodo.13383097-red.svg)](https://zenodo.org/records/13383097)\n[![pipeline status](https://gitlab.com/dlr-sy/mcodac/badges/mcd_development/pipeline.svg)]()\n\n# MCODAC\nMCODAC (Modular COmposite Damage Analysis Code) is a Fortran library for the evaluation of pristine and damaged composite structures. \nIn addition to basic mathematical tools for tensor manipulation, it contains multidimensional interpolation methods, numerical optimization routines and common utility algorithms used in continuum mechanics. \nFurthermore, the library contains analysis methods specifically tailored to composites, from micromechanical homogenization approaches to macroscopic fatigue models of orthotropic multilayer composites. \nThis project is compiled for Python using [f2py](https://numpy.org/doc/stable/f2py).\n> Installation from source requires an active Fortran compiler (ifort, gfortran). \n## Downloading\nUse GIT to get the latest code base. From the command line, use\n```\ngit clone https://gitlab.com/dlr-sy/mcodac mcodac\n```\nIf you check out the repository for the first time, you have to initialize all submodule dependencies first. Execute the following from within the repository. \n```\ngit submodule update --init --recursive\n```\nTo update all refererenced submodules to the latest production level, use\n```\ngit submodule foreach --recursive 'git pull origin $(git config -f $toplevel/.gitmodules submodule.$name.branch || echo master)'\n```\n## Installation\nMCODAC can be installed from source using [poetry](https://python-poetry.org). If you don't have [poetry](https://python-poetry.org) installed, run\n```\npip install poetry --pre --upgrade\n```\nto install the latest version of [poetry](https://python-poetry.org) within your python environment. Use\n```\npoetry update\n```\nto update all dependencies in the lock file or directly execute\n```\npoetry install\n```\nto install all dependencies from the lock file. Last, you should be able to import MCODAC as a python package.\n```python\nimport mcodac\n```\n## Example\nPlease refer to the linked [repository](https://gitlab.com/dlr-sy/mcodac) for specific application examples.\n## Contact\n* [Marc Garbade](mailto:marc.garbade@dlr.de)\n## Support\n* [List of Contributors](CONTRIBUTING.md)",
            "project_id": "61021603"
        },
        {
            "software_organization": "https://helmholtz.software/software/me-compute",
            "repo_link": "https://github.com/rizac/me-compute",
            "readme": "# <img align=\"left\" height=\"30\" src=\"https://www.gfz-potsdam.de/fileadmin/gfz/medien_kommunikation/Infothek/Mediathek/Bilder/GFZ/GFZ_Logo/GFZ-Logo_eng_RGB.svg\"> Me-compute <img align=\"right\" height=\"50\" src=\"https://www.gfz-potsdam.de/fileadmin/gfz/GFZ_Wortmarke_SVG_klein_en_edit.svg\">\n\n|Jump to: | [Installation](#installation) | [Usage](#usage) | [Citation](#citation) |\n| - | - | - | - |\n\n\n\nProgram to compute energy Magnitude (Me) from downloaded seismic events. \n\nThe download is performed via [stream2segment](https://github.com/rizac/stream2segment)\n(included in this package) into a custom SQLite or Postgres database (in this case, \nthe database has to be setup beforehand).\n\nOnce downloaded, events and data within a customizable time window can be \nfetched from the database in order to compute each event Me (Me = mean \nof all stations energy magnitudes in the 5th-95th percentiles). The computed Me are available\nin several formats: CSV, HDF, HTML and QuakeMl (see Usage below for details).\n\nThe download + processing routines can be chained and scheduled on a server to compute\nthe energy magnitude in semi-realtime (e.g. daily or weekly. See instructions below)\n\n\n## Installation\nMake virtualenv `python3 -m venv [PYPATH]` and activate it:\n`source [PYPATH]/bin/activate`. \n\n**Remember that any command of the program must be done with the virtual env activated**\n\nUpdate required packages for installing Python stuff:\n```console\npip install --upgrade pip setuptools\n```\n\nInstall the program: From the directory where you cloned `mecompute`: \n\n1. [Optional] If you want to be safer and install **exactly** the dependencies \n   with the tested versions, and you don't have conflicts with \n   existing dependencies (e.g., your virtualenv is empty and not supposed to \n   have other packages installed), \n   then you can run: `pip install -r ./requirements.txt` or \n   `pip install -r ./requirements.dev.txt` (the latter if you want to run tests)\n \n2. Install the program:\n   ```bash\n   pip install .\n   ```\n   or (if you want to run tests):\n   ```bash\n   pip install \".[dev]\"\n   ```\n   (add the `-e` option if you want to install in [editable mode](https://stackoverflow.com/a/35064498))\n   **The installation creates a new terminal command `me-compute` within your virtualenv,\n   that you can inspect via**: \n   ```bash\n   me-compute --help\n   ```\n\n## Usage\n\nFirst of all, you should configure your download routine. The repository contains \na `config` directory (git-ignored), with several configuration files that you can copy and modify.\nMost of them are for experienced users and are already filled with default values: \nthe only routine that has to be customized is the download routine\n(file `download.yaml`, see below)\n\n\n### Events and data Download:\n\nThe download routine downloads data and metadata from the configured FDSN\nevent and dataselect web services into a custom database (Sqlite or Postgres using\n[stream2segment](https://github.com/rizac/stream2segment). With Postgres,\nthe db has to be setup beforehand) . Open `download.yaml`\n(or a copy of it) and configure `dburl` (ideally, you might want to setup also\n`start`, `end`, `events_url` and `data_url`). Then run stream2segment with the `s2s`\ncommand:\n\n```commandline\ns2s download -c download.yaml\n```\n\n\n### Me computation\n\nTo compute the energy magnitude of the events saved on the db, you run the\n`me-compute` command with customized options, e.g.:\n\n```bash\nme-compute -s [START] -e [END] -d download.yaml ... [OUTPUT_DIR]\n```\n\n\nSTART and END are the start and end time of the \nevents to consider, in ISO format (e.g. \"2016-03-31\"). If omitted, they will be\ninferred (Type `me-compute --help` for more details)\n\nOUTPUT_DIR is the destination directory. You can use the special characters \n`%S%` and `%E%` that will be replaced with the start and end time strings (see above). \nThe output directory and its parents will be created if they do not exist. \n\nIn the output directory, the following files will be saved:\n\n- **station-energy-magnitude.hdf** A tabular file where each row represents a\n  station(^) and each column the station computed data and metadata,\n  including the station energy magnitude.\n  \n  (^) Note: technically speaking, a single HDF row represents a waveform. \n  We talk about station because by default we download a single channel \n  per station (the vertical component `BHZ`, see `download.yaml` \n  for details)\n  \n\n- **energy-magnitude.csv** A tabular file where each row represents a seismic \n  event, aggregating the result of the previous file into the final event energy \n  magnitude. The event Me is the mean of all station energy magnitudes within \n  the 5-95 percentiles. Empty or non-numeric Me values indicate that the energy \n  magnitude could not be computed or resulted in invalid values (NaN, null, \n  +-inf)\n\n\n- **energy-magnitude.html** A report that can be opened in the user browser to\n  visualize the computed energy magnitudes on maps and HTML tables\n\n\n- **[eventid1].xml, ..., [eventid1].xml** All processed events saved in QuakeML\n  format, updated with the information of their energy magnitude. Only events \n  with valid Me will be saved\n\n\n- **energy-magnitude.log** the log file where the info, errors and warnings\n  of the routine are stored. The core energy magnitude computation at station\n  level (performed via `stream2segment` utilities) has a separated and more\n  detailed log file (see below)\n\n\n- **station-energy-magnitude.log** the log file where the info, errors and \n  warnings of the station energy magnitude computation have been stored\n\n\n### Cron job (schedule downloads+ Me computation)\n\nAssuming your Python virtualenv is at `[VEN_PATH]`, with your python \nvirtualenv activated (`source [VENV_PATH]/bin/activate`),\ntype `which me-compute`. You should see something like\n`[VENV_PATH]/bin/me-compute` (same for `which s2s`). \n\nWith the paths above, you can set up cron jobs to schedule all above routines.  \nFor instance, below an example file that can be edited via\n`crontab -e` (https://linux.die.net/man/1/crontab):\n\nIt downloads every day shortly after midnight (00:05) events and data of the \nprevious day (the download time window must be configured in \nthe download.yaml file). Afterwards, it computes the energy magnitude at 5:00 AM\n(5 hours are a more than sufficient time to complete the download of all data):\n\n```bash \n# For more information see the manual pages of crontab(5) and cron(8)\n# \n# m h  dom mon dow   command\n5 0 * * * [VENV_PATH]/bin/python [VENV_PATH]/bin/s2s download -c /home/download.private.yaml\n0 5 * * * [VENV_PATH]/bin/python [VENV_PATH]/bin/me-compute -d [DOWNLOAD_YAML] -s [START] -e [END] \"[ROOT_DIR]/me-result_%S%_%E%\"\n```\n\n\n### Misc\n\n#### Run tests and generate test data\n\nRun: \n```commandline\npytest ./me-compute/test\n```\n\nNote that there is only one test routine generating files in a `test/tmp` directory\n(git-ignored). The directory is **not** deleted automatically in order to leave \ndevelopers the ability to perform an additional visual test on the generated output \n(e.g. HTML report)\n\n\n## Citation\n\n> Zaccarelli, Riccardo (2023): me-compute: a Python software to download events and data from FDSN web services and compute their energy magnitude (Me). GFZ Data Services. https://doi.org/10.5880/GFZ.2.6.2023.008\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mitk",
            "repo_link": "https://github.com/MITK/MITK",
            "readme": "![MITK Logo][logo]\n\nThe [Medical Imaging Interaction Toolkit][mitk] (MITK) is a free open-source software\nsystem for development of interactive medical image processing software. MITK\ncombines the [Insight Toolkit][itk] (ITK) and the [Visualization Toolkit][vtk] (VTK) with an application framework.\n\nThe links below provide high-level and reference documentation targeting different\nusage scenarios:\n\n - Get a [high-level overview][mitk-overview] about MITK with pointers to further\n   documentation\n - End-users looking for help with MITK applications should read the\n   [MITK User Manual][mitk-usermanual]\n - Developers contributing to or using MITK, please see the [MITK Developer Manual][mitk-devmanual]\n   as well as the [MITK API Reference][mitk-apiref]\n\nSee the [MITK homepage][mitk] for details.\n\nSupported platforms\n-------------------\n\nMITK is a cross-platform C++ toolkit and officially supports:\n\n - Windows\n - Linux\n - macOS\n\nFor details, please read the [Supported Platforms][platforms] page.\n\nLicense\n-------\n\nCopyright (c) [German Cancer Research Center (DKFZ)][dkfz]. All rights reserved.\n\nMITK is available as free open-source software under a [3-clause BSD license][license].\n\nDownload\n--------\n\nThe *MitkWorkbench* application and a bunch of command-line apps are released twice per year on our [Download][download] page and the [GitHub Releases][releases] page.\n\nThe official MITK source code is available in the [MITK Git repository][git_repo]. The Git clone command is\n\n    git clone https://github.com/MITK/MITK.git\n\nActive development takes place in the MITK develop branch and its usage is advised for advanced users only.\n\nHow to contribute\n-----------------\n\nContributions are encouraged. To make the contribution process as smooth as possible, please read [Contributing to MITK][contribute] before.\n\nBuild instructions\n------------------\n\nMITK uses [CMake][cmake] to configure a build tree. The following is a crash course about cloning, configuring, and building MITK with Ninja on Linux or macOS when all [prerequisites][prerequisites] are met:\n\n    git clone https://github.com/MITK/MITK.git\n    mkdir MITK-superbuild\n    cmake -S MITK -B MITK-superbuild -G \"Ninja\" -D CMAKE_BUILD_TYPE=Release\n    cmake --build MITK-superbuild\n\nOn Windows, configuring and building with Visual Studio/MSBuild would look something like this:\n\n    cmake -S MITK -B MITK-superbuild -G \"Visual Studio 17 2022\"\n    cmake --build MITK-superbuild --config Release -- -m\n\nRead the comprehensive [build instructions][build] page for details.\n\nUseful links\n------------\n\n - [Homepage][mitk]\n - [Download][download]\n - [Create an issue/ask for help][issues]\n\n[logo]: https://github.com/MITK/MITK/raw/master/mitk.png\n[mitk]: https://www.mitk.org\n[itk]: https://itk.org\n[vtk]: https://vtk.org\n[mitk-overview]: https://docs.mitk.org/2024.12/\n[mitk-usermanual]: https://docs.mitk.org/2024.12/UserManualPortal.html\n[mitk-devmanual]: https://docs.mitk.org/2024.12/DeveloperManualPortal.html\n[mitk-apiref]: https://docs.mitk.org/2024.12/usergroup0.html\n[platforms]: https://docs.mitk.org/2024.12/SupportedPlatformsPage.html\n[prerequisites]: https://docs.mitk.org/2024.12/BuildInstructionsPage.html#BuildInstructions_Prerequisites\n[build]: https://docs.mitk.org/2024.12/BuildInstructionsPage.html\n[dkfz]: https://www.dkfz.de\n[license]: https://github.com/MITK/MITK/blob/master/LICENSE\n[download]: https://www.mitk.org/Download\n[releases]: https://github.com/MITK/MITK/releases\n[git_repo]: https://github.com/MITK/MITK\n[contribute]: https://github.com/MITK/MITK/blob/master/CONTRIBUTING.md\n[cmake]: https://www.cmake.org\n[issues]: https://github.com/MITK/MITK/issues\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/membrain-v2",
            "repo_link": "https://github.com/teamtomo/membrain-seg",
            "readme": "# MemBrain-Seg\n\n[![License](https://img.shields.io/pypi/l/membrain-seg.svg?color=green)](https://github.com/teamtomo/membrain-seg/raw/main/LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/membrain-seg.svg?color=green)](https://pypi.org/project/membrain-seg)\n[![Python Version](https://img.shields.io/pypi/pyversions/membrain-seg.svg?color=green)](https://python.org)\n[![CI](https://github.com/teamtomo/membrain-seg/actions/workflows/ci.yml/badge.svg)](https://github.com/teamtomo/membrain-seg/actions/workflows/ci.yml)\n[![codecov](https://codecov.io/gh/teamtomo/membrain-seg/branch/main/graph/badge.svg)](https://codecov.io/gh/teamtomo/membrain-seg)\n\n\nMembrain-Seg<sup>1</sup> is a Python project developed by [teamtomo](https://github.com/teamtomo) for membrane segmentation in 3D for cryo-electron tomography (cryo-ET). This tool aims to provide researchers with an efficient and reliable method for segmenting membranes in 3D microscopic images. Membrain-Seg is currently under early development, so we may make breaking changes between releases.\n\n## Publication: \nMembrain-seg's current functionalities are described on more detail in our [preprint](https://www.biorxiv.org/content/10.1101/2024.01.05.574336v1).\n\n\n<p align=\"center\" width=\"100%\">\n    <img width=\"100%\" src=\"https://user-images.githubusercontent.com/34575029/248259282-ee622267-77fa-4c88-ad38-ad0cfd76b810.png\">\n</p>\n\nMembrain-Seg is currently under early development, so we may make breaking changes between releases.\n\n# Version Updates\nFor a detailed history of changes and updates, please refer to our [CHANGELOG.md](./CHANGELOG.md).\n\n\n# Overview\nMemBrain-seg is a practical tool for membrane segmentation in cryo-electron tomograms. It's built on the U-Net architecture and makes use of a pre-trained model for efficient performance.\nThe U-Net architecture and training parameters are largely inspired by nnUNet<sup>2</sup>.\n\n\nOur current best model is available for download [here](https://drive.google.com/file/d/1tSQIz_UCsQZNfyHg0RxD-4meFgolszo8/view?usp=sharing). Please let us know how it works for you.\nIf the given model does not work properly, you may want to try one of our previous versions:\n\nOther (older) model versions:\n- [v9 -- best model until 10th Aug 2023](https://drive.google.com/file/d/15ZL5Ao7EnPwMHa8yq5CIkanuNyENrDeK/view?usp=sharing)\n- [v9b -- model for non-denoised data until 10th Aug 2023](https://drive.google.com/file/d/1TGpQ1WyLHgXQIdZ8w4KFZo_Kkoj0vIt7/view?usp=sharing)\n\nIf you wish, you can also train a new model using your own data, or combine it with our (soon to come!) publicly-available dataset. \n\nTo enhance segmentation, MemBrain-seg includes preprocessing functions. These help to adjust your tomograms so they're similar to the data our network was trained on, making the process smoother and more efficient.\n\nExplore MemBrain-seg, use it for your needs, and let us know how it works for you!\n\n\nPreliminary [documentation](https://teamtomo.github.io/membrain-seg/) is available, but far from perfect. Please let us know if you encounter any issues, and we are more than happy to help (and get feedback what does not work yet).\n\n```\n[1] Lamm, L., Zufferey, S., Righetto, R.D., Wietrzynski, W., Yamauchi, K.A., Burt, A., Liu, Y., Zhang, H., Martinez-Sanchez, A., Ziegler, S., Isensee, F., Schnabel, J.A., Engel, B.D., and Peng, T, 2024. MemBrain v2: an end-to-end tool for the analysis of membranes in cryo-electron tomography. bioRxiv, https://doi.org/10.1101/2024.01.05.574336\n\n[2] Isensee, F., Jaeger, P.F., Kohl, S.A.A., Petersen, J., Maier-Hein, K.H., 2021. nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature Methods 18, 203-211. https://doi.org/10.1038/s41592-020-01008-z\n```\n\n# Installation\nFor detailed installation instructions, please look [here](https://teamtomo.github.io/membrain-seg/installation/).\n\n# Features\n## Segmentation\nSegmenting the membranes in your tomograms is the main feature of this repository. \nPlease find more detailed instructions [here](https://teamtomo.github.io/membrain-seg/Usage/Segmentation/).\n\n## Preprocessing\nCurrently, we provide the following two [preprocessing](https://github.com/teamtomo/membrain-seg/tree/main/src/membrain_seg/tomo_preprocessing) options:\n- Pixel size matching: Rescale your tomogram to match the training pixel sizes\n- Fourier amplitude matching: Scale Fourier components to match the \"style\" of different tomograms\n- Deconvolution: denoises the tomogram by applying the deconvolution filter from Warp\n\nFor more information, see the [Preprocessing](https://teamtomo.github.io/membrain-seg/Usage/Preprocessing/) subsection.\n\n## Model training\nIt is also possible to use this package to train your own model. Instructions can be found [here](https://teamtomo.github.io/membrain-seg/Usage/Training/).\n\n## Patch annotations\nIn case you would like to train a model that works better for your tomograms, it may be beneficial to add some more patches from your tomograms to the training dataset. \nRecommendations on how to to this can be found [here](https://teamtomo.github.io/membrain-seg/Usage/Annotations/).\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mercy",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/merkle-dag-matlab",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/Merkle-DAG-Matlab",
            "readme": "![MATLAB](https://img.shields.io/badge/MATLAB-%23D00000.svg?style=plastic&logo=mathworks&logoColor=white) ![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/Merkle-DAG-Matlab?style=plastic)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12808889.svg)](https://doi.org/10.5281/zenodo.12808889)\n\n# Merkle-DAG Implementation in MATLAB\n\nThis repository contains MATLAB scripts for implementing and using a Merkle Directed Acyclic Graph (DAG) data structure.\n\nThe Merkle-DAG is a cryptographic data structure used to efficiently verify the integrity and consistency of data blocks.\n\n### About\n\n> [IPFS Link](https://docs.ipfs.tech/concepts/merkle-dag/)\n\n### Overview\n\n- Construct a Merkle-DAG manually or from data blocks.\n- Traverse the graph structure and verify the integrity of data blocks.\n- Multiple hash algorithms for computing node hashes.\n   \n    Supported algorithms from Java Security (via MATLAB)  \n    ```matlab\n    import java.security.MessageDigest;\n    java.security.Security.getAlgorithms('MessageDigest')\n    ```\n\n### Scripts\n\n1. `MerkleDAGNode.m`\n\n   > Represents a node in the Merkle-DAG, holds data, compute hashes, and manage child nodes.\n\n2. `MerkleDAG.m`\n\n   > Constructs the Merkle-DAG from data blocks, performs integrity verification, and provides traversal methods (DFS & BFS).\n\n### Example Usages\n\n#### Manually Create the Merkle-DAG (Adding Nodes)\n\nUse case: for scenarios where the DAG structure is not strictly determined by the data itself (no specific relationships/dependencies).\n\n```matlab\nnode1 = MerkleDAGNode([1 2 3]);     % default: SHA-256, if no hash algorithm specified\nnode2 = MerkleDAGNode([4 5 6]);\nnode3 = MerkleDAGNode([7 8 9]);\n\n% Add children to node1 (hash recursively updated)\nnode1.addChild(node2);\nnode1.addChild(node3);\n\n% Add another child to node2    (hash recursively updated)\nnode4 = MerkleDAGNode([10 11 12]);\nnode2.addChild(node4);\n\n% Display the Merkle-DAG structure\nDAGGraph = MerkleDAG();\nDAGGraph.setRoot(node1)\nDAGGraph.traverseDFS();     % Depth-First (DFS) traversal\nDAGGraph.traverseBFS();     % Breadth-First (BFS) traversal\n\n```\n\n#### Build DAG from data blocks\n\nUse case: automated, allowing constructing a Merkle-DAG from a matrix of data blocks.\n\nEach row of the matrix represents a data block. The DAG is built by hashing these blocks into the graph. \nFor scenarios where the relationships between data blocks are determined by their positions in the matrix.\n\n```matlab\ndataBlocks = [      // compose data of the MerkleDAG as a matrix\n    1 2 3;\n    4 5 6;\n    7 8 9;\n    10 11 12;\n    13 14 15\n];\n\nmerkleDAG = MerkleDAG(dataBlocks, 'SHA-384');\n\n% Display the Merkle-DAG structure\nmerkleDAG.traverseDFS();     % Depth-First (DFS) traversal\nmerkleDAG.traverseBFS();     % Breadth-First (BFS) traversal\n```\n\n#### Integrity Verification\n\nThe verifyBlock method checks whether a specific data block is part of the Merkle-DAG. \nComputes the hash of the data block and verifies it against the hashes in the DAG.\n\n```matlab\n% Verify a specific data block \ndataBlockToVerify = [4 5 6];\nmerkleDAG.verifyBlock(dataBlockToVerify);\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/meshit",
            "repo_link": "https://github.com/bloech/MeshIt",
            "readme": "MeshIt 2010-2020\n================\n\nThe tool MeshIT uses TRIANGLE <http://www.cs.cmu.edu/~quake/triangle.html> and\nTETGEN <http://wias-berlin.de/software/tetgen> to generate a quality\ntetrahedral mesh based on structural geological information.\n\nThis procedure is fully automatized and needs at least scattered data points\nas input!\n\nMain developers: Mauro Cacace (<mailto:cacace@gfz-potsdam.de>) and\n                 Guido Blöcher (<mailto:bloech@gfz-potsdam.de>).\n\nSome extensions were added by PERFACCT (www.perfacct.eu) by the following developers:\n\t\t\t\tJohannes Spazier\n\t\t\t\tNihed Boussaidi\n\t\t\t\tDanny Puhan\n\nThe source can be compiled as it comes on Windows, Linux and MacOS by running the building options below.\nFor exporting the exodus file format used by Moose (https://github.com/idaholab/moose) the user has to specify some internal flags in the project file meshit.pro:\n \n*\tFor Linux and Mac we suggest to link the static exodus library which comes along with libMesh (https://libmesh.github.io/) provided by Moose framework installation:\n\t*\tSet the EXODUS_LIBMESH variable to `true`\n\t*\tDefine the path to the root directory of the `libmesh` installation using variable LIBMESH\n\n*\tFor Windows you have to link the dynamic exodus library which will be provided by the package mingw-w64-ucrt-x86_64-libexodus provided by the MSYS2 (https://www.msys2.org/) installation:\n\t*\tSet the EXODUS_LIBRARY variable to `true`\n\t*\tDefine the path the rootdirectory of 'exodusII' installation\n\t\nOn all platforms the following requirements are suggested and tested:\n\nWindows:\n\n    Qt 5.15.2 for Windows 64-bit\n\nLinux:\n\n    Qt 5.9.9 for Linux 64-bit\n\nMac:\n\n    Qt 5.14.1 for OS X\n\nPreparations:\n*\tFor Windows users, please follow the following steps for a proper `exodusII` dynamic library installation:\n\t*\tDownload the `msys2-x86_64` installer (https://www.msys2.org/)\n\t*\tRun the installer. Installing MSYS2 requires 64 bit Windows 10 or newer.\n\t*\tEnter your desired Installation Folder (short ASCII-only path on a NTFS volume, no accents, no spaces, no symlinks, no subst or network drives, no FAT).\n\t*\tWhen done, click Finish.\n\t*\tNow MSYS2 is ready for you and a terminal for the UCRT64 environment will launch.\n\t*\tInstall `mingw-w64-ucrt-x86_64-libexodus`. Run the following command:\n\n\t\t\tpacman -S mingw-w64-ucrt-x86_64-libexodus\n\n\t*\tTo enable the dynamic dependencies of the `exodusII` library add the root folder to your environment variable path:\n\t\t*\tOpen the Start Search, type in `env`, and choose `Edit the system environment variables`.\n\t\t*\tClick the `Environment Variables…` button.\n\t\t*\tUnder the `User Variables` section, find the row with “Path” in the first column, and click edit.\n\t\t*\tThe `Edit environment variable` UI will appear. Here, you can click “New” and type in the new path (default installation path C:\\msys64\\ucrt64) you want to add.\n\t\t*\tDismiss all of the dialogs by choosing “OK”. Your changes are saved!\n\t\t*\tYou will probably need to restart apps for them to pick up the change. Restarting the machine would ensure all apps are run with the PATH change.\n\n*\tFor macOS users, please check the version of macOS specified in the\n\t`meshit.pro` file (line `QMAKE_MACOSX_DEPLOYMENT_TARGET = 10.15`). By default, the version of macOS specified is 10.15 (macOS Catalina)\n\nBuilding:\n\n\tqmake meshit.pro\n\tmake/nmake/mingw32-make\n\nCite:\n*\thttps://doi.org/10.5281/zenodo.4327281\n*\tCacace, M., Blöcher, G. MeshIt - a software for three dimensional volumetric meshing of complex faulted reservoirs. Environ Earth Sci 74, 5191–5209 (2015). https://doi.org/10.1007/s12665-015-4537-x\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/messy",
            "repo_link": "https://gitlab.dkrz.de/MESSy/MESSy",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/metabolator",
            "repo_link": "https://codebase.helmholtz.cloud/metabolator/metabolator",
            "readme": "<!--\nSPDX-FileCopyrightText: 2024 Helmholtz-Zentrum Dresden - Rossendorf (HZDR)\n\nSPDX-License-Identifier: CC-BY-SA-4.0\n-->\n\n# METABOLATOR: Analysis of Microcalorimetric Metabolic Data Using Monod's Equation\n\nCurve fitting automation for metabolic load of bacteria in solutions.\nThe service is deployed at HZDR and available at <https://metabolator.hzdr.de>.\nSee also our software presentation\n[in the Helmholtz Research Software Directory](https://helmholtz.software/software/metabolator).\n\n![Screenshot of the METABOLATOR application](.gitlab/METABOLATOR.png)\n\n## Installation\n\nThis requires [Poetry](https://python-poetry.org/).\n\nInstall the package and its dependencies:\n\n```bash\npoetry install\n```\n\nTo install the development dependencies as well, run:\n\n```bash\npoetry install --with dev\n```\n\n## Usage\n\nEnter the virtual environment by running:\n\n```bash\npoetry shell\n```\n\nWithin Poetry shell, run this project as a Jupyter Notebook:\n\n```bash\njupyter notebook metabolator/METABOLATOR.ipynb\n```\n\nRun with Voilà:\n\n```bash\nvoila metabolator/METABOLATOR.ipynb\n```\n\n## Development\n\nFormat the code (within Poetry shell):\n\n```bash\nruff format .\n```\n\nRun the linter and apply potential fixes (within Poetry shell):\n\n```bash\nruff check --fix .\n```\n\n## Deployment\n\nThe `conf` directory contains an [example service file for systemd](conf/metabolator.service.example)\nas well as an [example nginx configuration](conf/metabolator.example.com).\nWe suggest running the application service as a dedicated user (not root).\nThis can be achieved by enabling lingering for the user with `loginctl`.\nFor more information see the [Voilà documentation](https://voila.readthedocs.io/en/stable/deploy.html#running-voila-on-a-private-server).\n\n## Providing (Example) Datasets\n\nExample dataset files (common spreadsheet formats) can be placed inside the\n`metabolator/static/datasets` directory.\nPlease make sure to place a license file next to the dataset.\nThis can be done with `reuse annotate`\n\nThe app also shows search links for Rodare and Zenodo.\nThese searches will find publications of type dataset on the respective platform that have been\ntagged with the keyword `metabolator`.\n",
            "project_id": "4596"
        },
        {
            "software_organization": "https://helmholtz.software/software/methylkit",
            "repo_link": "https://github.com/al2na/methylKit",
            "readme": "\n\n<a name=\"logo\"/>\n<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/al2na/methylKit/master/inst/methylKit_logo.png\" alt=\"methylKit Logo\"  ></img>\n</a>\n</div>\n\nmethylKit \n========\n\nBuild Status \n\n|  |  | \n| - | - |\n| Github | [![Build Status](https://github.com/al2na/methylKit/actions/workflows/check-standard.yaml/badge.svg)](https://github.com/al2na/methylKit/actions/workflows/check-standard.yaml) |\n| Bioc Release | [![Bioc release status](https://www.bioconductor.org/shields/build/release/bioc/methylKit.svg)](https://bioconductor.org/checkResults/release/bioc-LATEST/methylKit) | \nBioc Devel | [![Bioc devel status](https://www.bioconductor.org/shields/build/devel/bioc/methylKit.svg?text=esfes&)](https://bioconductor.org/checkResults/devel/bioc-LATEST/methylKit) | \n\n\n[![GitHub R package version](https://img.shields.io/github/r-package/v/al2na/methylKit?label=version&)](https://github.com/al2na/methylKit/blob/master/NEWS)\n[![codecov](https://codecov.io/github/al2na/methylKit/branch/master/graphs/badge.svg)](https://codecov.io/github/al2na/methylKit) \n\n# Introduction\n\n*methylKit* is an [R](http://en.wikipedia.org/wiki/R_%28programming_language%29) package \nfor DNA methylation analysis and annotation from high-throughput bisulfite sequencing. The \npackage is designed to deal with sequencing data from \n[RRBS](http://www.nature.com/nprot/journal/v6/n4/abs/nprot.2010.190.html) and its variants,\nbut also target-capture methods such as [Agilent SureSelect \nmethyl-seq](http://www.halogenomics.com/sureselect/methyl-seq). \nIn addition, methylKit can \ndeal with base-pair resolution data for 5hmC obtained from Tab-seq or oxBS-seq. It can also \nhandle whole-genome bisulfite sequencing data if proper input format is provided.\n\n## Current Features\n\n * Coverage statistics\n * Methylation statistics\n * Sample correlation and clustering\n * Differential methylation analysis \n * Feature annotation and accessor/coercion functions \n * Multiple visualization options  \n * Regional and tiling windows analysis\n * (Almost) proper [documentation](https://bioconductor.org/packages/release/bioc/vignettes/methylKit/inst/doc/methylKit.html)\n * Reading methylation calls directly from [Bismark(Bowtie/Bowtie2](http://www.bioinformatics.bbsrc.ac.uk/projects/bismark/) alignment files\n * Batch effect control\n * Multithreading support (for faster differential methylation calculations) \n * Coercion to objects from Bioconductor package GenomicRanges\n * Reading methylation percentage data from generic text files\n\n\n\n\n\n## Staying up-to-date\n\nYou can subscribe to our googlegroups page to get the latest information about new releases and features (low-frequency, only updates are posted)\n\n- https://groups.google.com/forum/#!forum/methylkit\n\nTo ask questions please use methylKit_discussion forum\n\n- https://groups.google.com/forum/#!forum/methylkit_discussion\n\nYou can also check out the blogposts we make on using methylKit\n\n- http://zvfak.blogspot.de/search/label/methylKit\n\n-------\n\n## Installation\n\nin R console,\n```r\nlibrary(devtools)\ninstall_github(\"al2na/methylKit\", build_vignettes=FALSE, \n  repos=BiocManager::repositories(),\n  dependencies=TRUE)\n```\nif this doesn't work, you might need to add `type=\"source\"` argument.\n\n### Install the development version\n```r\nlibrary(devtools)\ninstall_github(\"al2na/methylKit\", build_vignettes=FALSE, \n  repos=BiocManager::repositories(),ref=\"development\",\n  dependencies=TRUE)\n```\nif this doesn't work, you might need to add `type=\"source\"` argument.\n\n\n-------\n\n# How to Use\n\nTypically, bisulfite converted reads are aligned to the genome and % methylation value per base is calculated by processing alignments. *`methylKit`* takes that  % methylation value per base information as input. Such input file may be obtained from [AMP pipeline](http://code.google.com/p/amp-errbs/) for aligning RRBS reads. A typical input file looks like this:\n\n```\nchrBase\tchr\tbase\tstrand\tcoverage\tfreqC\tfreqT\nchr21.9764539\tchr21\t9764539\tR\t12\t25.00\t75.00\nchr21.9764513\tchr21\t9764513\tR\t12\t0.00\t100.00\nchr21.9820622\tchr21\t9820622\tF\t13\t0.00\t100.00\nchr21.9837545\tchr21\t9837545\tF\t11\t0.00\t100.00\nchr21.9849022\tchr21\t9849022\tF\t124\t72.58\t27.42\nchr21.9853326\tchr21\t9853326\tF\t17\t70.59\t29.41\n\n```\n\n\n*`methylKit`* reads in those files and performs basic statistical analysis and annotation for differentially methylated regions/bases. Also a tab separated text file with a generic format can be read in, such as methylation ratio files from [BSMAP](http://code.google.com/p/bsmap/), see [here](http://zvfak.blogspot.com/2012/10/how-to-read-bsmap-methylation-ratio.html) for an example. Alternatively, `read.bismark` function can read SAM file(s) output by [Bismark](http://www.bioinformatics.bbsrc.ac.uk/projects/bismark/)(using bowtie/bowtie2) aligner (the SAM file must be sorted based on chromosome and read start). The sorting must be done by unix sort or samtools, sorting using other tools may change the column order of the SAM file and that will cause an error. \n\nBelow, there are several options showing how to do basic analysis with *`methylKit`*.\n\n## Documentation ##\n * You can look at the vignette [here](https://bioconductor.org/packages/release/bioc/vignettes/methylKit/inst/doc/methylKit.html). This is the primary source of documentation. It includes detailed examples.\n * You can check out the [slides](https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/methylkit/methylKitTutorialSlides_2013.pdf ) for a tutorial at EpiWorkshop 2013. This works with older versions of methylKit, you may need to update the function names.\n * You can check out the [tutorial](https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/methylkit/methylKitTutorial_feb2012.pdf) prepared for  EpiWorkshop 2012. This works with older versions of methylKit, you may need to update the function names.\n* You can check out the [slides](https://www.slideshare.net/AlexanderGosdschan/eurobioc-2018-metyhlkit-overview) prepared for EuroBioc 2018. This also includes more recent features of methylKit  and is meant to give you a quick overview about what you can do with the package. \n\n\n\n\n\n\n## Downloading Annotation Files\nAnnotation files in BED format are needed for annotating your differentially methylated regions. You can download annotation files from UCSC table browser for your genome of interest. Go to  [http://genome.ucsc.edu/cgi-bin/hgGateway]. On the top menu click on \"tools\" then \"table browser\". Select your \"genome\" of interest and \"assembly\" of interest from the drop down menus. Make sure you select the correct genome and assembly. Selecting wrong genome and/or assembly will return unintelligible results in downstream analysis. \n\nFrom here on you can either download *gene annotation* or *CpG island annotation*.\n\n1. For gene annotation, select _\"Genes and Gene prediction tracks\"_ from the *\"group\"* drop-down menu. Following that, select _\"Refseq Genes\"_ from the *\"track\"* drop-down menu. Select _\"BED- browser extensible data\"_ for the *\"output format\"*. Click *\"get output\"* and on the following page click *\"get BED\"* without changing any options. save the output as a text file.\n2. For CpG island annotation, select _\"Regulation\"_ from the *\"group\"* drop-down menu. Following that, select _\"CpG islands\"_ from the *\"track\"* drop-down menu. Select _\"BED- browser extensible data\"_  for the *\"output format\"*. Click *\"get output\"* and on the following page click *\"get BED\"* without changing any options. save the output as a text file.\n\n\nIn addition, you can check this tutorial to learn how to download any track from UCSC in BED format (http://www.openhelix.com/cgi/tutorialInfo.cgi?id=28)\n\n\n\n\n-------\n# R script for Genome Biology publication\nThe most recent version of the R script in the Genome Biology manuscript is [here](http://code.google.com/p/methylkit/downloads/list?q=label:AdditionalFile4 ).\n\n-------\n# Citing methylKit\nIf you used methylKit please cite:\n\n\n * Altuna Akalin, Matthias Kormaksson, Sheng Li, Francine E. Garrett-Bakelman, Maria E. Figueroa, Ari Melnick, Christopher E. Mason. _(2012)_. *\"[methylKit: A comprehensive R package for the analysis of genome-wide DNA methylation profiles.](http://genomebiology.com/2012/13/10/R87/)\"* _Genome Biology_ , 13:R87.\n\nIf you used flat-file objects or over-dispersion corrected tests please consider citing:\n\n* Wreczycka K, Gosdschan A, Yusuf D, Grüning B, Assenov Y, Akalin A. *\"[Strategies for analyzing bisulfite sequencing data.](https://linkinghub.elsevier.com/retrieve/pii/S0168-1656(17)31593-6)\"* J Biotechnol., 2017\n\nand also consider citing the following publication as a use-case with specific cutoffs:\n\n * Altuna Akalin, Francine E. Garrett-Bakelman, Matthias Kormaksson, Jennifer Busuttil, Lu Zhang, Irina Khrebtukova, Thomas A. Milne, Yongsheng Huang, Debabrata Biswas, Jay L. Hess, C. David Allis, Robert G. Roeder, Peter J. M. Valk, Bob Löwenberg, Ruud Delwel, Hugo F. Fernandez, Elisabeth Paietta, Martin S. Tallman, Gary P. Schroth, Christopher E. Mason, Ari Melnick, Maria E. Figueroa. _(2012)_. *\"[Base-Pair Resolution DNA Methylation Sequencing Reveals Profoundly Divergent Epigenetic Landscapes in Acute Myeloid Leukemia.](http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1002781)\"* _PLoS Genetics_ 8(6).\n\n-------\n# Contact & Questions\ne-mail to [methylkit_discussion@googlegroups.com](mailto:methylkit_discussion@googlegroups.com ) or post a question using [the web interface](https://groups.google.com/forum/#!forum/methylkit_discussion).\n\nif you are going to submit bug reports or ask questions, please send sessionInfo() output from R console as well.\n\nQuestions are very welcome, although we suggest you read the paper, documentation(function help pages and the vignette) and [ blog entries](http://zvfak.blogspot.com/search/label/methylKit) first. The answer to your question might be there already.\n\n-------\n# Contribute to the development\nSee the [trello board](https://trello.com/b/k2kv1Od7/methylkit) for methylKit development. You can contribute to the methylKit development via github ([http://github.com/al2na/methylKit/]) by opening an issue and discussing what you want to contribute, we will guide you from there. In addition, you should:\n\n * Bump up the version in the DESCRIPTION file on the 3rd number. For example, the master branch has the version numbering as in \"X.Y.1\". If you make a change to master branch you should bump up the version in the DESCRIPTION file to \"X.Y.2\".\n\n * Add your changes to the NEWS file as well under the correct version and appropriate section. Attribute the changes to yourself, such as \"Contributed by X\"\n \nLicense\n---------\nArtistic License/GPL\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/metrics-reloaded",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/mfdfa",
            "repo_link": "https://github.com/LRydin/MFDFA",
            "readme": "[![DOI:10.1016/j.cpc.2021.108254](http://img.shields.io/badge/DOI-10.1016/j.cpc.2021.108254-00ff00.svg)](https://doi.org/10.1016/j.cpc.2021.108254)\n[![arXiv](https://img.shields.io/badge/arXiv-2104.10470-00ff00.svg)](https://arxiv.org/abs/2104.10470)\n[![zenodo](https://zenodo.org/badge/224135077.svg)](https://zenodo.org/badge/latestdoi/224135077)\n![PyPI - License](https://img.shields.io/pypi/l/MFDFA)\n![PyPI](https://img.shields.io/pypi/v/MFDFA)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/MFDFA)\n[![Build Status](https://github.com/LRydin/MFDFA/actions/workflows/CI.yml/badge.svg)](https://github.com/LRydin/MFDFA/actions/workflows/CI.yml)\n[![codecov](https://codecov.io/gh/LRydin/MFDFA/branch/master/graph/badge.svg)](https://codecov.io/gh/LRydin/MFDFA)\n[![Documentation Status](https://readthedocs.org/projects/mfdfa/badge/?version=latest)](https://mfdfa.readthedocs.io/en/latest/?badge=latest)\n\n\n# MFDFA\nMultifractal Detrended Fluctuation Analysis `MFDFA` is a model-independent method to uncover the self-similarity of a stochastic process or auto-regressive model.\n`DFA` was first developed by Peng *et al.*<sup>1</sup> and later extended to study multifractality `MFDFA` by Kandelhardt *et al.*<sup>2</sup>.\n\nIn the latest release there is as well added a moving window system, especially useful for short timeseries, a recent extension to DFA called *extended DFA*, and the extra feature of Empirical Mode Decomposition as detrending method.\n\n# Installation\nTo install MFDFA you can simply use\n\n```\npip install MFDFA\n```\nAnd on your favourite editor simply import `MFDFA` as\n```python\nfrom MFDFA import MFDFA\n```\nThere is an added library `fgn` to generate fractional Gaussian noise.\n\nYou can find the latest published paper of this library in Computer Physics Communications [L. Rydin Gorjão, G. Hassan, J. Kurths, and D. Witthaut, _MFDFA: Efficient multifractal detrended fluctuation analysis in python_, Computer Physics Communications *273*, 108254 2022](https://doi.org/10.1016/j.cpc.2021.108254). You can find the paper [here](https://github.com/LRydin/MFDFA/blob/master/paper/paper.pdf).\n\n# The `MFDFA` library\n`MFDFA` basis is solely dependent on `numpy`, especially `numpy`'s `polynomial`. In version 0.3 a [Empirical Mode Decomposition](https://en.wikipedia.org/wiki/Hilbert%E2%80%93Huang_transform) method was added for an alternative method of detrending timeseries, relying on [Dawid Laszuk's](https://github.com/laszukdawid/PyEMD) `PyEMD`.\n\n# Employing the `MFDFA` library\n\n## An exemplary one-dimensional fractional Ornstein–Uhlenbeck process\nThe rationale here is simple: Numerically integrate a stochastic process in which we know exactly the fractal properties, characterised by the Hurst coefficient, and recover this with MFDFA.\nWe will use a fractional Ornstein–Uhlenbeck, a commonly employ stochastic process with mean-reverting properties.\nFor a more detailed explanation on how to integrate an Ornstein–Uhlenbeck process, see the [kramersmoyal's package](https://github.com/LRydin/KramersMoyal#a-one-dimensional-stochastic-process).\nYou can also follow the [fOU.ipynb](/examples/fOU.ipynb)\n\n### Generating a fractional Ornstein–Uhlenbeck process\nThis is one method of generating a (fractional) Ornstein–Uhlenbeck process with *H=0.7*, employing a simple Euler–Maruyama integration method\n\n```python\n# Imports\nfrom MFDFA import MFDFA\nfrom MFDFA import fgn\n# where this second library is to generate fractional Gaussian noises\n\n# integration time and time sampling\nt_final = 2000\ndelta_t = 0.001\n\n# Some drift theta and diffusion sigma parameters\ntheta = 0.3\nsigma = 0.1\n\n# The time array of the trajectory\ntime = np.arange(0, t_final, delta_t)\n\n# The fractional Gaussian noise\nH = 0.7\ndB = (t_final ** H) * fgn(N = time.size, H = H)\n\n# Initialise the array y\ny = np.zeros([time.size])\n\n# Integrate the process\nfor i in range(1, time.size):\n    y[i] = y[i-1] - theta * y[i-1] * delta_t + sigma * dB[i]\n```\nAnd now you have a fractional process with a self-similarity exponent *H=0.7*\n\n### Using the `MFDFA`\nTo now utilise the `MFDFA`, we take this exemplary process and run the (multifractal) detrended fluctuation analysis. For now lets consider only the monofractal case, so we need only `q=2`.\n```python\n# Select a band of lags, which usually ranges from\n# very small segments of data, to very long ones, as\nlag = np.unique(np.logspace(0.5, 3, 100).astype(int))\n# Notice these must be ints, since these will segment\n# the data into chucks of lag size\n\n# Select the power q\nq = 2\n\n# The order of the polynomial fitting\norder = 1\n\n# Obtain the (MF)DFA as\nlag, dfa = MFDFA(y, lag = lag, q = q, order = order)\n```\n\nNow we need to visualise the results, which can be understood in a log-log scale. To find *H* we need to fit a line to the results in the log-log plot\n```python\n# To uncover the Hurst index, lets get some log-log plots\nplt.loglog(lag, dfa, 'o', label='fOU: MFDFA q=2')\n\n# And now we need to fit the line to find the slope. Don't\n# forget that since you are plotting in a double logarithmic\n# scales, you need to fit the logs of the results\nH_hat = np.polyfit(np.log(lag)[4:20],np.log(dfa[4:20]),1)[0]\n\n# Now what you should obtain is: slope = H + 1\nprint('Estimated H = '+'{:.3f}'.format(H_hat[0]))\n```\n\n<img src=\"docs/_static/fig1.png\" title=\"MFDFA of a fractional Ornstein–Uhlenbeck process\" height=\"250\"/>\n\n\n## Uncovering multifractality in stochastic processes\nYou can find more about multifractality in the [documentation](https://mfdfa.readthedocs.io/en/latest/1dLevy.html).\n\n# Changelog\n- Version 0.4.3 - Reverting negative values in the estimation of the singularity strenght α.\n- Version 0.4.2 - Corrected spectral plots. Added [examples](https://github.com/LRydin/MFDFA/tree/master/examples) from the paper.\n- Version 0.4.1 - Added conventional spectral plots as _h(q)_ vs _q_, _τ(q)_ vs _q_, and _f(α)_ vs _α_.\n- Version 0.4 - EMD is now optional. Restored back compatibility: py3.3 to py3.9. For EMD py3.6 or larger is needed.\n- Version 0.3 - Adding EMD detrending. First release. PyPI code.\n- Version 0.2 - Removed experimental features. Added documentation\n- Version 0.1 - Uploaded initial working code\n\n# Contributions\nI welcome reviews and ideas from everyone. If you want to share your ideas or report a bug, open an [issue](https://github.com/LRydin/KramersMoyal/issues) here on GitHub, or contact me directly.\nIf you need help with the code, the theory, or the implementation, do not hesitate to reach out, I am here to help.\nThis package abides to a [Conduct of Fairness](contributions.md).\n\n# Literature and Support\n### Submission history\nThis library has been submitted for publication at [The Journal of Open Source Software](https://joss.theoj.org/) in December 2019. It was rejected. The review process can be found [here on GitHub](https://github.com/openjournals/joss-reviews/issues/1966). The plan is to extend the library and find another publisher.\n\n### History\nThis project was started in 2019 at the [Faculty of Mathematics, University of Oslo](https://www.mn.uio.no/math/english/research/groups/risk-stochastics/) in the Risk and Stochastics section by Leonardo Rydin Gorjão and is supported by Dirk Witthaut and the [Institute of Energy and Climate Research Systems Analysis and Technology Evaluation](https://www.fz-juelich.de/iek/iek-ste/EN/Home/home_node.html). I'm very thankful to all the folk in Section 3 in the Faculty of Mathematics, University of Oslo, for helping me getting around the world of stochastic processes: Dennis, Anton, Michele, Fabian, Marc, Prof. Benth and Prof. di Nunno. In April 2020 Galib Hassan joined in extending `MFDFA`, particularly the implementation of `EMD`.\n\n\n### Funding\nHelmholtz Association Initiative *Energy System 2050 - A Contribution of the Research Field Energy* and the grant No. VH-NG-1025; *STORM - Stochastics for Time-Space Risk Models* project of the Research Council of Norway (RCN) No. 274410, and the *E-ON Stipendienfonds*.\n\n### References\n<sup>1</sup>Peng, C.-K., Buldyrev, S. V., Havlin, S., Simons, M., Stanley, H. E., & Goldberger, A. L. (1994). *Mosaic organization of DNA nucleotides*. [Physical Review E, 49(2), 1685–1689](https://doi.org/10.1103/PhysRevE.49.1685)\\\n<sup>2</sup>Kantelhardt, J. W., Zschiegner, S. A., Koscielny-Bunde, E., Havlin, S., Bunde, A., & Stanley, H. E. (2002). *Multifractal detrended fluctuation analysis of nonstationary time series*. [Physica A: Statistical Mechanics and Its Applications, 316(1-4), 87–114](https://doi.org/10.1016/S0378-4371(02)01383-3)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mhm",
            "repo_link": "https://git.ufz.de/mhm/mhm",
            "readme": "",
            "project_id": "731"
        },
        {
            "software_organization": "https://helmholtz.software/software/mibianto",
            "repo_link": "https://github.com/ccb-sb/mibianto",
            "readme": "# MiBiAnTo: An Online Microbiome Analysis Tool\n\n[Mibianto Webpage](https://www.ccb.uni-saarland.de/mibianto)\n\n## Issues, queries and request\n\nWe have created this GitHub repository to handle communication with users. Please feel free to make use of it to get in touch with questions or remarks regarding the database website or content.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/micromechanics-indentationgui",
            "repo_link": "https://github.com/micromechanics/indentationGUI",
            "readme": "[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.11563149.svg)](https://doi.org/10.5281/zenodo.11563149)\n\n<h2 align = \"center\">\nmicromechanics-indentationGUI\n</h2>\n<p align=\"center\">\n  <img\n  src=\"https://raw.githubusercontent.com/micromechanics/indentationGUI/main/micromechanics_indentationGUI/pic/logo.png\" \n  width=\"314\"\n  title=\"micromechanics-indentationGUI\" >\n</p>\n\n# Install\n- Create a new environment (python >= 3.8) using **anaconda-navigator** (https://www.anaconda.com/). In Anaconda's documentation (https://docs.anaconda.com/free/navigator/) you will learn:\n  - how to **install** anaconda-navigator in the section of \"*Anaconda Navigator* => *Installation*\" (reading takes ~5 min), \n  - how to **create and activate** a new environment in the section of \"*Anaconda Navigator* => *Tutorials* => *How to create a Python 3.5 environment from Anaconda2 or Anaconda3*\" (reading takes ~5 min).\n\n- In the terminal of the environment created by Anaconda Navigator, keyboard type the following command and press Enter\n``` bash\npip install micromechanics-indentationGUI\n```\n# Upgrade\nIn the terminal, keyboard type the following command and press Enter\n``` bash\npip install --upgrade micromechanics-indentationGUI\n```\n# Usage\nUsers need to know:\n- For fast reading using **HDF5** files:\n  - Using the given original file (e.g. the XLSX file for G200X), the HDF5 file will be automatically generated at the first calibration/calculation (or when an HDF5 file with the same name as the XLSX file does not exist).\n  - The automatically generated HDF5 file has the same file name as the original file (e.g. the XLSX file for G200X) except the file extension of \".h5\" and locates in the same folder as the original file.\n  - The original file extension (e.g. '.xlsx' for G200X) should be given in the path instead of the file extension of the HDF5 file (\".h5\").\n  - **[Important]** If you changed the content of the original file, please delete the correspoding HDF5 file.\n\nRunning by keyboard typing the following command and pressing Enter in the terminal\n``` bash\nmicromechanics-indentationGUI\n``` \n# Uninstall\nIn the terminal, keyboard type the following command and press Enter\n``` bash\npip uninstall micromechanics-indentationGUI\n```\n\n# More detailed descriptions for developers\n\n# Prepare and create a new version\n- Delete RecentFiles.txt in /indentationGUI/micromechanics_indentationGUI\n\n- Delete *.hf in /indentationGUI/micromechanics_indentationGUI/Examples\n\n- Set \"# pylint: skip-file\" for all files named \"***_ui.py\"\n\n- Test the code: linting, documentation and then the tests from the project's main directory\n``` bash\npylint micromechanics_indentationGUI/\nmake -C docs html\n# python tests/testVerification.py\n```\n\nThen upload/create-pull-request to GitHub, via\n``` bash\n./commit.py 'my message'\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/millepede-ii",
            "repo_link": "https://gitlab.desy.de/claus.kleinwort/millepede-ii",
            "readme": "# Millepede-II\n\nMillepede II is a package for linear least squares fits with a large number of parameters. Developed for the alignment and calibration of tracking detectors.",
            "project_id": "1683"
        },
        {
            "software_organization": "https://helmholtz.software/software/minterpy",
            "repo_link": "https://github.com/casus/minterpy",
            "readme": "![](./docs/assets/Wordmark-color.png)\n\n[![Code style: black][black-badge]][black-link]\n# minterpy\n\n<figure class=\"quote\">\n  <blockquote>\n  to minterpy *sth.* (transitive verb) -- to produce a multivariate polynomial representation of *sth.* .\n  </blockquote>\n  <figcaption>\n    &mdash; The minterpy developers in <cite>[\"Lifting the curse of dimensionality\"](https://interpol.pages.hzdr.de/minterpy/fundamentals/introduction.html)</cite>\n  </figcaption>\n</figure>\n\n---\n\n`minterpy` is an open-source Python package for a multivariate generalization\nof the classical Newton and Lagrange interpolation schemes as well as related tasks.\nIt is based on an optimized re-implementation of\nthe multivariate interpolation prototype algorithm (*MIP*) by Hecht et al.[^1]\nand thereby provides software solutions that lift the curse of dimensionality from interpolation tasks.\nWhile interpolation occurs as the bottleneck of most computational challenges,\n`minterpy` aims to free empirical sciences from their computational limitations.\n\n`minterpy` is continuously extended and improved\nby adding further functionality and modules that provide novel digital solutions\nto a broad field of computational challenges, including but not limited to:\n\n- multivariate interpolation\n- non-linear polynomial regression\n- numerical integration\n- global (black-box) optimization\n- surface level-set methods\n- non-periodic spectral partial differential equations (PDE) solvers on\n  flat and complex geometries\n- machine learning regularization\n- data reconstruction\n- computational solutions in algebraic geometry\n\n## Installation\n\nSince this implementation is a prototype,\nwe currently only provide the installation by self-building from source.\nWe recommend to using `git` to get the `minterpy` source:\n\n```bash\ngit clone https://gitlab.hzdr.de/interpol/minterpy.git\n```\n\nWithin the source directory,\nyou may use the following package manager to install ``minterpy``.\n\nA best practice is to create a virtual environment for `minterpy`.\nYou can do this with the help of [conda] and the ``environment.yaml`` by:\n\n```bash\nconda env create -f environment.yaml\n```\n\nA new conda environment called `minterpy` is created.\nActivate the new environment by:\n\n```bash\nconda activate minterpy\n```\n\nFrom within the environment, install the `minterpy` using [pip],\n\n```bash\npip install [-e] .[all,dev,docs]\n```\n\nwhere the flag `-e` means the package is directly linked\ninto the python site-packages of your Python version.\nThe options `[all,dev,docs]` refer to the requirements defined\nin the `options.extras_require` section in `setup.cfg`.\n\nYou **must not** use the command `python setup.py install` to install `minterpy`,\nas you cannot always assume the files `setup.py` will always be present\nin the further development of `minterpy`.\n\nFinally, if you want to deactivate the conda environment, type:\n\n```bash\nconda deactivate\n```\n\nAlternative to conda, you can create a new virtual environment via\n[venv], [virtualenv], or [pyenv-virtualenv].\nSee [CONTRIBUTING.md](./CONTRIBUTING.md) for details.\n\n## Quickstart\n\nWith `minterpy` one can easily interpolate a given function.\nFor instance, take the function `f(x) = x\\sin(10x)` in one dimension:\n\n```python\n    import numpy as np\n\n    def test_function(x):\n        return x * np.sin(10*x)\n```\n\nIn order to `minterpy` the function `test_function`\none can use the top-level function `interpolate`:\n\n```python\n    import minterpy as mp\n\n    interpolant = mp.interpolate(test_function,spatial_dimension=1, poly_degree=64)\n```\n\nHere, interpolant is a callable function,\nwhich can be used as a representation of `test_function`.\n`interpolate` takes as arguments the function to interpolate,\nthe number of dimensions (`spatial_dimension`),\nand the degree of the underlying polynomial (`poly_degree`).\n\nYou may adjust this parameter in order to get higher accuracy.\nFor the example above, a degree of 64 produces an interpolant that reproduces\nthe `test_function` almost up to machine precision:\n\n```python\n    import matplotlib.pylab as plt\n\n    x = np.linspace(-1,1,100)\n\n    plt.plot(x,interpolant(x),label=\"interpolant\")\n    plt.plot(x,test_function(x),\"k.\",label=\"test function\")\n    plt.legend()\n    plt.show()\n```\n<img src=\"./docs/assets/images/test-function1D.png\" alt=\"Compare test function with its interpolant\" width=\"400\"/>\n\n\nFor more comprehensive examples, see the [getting started guides](https://interpol.pages.hzdr.de/minterpy/getting-started/index.html)\nsection of the ``minterpy`` docs.\n\n## Testing\n\nAfter installation, we encourage you to at least run the unit tests of `minterpy`,\nwhere we use [`pytest`](https://docs.pytest.org/en/6.2.x/) to run the tests.\n\nIf you want to run all tests, type:\n\n```bash\npytest [-vvv]\n```\n\nfrom within the `minterpy` source directory.\n\n## Contributing to `minterpy`\n\nContributions to the `minterpy` packages are highly welcome.\nWe recommend you have a look at the [CONTRIBUTING.md](./CONTRIBUTING.md) first.\nFor a more comprehensive contribution guide visit\nthe [Contributors section](link-to-developer-section) of the documentation.\n\n## Credits and contributors\n\nThis work was partly funded by the Center for Advanced Systems Understanding (CASUS)\nthat is financed by Germany’s Federal Ministry of Education and Research (BMBF)\nand by the Saxony Ministry for Science, Culture and Tourism (SMWK)\nwith tax funds on the basis of the budget approved by the Saxony State Parliament.\n\n### The minterpy development team\n\nThe core development of the `minterpy` is currently done\nby a small team at the Center for Advanced Systems Understanding ([CASUS]),\nnamely\n\n- Uwe Hernandez Acosta ([HZDR]/[CASUS]) (u.hernandez@hzdr.de)\n- Sachin Krishnan Thekke Veettil ([HZDR]/[CASUS]) (s.thekke-veettil@hzdr.de)\n- Damar Wicaksono ([HZDR]/[CASUS]) (d.wicaksono@hzdr.de)\n- Janina Schreiber ([HZDR]/[CASUS]) (j.schreiber@hzdr.de)\n\n### Mathematical foundation\n\n- Michael Hecht ([HZDR]/[CASUS]) (m.hecht@hzdr.de)\n\n### Former Members and Contributions\n\n- Jannik Michelfeit\n- Nico Hoffman ([HZDR])\n- Steve Schmerler ([HZDR])\n- Vidya Chandrashekar (TU Dresden)\n\n### Acknowledgement\n\n- Klaus Steiniger ([HZDR])\n- Patrick Stiller ([HZDR])\n- Matthias Werner ([HZDR])\n- Krzysztof Gonciarz ([MPI-CBG],[CSBD])\n- Attila Cangi ([HZDR]/[CASUS])\n- Michael Bussmann ([HZDR]/[CASUS])\n\n### Community\n\nThis package would not be possible without many contributions done\nfrom the community as well.\nFor that, we want to send big thanks to:\n\n  - the guy who will show me how to include a list of contributors on github/gitlab\n\n\n## License\n\n[MIT](LICENSE) © minterpy development team\n\n[^1]: [arXiv:2010.10824](https://arxiv.org/abs/2010.10824)\n\n[conda]: https://docs.conda.io/\n[pip]: https://pip.pypa.io/en/stable/\n[venv]: https://docs.python.org/3/tutorial/venv.html\n[virtualenv]: https://virtualenv.pypa.io/en/latest/\n[pyenv-virtualenv]: https://github.com/pyenv/pyenv-virtualenv\n[pre-commit]: https://pre-commit.com/\n[Jupyter]: https://jupyter.org/\n[nbstripout]: https://github.com/kynan/nbstripout\n[Google style]: http://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings\n[virtualenv]: https://virtualenv.pypa.io/en/latest/index.html\n[pytest]: https://docs.pytest.org/en/6.2.x/\n[CASUS]: https://www.casus.science\n[HZDR]: https://www.hzdr.de\n[MPI-CBG]: https://www.mpi-cbg.de\n[CSBD]: https://www.csbdresden.de\n\n\n\n[black-badge]:              https://img.shields.io/badge/code%20style-black-000000.svg\n[black-link]:               https://github.com/psf/black\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mirp",
            "repo_link": "https://github.com/oncoray/mirp",
            "readme": "<img src=\"https://raw.githubusercontent.com/oncoray/mirp/master/icon/mirp.svg\" align=\"right\" width=\"120\"/>\r\n\r\n![GitHub License](https://img.shields.io/github/license/oncoray/mirp)\r\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mirp)\r\n[![PyPI - Version](https://img.shields.io/pypi/v/mirp)](https://pypi.org/project/mirp/)\r\n![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/oncoray/mirp/auto-test-dependencies_timed.yml)\r\n[![JOSS](https://joss.theoj.org/papers/165c85b1ecad891550a21b12c8b2e577/status.svg)](https://joss.theoj.org/papers/165c85b1ecad891550a21b12c8b2e577)\r\n\r\n# Medical Image Radiomics Processor\r\n\r\nMIRP is a python package for quantitative analysis of medical images. It focuses on processing images for integration\r\nwith radiomics workflows. These workflows either use quantitative features computed using MIRP, or directly use MIRP\r\nto process images as input for neural networks and other deep learning models.\r\n\r\nMIRP offers the following main functionality:\r\n\r\n- [Extract and collect metadata](https://oncoray.github.io/mirp/image_metadata.html) from medical images.\r\n- [Find and collect labels or names](https://oncoray.github.io/mirp/mask_labels.html) of regions of interest from image \r\n  segmentations.\r\n- [Compute quantitative features](https://oncoray.github.io/mirp/quantitative_image_analysis.html) from regions of interest in medical images.\r\n- [Process images for deep learning](https://oncoray.github.io/mirp/deep_learning.html).\r\n\r\n## Tutorials\r\n\r\nWe currently offer the following tutorials:\r\n\r\n- [Computing quantitative features from MR images](https://oncoray.github.io/mirp/tutorial_compute_radiomics_features_mr.html)\r\n- [Applying filters to images](https://oncoray.github.io/mirp/tutorial_apply_image_filter.html)\r\n\r\n## Documentation\r\n\r\nDocumentation can be found here: https://oncoray.github.io/mirp/\r\n\r\n## Supported Python and OS\r\n\r\nMIRP currently supports the following Python versions and operating systems: \r\n\r\n| Python | Linux     | Win       | OSX       |\r\n|--------|-----------|-----------|-----------|\r\n| 3.10   | Supported | Supported | Supported |\r\n| 3.11   | Supported | Supported | Supported |\r\n| 3.12   | Supported | Supported | Supported |\r\n\r\n## Supported imaging and mask modalities\r\n\r\nMIRP currently supports the following image modalities:\r\n\r\n| File format | File type | Supported modality                              |\r\n|-------------|-----------|-------------------------------------------------|\r\n| DICOM       | image     | CT, MR (incl. ADC, DCE), PT, RTDOSE, CR, DX, MG |\r\n| DICOM       | mask      | RTSTRUCT, SEG                                   |\r\n| NIfTI       | any       | any                                             |\r\n| NRRD        | any       | any                                             |\r\n| numpy       | any       | any                                             |\r\n\r\nNIfTI, NRRD, and numpy files support any kind of (single-channel) image. MIRP cannot process RGB or 4D images.\r\n\r\n## Installing MIRP\r\nMIRP is available from PyPI and can be installed using `pip`, or other installer tools:\r\n\r\n```commandline\r\npip install mirp\r\n```\r\n\r\n## Examples - Computing Radiomics Features\r\n\r\nMIRP can be used to compute quantitative features from regions of interest in images in an IBSI-compliant manner \r\nusing a standardized workflow This requires both images and masks. MIRP can process DICOM, NIfTI, NRRD and numpy \r\nimages. Masks are DICOM radiotherapy structure sets (RTSTRUCT), DICOM segmentation (SEG) or volumetric data with \r\ninteger labels (e.g. 1, 2, etc.).\r\n\r\nBelow is a minimal working example for extracting features from a single image file and its mask.\r\n\r\n```python\r\nfrom mirp import extract_features\r\n\r\nfeature_data = extract_features(\r\n    image=\"path to image\",\r\n    mask=\"path to mask\",\r\n    base_discretisation_method=\"fixed_bin_number\",\r\n    base_discretisation_n_bins=32\r\n)\r\n```\r\nInstead of providing the path to the image (`\"path_to_image\"`), a numpy image can be provided, and the same goes for \r\n`\"path to mask\"`. The disadvantage of doing so is that voxel spacing cannot be determined. \r\n\r\nMIRP also supports processing images and masks for multiple samples (e.g., patients). The syntax is much the same, \r\nbut depending on the file type and directory structure, additional arguments need to be specified. For example, \r\nassume that files are organised in subfolders for each sample, i.e. `main_folder / sample_name / subfolder`. The \r\nminimal working example is then:\r\n\r\n```python\r\nfrom mirp import extract_features\r\n\r\nfeature_data = extract_features(\r\n    image=\"path to main image directory\",\r\n    mask=\"path to main mask directory\",\r\n    image_sub_folder=\"image subdirectory structure relative to main image directory\",\r\n    mask_sub_folder=\"mask subdirectory structure relative to main mask directory\",\r\n    base_discretisation_method=\"fixed_bin_number\",\r\n    base_discretisation_n_bins=32\r\n)\r\n```\r\nThe above example will compute features sequentially. MIRP supports parallel processing using the `ray` package. \r\nFeature computation can be parallelized by specifying the `num_cpus` argument, e.g. `num_cpus=2` for two CPU threads.\r\n\r\n## Examples - Image Preprocessing for Deep Learning\r\nDeep learning-based radiomics is an alternative to using predefined quantitative features. MIRP supports \r\npreprocessing of images and masks using the same standardized workflow that is used for computing features.\r\n\r\nBelow is a minimal working example for preprocessing deep learning images. Note that MIRP uses the numpy notation \r\nfor indexing, i.e. indices are ordered [*z*, *y*, *x*].\r\n\r\n```python\r\nfrom mirp import deep_learning_preprocessing\r\n\r\nprocessed_images = deep_learning_preprocessing(\r\n    image=\"path to image\",\r\n    mask=\"path to mask\",\r\n    crop_size=[50, 224, 224]\r\n)\r\n```\r\n\r\n## Examples - Summarising Image Metadata\r\n\r\nMIRP can also summarise image metadata. This is particularly relevant for DICOM files that have considerable \r\nmetadata. Other files, e.g. NIfTI, only have metadata related to position and spacing of the image.\r\n\r\nBelow is a minimal working example for extracting metadata from a single image file.\r\n```python\r\nfrom mirp import extract_image_parameters\r\n\r\nimage_parameters = extract_image_parameters(\r\n    image=\"path to image\"\r\n)\r\n```\r\n\r\nMIRP also supports extracting metadata from multiple files. For example, assume that files are organised in \r\nsubfolders for each sample, i.e. `main_folder / sample_name / subfolder`. The minimal working example is then:\r\n```python\r\nfrom mirp import extract_image_parameters\r\n\r\nimage_parameters = extract_image_parameters(\r\n    image=\"path to main image directory\",\r\n    image_sub_folder=\"image subdirectory structure relative to main image directory\"\r\n)\r\n```\r\n\r\n## Examples - Finding labels\r\n\r\nMIRP can identify which labels are present in masks. For a single mask file, labels can be retrieved as follows:\r\n```python\r\nfrom mirp import extract_mask_labels\r\n\r\nmask_labels = extract_mask_labels(\r\n    mask=\"path to mask\"\r\n)\r\n```\r\n\r\nMIRP supports extracting labels from multiple masks. For example, assume that files are organised in subfolders for \r\neach sample, i.e. `main_folder / sample_name / subfolder`. The minimal working example is then:\r\n```python\r\nfrom mirp import extract_mask_labels\r\nmask_labels = extract_mask_labels(\r\n    mask=\"path to main mask directory\",\r\n    mask_sub_folder=\"mask subdirectory structure relative to main mask directory\"\r\n)\r\n```\r\n\r\n## Transitioning to version 2\r\n\r\nVersion 2 is a major refactoring of the previous code base. For users this brings the following noticeable changes:\r\n\r\n- MIRP was previously configured using two `xml` files: [`config_data.xml`](mirp/config_data.xml) for configuring\r\n  directories, data to be read, etc., and [`config_settings.xml`](mirp/config_settings.xml) for configuring experiments.\r\n  While these two files can still be used, MIRP can now be configured directly, without using these files.\r\n- The main functions of MIRP (`mainFunctions.py`) have all been re-implemented.\r\n  - `mainFunctions.extract_features` is now `extract_features` (functional form) or\r\n    `extract_features_generator` (generator). The replacements allow for both writing\r\n    feature values to a directory and returning them as function output. \r\n  - `mainFunctions.extract_images_to_nifti` is now `extract_images` (functional form) or\r\n     `extract_images_generator` (generator). The replacements allow for both writing \r\n     images to a directory (e.g., in NIfTI or numpy format) and returning them as function output.\r\n  - `mainFunctions.extract_images_for_deep_learning` has been replaced by \r\n    `deep_learning_preprocessing` (functional form) and \r\n    `deep_learning_preprocessing_generator` (generator).\r\n  - `mainFunctions.get_file_structure_parameters` and `mainFunctions.parse_file_structure` are deprecated, as the\r\n    the file import system used in version 2 no longer requires a rigid directory structure.\r\n  - `mainFunctions.get_roi_labels` is now `extract_mask_labels`.\r\n  - `mainFunctions.get_image_acquisition_parameters` is now `extract_image_parameters`.\r\n\r\nFor advanced users and developers, the following changes are relevant:\r\n- MIRP previously relied on `ImageClass` and `RoiClass` objects. These have been completely replaced by `GenericImage`\r\n  (and its subclasses, e.g. `CTImage`) and `BaseMask` objects, respectively. New image modalities can be added as\r\n  subclass of `GenericImage` in the `mirp.images` submodule.\r\n- File import, e.g. from DICOM or NIfTI files, in version 1 was implemented in an ad-hoc manner, and required a rigid\r\n  directory structure. Since version 2, file import is implemented using an object-oriented approach, and directory\r\n  structures are more flexible. File import of new modalities can be implemented as a relevant subclass of `ImageFile`.\r\n- MIRP now uses the `ray` package for parallel processing.\r\n\r\n# Citation info\r\nMIRP has been published in *Journal of Open Source Software*:\r\n```Zwanenburg A, Löck S. MIRP: A Python package for standardised radiomics. J Open Source Softw. 2024;9: 6413. doi:10.21105/joss.06413```\r\n\r\n# Contributing\r\nIf you have ideas for improving MIRP, please read the short [contribution guide](./CONTRIBUTING.md).\r\n\r\n# Developers and contributors\r\n\r\nMIRP is developed by:\r\n* Alex Zwanenburg\r\n\r\nWe would like thank the following contributors:\r\n* Stefan Leger\r\n* Sebastian Starke\r\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mlair",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/esde/machine-learning/mlair",
            "readme": "![MLAir Logo.]( docs/logo/MLAir_Logo.png)\n\n# MLAir - Machine Learning on Air Data\n\nMLAir (Machine Learning on Air data) is an environment that simplifies and accelerates the creation of new machine \nlearning (ML) models for the analysis and forecasting of meteorological and air quality time series. You can find the\ndocs [here](https://esde.pages.jsc.fz-juelich.de/machine-learning/mlair/docs/).\n\n[[_TOC_]]\n\n# Installation\n\nMLAir is based on several python frameworks. To work properly, you have to install all packages from the \n`requirements.txt` file. Additionally to support the geographical plotting part it is required to install geo\npackages built for your operating system. Unfortunately, the names of these package may differ for different systems.\nIn this instruction, we try to address users of different operating systems namely openSUSE Leap, Ubuntu and macOS.\nIf the installation is still not working, we recommend skipping the geographical plot. We have put together a small \nworkaround [here](#workaround-to-skip-geographical-plot). For special instructions to install MLAir on the Juelich \nHPC systems, see [here](#special-instructions-for-installation-on-jülich-hpc-systems).\n\n* Make sure to have the **python3.6** version installed (We are already using python3.8, but will refer to python3.6 \n  here as this was used for long time and is therefore tested well.)\n* (geo) A **c++ compiler** is required for the installation of the program **cartopy**\n* (geo) Install **proj** and **GEOS** on your machine using the console.\n* Install the **python3.6 develop** libraries.\n* Install all **requirements** from [`requirements.txt`](https://gitlab.jsc.fz-juelich.de/esde/machine-learning/mlair/-/blob/master/requirements.txt)\n  preferably in a virtual environment. You can use `pip install -r requirements.txt` to install all requirements at \n  once. Note, we recently updated the version of Cartopy and there seems to be an ongoing \n  [issue](https://github.com/SciTools/cartopy/issues/1552) when installing **numpy** and **Cartopy** at the same time. \n  If you run into trouble, you could use \n `cat requirements.txt | cut -f1 -d\"#\" | sed '/^\\s*$/d' | xargs -L 1 pip install` instead or first install numpy with \n `pip install numpy==<version_from_reqs>` followed be the default installation of requirements. For the latter, you can\n  also use `grep numpy requirements.txt | xargs pip install`.\n* Installation of **MLAir**:\n    * Either clone MLAir from the [gitlab repository](https://gitlab.jsc.fz-juelich.de/esde/machine-learning/mlair.git) \n      and use it without installation (beside the requirements) \n    * or download the distribution file ([current version](https://gitlab.jsc.fz-juelich.de/esde/machine-learning/mlair/-/blob/master/dist/mlair-2.4.0-py3-none-any.whl)) \n      and install it via `pip install <dist_file>.whl`. In this case, you can simply import MLAir in any python script \n      inside your virtual environment using `import mlair`.\n\n## openSUSE Leap 15.1\n\n* c++ compiler\n\n`sudo zypper install gcc-c++`\n\n* geo packages\n\n`sudo zypper install proj geos-devel`\n\n* depending on the pre-installed packages it could be required to install further packages\n\n`sudo zypper install libproj-devel binutils gdal-devel graphviz graphviz-gnome`\n\n* python develop libraries\n\n`sudo zypper install python3-devel`\n\n## Ubuntu 20.04.1\n\n* c++ compiler\n\n`sudo apt install build-essential` \n\n* geo packages\n\n`sudo apt install proj-bin libgeos-dev libproj-dev`\n\n* depending on the pre-installed packages it could be required to install further packages\n\n`sudo apt install graphviz libgeos++-dev`\n\n* python develop libraries\n\n`sudo apt install python3.6-dev`\n\n## macOS & windows\n\nThe installation on macOS is not tested yet. The following commands are possibly needed:\n\n`brew install geos`\n\n`sudo port install graphviz`\n\nThe installation on Windows is not tested yet.\n\n# How to start with MLAir\n\nIn this section, we show three examples how to work with MLAir. Note, that for these examples MLAir was installed using\nthe distribution file. In case you are using the git clone it is required to adjust the import path if not directly\nexecuted inside the source directory of MLAir. There is also a downloadable \n[Jupyter Notebook](https://gitlab.jsc.fz-juelich.de/esde/machine-learning/mlair/-/blob/master/supplement/Examples_from_manuscript.ipynb) \nprovided in that you can run the following examples. Note that this notebook still requires an installation of MLAir.\n\n## Example 1\n\nWe start MLAir in a dry run without any modification. Just import mlair and run it.\n```python\nimport mlair\n\n# just give it a dry run without any modification \nmlair.run()\n```\nThe logging output will show you many informations. Additional information (including debug messages) are collected \ninside the experiment path in the logging folder.\n```log\nINFO: DefaultWorkflow started\nINFO: ExperimentSetup started\nINFO: Experiment path is: /home/<usr>/mlair/testrun_network \n...\nINFO: load data for DEBW107 from JOIN\nINFO: load data for DEBY081 from JOIN\nINFO: load data for DEBW013 from JOIN\nINFO: load data for DEBW076 from JOIN\nINFO: load data for DEBW087 from JOIN\n...\nINFO: Training started\n...\nINFO: DefaultWorkflow finished after 0:03:04 (hh:mm:ss)\n```\n\n## Example 2\n\nNow we update the stations and customise the window history size parameter.\n\n```python\nimport mlair\n\n# our new stations to use\nstations = ['DEBW030', 'DEBW037', 'DEBW031', 'DEBW015', 'DEBW107']\n\n# expanded temporal context to 14 (days, because of default sampling=\"daily\")\nwindow_history_size = 14\n\n# restart the experiment with little customisation\nmlair.run(stations=stations, \n          window_history_size=window_history_size)\n```\nThe output looks similar, but we can see, that the new stations are loaded.\n```log\nINFO: DefaultWorkflow started\nINFO: ExperimentSetup started\n...\nINFO: load data for DEBW030 from JOIN \nINFO: load data for DEBW037 from JOIN \nINFO: load data for DEBW031 from JOIN \nINFO: load data for DEBW015 from JOIN \n...\nINFO: Training started\n...\nINFO: DefaultWorkflow finished after 00:02:03 (hh:mm:ss)\n```\n\n## Example 3\n\nLet's just apply our trained model to new data. Therefore we keep the window history size parameter but change the stations.\nIn the run method, we need to disable the trainable and create new model parameters. MLAir will use the model we have\ntrained before. Note, this only works if the experiment path has not changed or a suitable trained model is placed \ninside the experiment path.\n```python\nimport mlair\n\n# our new stations to use\nstations = ['DEBY002', 'DEBY079']\n\n# same setting for window_history_size\nwindow_history_size = 14\n\n# run experiment without training\nmlair.run(stations=stations, \n          window_history_size=window_history_size, \n          create_new_model=False, \n          train_model=False)\n```\nWe can see from the terminal that no training was performed. Analysis is now made on the new stations.\n```log\nINFO: DefaultWorkflow started\n...\nINFO: No training has started, because train_model parameter was false. \n...\nINFO: DefaultWorkflow finished after 0:01:27 (hh:mm:ss)\n```\n\n\n# Default Workflow\n\nMLAir is constituted of so-called `run_modules` which are executed in a distinct order called `workflow`. MLAir\nprovides a `default_workflow`. This workflow runs the run modules `ExperimentSetup`, `PreProcessing`,\n`ModelSetup`, `Training`, and `PostProcessing` one by one.\n\n![Sketch of the default workflow.](docs/_source/_plots/run_modules_schedule.png)\n\n```python\nimport mlair\n\n# create your custom MLAir workflow\nDefaultWorkflow = mlair.DefaultWorkflow()\n# execute default workflow\nDefaultWorkflow.run()\n```\nThe output of running this default workflow will be structured like the following.\n```log\nINFO: DefaultWorkflow started\nINFO: ExperimentSetup started\n...\nINFO: ExperimentSetup finished after 00:00:01 (hh:mm:ss)\nINFO: PreProcessing started\n...\nINFO: PreProcessing finished after 00:00:11 (hh:mm:ss)\nINFO: ModelSetup started\n...\nINFO: ModelSetup finished after 00:00:01 (hh:mm:ss)\nINFO: Training started\n...\nINFO: Training finished after 00:02:15 (hh:mm:ss)\nINFO: PostProcessing started\n...\nINFO: PostProcessing finished after 00:01:37 (hh:mm:ss)\nINFO: DefaultWorkflow finished after 00:04:05 (hh:mm:ss)\n```\n\n# Customised Run Module and Workflow\n\nIt is possible to create new custom run modules. A custom run module is required to inherit from the base class\n`RunEnvironment` and to hold the constructor method `__init__()`. This method has to execute the module on call.\nIn the following example, this is done by using the `_run()` method that is called by the initialiser. It is\npossible to parse arguments to the custom run module as shown.\n\n```python\nimport mlair\nimport logging\n\nclass CustomStage(mlair.RunEnvironment):\n    \"\"\"A custom MLAir stage for demonstration.\"\"\"\n\n    def __init__(self, test_string):\n        super().__init__()  # always call super init method\n        self._run(test_string)  # call a class method\n\n    def _run(self, test_string):\n        logging.info(\"Just running a custom stage.\")\n        logging.info(\"test_string = \" + test_string)\n        epochs = self.data_store.get(\"epochs\")\n        logging.info(\"epochs = \" + str(epochs))\n```\n\nIf a custom run module is defined, it is required to adjust the workflow. For this, you need to load the empty\n`Workflow` class and add each run module that is required. The order of adding modules defines the order of\nexecution if running the workflow.\n\n```python\n# create your custom MLAir workflow\nCustomWorkflow = mlair.Workflow()\n# provide stages without initialisation\nCustomWorkflow.add(mlair.ExperimentSetup, epochs=128)\n# add also keyword arguments for a specific stage\nCustomWorkflow.add(CustomStage, test_string=\"Hello World\")\n# finally execute custom workflow in order of adding\nCustomWorkflow.run()\n```\n\nThe output will look like:\n\n```log\nINFO: Workflow started\n...\nINFO: ExperimentSetup finished after 00:00:12 (hh:mm:ss)\nINFO: CustomStage started\nINFO: Just running a custom stage.\nINFO: test_string = Hello World\nINFO: epochs = 128\nINFO: CustomStage finished after 00:00:01 (hh:mm:ss)\nINFO: Workflow finished after 00:00:13 (hh:mm:ss)\n```\n\n# Custom Model\n\nCreate your own model to run your personal experiment. To guarantee a proper integration in the MLAir workflow, models\nare restricted to inherit from the `AbstractModelClass`. This will ensure a smooth training and evaluation\nbehaviour.\n\n## How to create a customised model?\n\n* Create a new model class inheriting from `AbstractModelClass`\n\n```python\nfrom mlair import AbstractModelClass\n\nclass MyCustomisedModel(AbstractModelClass):\n\n    def __init__(self, input_shape: list, output_shape: list):\n\n        # set attributes shape_inputs and shape_outputs\n        super().__init__(input_shape[0], output_shape[0])\n\n        # apply to model\n        self.set_model()\n        self.set_compile_options()\n        self.set_custom_objects(loss=self.compile_options['loss'])\n```\n\n* Make sure to add the `super().__init__()` and at least `set_model()` and `set_compile_options()` to your\n  custom init method.\n* The shown model expects a single input and output branch provided in a list. Therefore shapes of input and output are\n  extracted and then provided to the super class initialiser.\n* Some general settings like the dropout rate are set in the init method additionally.\n* If you have custom objects in your model, that are not part of the keras or tensorflow frameworks, you need to add\n  them to custom objects. To do this, call `set_custom_objects` with arbitrarily kwargs. In the shown example, the\n  loss has been added for demonstration only, because we use a build-in loss function. Nonetheless, we always encourage\n  you to add the loss as custom object, to prevent potential errors when loading an already created model instead of\n  training a new one.\n* Now build your model inside `set_model()` by using the instance attributes `self._input_shape` and\n  `self._output_shape` and storing the model as `self.model`.\n\n```python\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import PReLU, Input, Conv2D, Flatten, Dropout, Dense\n\nclass MyCustomisedModel(AbstractModelClass):\n\n    def set_model(self):\n        x_input = Input(shape=self._input_shape)\n        x_in = Conv2D(4, (1, 1))(x_input)\n        x_in = PReLU()(x_in)\n        x_in = Flatten()(x_in)\n        x_in = Dropout(0.1)(x_in)\n        x_in = Dense(16)(x_in)\n        x_in = PReLU()(x_in)\n        x_in = Dense(self._output_shape)(x_in)\n        out = PReLU()(x_in)\n        self.model = keras.Model(inputs=x_input, outputs=[out])\n```\n\n* Your are free how to design your model. Just make sure to save it in the class attribute model.\n* Additionally, set your custom compile options including the loss definition.\n\n```python\nfrom tensorflow.keras.losses import mean_squared_error as mse\n\nclass MyCustomisedModel(AbstractModelClass):\n\n    def set_compile_options(self):\n        self.initial_lr = 1e-2\n        self.optimizer = keras.optimizers.SGD(lr=self.initial_lr, momentum=0.9)\n        self.loss = mse\n        self.compile_options = {\"metrics\": [\"mse\", \"mae\"]}\n```\n\n* The allocation of the instance parameters `initial_lr`, `optimizer`, and `lr_decay` could be also part of\n  the model class' initialiser. The same applies to `self.loss` and `compile_options`, but we recommend to use\n  the `set_compile_options` method for the definition of parameters, that are related to the compile options.\n* More important is that the compile options are actually saved. There are three ways to achieve this.\n\n  * (1): Set all compile options by parsing a dictionary with all options to `self.compile_options`.\n  * (2): Set all compile options as instance attributes. MLAir will search for these attributes and store them.\n  * (3): Define your compile options partly as dictionary and instance attributes (as shown in this example).\n  * If using (3) and defining the same compile option with different values, MLAir will raise an error.\n\n    Incorrect: (Will raise an error because of a mismatch for the `optimizer` parameter.)\n    ```python\n    def set_compile_options(self):\n        self.optimizer = keras.optimizers.SGD()\n        self.loss = keras.losses.mean_squared_error\n        self.compile_options = {\"optimizer\" = keras.optimizers.Adam()}\n    ```\n    \n## How to plug in the customised model into the workflow?\n* Make use of the `model` argument and pass `MyCustomisedModel` when instantiating a workflow.\n```python\nfrom mlair.workflows import DefaultWorkflow\n\nworkflow = DefaultWorkflow(model=MyCustomisedModel)\nworkflow.run()\n```\n\n\n## Specials for Branched Models\n\n* If you have a branched model with multiple outputs, you need either set only a single loss for all branch outputs or\n  provide the same number of loss functions considering the right order.\n\n```python\nclass MyCustomisedModel(AbstractModelClass):\n\n    def set_model(self):\n        ...\n        self.model = keras.Model(inputs=x_input, outputs=[out_minor_1, out_minor_2, out_main])\n\n    def set_compile_options(self):\n        self.loss = [keras.losses.mean_absolute_error] +  # for out_minor_1\n                    [keras.losses.mean_squared_error] +   # for out_minor_2\n                    [keras.losses.mean_squared_error]     # for out_main\n```\n\n\n## How to access my customised model?\n\nIf the customised model is created, you can easily access the model with\n\n```python\n>>> MyCustomisedModel().model\n<your custom model>\n```\n\nThe loss is accessible via\n\n```python\n>>> MyCustomisedModel().loss\n<your custom loss>\n```\n\nYou can treat the instance of your model as instance but also as the model itself. If you call a method, that refers to\nthe model instead of the model instance, you can directly apply the command on the instance instead of adding the model\nparameter call.\n\n```python\n>>> MyCustomisedModel().model.compile(**kwargs) == MyCustomisedModel().compile(**kwargs)\nTrue\n```\n\n# Data Handlers\n\nData handlers are responsible for all tasks related to data like data acquisition, preparation and provision. A data \nhandler must inherit from the abstract base class `AbstractDataHandler` and requires the implementation of the \n`__init__()` method and the accessors `get_X()` and `get_Y()`. In the following, we show an example how a custom data \nhandler could look like.\n\n```python\nimport datetime as dt\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\n\nfrom mlair.data_handler import AbstractDataHandler\n\nclass DummyDataHandler(AbstractDataHandler):\n\n    def __init__(self, name, number_of_samples=None):\n        \"\"\"This data handler takes a name argument and the number of samples to generate. If not provided, a random \n        number between 100 and 150 is set.\"\"\"\n        super().__init__()\n        self.name = name\n        self.number_of_samples = number_of_samples if number_of_samples is not None else np.random.randint(100, 150)\n        self._X = self.create_X()\n        self._Y = self.create_Y()\n\n    def create_X(self):\n        \"\"\"Inputs are random numbers between 0 and 10 with shape (no_samples, window=14, variables=5).\"\"\"\n        X = np.random.randint(0, 10, size=(self.number_of_samples, 14, 5))  # samples, window, variables\n        datelist = pd.date_range(dt.datetime.today().date(), periods=self.number_of_samples, freq=\"H\").tolist()\n        return xr.DataArray(X, dims=['datetime', 'window', 'variables'], coords={\"datetime\": datelist,\n                                                                                 \"window\": range(14),\n                                                                                 \"variables\": range(5)})\n    \n    def create_Y(self):\n        \"\"\"Targets are normal distributed random numbers with shape (no_samples, window=5, variables=1).\"\"\"\n        Y = np.round(0.5 * np.random.randn(self.number_of_samples, 5, 1), 1)  # samples, window, variables\n        datelist = pd.date_range(dt.datetime.today().date(), periods=self.number_of_samples, freq=\"H\").tolist()\n        return xr.DataArray(Y, dims=['datetime', 'window', 'variables'], coords={\"datetime\": datelist,\n                                                                                 \"window\": range(5),\n                                                                                 \"variables\": range(1)})\n\n    def get_X(self, upsampling=False, as_numpy=False):\n        \"\"\"Upsampling parameter is not used for X.\"\"\"\n        return np.copy(self._X) if as_numpy is True else self._X\n\n    def get_Y(self, upsampling=False, as_numpy=False):\n        \"\"\"Upsampling parameter is not used for Y.\"\"\"\n        return np.copy(self._Y) if as_numpy is True else self._Y\n\n    def __str__(self):\n        return self.name\n\n```\n\n\n# Special Remarks\n\n## Workaround to skip geographical plot\n\nIf it is not possible to install all required geo libraries on your system, a good compromise is to skip the creation\nof the geographical plot. Therefore, it is required to remove the plot from the `plot_list` manually. We recommend to\nuse this code snippet as a starting point.\n\n```python\nfrom mlair.helpers import remove_items\nfrom mlair.configuration.defaults import DEFAULT_PLOT_LIST\n\nmlair.run(plot_list=remove_items(DEFAULT_PLOT_LIST, \"PlotStationMap\"))\n\n```\n\n## Special instructions for installation on Jülich HPC systems\n\n_Please note, that the HPC setup is customised for JUWELS and HDFML. When using another HPC system, you can use the HPC \nsetup files as a skeleton and customise it to your needs._\n\nThe following instruction guide you through the installation on JUWELS and HDFML. \n* Clone the repo to HPC system (we recommend to place it in `/p/projects/<project name>`).\n* Setup venv by executing `source setupHPC.sh`. This script loads all pre-installed modules and creates a venv for \nall other packages. Furthermore, it creates slurm/batch scripts to execute code on compute nodes.\nYou have to enter the HPC project's budget name (--account flag).\n* The default external data path on JUWELS and HDFML is set to `/p/project/deepacf/intelliaq/<user>/DATA/toar_<sampling>`. \nTo choose a different location open `run.py` and add the following keyword argument to `ExperimentSetup`: \n`data_path=<your>/<custom>/<path>`. \n* Execute `python run.py` on a login node to download example data. The program will throw an OSerror after downloading.\n* Execute either `sbatch run_juwels_develgpus.bash` or `sbatch run_hdfml_batch.bash` to verify that the setup went well.\n* Currently cartopy is not working on our HPC system, therefore PlotStations does not create any output.\n\nNote: The method `PartitionCheck` currently only checks if the hostname starts with `ju` or `hdfmll`. \nTherefore, it might be necessary to adopt the `if` statement in `PartitionCheck._run`.\n\n## Security using JOIN\n\n* To use hourly data from ToarDB via JOIN interface, a private token is required. Request your personal access token and\nadd it to `src/join_settings.py` in the hourly data section. Replace the `TOAR_SERVICE_URL` and the `Authorization` \nvalue. To make sure, that this **sensitive** data is not uploaded to the remote server, use the following command to\nprevent git from tracking this file: `git update-index --assume-unchanged src/join_settings.py`\n\n\n## Known Issues\n\n### Problem with multiprocessing\n\n* cpython and python's native multiprocessing can crash when using the multiprocessing approach for preprocessing. This \nis caused by an internal limitation in order of 2GB. When using long periods and therefore very big data, \nmultiprocessing is not able to handle these data correctly:\n```shell\nFile \"mlair/mlair/run_modules/pre_processing.py\", line X, in validate_station\n  dh, s = p.get()\nFile \"multiprocessing/pool.py\", line 644, in get\n  raise self._value\nmultiprocessing.pool.MaybeEncodingError: Error sending result: '(DEMV012, 'DEMV012')'. Reason: 'error(\"'i' format requires -2147483648 <= number <= 2147483647\",)'\n```\n* to solve this issue, either update your python version to >=3.8 (warning, this version is not tested with MLAir) or \napply the patch that is applied in this commit \nhttps://github.com/python/cpython/commit/bccacd19fa7b56dcf2fbfab15992b6b94ab6666b or as proposed in this comment \nhttps://stackoverflow.com/questions/47776486/python-struct-error-i-format-requires-2147483648-number-2147483647\n",
            "project_id": "2411"
        },
        {
            "software_organization": "https://helmholtz.software/software/mmpxrt",
            "repo_link": "https://codebase.helmholtz.cloud/smid55/mmpxrt",
            "readme": "# mmpxrt\r\nRaytracing code for x-ray spectrometers with (not only) mossaic crystals\r\nWritten 2017-2020, Michal Smid\r\n\r\nThis is a raytracing code for design and analysis of x-ray spectrometers. Useful tool for (rather) experienced physicist. For more info about distribution, installation, usage, etc. of this package, please see attached manual.\r\n\r\nThe code is described in this paper, please cite it if you use the softare:\r\n\r\nM. Šmíd, X.Pan, and K. Falk, “X-ray spectrometer simulation code with a detailed support of mosaic crystals,” **Comput. Phys. Commun.**\r\n262, 107811 (2021).   https://doi.org/10.1016/j.cpc.2020.107811\r\n\r\nAll files related to the code are available at:\r\nhttps://codebase.helmholtz.cloud/smid55/mmpxrt\r\n\r\nThe packaging was done by using this manual: https://packaging.python.org/tutorials/packaging-projects/\r\n\r\n\r\n## Structure of the repository:\r\n-test cases - the folder with examples (test cases), i.e. executable python scripts,\r\n    which are dependent on the proper installation of the mmpxrt library  \r\n-mmpxrt_manual.odt - The manual, also quite useful file...   \r\n-mmpxrt.pdf - Draft of a scientific paper describing the code.  \r\n-mmpxrt - is a directory containing the pip package and all that it needs to be built.  \r\n.|- dist - produced resulting pip packages; these are already uploaded to PiPY, so you can install the codes easily  \r\n.|-mmpxrt - the actual folder with the script  \r\n...|-mmpxrt.py - the actual script; Technically speaking, this is the only file conaining the code:-)   \r\n",
            "project_id": "1225"
        },
        {
            "software_organization": "https://helmholtz.software/software/mdis",
            "repo_link": "https://git.gfz-potsdam.de/icdp-osg/mdis",
            "readme": "# mDIS Project\n\n[![frontend coverage](https://gitlab.informationsgesellschaft.com/dis/dis/badges/master/coverage.svg?job=test_frontend&key_text=frontend+coverage&key_width=120&style=flat-square)](https://gitlab.informationsgesellschaft.com/dis/dis/badges/master/coverage.svg?job=test_frontend&key_text=frontend+coverage&key_width=120&style=flat-square)\n\n[![backend coverage](https://gitlab.informationsgesellschaft.com/dis/dis/badges/master/coverage.svg?job=test_backend&key_text=backend+coverage&key_width=120&style=flat-square)](https://gitlab.informationsgesellschaft.com/dis/dis/badges/master/coverage.svg?job=test_backend&key_text=backend+coverage&key_width=120&style=flat-square)\n\nThis project is merging two frontend and backend technology together in the same repository.\nIt uses Yii2 and Vue in order to get the most benefit from both frameworks.\n\nThe template contains the basic features including user login/logout and a contact page.\nIt includes all commonly used configurations that would allow you to focus on adding new\nfeatures to your application.\n\n## DIRECTORY STRUCTURE\n\nThe application structure is similar to a Vue project created by the vue-cli with the command `vue create <app name>`.\nThere are two remarkable differences:\n\n- an extra **`backend`** directory that contains Yii2 code,\n- the **`dist`** folder (containing the build version) was renamed to **`web`**.\n\n      +-- backend                 Yii2 Code (Server Side / API)\n      |   +-- assets/              Assets definition\n      |   +-- behaviors/           Special-Purpose Calculation, e.g. IGSN, AutoIncr\n      |   +-- bin/                 Command line scripts (e.g. for auto printing reports)\n      |   +-- commands/            yii console commands (controllers)\n      |   +-- components/          Several components and helpers used elsewhere\n      |   +-- config/              Application configurations (web, db backends, igsn, ldap, ...)\n      |   +-- controllers/         Web controller classes\n      |   +-- data/                Uploaded files (associated to database table archive_file)\n      |   +-- dis_migration/       Migration classes for Legacy DIS import\n      |   +-- dis_templates/       Json files defining models and forms as Json files\n      |       +-- defaults/        Default models and forms \n      |       +-- forms/           Customized form templates (initially copied from defaults/forms) \n      |       +-- models/          Customized model templates (initially copied from defaults/models) \n      |   +-- forms/               Form PHP classes\n      |   +-- models/              Model PHP classes that can be customized\n      |       +-- base/            Base model PHP classes (twoway-data bindings) automatically generated from template manager\n      |       +-- core/            Core model PHP classes\n      |   +-- modules/             Modules (Code Generator as an example)\n      |       +-- api/             Rest API used from frontend and elsewhere to access data\n      |       +-- cg/              Code generator to create PHP model and vue form files\n      |   +-- rbac/                Specialisations for user and rights management\n      |   +-- reports/             Report-, export- and action scripts called from forms\n      |   +-- resources/           Overriden data model classes for the API (User.php)\n      |   +-- runtime/             Files generated during runtime (cache, logs, debug info...)\n      |   +-- vendor/              Dependent 3rd-party PHP packages\n      |   +-- views/               View files for the Web application\n      |   +-- widgets/             General purpose components (Alert.php)\n      +-- public                   Public static assets (index.html, index.php, favicons)\n      +-- src                      Vue source code\n      |   +-- assets               Logos, etc.\n      |   +-- components           Display components and input components\n      |   +-- forms                Input forms generated from template manager or customized\n      |   +-- mixins               Input validators (not really components or screens)\n      |   +-- pages                Screens: Login, CoreSection, Dashboard\n      |   +-- plugins              User interface components, like vuetify.js\n      |   +-- services             BackendService (Auth), CrudService (data manipulation), etc.\n      |   +-- store                State management like: is logged in, isDark, snackbar, ...\n      |   +-- style                Stylus directives, will be compiled to css\n      |   +-- util                 Utility javascripts \n      +-- tests                    Frontend tests\n      +-- web                      Output folder for command `npm run build` + customized logos, etc.\n\n## REQUIREMENTS\n\nThe minimum requirement by this project template that your Web server supports PHP 7.1. PHP 8.1 is not supported (yet).\n\n## INSTALLATION\n\n### Security Note\n\nmDIS code contains some default users and passwords. If you plan to run mDIS as a WebApp on the public internet, please change these passwords.\n\nDo so either *before* installation or after installation.\n\n#### Before Installation\n\nChange usernames and passwords\n\n- either check the file `backend/commands/SeedController.php`. Change default usernames and passwords according to your preferences.\n- or change the mode of installation to `LDAP`. See the files `backend/config/web.php` and `backend/config/ldap-example.php` for instructions. This way default usernames and passwords will not be used.\n\n#### After mDIS installation\n\nChange usernames and passwords\n\nChange usernames and passwords using the mDIS web interface. Login as `admininstrator` and change the passwords of the default users. The password manager is reachable via Sidebar item \"Settings\" -> \"User Manager\".\n\n### Install via Composer\n\n@TODO\n\n### Install from an Archive File\n\n@TODO\n\n### Install with Docker\n\nThis is only a basic installation. Depending on your environment, Docker version and Docker skills, you might need to adapt the `docker-compose.yml` and related files (e.g., `.env`).\n\nClone the repository and cd into the `dis` folder.\n\nPrepare docker environment file by copying `.env-dev` to `.env`.\n\nUpdate your vendor packages\n\n    docker-compose run --rm php composer update --prefer-dist\n\nRun the installation scripts (this is a standard `composer` command)\n\n    docker-compose run --rm php composer install\n\nRun post project creation triggers (set required permissions)\n\n    docker-compose run --rm php composer run-script post-create-project-cmd\n\nInstall frontend dependencies (3rd party Javascript code)\n\n    npm install\n\nTo generate frontend bundle (the mDIS webapp), use one of the following commands\n\n```sh\n# for production build\n# This command produces a production-ready bundle in the /web directory \n# (see https://cli.vuejs.org/guide/cli-service.html#vue-cli-service-build)\nnpm run build \n\n# for JavaScript development (advanced)\n# starts Webpack dev server, builds JS sourcemaps and other things\n# (see https://cli.vuejs.org/guide/cli-service.html#vue-cli-service-serve)\nnpm run serve \n```\n\nStart the containers\n\n    docker-compose up # add -d to run as deamon (in the background)\n\nYou can then access the application at `http://127.0.0.1:8000`\n\n> After adding NodeJS to the PHP container, first build time was increased. Take the build option out and uncomment the image line if do not need NodeJS in the container.\n> check [here](https://github.com/docker/compose/issues/4396) and [here](https://github.com/docker/toolbox/issues/613) for suggested solutions.\n\nOn the command line you should execute something like this:\n\n    docker ps | grep dis\n\nResult:\n\n```text\n\nCONTAINER ID        IMAGE                             COMMAND                  CREATED             STATUS              PORTS                    NAMES\n71b25a7418dd        yiisoftware/yii2-php:7.3-apache   \"docker-php-entrypoi…\"   23 hours ago        Up 13 seconds       0.0.0.0:8000->80/tcp     dis_php_1\n57cdf5ca735e        mariadb                           \"docker-entrypoint.s…\"   23 hours ago        Up 23 hours         0.0.0.0:8001->3306/tcp   dis_db_1\n7424a0f9f6a7        adminer                           \"entrypoint.sh docke…\"   3 days ago          Up 3 days           0.0.0.0:8002->8080/tcp   dis_adminer_1\n```\n\nRightmost Column `NAMES` signifies:\n\n- `dis_php_1` - Webserver with *PHP/Yii2* Application\n- `dis_db_1`  - *Mariadb*, Database Server\n- `dis_adminer_1` - *Adminer*, Web-based Database Administration Tool\n\nOptionally, stop the containers with `docker stop dis_php_1 dis_db_1 dis_adminer_1`.\n\nApply database migrations to create required tables and seed data\n\n```bash\n# bash into php container\ndocker exec -it dis_php_1 bash\n# then call yii migrations\n./yii migrate\n# seed users accounts\nyii seed/users\n# load DSEIS data\nyii seed/example-dump \n# seed users forms permissions\nyii seed/form-permissions\n\n```\n\nThe `mariadb` container stores persistent mDIS data inside Docker volume `dis_dbvolume`:\n\n`docker volume inspect dis_dbvolume`\n\nThis enables the container to \"survive\" restarts, keeping data created by both the `yii migrate` command and data eventually entered by the DIS user.\n\n**NOTES:**\n\n- Minimum required Docker engine version `17.04` for development (see [Performance tuning for volume mounts](https://docs.docker.com/docker-for-mac/osxfs-caching/))\n- The default configuration uses a host-volume in your home directory `.composer-docker` for php-composer caches\n\n## CONFIGURATION\n\n### Database\n\n> This configuration is not needed for docker installation.\n\nEdit the file `config/db.php` with real data, for example:\n\n```php\nreturn [\n    'class' => 'yii\\db\\Connection',\n    'dsn' => 'mysql:host=your_host;dbname=your_db_name',\n    'username' => 'your_db_user',\n    'password' => 'your_db_password',\n    'charset' => 'utf8',\n];\n```\n\n## UPGRADE TO V3\n\nIn January 2022 we decided to remove several files from the repository that where automatically generated or usually modified in an instance.\nAdditionally several separately developed branches have been merged including the new standard data model of ICDP.\nThe Branch \"mDIS V2\" keeps the version before that braking changes. To update an exisiting instance to the new Version 3.x, please follow these steps:\n\n1. Make sure you are on the `master` branch, type `git pull` in order to update the project.\n- If you do a `git pull`, various modified files will probably be criticized.\n- All files in `backend/models/base` can be restored via \"git restore\" (they will be deleted on pull)\n  - All files in `backend/models` and `backend/forms` that have not been specialized can be reset (they will be deleted on pull)\n  - All files `src/forms/*.vue.generated` can be reset (they will be deleted on pull)\n  - The specialized files in `backend/models/` and `/backend/forms/` can be detached from the repository: `git rm -cached <path-to-file-that-dont-want-to track>` \n  - Now git pull should work\n2. Type `composer install` in the console.\n3. Type `./yii upgrade 3` in the console.\n    * This command will do the following:\n      * Copy the default models templates to ‘backend/dis_templates/models’.\n      * Copy the default forms templates to ‘backend/dis_templates/models’.\n      * Create the missing tables in the data base according to the already copied models templates.\n      *\tApply the migrations of `usuario` library.\n      * Update the PHP models and form as also the `*.vue.generated` files.\n4. Delete the folder `node_modules` from your project root.\n5. Type `npm install` in the console, to rebuild the `node_modules` folder.\n6. Type `npm run build` in order to create a new build or `npm run serve` to serve.\n",
            "project_id": "2781"
        },
        {
            "software_organization": "https://helmholtz.software/software/mode-behave",
            "repo_link": "https://github.com/julianreul/mode_behave",
            "readme": "Model Purpose and General Information\n=====================================\nMO|DE.behave is a Python-based software package for the estimation and \nsimulation of discrete choice models. The purpose of this software is to enable \nthe rapid quantitative analysis of survey data on choice behavior, \nutilizing advanced discrete choice methods. \nTherefore, MO|DE.behave incorporates estimation routines for conventional \nmultinomial logit models, as well as for mixed logit models with nonparametric \ndistributions.\nFurthermore, MO|DE.behave contains a set of post-processing tools for visualizing \nestimation and simulation results. Additionally, pre-estimated \ndiscrete choice simulation methods for transportation research are included to \nenrich the software package for this specific community.\n\nOn mixed logit models:\nIn recent years, a new modeling approach in the field of discrete choice theory \nbecame popular – the mixed logit model (see Train, K. (2009): \"Mixed logit\", \nin Discrete choice methods with simulation (pp. 76–93), Cambridge University Press). \nConventional discrete choice models only have a limited capability to describe \nthe heterogeneity of choice preferences within a base population, i.e., \nthe divergent choice behavior of different individuals or consumer groups can \nonly be studied to a limited degree. Mixed logit models overcome this deficiency and \nallow for the analysis of preference distributions across base populations.\n\nCommunication and contribution:\nWe encourage active participation in the software development process to adapt \nit to user needs. If you would like to contribute to the project or report any bugs, \nplease refer to the contribution-file or simply create an issue in the repository.\nFor any other interests (e.g. potential research collaborations), please \ndirectly contact the project maintainers via email, as indicated and \nupdated on GitHub.\n\nDocumentation on GitHub Pages: https://fzj-iek3-vsa.github.io/mode_behave/\n\nInstallation\n============\n1. Download or clone the repository to a local folder.\n#. Open (Anaconda) Prompt.\n#. Create a new environment from reference_environment.yml file (recommended)::\n\n      conda env create -f reference_environment.yml\n      \n#. Activate the environment with::\n\n      conda activate env_mode_behave\n      \n#. cd to the directory, where you stored the repository and where the setup.py file is located.\n\n#. In this folder run::\n    \n      pip install -e .\n      \n#. Alternatively, run::\n      \n      pip install mode-behave\n\n\nWorkflow\n========\n\nThis section explains an exemplary workflow from model setup to estimation \nand post-processing for a sub-sample of survey data on household decisions\non the type of propulsion technology when purchasing a new car.\nThe propulsion types are differentiated into \"ICEV: Internal combustion engine vehicle\",\n\"PHEV: Plug-in Hybrid Electric Vehicle\", \"BEV: Battery Electric Vehicle\", \nand \"FCEV: Fuel Cell Electric Vehicle\".\nThe data was collected in the year 2021 among German households and \nthe respective sub-sample is provided with the model (./mode_behave_public/InputData/example_data.csv).\nThe complete script accessible as well (./mode_behave_public/Deployments/example_estimation.py)\n\n1. Import model and required modules with::\n\n      import numpy as np\n      import pandas as pd\n      \n      import mode_behave_public as mb\n      \n2. Load data with (PATH_TO_DATA requires individual definition. See below for further documentation on required data formats.)::\n      \n      example_data = pd.read_csv(PATH_TO_DATA + \"example_data.csv\")\n      \n3. Definition of model parameters \"PURCHASE_PRICE\", \"RANGE\", and \"CHARGING_FUELING_TIME\". See section \"Structure of Parameters and Input Data\" for further information::\n      \n      param_fixed = []\n      param_random = ['PURCHASE_PRICE', 'RANGE', 'CHARGING_FUELING_TIME']\n\n      param_temp = {'constant': \n                        {\n                         'fixed':[],\n                         'random':[]\n                         },\n                    'variable':\n                        {\n                         'fixed': [],\n                         'random':[]\n                         }\n                    }\n\n      param_temp['variable']['fixed'] = param_fixed\n      param_temp['variable']['random'] = param_random  \n\n4. Initialize a model with::\n    \n      model = mb.Core(\n          param=param_temp, \n          data_in=example_data, \n          alt=4,\n          equal_alt=1,\n          include_weights=False\n          )\n      \n   The structure of the input data and the parameter-input are given below.\n\n5. Estimate the model with::\n\n    model.estimate_mixed_logit(\n        min_iter=10, \n        max_iter=1000,\n        tol=0.01,\n        space_method = 'std_value',\n        scale_space = 2,\n        max_shares = 1000,\n        bits_64=True,\n        t_stats_out=False\n        )\n      \n    The estimation of the mixed logit model can be modified by definition of keyword-arguments\n    during instantiation and within the estimation-method itself.\n    \n    Arguments for instantiation (ov.Core(...))::\n    \n        dict param:\n            Indicates the names of the model attributes. \n            The attribute-names shall be derived from the column names of the input data.\n        str data_name: \n            Indicates the name of the input data-file. \n        int alt: \n            Indicates the number of considered choice alternatives.\n        int equal_alt: \n            Indicates the maximum number of equal choice alternatives per choice set.\n    \n    Keyword-arguments for instantiation (ov.Core(...))::\n    \n        boolean include_weights: \n            If this is set to True, the model will search for a\n            column in the input-data, called \"weight\", which indicates the weight\n            for each observation. Defaults to True.\n    \n    Keyword-arguments for estimation-method (model.estimate_mixed_logit(...))::\n    \n        int min_inter: \n            Min. iterations for EM-algorithm.\n        int max_iter: \n            Max. iterations for EM-algorithm.\n        float tol: \n            Numerical tolerance of EM-algorithm.\n        bool bit_64: \n            Defaults to False. If set to True, all numbers are calculated\n            in 64-bit format, which increases precision, but also runtime.\n        str space_method: \n            Defines the chosen method to span the parameter space for the mixed logit estimation.\n        int scale_space: \n            Defines the size of the space, relative to the chosen space_method.\n        int max_shares: \n            Defines the maximum number of points to be observed in the parameter space.\n\n      \n6. Visualize the estimated preferences::\n\n    model.visualize_space(\n        k=2, \n        scale_individual=True, \n        cluster_method='kmeans', \n        external_points=np.array([model.initial_point]),\n        bw_adjust=0.03,\n        names_choice_options={0: \"ICEV\", 1: \"PHEV\", 2: \"BEV\", 3: \"FCEV\"}\n        )\n\n    Keyword-arguments::\n           \n        int k:\n            Number of preference clusters to be analyzed.\n        boolean scale_individual:\n            Scales the visualized preferences to fit the bounds (-1, 1),\n            to ease the comparability of preferences between different model attributes.\n        str cluster_method:\n            Defines the clustering algorithm for the identification of\n            diverging preference groups.\n        array external_points:\n            An array of preferences to be visualized in the figure as \n            a reference point. In this case, the mean preferences of the \n            base population are visualized with \"model.initial_point\"\n        float bw_adjust:\n            Smoothing parameter for the displayed preference distribution.\n        dict names_choice_options:\n            This dictionary can be used to define the names of the choice options.\n            \n7. Simulate the choice probabilities for each choice options in diverging scenarios (more exemplary use cases of this method can be found in the script example_estimation.py)::\n    \n    model.forecast(method='MNL', \n                sense_scenarios={\"Cheap_EV\": {\n                    \"PURCHASE_PRICE\": [[1.1], [1.1], [0.5], [0.5]]}\n                    },\n                names_choice_options={0: \"ICEV\", 1: \"PHEV\", 2: \"BEV\", 3: \"FCEV\"},\n                name_scenario='sensitivity'\n                )\n\n    Keyword-arguments::\n           \n        str method:\n            Defines the type of choice model to be used among \n            \"MNL\" (Multinomial logit), \"LC\" (Latent class), and \"MXL\" (Mixed logit) \n        dict sense_scenarios:\n            Can be used to define diverging scenarios from the base scenario,\n            which is defined by the mean values in the base data. The values\n            indicate scaling factors by which the attributes are changed.\n            E.g., a value of 1.1 for the attribute \"PURCHASE_PRICE\" indicates\n            a 10% increase in the purchase price for the respective choice option.\n        dict names_choice_options:\n            This dictionary can be used to define the names of the choice options.\n        str name_scenario:\n            This string can be defined to declare the scenario name. It is \n            used to store the generated visualization under this name \n            in the output folder \"./mode_behave_public/Visualizations/\"\n               \n\nTesting\n=======\n\nThe software includes testing routines, written with the package *unittest*, \nto ensure its functionality throughout the development process. \nThe first test-routine checks the functionality\nof the estimation routines (PATH: *./test/test_estimation.py*), while the second\ntest routine checks the functionality of simulation routines \n(PATH: *./test/test_simulation.py*)\n\nThese testing routines can be activated in two ways:\n\n1. Via GitHub Actions:\n    Whenever a new commit is pushed to the repository, GitHub Actions\n    are automatically triggered, which execute the test routines.\n    The test results are displayed in the GitHub Actions tab in the \n    software's repository online.\n2. Via manual execution:\n    Alternatively, the test routines can be called manually. You might chose\n    this option, if you develop the software locally and want to validate \n    your changes before pushing a new commit. To execute the existing test \n    routines manually, open the (Anaconda) prompt and enter these commands::\n        \n        cd \"PATH_TO_MODULE/test/\"\n        python -m unittest test_estimation.py\n        python -m unittest test_simulation.py\n        \n    These commands execute the two test routines for estimation and simulation.\n    Substitute *PATH_TO_MODULE* with the path to the repository's home\n    directory on your local machine.\n        \n\nIf new features are added to the software, there should also be new test\nroutines added, which check their sustained functionality thoughout the \ndevelopment process (test-driven development).\n    \n\nStructure of Parameters and Input Data\n======================================\n\n1. Input data\n\n   The input dataset contains the observations with which the model is \n   calibrated. The input data is called with the specified string of the\n   keyword-argument *data_in*. The input data must be loaded from .csv- or \n   .pickle-format before model initialization.\n   The data shall follow the structure below::\n   \n       Rows: \n           Observations.\n       \n       Columns:\n           One column per parameter of the utility function AND per alternative AND per equal alternative.\n           Specified as: **'Attribute_name_' + str(no_alternative) + str(no_equal_alternative)**\n           \n           One column for the choice-indication of EACH alternative AND per equal alternative.\n           Specified as: **choice_' + str(no_alternative) + str(no_equal_alternative)**\n           \n           One column per alternative AND per equal alternative, indicating the availability.\n           Specified as: **'av_' + str(no_alternative) + str(no_equal_alternative)**\n           \n           If a parameter is constant across alternatives or equal alternatives, then let the columns be equal.\n           \n           Furthermore, the observations can be given a weight. Therefore, an additional column needs to be provided, named 'weight'. - Without any further suffix.\n       \n       Index: The index shall start from '0'.\n          \n2. Initialization argument 'param':\n    \n   'param' is specified as a dictionary containing the attribute names of the \n   utility function, sorted by type::\n   \n       param['constant']['fixed']: \n           Attributes, which are constant over choice \n           options and fixed within the parameter space. \n       param['constant']['random']: \n           Attributes, which are constant over choice \n           options and randomly distributed over the parameter space. \n       param['variable']['fixed']: \n           Attributes, which vary over choice \n           options and are fixed within the parameter space. \n       param['variable']['random']: \n           Attributes, which vary over choice \n           options and are randomly distributed over the parameter space. \n     \n3. The vector x, containing the initial estimates for the logit coefficients.\n\n   The coefficients in vector x (solution vector of maximum likelihood optimization)\n   follow a certain structure (alternatives=alt)::\n   \n       x[:(alt-1)]: \n           ASC-constants for the alternatives 1-#of alternatives. ASC for choice option 0 defaults to 0.\n       x[(alt-1):(alt-1)+no_constant_fixed]: \n           Coefficients of constant and fixed attributes.\n       x[(alt-1)+no_constant_fixed:(alt-1)+(no_constant_fixed+no_constant_random)]: \n           Coefficients of constant and fixed attributes.   \n       x[(alt-1)+(no_constant_fixed+no_constant_random):(alt-1)+(no_constant_fixed+no_constant_random)+no_variable_fixed*alt]: \n           Coefficients of variable (thus multiplication with alternatives) \n           and fixed attributes.\n       x[(alt-1)+(no_constant_fixed+no_constant_random)+no_variable_fixed*alt:(alt-1)+(no_constant_fixed+no_constant_random)+(no_variable_fixed+no_variable_random)*alt]: \n           Coefficients of variable and random attributes.\n      \nTheoretical Background\n======================\nA mixed logit model is a multinomial logit model (MNL), in which the coefficients \ndo not take a single value, but are distributed over a parameter space. \nWithin this package, the mixed logit models \nare estimated on a discrete parameter space, which is specified by the researcher (nonparametric design).\nThe discrete subsets of the parameter space are called classes, \nanalogously to latent class models (LCM). The goal of the estimation procedure\nis to estimate the optimal share, i.e. weight, of each class within the discrete parameter space.\nThe algorithm roughly follows the procedure below:\n\n1. Estimate initial coefficients of a standard multinomial logit model.\n2. Specify a continuous parameter space for the random coefficients with\n   the mean and the standard deviation of each initially calculated random coefficient. \n   (The standard deviation can be calculated from a k-fold cross-validation.)\n   Alternatively, the parameter space can be defined via the absolute values\n   of the parameters.\n3. Draw points (maximum number of point = -max_shares-) from the parameter space via latin hypercube sampling.\n3. Estimate the optimal share for each drawn point with an expectation-maximization (EM) algorithm. (see Train, 2009)\n\n      \nFurther reading:\n\n* Train, K. (2009): \"Mixed logit\", in Discrete choice methods with simulation (pp. 76–93), Cambridge University Press\n* Train, K. (2008): \"EM algorithms for nonparametric estimation of mixing distributions\", in Journal of Choice Modelling, 1(1), 40–69, https://doi.org/10.1016/S1755-5345(13)70022-8\n* Train, K. (2016): \"Mixed logit with a flexible mixing distribution\", in Journal of Choice Modelling, 19, 40–53, https://doi.org/10.1016/j.jocm.2016.07.004\n* McFadden, D. and Train, K. (2000): \"Mixed MNL models for discrete response\", in Journal of Applied Econometrics, 15(5), 447-470, https://www.jstor.org/stable/2678603 \n\nPost-Analysis\n=============\n\n1. Access of estimated coefficients and summary statistics::\n        \n    model.shares: \n        Estimated shares of discrete classes within parameter space.\n    model.points: \n        Parameter space of random coefficients.\n    model.initial_point: \n        Coefficients of initially estimated logit model.\n     \n2. Visualization of parameter space::\n\n    model.visualize_space(**kwargs)\n      \n    int k:\n        k incidates the number of cluster centers, \n        to which the estimated random parameters \n        of the mixed logit model shall be attributed. \n        \n    The cluster centers indicate different potential choice or consumer groups. \n    This method clusters the estimated random preferences and shows \n    the position of the cluster centers as well as the overall distribution\n    of estimated random parameters across the whole parameter space.\n      \n3. Forecast with cluster centers::\n\n    model.forecast(method, **kwargs)\n                \n    str method:\n        \"method\" indicates the type of the discrete choice model (\"MNL\", \"MXL\", or \"LC\" for latent class).\n    int k:\n        Also \"k\" can be given to indicate the number of cluster centers which shall be analyzed.\n    dict sense_scenarios:\n        Indicates the relative change in the value of selected model attributes.\n        This keyword is useful for conducting sensitivity analyses.\n    list av_external:\n        This parameter is used to externally define the availabilities of certain\n        choice options. E.g., if a choice option shall be excluded from the simulation.\n        \n    This method forecasts the mean choice, based on the estimated parameters \n    of each cluster center and the attribute values of the base data. \n    It is a good reference point to study the diverging choice\n    behavior of each cluster center.\n\n4. Cluster the drawn points from the parameter space to similar preference groups (e.g. consumer groups)::\n\n    model.cluster_space(method, k, **kwargs)\n    \n    str method:\n        Indicates the clustering algorithm, e.g. kmeans. \n    int k:\n        Indicates the number of cluster centers.\n    \n    The output of this method is the classification of the drawn points\n    from the parameter space into clusters. The second output are\n    the calculated cluster centers. The clusters can be interpreted as consumer groups.\n\n5. Assignment of observations to cluster centers::\n    \n    model.assign_to_cluster(**kwargs)\n    \n    This method calculates probabilities for each observation in the base data,\n    which indicate the likelihood with which an observation belongs to a \n    cluster center (the method internally calls self.cluster_space to\n    determine the cluster centers). \n    This method is useful to characterize the consumer groups.\n          \nSimulation\n==========\n\nThe model incorporates a class **Simulation**, which contains customized\nmethods to simulate previously estimated choice models.\nIn order to simulate choice probabilities, the model must be instantiated as follows::\n\n   model = mb.Core(model_type = 'simulation', simulation_type = 'mode_choice')\n   \n   str simulation_type:\n       Specifies which kind of simulation shall be conducted.\n       Currently only MNL-simulations are implemented.\n\nThe following MNL-simulations are currently available:\n\n**MNL-Model for Mode-Choice (simulation_type = 'mode_choice')**::\n\n    model.simulate_mode_choice(agegroup, occupation, regiontype, distance, av)\n    \nThe method simulates the probability of mode choice for ten different modes\n(Walking, Biking, MIV-self, MIV-co, bus_near, train_near, train_city, bus_far, train_far, carsharing).\nInput parameters are the agegroup of the simulated agent (1: <18, 2: 18-65, 3: >65),\nthe occupation (1: full-time work, 2: part-time, 3: education, 4: no occupation),\nthe regiontype of residence (according to RegioStaR7 - BMVI classification),\ndistance (travel cost and time are derived from this variable, based on \ncost-assumptions for the year 2020. Also, the regiontype for the calculation\nof average speeds is assumed to be identical with the specified regiontype\nof the home location of the agent),\nas well as the availability of each mode in numpy-array format.\nFilename of pre-estimated model parameters: 'initial_point_mode'\n\n**MNL-model for the probability of the number of cars per households (simulation_type = 'car_ownership')**::\n\n   model.simulate_hh_cars(regiontype, hh_size,\n                        adults_working, children, htype, quali_opnv, sharing,\n                        relative_cost_per_car, age_adults)\n                         \nThe method simulates the probability, that a household owns 0-3+ cars (4 discrete alternatives).\nInput parameters are the regiontype of residence in I/O-format according to \nRegioStaR7 BMVI classification (e.g.: regiontype = 1 for \"Metropolis\"),\nthe household size (hh_size), the number of working adults (adults_working),\nthe number of children in the household (children), the housing type (htype)\nin I/O-format (e.g.: 1, if individual house, 0, if multi-apartment house),\nthe quality of public transport in the residence area (1: Very Bad, 2: Bad, 3: Good, 4: Very Good),\nwhether the household holds a carsharing-membership (sharing), the\nratio of the average car price divided by net monthly household income (relative_cost_per_car).\nAverage market prices can be derived from Kraus' vehicle cost model.\nLast input parameter is the average age of the adults, living in the household,\nscaled by *0.1!"
        },
        {
            "software_organization": "https://helmholtz.software/software/moovie",
            "repo_link": "https://jugit.fz-juelich.de/IBG-1/ModSim/MooViE",
            "readme": "# <img src=\"docs/source/images/logo.png\" alt=\"MooViE\" width=\"500\"/>\n\nMooViE is an easy-to-use tool to display multidimensional data with input-output semantics from all research domains.\nIt is developed at the [Institute of Bio- and Geosciences 1: Biotechnology](https://www.fz-juelich.de/en/ibg/ibg-1) (IBG-1) of the [Forschungszentrum Jülich](https://www.fz-juelich.de/en). \nMooViE supports researcher in studying the mapping of several inputs to several outputs in large multivariate data\nsets. MooViE comes with a simple graphical user interface (GUI) that allows the user to interactively filter the \ndata and configure the style. For reproducibility and pipeline integration also a command line interface and an\nAPI are available.\n\n<div align=\"center\">\n<img src=\"docs/source/images/red.png\" alt=\"MooViE scene\" width=\"500\">\n</div>\n\n## Documentation\n\nCheck out the official documentation on [readthedocs](https://moovie.readthedocs.io).\n\n## Contributing\n\nContriubtions are very welcome.\n**For any form of collaboration us through our gitlab instance [jugit](https://jugit.fz-juelich.de/IBG-1/ModSim/MooViE).**\nLogin there is possible through Helmholtz AAI e.g. with your Google or GitHub account.",
            "project_id": "2060"
        },
        {
            "software_organization": "https://helmholtz.software/software/mptrac",
            "repo_link": "https://github.com/slcs-jsc/mptrac",
            "readme": "# Massive-Parallel Trajectory Calculations\n\nMassive-Parallel Trajectory Calculations (MPTRAC) is a Lagrangian particle dispersion model for the analysis of atmospheric transport processes in the free troposphere and stratosphere.\n\n![logo](https://github.com/slcs-jsc/mptrac/blob/master/docs/logo/MPTRAC_320px.png)\n\n[![release (latest by date)](https://img.shields.io/github/v/release/slcs-jsc/mptrac)](https://github.com/slcs-jsc/mptrac/releases)\n[![commits since latest release (by SemVer)](https://img.shields.io/github/commits-since/slcs-jsc/mptrac/latest)](https://github.com/slcs-jsc/mptrac/commits/master)\n[![last commit](https://img.shields.io/github/last-commit/slcs-jsc/mptrac.svg)](https://github.com/slcs-jsc/mptrac/commits/master)\n[![top language](https://img.shields.io/github/languages/top/slcs-jsc/mptrac.svg)](https://github.com/slcs-jsc/mptrac/tree/master/src)\n[![code size in bytes](https://img.shields.io/github/languages/code-size/slcs-jsc/mptrac.svg)](https://github.com/slcs-jsc/mptrac/tree/master/src)\n[![codacy](https://api.codacy.com/project/badge/Grade/a9de7b2239f843b884d2a4eb583726c9)](https://app.codacy.com/gh/slcs-jsc/mptrac?utm_source=github.com&utm_medium=referral&utm_content=slcs-jsc/mptrac&utm_campaign=Badge_Grade_Settings)\n[![codecov](https://codecov.io/gh/slcs-jsc/mptrac/branch/master/graph/badge.svg?token=4X6IEHWUBJ)](https://codecov.io/gh/slcs-jsc/mptrac)\n[![tests](https://img.shields.io/github/actions/workflow/status/slcs-jsc/mptrac/tests.yml?branch=master&label=tests)](https://github.com/slcs-jsc/mptrac/actions)\n[![docs](https://img.shields.io/github/actions/workflow/status/slcs-jsc/mptrac/docs.yml?branch=master&label=docs)](https://slcs-jsc.github.io/mptrac)\n[![license](https://img.shields.io/github/license/slcs-jsc/mptrac.svg)](https://github.com/slcs-jsc/mptrac/blob/master/COPYING)\n[![doi](https://zenodo.org/badge/DOI/10.5281/zenodo.4400597.svg)](https://doi.org/10.5281/zenodo.4400597)\n\n## Features\n\n* MPTRAC calculates air parcel trajectories by solving the kinematic equation of motion using given horizontal wind and vertical velocity fields from global reanalyses or forecasts.\n* Mesoscale diffusion and subgrid-scale wind fluctuations are simulated using the Langevin equation to add stochastic perturbations to the trajectories. A new inter-parcel exchange module represents mixing of air.\n* Additional modules are implemented to simulate convection, sedimentation, exponential decay, gas and aqueous phase chemistry, and wet and dry deposition.\n* Meteorological data pre-processing code provides estimates of the boundary layer, convective available potential energy, geopotential heights, potential vorticity, and tropopause data.\n* Various output methods for particle, grid, ensemble, profile, sample, and station data. Gnuplot and ParaView interfaces for visualization.\n* MPI-OpenMP-OpenACC hybrid parallelization and distinct code optimizations for efficient use from single workstations to HPC and GPU systems.\n* Distributed open source under the terms of the GNU GPL.\n\n## Getting started\n\n### Prerequisites\n\nThis README file describes how to install MPTRAC on a Linux system.\n\nThe following software dependencies are required to compile MPTRAC:\n\n* the [GNU make](https://www.gnu.org/software/make) build tool\n* the C compiler of the [GNU Compiler Collection (GCC)](https://gcc.gnu.org)\n* the [GNU Scientific Library (GSL)](https://www.gnu.org/software/gsl) for numerical calculations\n* the [netCDF library](http://www.unidata.ucar.edu/software/netcdf) for file-I/O\n\nThe following optional software is required to enable additional features of MPTRAC:\n\n* the distributed version control system [Git](https://git-scm.com/) to access the code repository\n* the [HDF5 library](https://www.hdfgroup.org/solutions/hdf5) to enable the netCDF4 file format\n* the [Zstandard library](https://facebook.github.io/zstd) and the [zfp library](https://computing.llnl.gov/projects/zfp) for compressed meteo data\n* the [NVIDIA HPC Software Development Kit](https://developer.nvidia.com/hpc-sdk) for GPU support\n* an MPI library such as [OpenMPI](https://www.open-mpi.org) or [ParaStationMPI](https://github.com/ParaStation/psmpi) for HPC support\n* the graphing utility [gnuplot](http://www.gnuplot.info) for visualization\n\nSome of the software is provided along with the MPTRAC repository, please see next section.\n\n### Installation\n\nStart by downloading the latest or one of the previous [MPTRAC releases](https://github.com/slcs-jsc/mptrac/releases). Unzip the release file:\n\n    unzip mptrac-x.y.zip\n\nAlternatively, you can get the development version of the software from the GitHub repository:\n\n    git clone https://github.com/slcs-jsc/mptrac.git\n\nSeveral libraries shipped along with MPTRAC can be compiled and installed by running a build script:\n\n    cd [mptrac_directory]/libs\n    ./build.sh -a\n\nThen change to the source directory and edit the `Makefile` according to your needs:\n\n    cd [mptrac_directory]/src\n    emacs Makefile\n\nIn particular, you may want to check:\n\n* Edit the `LIBDIR` and `INCDIR` paths to point to the directories where the GSL, netCDF, and other libraries are located on your system.\n\n* By default, the MPTRAC binaries are linked statically, i.e., they can be copied and used on other machines. However, sometimes static compilation causes problems, e.g., in combination with dynamically compiled GSL and netCDF libraries or when using MPI or OpenACC. In this case, disable the `STATIC` flag and remember to set the `LD_LIBRARY_PATH` to include the paths to the shared libraries.\n\n* To make use of the MPI parallelization of MPTRAC, the `MPI` flag must be enabled. Further steps will require an MPI library such as OpenMPI to be available on your system. To make use of the OpenACC parallelization, the `GPU` flag must be enabled. The NVIDIA HPC SDK is required to compile the GPU code. MPTRAC's OpenMP parallelization is always enabled.\n\nNext, try compiling the code:\n\n    make [-j]\n\nTo run the test cases to check the installation, use\n\n    make check\n\nThis will run a series of tests sequentially. It will stop if any of the tests fail. Please check the log messages.\n\n### Run the example\n\nAn example is provided to illustrate how to simulate the dispersion of volcanic ash from the eruption of the Puyehue-Cordón Caulle volcano, Chile, in June 2011.\n\nThe example can be found in the `projects/example/` subdirectory. The `projects/` subdirectory can also be used to store the results of your own simulation experiments with MPTRAC.\n\nThe example simulation is controlled by a shell script:\n\n    cd mptrac/projects/example\n    ./run.sh\n\nSee the `run.sh` script for how to invoke MPTRAC programs such as `atm_init` and `atm_split` to initialize the trajectory seeds and `trac` to compute the trajectories.\n\nThe script generates simulation output in the `examples/data` subdirectory. The corresponding reference data can be found in `examples/data.ref`.\n\nA set of plots of the simulation output at different time steps after the eruption, generated by means of the `gnuplot` plotting tool, can be found in `examples/plots`. The plots should look similar to the output provided in `examples/plots.ref`.\n\nThis is an example showing the particle positions and grid output on 6th and 8th of June 2011:\n<p align=\"center\"><img src=\"projects/example/plots.ref/atm_2011_06_06_00_00.tab.png\" width=\"45%\"/> &emsp; <img src=\"projects/example/plots.ref/grid_2011_06_06_00_00.tab.png\" width=\"45%\"/></p>\n<p align=\"center\"><img src=\"projects/example/plots.ref/atm_2011_06_08_00_00.tab.png\" width=\"45%\"/> &emsp; <img src=\"projects/example/plots.ref/grid_2011_06_08_00_00.tab.png\" width=\"45%\"/></p>\n\n## Further information\n\nThese are the main scientific publications that provide information about MPTRAC:\n\n* Hoffmann, L., Baumeister, P. F., Cai, Z., Clemens, J., Griessbach, S., Günther, G., Heng, Y., Liu, M., Haghighi Mood, K., Stein, O., Thomas, N., Vogel, B., Wu, X., and Zou, L.: Massive-Parallel Trajectory Calculations version 2.2 (MPTRAC-2.2): Lagrangian transport simulations on graphics processing units (GPUs), Geosci. Model Dev., 15, 2731–2762, https://doi.org/10.5194/gmd-15-2731-2022, 2022.\n\n* Hoffmann, L., T. Rößler, S. Griessbach, Y. Heng, and O. Stein, Lagrangian transport simulations of volcanic sulfur dioxide emissions: Impact of meteorological data products, J. Geophys. Res. Atmos., 121, 4651-4673, https://doi.org/10.1002/2015JD023749, 2016. \n\nAdditional references are collected on the [references web page](https://slcs-jsc.github.io/mptrac/references/).\n\nMore detailed information for users of MPTRAC is provided in the [user manual](https://slcs-jsc.github.io/mptrac).\n\nInformation for developers of MPTRAC can be found in the [doxygen manual](https://slcs-jsc.github.io/mptrac/doxygen).\n\n## Contributing\n\nWe are interested in supporting operational and research applications with MPTRAC.\n\nYou can submit bug reports or feature requests on the [issue tracker](https://github.com/slcs-jsc/mptrac/issues).\n\nProposed code changes and fixes can be submitted as [pull requests](https://github.com/slcs-jsc/mptrac/pulls).\n\nPlease do not hesitate to contact us if you have any questions or need assistance.\n\n## License\n\nMPTRAC is being developed at the Jülich Supercomputing Centre, Forschungszentrum Jülich, Germany.\n\nMPTRAC is distributed under the terms of the [GNU General Public License v3.0](https://github.com/slcs-jsc/mptrac/blob/master/COPYING).\n\nPlease see the [citation file](https://github.com/slcs-jsc/mptrac/blob/master/CITATION.cff) for more information about citing the MPTRAC model in scientific publications.\n\n## Contact\n\nDr. Lars Hoffmann\n\nJülich Supercomputing Centre, Forschungszentrum Jülich\n\ne-mail: l.hoffmann@fz-juelich.de\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mss",
            "repo_link": "https://github.com/Open-MSS/MSS",
            "readme": "**Chat:**\n[![IRC: #mss-general on libera.chat](https://img.shields.io/badge/libera.chat-%23MSS_General-blue)](https://web.libera.chat/?channels=#mss-general)\n[![IRC: #mss-gsoc on libera.chat](https://img.shields.io/badge/libera.chat-%23MSS_GSoC-brightgreen)](https://web.libera.chat/?channels=#mss-gsoc)\n\n\nMission Support System Usage Guidelines\n=======================================\n\nWelcome to the Mission Support System software for planning\natmospheric research flights. This document is intended to point you\ninto the right direction in order to get the software working on your\ncomputer.\n\n\nInstalling MSS\n==============\n\nAutomatically\n-------------\n\n- For **Windows**, go [here](https://github.com/Open-MSS/mss-install/blob/main/Windows.bat?raw=1)\n    - Right click on the webpage and select \"Save as...\" to download the file\n    - Double click the downloaded file and follow further instructions\n        - For fully automatic installation, open cmd and execute it with `/Path/To/Windows.bat -a`\n- For **Linux/Mac**, go [here](https://github.com/Open-MSS/mss-install/blob/main/LinuxMac.sh?raw=1)\n    - Right click on the webpage and select \"Save as...\" to download the file\n    - Make it executable via `chmod +x LinuxMac.sh`\n    - Execute it and follow further instructions `./LinuxMac.sh`\n        - For fully automatic installation, run it with the -a parameter `./LinuxMac.sh -a`\n\nManually\n--------\n\nAs **Beginner** start with an installation of Miniforge\nGet [miniforge](https://github.com/conda-forge/miniforge#download) for your Operation System\n\n\nYou must install mss into a new environment to ensure the most recent\nversions for dependencies (On the Anaconda Prompt on Windows, you have\nto leave out the 'source' here and below).\n\n```\n  $ mamba create -n mssenv\n  $ mamba activate mssenv\n  (mssenv) $ mamba install mss python\n```\nFor updating an existing MSS installation to the current version, it is\nbest to install it into a new environment. If an existing environment\nshall be updated, it is important to update all packages in this\nenvironment.\n\n```\n  $ mamba activate mssenv\n  (mssenv) $ msui --update\n```\n\nIt is possible to list all versions of `mss` available on your platform with:\n\n```\n    $ mamba search mss --channel conda-forge\n```\n\nFor a simple test you can setup a demodata wms server and start a msolab server with default settings\n\n```\n  (mssenv) $ mswms_demodata --seed\n  (mssenv) $ export PYTHONPATH=~/mss\n  (mssenv) $ mswms &\n  (mssenv) $ mscolab start &\n  (mssenv) $ msui\n```\n\n\n\n\nCurrent release info\n====================\n[![Conda Version](https://img.shields.io/conda/vn/conda-forge/mss.svg)](https://anaconda.org/conda-forge/mss)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6572620.svg)](https://doi.org/10.5281/zenodo.6572620)\n[![JuRSE Code Pick](https://img.shields.io/badge/JuRSE_Code_Pick-July_2024-blue)](https://www.fz-juelich.de/en/rse/jurse-community/jurse-code-of-the-month/july-2024)\n[![Conda Platforms](https://img.shields.io/conda/pn/conda-forge/mss.svg)](https://anaconda.org/conda-forge/mss)\n[![DOCS](https://img.shields.io/badge/%F0%9F%95%AE-docs-green.svg)](https://mss.rtfd.io)\n[![Conda Recipe](https://img.shields.io/badge/recipe-mss-green.svg)](https://anaconda.org/conda-forge/mss)\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/mss.svg)](https://anaconda.org/conda-forge/mss)\n[![Coverage Status](https://coveralls.io/repos/github/Open-MSS/MSS/badge.svg?branch=develop)](https://coveralls.io/github/Open-MSS/MSS?branch=develop)\n\n\n\n\n\nPublications\n============\n\nPlease read the reference documentation\n\n   Bauer, R., Grooß, J.-U., Ungermann, J., Bär, M., Geldenhuys, M., and Hoffmann, L.: The Mission Support\n   System (MSS v7.0.4) and its use in planning for the SouthTRAC aircraft campaign, Geosci.\n   Model Dev., 15, 8983–8997, https://doi.org/10.5194/gmd-15-8983-2022, 2022.\n\n   Rautenhaus, M., Bauer, G., and Doernbrack, A.: A web service based\n   tool to plan atmospheric research flights, Geosci. Model Dev., 5,\n   55-71, https://doi.org/10.5194/gmd-5-55-2012, 2012.\n\nand the paper's Supplement (which includes a tutorial) before using the\napplication. The documents are available at:\n\n- http://www.geosci-model-dev.net/5/55/2012/gmd-5-55-2012.pdf\n- http://www.geosci-model-dev.net/5/55/2012/gmd-5-55-2012-supplement.pdf\n\nFor copyright information, please see the files NOTICE and LICENSE, located\nin the same directory as this README file.\n\n\n   When using this software, please be so kind and acknowledge its use by\n   citing the above mentioned reference documentation in publications,\n   presentations, reports, etc. that you create. Thank you very much.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/mtress",
            "repo_link": "https://github.com/mtress/mtress",
            "readme": "# Model Template for Renewable Energy Supply Systems (MTRESS)\n\nThis is a generic model for [oemof.solph](https://github.com/oemof/oemof-solph/)\nthat provides a variety of possible technology combinations for energy supply systems.\nIt is tailored for optimising control strategies fulfilling fixed demand time series\nfor electricity, heat, and domestic hot water using any selected combination\nof the implemented supply technologies.\n\nThe development of Version 2 was funded by the Federal Ministry for Economic Affairs and Energy (BMWi)\nand the Federal Ministry of Education and Research (BMBF) of Germany\nin the project ENaQ (project number 03SBE111).\nThe development of the heat sector formulations in Version 3 was funded by the Federal Ministry of\nEducation and Research (BMBF) of Germany in the project Wärmewende Nordwest (project number 03SF0624).\n\n\n## Installation\n\nMTRESS depends on solph, which is automatically instaled using pip\nif you `pip install mtress`. However, pip will not install a solver,\nto perform the actual optimisation. Please refer to the\n[documentation of solph](https://oemof-solph.readthedocs.io/en/v0.4.4/readme.html#installing-a-solver)\nto learn how to install a solver.\n\n\n## Contributing\n\nYou are welcome to contribute to MTRESS. We use [Black code style](https://black.readthedocs.io/),\nand put our code under [MIT license](LICENSE). When contributing, you need to do the same.\nFor smaller changes, you can just open a merge request. If you plan something bigger,\nplease open an issue first, so that we can discuss beforehand and avoid double work.\n\n\n## Contact\n\nThe software development is administrated by [Patrik Schönfeldt](mailto:patrik.schoenfeldt@dlr.de),\nfor general questions please contact him. Individual authors may leave their contact information\nin the [citation.cff](CITATION.cff).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/multiphase-code-repository-by-hzdr",
            "repo_link": "https://codebase.helmholtz.cloud/fwdc/multiphase/code",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/nest",
            "repo_link": "https://github.com/nest/nest-simulator",
            "readme": "# The Neural Simulation Tool - NEST\n\n[![Documentation](https://img.shields.io/readthedocs/nest-simulator?logo=readthedocs&logo=Read%20the%20Docs&label=Documentation)](https://nest-simulator.org/documentation)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/2218/badge)](https://bestpractices.coreinfrastructure.org/projects/2218)\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/nest/nest-simulator/badge)](https://scorecard.dev/viewer/?uri=github.com/nest/nest-simulator)\n[![License](http://img.shields.io/:license-GPLv2+-green.svg)](http://www.gnu.org/licenses/gpl-2.0.html)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10834751.svg)](https://doi.org/10.5281/zenodo.10834751)\n\n[![Latest release](https://img.shields.io/github/release/nest/nest-simulator.svg?color=brightgreen&label=latest%20release)](https://github.com/nest/nest-simulator/releases)\n[![GitHub contributors](https://img.shields.io/github/contributors/nest/nest-simulator?logo=github)](https://github.com/nest/nest-simulator)\n[![GitHub commit activity](https://img.shields.io/github/commit-activity/y/nest/nest-simulator?logo=github&color=%23ff6633)](https://github.com/nest/nest-simulator)\n\n[![Ubuntu version](https://img.shields.io/badge/ubuntu-(PPA)-blue?logo=debian)](https://nest-simulator.readthedocs.io/en/latest/installation/)\n[![Fedora package](https://img.shields.io/fedora/v/nest?logo=fedora)](https://src.fedoraproject.org/rpms/nest)\n[![conda-forge version](https://img.shields.io/conda/vn/conda-forge/nest-simulator.svg?logo=conda-forge&logoColor=white)](https://anaconda.org/conda-forge/nest-simulator)\n[![Homebrew version](https://img.shields.io/homebrew/v/nest.svg?logo=apple)](https://formulae.brew.sh/formula/nest)\n[![Docker Image Version](https://img.shields.io/docker/v/nest/nest-simulator?color=blue&label=docker&logo=docker&logoColor=white&sort=semver)](https://hub.docker.com/r/nest/nest-simulator)\n[![Virtual applicance](https://img.shields.io/badge/VM-v3.7-blue?logo=CodeSandbox)](https://nest-simulator.readthedocs.io/en/latest/installation/livemedia.html#live-media)\n\n[![YouTube Video Views](https://img.shields.io/youtube/views/K7KXmIv6ROY?style=social)](https://www.youtube.com/results?search_query=nest-simulator+neurons)\n[![Twitter Follow](https://img.shields.io/twitter/follow/nestsimulator?style=social)](https://twitter.com/nestsimulator)\n\nNEST is a simulator for spiking neural network models that focuses on the\ndynamics, size and structure of neural systems rather than on the exact\nmorphology of individual neurons.\n\nA NEST simulation tries to follow the logic of an electrophysiological\nexperiment that takes place inside a computer with the difference that the\nneural system to be investigated must be defined by the experimenter.\n\nNEST is ideal for networks of spiking neurons of any size, for example:\n\n- Models of information processing, e.g., in the visual or auditory cortex of\n  mammals,\n- Models of network activity dynamics, e.g., laminar cortical networks or\n  balanced random networks,\n- Models of learning and plasticity.\n\n## Key features of NEST\n\n* NEST provides a Python interface or a stand-alone application\n* NEST provides a large collection of [neurons and synapse models](https://nest-simulator.org/documentation/models/index.html)\n* NEST provides numerous [example network scripts](https://nest-simulator.org/documentation/examples/index.html) along with\n  [tutorials and guides](https://nest-simulator.org/documentation/get-started_index.html) to help you develop your simulation\n* NEST has a large community of experienced developers and users; NEST was first released in 1994 under the name SYNOD, and has been extended and improved ever since\n* NEST is extensible: you can extend NEST by adding your own modules\n* NEST is scalable: Use NEST on your laptop or the largest supercomputers\n* NEST is memory efficient: It makes the best use of your multi-core computer and compute clusters with minimal user intervention\n* NEST is an open source project and is licensed under the GNU General Public License v2 or later\n* NEST employs continuous integration workflows in order to maintain high code quality standards for correct and reproducible simulations\n\n\n## Documentation\n\nPlease visit our [online documentation](https://nest-simulator.org/documentation) for details on installing and using NEST.\n\n\n## Cite NEST\n\nIf you use NEST as part of your research, please cite the *version* of NEST you used.\nThe full citation for each release can be found on [Zenodo](https://zenodo.org/search?q=title%3ANEST%20AND%20-description%3Agraphical%20AND%20simulator&l=list&p=1&s=10&sort=publication-desc)\n\nFor general citations, please use\n\n`Gewaltig M-O & Diesmann M (2007) NEST (Neural Simulation Tool) Scholarpedia 2(4):1430.`\n\n## Contact\n\n\nIf you need help or would like to discuss an idea or issue,\njoin our [maling list](https://nest-simulator.org/documentation/developer_space/guidelines/mailing_list_guidelines.html),\nwhere we encourage active participation from our developers and users to share their knowledge and experience with NEST.\n\n\nYou can find other [ways to get in touch here](https://nest-simulator.org/documentation/community.html).\n\n\n## Contribute\n\nNEST is built on an active community and we welcome contributions to our code and documentation.\n\n\nFor bug reports, feature requests, documentation improvements, or other issues,\nyou can create a [GitHub issue](https://github.com/nest/nest-simulator/issues/new/choose),\n\nFor working with NEST code and documentation, you can find guidelines for contributions\n[in our documentation](https://nest-simulator.org/documentation/developer_space/index.html#contribute-to-nest)\n\n\n## Publications\n\nYou can find a list of NEST [related publications here](https://www.nest-simulator.org/publications/).\n\n## License\n\n\nNEST is open source software and is licensed under the [GNU General Public\nLicense v2](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html) or\nlater.\n\nGeneral information on the NEST Initiative can be found at\nits homepage at https://www.nest-initiative.org.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/nest-ml",
            "repo_link": "https://github.com/nest/nestml",
            "readme": "[![astropy](http://img.shields.io/badge/powered%20by-AstroPy-orange.svg?style=flat)](http://www.astropy.org/) [![NESTML build](https://github.com/nest/nestml/actions/workflows/nestml-build.yml/badge.svg)](https://github.com/nest/nestml/actions/)\n\n# NESTML: The NEST Modelling Language\n\nNESTML is a domain-specific language that supports the specification of neuron models in a precise and concise syntax, based on the syntax of Python. Model equations can either be given as a simple string of mathematical notation or as an algorithm written in the built-in procedural language. The equations are analyzed by the associated toolchain, written in Python, to compute an exact solution if possible or use an appropriate numeric solver otherwise.\n\n## Documentation\n\nFull documentation can be found at:\n\n<pre><p align=\"center\"><a href=\"https://nestml.readthedocs.io/\">https://nestml.readthedocs.io/</a></p></pre>\n\n## Directory structure\n\n`models` - Example neuron models in NESTML format.\n\n`pynestml` - The source code of the PyNESTML toolchain.\n\n`tests` - A collection of tests for testing of the toolchain's behavior.\n\n`doc` - The documentation of the modeling language NESTML as well as processing toolchain PyNESTML.\n\n`extras` - Miscellaneous development tools, editor syntax highlighting rules, etc.\n\n## License\n\nCopyright (C) 2017 The NEST Initiative\n\nNESTML is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 2 of the License, or (at your option) any later version.\n\nNESTML is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License along with NESTML. If not, see <http://www.gnu.org/licenses/>.\n\n## Acknowledgements\n\nThis software was initially supported by the JARA-HPC Seed Fund *NESTML - A modeling language for spiking neuron and synapse models for NEST* and the Initiative and Networking Fund of the Helmholtz Association and the Helmholtz Portfolio Theme *Simulation and Modeling for the Human Brain*.\n\nThis software was developed in part or in whole in the Human Brain Project, funded from the European Union's Horizon 2020 Framework Programme for Research and Innovation under Specific Grant Agreements No. 720270, No. 785907 and No. 945539 (Human Brain Project SGA1, SGA2 and SGA3).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/nuclear-nexus",
            "repo_link": "https://gitlab.desy.de/fs-mcp/nuclear-nexus",
            "readme": "# Nexus - Nuclear Elastic X-ray scattering Universal Software\n\nThe *Nuclear Elastic X-ray scattering Universal Software* (*NEXUS*) is a *Python* package for simulating and fitting of\n\n* Moessbauer spectra\n* nuclear resonant scattering (NRS) data\n* pure electronic X-ray reflectivities (XRR)\n* nuclear X-ray reflectivities (nXRR)\n* polarization dependent electronic scattering.\n\n## Documentation\n\n[comment]: http://lars.bocklage.pages.hzdr.de/nuclearnexus\n\nhttps://fs-mcp.pages.desy.de/nuclear-nexus/\n\n## Support\nIn case you find bugs, need support in using the software, have questions on how to setup an evaluation, or you need additional features, please contact:\n\nLars Bocklage - lars.bocklage@desy.de\n\nMany thanks go to Leon Merten Lohse for setting up the GitLab environment and all users for feedback and bug reports.\n",
            "project_id": "6038"
        },
        {
            "software_organization": "https://helmholtz.software/software/nnu-net",
            "repo_link": "https://github.com/MIC-DKFZ/nnUNet",
            "readme": "# Welcome to the new nnU-Net!\n\nClick [here](https://github.com/MIC-DKFZ/nnUNet/tree/nnunetv1) if you were looking for the old one instead.\n\nComing from V1? Check out the [TLDR Migration Guide](documentation/tldr_migration_guide_from_v1.md). Reading the rest of the documentation is still strongly recommended ;-)\n\n## **2024-04-18 UPDATE: New residual encoder UNet presets available!**\nResidual encoder UNet presets substantially improve segmentation performance.\nThey ship for a variety of GPU memory targets. It's all awesome stuff, promised! \nRead more :point_right: [here](documentation/resenc_presets.md) :point_left:\n\nAlso check out our [new paper](https://arxiv.org/pdf/2404.09556.pdf) on systematically benchmarking recent developments in medical image segmentation. You might be surprised!\n\n# What is nnU-Net?\nImage datasets are enormously diverse: image dimensionality (2D, 3D), modalities/input channels (RGB image, CT, MRI, microscopy, ...), \nimage sizes, voxel sizes, class ratio, target structure properties and more change substantially between datasets. \nTraditionally, given a new problem, a tailored solution needs to be manually designed and optimized  - a process that \nis prone to errors, not scalable and where success is overwhelmingly determined by the skill of the experimenter. Even \nfor experts, this process is anything but simple: there are not only many design choices and data properties that need to \nbe considered, but they are also tightly interconnected, rendering reliable manual pipeline optimization all but impossible! \n\n![nnU-Net overview](documentation/assets/nnU-Net_overview.png)\n\n**nnU-Net is a semantic segmentation method that automatically adapts to a given dataset. It will analyze the provided \ntraining cases and automatically configure a matching U-Net-based segmentation pipeline. No expertise required on your \nend! You can simply train the models and use them for your application**.\n\nUpon release, nnU-Net was evaluated on 23 datasets belonging to competitions from the biomedical domain. Despite competing \nwith handcrafted solutions for each respective dataset, nnU-Net's fully automated pipeline scored several first places on \nopen leaderboards! Since then nnU-Net has stood the test of time: it continues to be used as a baseline and method \ndevelopment framework ([9 out of 10 challenge winners at MICCAI 2020](https://arxiv.org/abs/2101.00232) and 5 out of 7 \nin MICCAI 2021 built their methods on top of nnU-Net, \n [we won AMOS2022 with nnU-Net](https://amos22.grand-challenge.org/final-ranking/))!\n\nPlease cite the [following paper](https://www.google.com/url?q=https://www.nature.com/articles/s41592-020-01008-z&sa=D&source=docs&ust=1677235958581755&usg=AOvVaw3dWL0SrITLhCJUBiNIHCQO) when using nnU-Net:\n\n    Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring \n    method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n\n\n## What can nnU-Net do for you?\nIf you are a **domain scientist** (biologist, radiologist, ...) looking to analyze your own images, nnU-Net provides \nan out-of-the-box solution that is all but guaranteed to provide excellent results on your individual dataset. Simply \nconvert your dataset into the nnU-Net format and enjoy the power of AI - no expertise required!\n\nIf you are an **AI researcher** developing segmentation methods, nnU-Net:\n- offers a fantastic out-of-the-box applicable baseline algorithm to compete against\n- can act as a method development framework to test your contribution on a large number of datasets without having to \ntune individual pipelines (for example evaluating a new loss function)\n- provides a strong starting point for further dataset-specific optimizations. This is particularly used when competing \nin segmentation challenges\n- provides a new perspective on the design of segmentation methods: maybe you can find better connections between \ndataset properties and best-fitting segmentation pipelines?\n\n## What is the scope of nnU-Net?\nnnU-Net is built for semantic segmentation. It can handle 2D and 3D images with arbitrary \ninput modalities/channels. It can understand voxel spacings, anisotropies and is robust even when classes are highly\nimbalanced.\n\nnnU-Net relies on supervised learning, which means that you need to provide training cases for your application. The number of \nrequired training cases varies heavily depending on the complexity of the segmentation problem. No \none-fits-all number can be provided here! nnU-Net does not require more training cases than other solutions - maybe \neven less due to our extensive use of data augmentation. \n\nnnU-Net expects to be able to process entire images at once during preprocessing and postprocessing, so it cannot \nhandle enormous images. As a reference: we tested images from 40x40x40 pixels all the way up to 1500x1500x1500 in 3D \nand 40x40 up to ~30000x30000 in 2D! If your RAM allows it, larger is always possible.\n\n## How does nnU-Net work?\nGiven a new dataset, nnU-Net will systematically analyze the provided training cases and create a 'dataset fingerprint'. \nnnU-Net then creates several U-Net configurations for each dataset: \n- `2d`: a 2D U-Net (for 2D and 3D datasets)\n- `3d_fullres`: a 3D U-Net that operates on a high image resolution (for 3D datasets only)\n- `3d_lowres` → `3d_cascade_fullres`: a 3D U-Net cascade where first a 3D U-Net operates on low resolution images and \nthen a second high-resolution 3D U-Net refined the predictions of the former (for 3D datasets with large image sizes only)\n\n**Note that not all U-Net configurations are created for all datasets. In datasets with small image sizes, the \nU-Net cascade (and with it the 3d_lowres configuration) is omitted because the patch size of the full \nresolution U-Net already covers a large part of the input images.**\n\nnnU-Net configures its segmentation pipelines based on a three-step recipe:\n- **Fixed parameters** are not adapted. During development of nnU-Net we identified a robust configuration (that is, certain architecture and training properties) that can \nsimply be used all the time. This includes, for example, nnU-Net's loss function, (most of the) data augmentation strategy and learning rate.\n- **Rule-based parameters** use the dataset fingerprint to adapt certain segmentation pipeline properties by following \nhard-coded heuristic rules. For example, the network topology (pooling behavior and depth of the network architecture) \nare adapted to the patch size; the patch size, network topology and batch size are optimized jointly given some GPU \nmemory constraint. \n- **Empirical parameters** are essentially trial-and-error. For example the selection of the best U-net configuration \nfor the given dataset (2D, 3D full resolution, 3D low resolution, 3D cascade) and the optimization of the postprocessing strategy.\n\n## How to get started?\nRead these:\n- [Installation instructions](documentation/installation_instructions.md)\n- [Dataset conversion](documentation/dataset_format.md)\n- [Usage instructions](documentation/how_to_use_nnunet.md)\n\nAdditional information:\n- [Learning from sparse annotations (scribbles, slices)](documentation/ignore_label.md)\n- [Region-based training](documentation/region_based_training.md)\n- [Manual data splits](documentation/manual_data_splits.md)\n- [Pretraining and finetuning](documentation/pretraining_and_finetuning.md)\n- [Intensity Normalization in nnU-Net](documentation/explanation_normalization.md)\n- [Manually editing nnU-Net configurations](documentation/explanation_plans_files.md)\n- [Extending nnU-Net](documentation/extending_nnunet.md)\n- [What is different in V2?](documentation/changelog.md)\n\nCompetitions:\n- [AutoPET II](documentation/competitions/AutoPETII.md)\n\n[//]: # (- [Ignore label]&#40;documentation/ignore_label.md&#41;)\n\n## Where does nnU-Net perform well and where does it not perform?\nnnU-Net excels in segmentation problems that need to be solved by training from scratch, \nfor example: research applications that feature non-standard image modalities and input channels,\nchallenge datasets from the biomedical domain, majority of 3D segmentation problems, etc . We have yet to find a \ndataset for which nnU-Net's working principle fails!\n\nNote: On standard segmentation \nproblems, such as 2D RGB images in ADE20k and Cityscapes, fine-tuning a foundation model (that was pretrained on a large corpus of \nsimilar images, e.g. Imagenet 22k, JFT-300M) will provide better performance than nnU-Net! That is simply because these \nmodels allow much better initialization. Foundation models are not supported by nnU-Net as \nthey 1) are not useful for segmentation problems that deviate from the standard setting (see above mentioned \ndatasets), 2) would typically only support 2D architectures and 3) conflict with our core design principle of carefully adapting \nthe network topology for each dataset (if the topology is changed one can no longer transfer pretrained weights!) \n\n## What happened to the old nnU-Net?\nThe core of the old nnU-Net was hacked together in a short time period while participating in the Medical Segmentation \nDecathlon challenge in 2018. Consequently, code structure and quality were not the best. Many features \nwere added later on and didn't quite fit into the nnU-Net design principles. Overall quite messy, really. And annoying to work with.\n\nnnU-Net V2 is a complete overhaul. The \"delete everything and start again\" kind. So everything is better \n(in the author's opinion haha). While the segmentation performance [remains the same](https://docs.google.com/spreadsheets/d/13gqjIKEMPFPyMMMwA1EML57IyoBjfC3-QCTn4zRN_Mg/edit?usp=sharing), a lot of cool stuff has been added. \nIt is now also much easier to use it as a development framework and to manually fine-tune its configuration to new \ndatasets. A big driver for the reimplementation was also the emergence of [Helmholtz Imaging](http://helmholtz-imaging.de), \nprompting us to extend nnU-Net to more image formats and domains. Take a look [here](documentation/changelog.md) for some highlights.\n\n# Acknowledgements\n<img src=\"documentation/assets/HI_Logo.png\" height=\"100px\" />\n\n<img src=\"documentation/assets/dkfz_logo.png\" height=\"100px\" />\n\nnnU-Net is developed and maintained by the Applied Computer Vision Lab (ACVL) of [Helmholtz Imaging](http://helmholtz-imaging.de) \nand the [Division of Medical Image Computing](https://www.dkfz.de/en/mic/index.php) at the \n[German Cancer Research Center (DKFZ)](https://www.dkfz.de/en/index.html).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/nodejs-tcp-server-client",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/Nodejs-TCP-Server-Client",
            "readme": "![NODE.JS](https://img.shields.io/badge/NODE.JS-%2343853D.svg?&style=plastic&logo=node.js&logoColor=white) ![JavaScript](https://img.shields.io/badge/JavaScript-323330?style=plastic&logo=javascript&logoColor=f7df1e) ![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/nodejs-tcp_server-client?&color=green&style=plastic)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12808924.svg)](https://doi.org/10.5281/zenodo.12808924) [![SWH](https://archive.softwareheritage.org/badge/swh:1:dir:3022219080921ea266808592fa83f3afc5242282/)](https://archive.softwareheritage.org/swh:1:dir:3022219080921ea266808592fa83f3afc5242282;origin=https://github.com/Ramy-Badr-Ahmed/node-tcp;visit=swh:1:snp:e0d42b65bc06365c756247a55b21ca431f17a53a;anchor=swh:1:rev:d9e2239926489996936d18aa5804ce1fc2503181)\n\n\n# TCP Communication with Node.js\n\nA TCP server and client implementation using Node.js's `net` module, operating at the Transport Layer of the OSI Model.\n\nThis implementation focuses on direct communication without additional overhead such as data compression or encryption/decryption, suitable for safe and trusted networks.\n\nThe TLS variant (@Presentation-Layer of the OSI Model) is located here: [Node-TLS](https://github.com/Ramy-Badr-Ahmed/node-tls)\n\n#### Some Use Cases:\n\n- Network Diagnostics \n    > Test network connectivity and latency between network segments.\n\n- Embedded Systems Communication\n  > Integrate TCP client with embedded devices (e.g. Raspberry Pi, Arduino with Ethernet/Wi-Fi shields) to send data to a central server (for monitoring and control).\n\n- Time Synchronization\n  > Use the server to provide a timestamp service for devices on a network (ensure synchronized time across various systems).\n\n- IoT Apps\n    > Use the TCP server as a central hub to collect data from various IoT devices.\n   \n    > Set up the TCP client to send sensor data periodically from remote IoT devices to the server for analysis (centralized data receiver/logger).\n  \n#### Quick Start:\nServer:\n```shell\nnpm install\nnode tcpServer.js   # Runs Server\n```\nClient:\n```shell\nnpm install\nnode tcpClient.js   # Runs Client\n```  \n\nLogs and Outputs:\n\nThe server and client will log various server/client events and actions, such as connection establishment, data transmission, and encountered errors.\n\nReferences\n\n- [Net Module](https://nodejs.org/api/net.html)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/nodejs-tls-server-client",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/Nodejs-TLS-Server-Client",
            "readme": "![NODE.JS](https://img.shields.io/badge/NODE.JS-%2343853D.svg?&style=plastic&logo=node.js&logoColor=white) ![JavaScript](https://img.shields.io/badge/JavaScript-323330?style=plastic&logo=javascript&logoColor=f7df1e) ![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/nodejs-tls_server-client?color=green&style=plastic)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12808908.svg)](https://doi.org/10.5281/zenodo.12808908) [![SWH](https://archive.softwareheritage.org/badge/swh:1:dir:8017c373f704257957a1cc9b5044c7347651b899/)](https://archive.softwareheritage.org/swh:1:dir:8017c373f704257957a1cc9b5044c7347651b899;origin=https://github.com/Ramy-Badr-Ahmed/node-tls;visit=swh:1:snp:eec57a10aaa0a231ac22e6c8a476c167a0669b66;anchor=swh:1:rev:0b48c4c274fb30ea4c7913f1d77083f9e2baa888) \n\n# TLS Communication with Node.js\n\nA TLS server and client implementation using Node.js's tls module, operating at the Presentation Layer of the OSI Model. \n\nThis implementation focuses on encrypted and authenticated communication, suitable for secure and trusted networks.\n\nThe TCP variant (@Transport-Layer of the OSI Model) is located here: [Node-TCP](https://github.com/Ramy-Badr-Ahmed/node-tcp)\n\n#### Use Cases:\n\n- Network Security\n\n    > Ensure secure communication between network segments with TLS encryption and certificate-based authentication.\n\n- Secure Embedded Systems Communication\n\n    > Integrate TLS client with embedded devices (e.g., Raspberry Pi, Arduino with Ethernet/Wi-Fi shields) to send data securely to a central server (for monitoring and control).\n\n- Secure Time Synchronization\n\n    > Use the server to provide a timestamp service for devices on a network (ensure synchronized time across various systems with TLS security).\n\n- Secure IoT Applications\n\n    > Use the TLS server as a central hub to collect data from various IoT devices securely.\n    \n    > Set up the TLS client to send sensor data periodically from remote IoT devices to the server for analysis (centralized secure data receiver/logger).\n\n### Quick Start:\n\nPrerequisites:\n\n- Node.js (v14.x or later)\n- OpenSSL (for generating certificates)\n\nServer:\n\nPlace server certificate and key under the `Certs\\server` directory\n\n```shell\nnpm install\nnode tlsServer.js   # Runs Server\n```  \n\nClient:\n\nPlace client certificate and key under the `Certs\\client` directory\n\n```shell\nnpm install\nnode tlsClient.js   # Runs Client\n```  \n\nLogs and Outputs:\n\nThe server and client will log various events and actions, such as connection establishment, data transmission, handshake report, session management, and encountered errors.\n\nReferences\n\n- [TLS (SSL) Module](https://nodejs.org/api/tls.html)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/novosparc",
            "repo_link": "https://github.com/rajewsky-lab/novosparc",
            "readme": "|PyPI| |Docs| |PePy|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/novosparc.svg\n   :target: https://pypi.org/project/novosparc/\n.. |Docs| image:: https://readthedocs.org/projects/novosparc/badge/?version=latest\n   :target: https://novosparc.readthedocs.io/\n.. |PePy| image:: https://static.pepy.tech/badge/novosparc\n   :target: https://pepy.tech/project/novosparc\n\nnovoSpaRc - *de novo* Spatial Reconstruction of Single-Cell Gene Expression\n===========================================================================\n\n.. image:: https://raw.githubusercontent.com/nukappa/nukappa.github.io/master/images/novosparc.png\n   :width: 90px\n   :align: left\n\n``novoSpaRc`` predicts locations of single cells in space by solely using \nsingle-cell RNA sequencing data. An existing reference database of marker genes\nis not required, but significantly enhances performance if available.\n\n``novoSpaRc`` accompanies the following publications:\n\n    | *Gene Expression Cartography*\n    | M Nitzan*, N Karaiskos*, N Friedman†, N Rajewsky†\n    | `Nature (2019) <https://www.nature.com/articles/s41586-019-1773-3>`_\n\nand\n\n    | *novoSpaRc: flexible spatial reconstruction of single-cell gene expression with optimal transport*\n    | N Moriel*, E Senel*, N Friedman, N Rajewsky, N Karaiskos†, M Nitzan†\n    | `Nature Protocols (2021) <https://www.nature.com/articles/s41596-021-00573-7>`_\n\nRead the `documentation <https://novosparc.readthedocs.io>`_ and the \n`tutorial <https://github.com/rajewsky-lab/novosparc/blob/master/reconstruct_drosophila_embryo_tutorial.ipynb>`_ for more information.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/o3as",
            "repo_link": "https://git.scc.kit.edu/synergy.o3as/",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/odm2sms",
            "repo_link": "https://jugit.fz-juelich.de/sms/odm2sms",
            "readme": "# Migration ODM to SMS\nThis project contains tool support for the migration of metadata from the observation data model (ODM) to the sensor-management-system (SMS) data model.\n\n# Requirements\n- Python 3.11 or higher (required by `tomllib`) referred to as `python3.11`\n- The Python package manager PIP\n- You need to have a postgresql installation on the machine which runs the script in order to work with the package `psycopg2-binary`.\n## Setup\n```\ngit clone https://jugit.fz-juelich.de/sms/odm-importer.git\ncd odm-importer\npython3.11 -m pip install virtualenv\npython3.11 -m virtualenv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n## Run\n```\npython odm2sms.py -h\n```",
            "project_id": "8994"
        },
        {
            "software_organization": "https://helmholtz.software/software/odv",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/oemof-solph",
            "repo_link": "https://github.com/oemof/oemof-solph/",
            "readme": "\n|tox-pytest| |tox-checks| |appveyor| |coveralls| |codecov|\n\n|scrutinizer| |codacy| |codeclimate|\n\n|wheel| |packaging| |supported-versions|\n\n|docs| |zenodo|\n\n|version| |commits-since| |chat|\n\n\n------------------------------\n\n.. |tox-pytest| image:: https://github.com/oemof/oemof-solph/workflows/tox%20pytests/badge.svg?branch=dev\n     :target: https://github.com/oemof/oemof-solph/actions?query=workflow%3A%22tox+checks%22\n\n.. |tox-checks| image:: https://github.com/oemof/oemof-solph/workflows/tox%20checks/badge.svg?branch=dev\n     :target: https://github.com/oemof/oemof-solph/actions?query=workflow%3A%22tox+checks%22\n\n.. |packaging| image:: https://github.com/oemof/oemof-solph/workflows/packaging/badge.svg?branch=dev\n     :target: https://github.com/oemof/oemof-solph/actions?query=workflow%3Apackaging\n\n.. |docs| image:: https://readthedocs.org/projects/oemof-solph/badge/?style=flat\n    :target: https://readthedocs.org/projects/oemof-solph\n    :alt: Documentation Status\n\n.. |appveyor| image:: https://ci.appveyor.com/api/projects/status/github/oemof/oemof-solph?branch=dev&svg=true\n    :alt: AppVeyor Build Status\n    :target: https://ci.appveyor.com/project/oemof-developer/oemof-solph\n\n.. |coveralls| image:: https://coveralls.io/repos/oemof/oemof-solph/badge.svg?branch=dev&service=github\n    :alt: Coverage Status\n    :target: https://coveralls.io/github/oemof/oemof-solph\n\n.. |codecov| image:: https://codecov.io/gh/oemof/oemof-solph/branch/dev/graphs/badge.svg?branch=dev\n    :alt: Coverage Status\n    :target: https://codecov.io/gh/oemof/oemof-solph\n\n.. |codacy| image:: https://api.codacy.com/project/badge/Grade/a6e5cb2dd2694c73895e142e4cf680d5\n    :target: https://app.codacy.com/gh/oemof/oemof-solph/dashboard\n    :alt: Codacy Code Quality Status\n\n.. |codeclimate| image:: https://codeclimate.com/github/oemof/oemof-solph/badges/gpa.svg\n   :target: https://codeclimate.com/github/oemof/oemof-solph\n   :alt: CodeClimate Quality Status\n\n.. |version| image:: https://img.shields.io/pypi/v/oemof.solph.svg\n    :alt: PyPI Package latest release\n    :target: https://pypi.org/project/oemof.solph\n\n.. |wheel| image:: https://img.shields.io/pypi/wheel/oemof.solph.svg\n    :alt: PyPI Wheel\n    :target: https://pypi.org/project/oemof.solph\n\n.. |supported-versions| image:: https://img.shields.io/pypi/pyversions/oemof.solph.svg\n    :alt: Supported versions\n    :target: https://pypi.org/project/oemof.solph\n\n.. |supported-implementations| image:: https://img.shields.io/pypi/implementation/oemof.solph.svg\n    :alt: Supported implementations\n    :target: https://pypi.org/project/oemof.solph\n\n.. |commits-since| image:: https://img.shields.io/github/commits-since/oemof/oemof-solph/latest/dev\n    :alt: Commits since latest release\n    :target: https://github.com/oemof/oemof-solph/compare/master...dev\n\n.. |zenodo| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.596235.svg\n    :alt: Zenodo DOI\n    :target: https://doi.org/10.5281/zenodo.596235\n\n.. |scrutinizer| image:: https://img.shields.io/scrutinizer/quality/g/oemof/oemof-solph/dev.svg\n    :alt: Scrutinizer Status\n    :target: https://scrutinizer-ci.com/g/oemof/oemof-solph/\n\n.. |chat| image:: https://img.shields.io/badge/chat-oemof:matrix.org-%238ADCF7\n     :alt: matrix-chat\n     :target: https://matrix.to/#/#oemof:matrix.org\n\n\n.. figure:: https://raw.githubusercontent.com/oemof/oemof-solph/492e3f5a0dda7065be30d33a37b0625027847518/docs/_logo/logo_oemof_solph_FULL.svg\n    :align: center\n\n------------------------------\n\n===========\noemof.solph\n===========\n\n**A model generator for energy system modelling and optimisation (LP/MILP)**\n\n.. contents::\n    :depth: 2\n    :local:\n    :backlinks: top\n\n\nIntroduction\n============\n\nThe oemof.solph package is part of the\n`Open energy modelling framework (oemof) <https://github.com/oemof/oemof>`_.\nThis is an organisational framework to bundle tools for energy (system) modelling.\noemof-solph is a model generator for energy system modelling and optimisation.\n\nThe package ``oemof.solph`` is very often called just ``oemof``.\nThis is because installing the ``oemof`` meta package was once the best way to get ``oemof.solph``.\nNotice that you should prefeably install ``oemof.solph`` instead of ``oemof``\nif you want to use ``solph``.\n\n\nEverybody is welcome to use and/or develop oemof.solph.\nRead our `contribution <https://oemof.readthedocs.io/en/latest/contributing.html>`_ section.\n\nContribution is already possible on a low level by simply fixing typos in\noemof's documentation or rephrasing sections which are unclear.\nIf you want to support us that way please fork the oemof-solph repository to your own\nGitHub account and make changes as described in the `github guidelines <https://docs.github.com/en/get-started/quickstart/hello-world>`_\n\nIf you have questions regarding the use of oemof including oemof.solph you can visit the openmod forum (`tag oemof <https://forum.openmod-initiative.org/tags/c/qa/oemof>`_ or `tag oemof-solph <https://forum.openmod-initiative.org/tags/c/qa/oemof-solph>`_) and open a new thread if your questions hasn't been already answered.\n\nKeep in touch! - You can become a watcher at our `github site <https://github.com/oemof/oemof>`_,\nbut this will bring you quite a few mails and might be more interesting for developers.\nIf you just want to get the latest news, like when is the next oemof meeting,\nyou can follow our news-blog at `oemof.org <https://oemof.org/>`_.\n\nDocumentation\n=============\nThe `oemof.solph documentation <https://oemof-solph.readthedocs.io/>`_ is powered by readthedocs. Use the `project site <https://readthedocs.org/projects/oemof>`_ of oemof.solph to choose the version of the documentation. Go to the `download page <https://readthedocs.org/projects/oemof/downloads/>`_ to download different versions and formats (pdf, html, epub) of the documentation.\n\n\n.. _installation_label:\n\nInstallation\n============\n\n\nIf you have a working Python installation, use pypi to install the latest version of oemof.solph.\nPython >= 3.8 is recommended. Lower versions may work but are not tested.\n\nWe highly recommend to use virtual environments.\nPlease refer to the documentation of your Python distribution (e.g. Anaconda,\nMicromamba, or the version of Python that came with your Linux installation)\nto learn how to set up and use virtual environments.\n\n::\n\n    (venv) pip install oemof.solph\n\nIf you want to use the latest features, you might want to install the **developer version**. The developer version is not recommended for productive use::\n\n    (venv) pip install https://github.com/oemof/oemof-solph/archive/dev.zip\n\n\nFor running an oemof-solph optimisation model, you need to install a solver.\nFollowing you will find guidelines for the installation process for different operating systems.\n\n.. _windows_solver_label:\n.. _linux_solver_label:\n\nInstalling a solver\n-------------------\n\nThere are several solvers that can work with oemof, both open source and commercial.\nTwo open source solvers are widely used (CBC and GLPK), but oemof suggests CBC (Coin-or branch and cut).\nIt may be useful to compare results of different solvers to see which performs best.\nOther commercial solvers, like Gurobi or Cplex, are also options.\nHave a look at the `pyomo docs <https://pyomo.readthedocs.io/en/stable/api/pyomo.solvers.plugins.solvers.html>`_\nto learn about which solvers are supported.\n\nCheck the solver installation by executing the test_installation example below (see section Installation Test).\n\n**Linux**\n\nTo install the solvers have a look at the package repository of your Linux distribution or search for precompiled packages. GLPK and CBC ares available at Debian, Feodora, Ubuntu and others.\n\n**Windows**\n\n 1. Download `CBC <https://github.com/coin-or/Cbc/releases>`_\n 2. Download `GLPK (64/32 bit) <https://sourceforge.net/projects/winglpk/>`_\n 3. Unpack CBC/GLPK to any folder (e.g. C:/Users/Somebody/my_programs)\n 4. Add the path of the executable files of both solvers to the PATH variable using `this tutorial <https://www.computerhope.com/issues/ch000549.htm>`_\n 5. Restart Windows\n\nCheck the solver installation by executing the test_installation example (see the `Installation test` section).\n\n\n**Mac OSX**\n\nPlease follow the installation instructions on the respective homepages for details.\n\nCBC-solver: https://github.com/coin-or/Cbc\n\nGLPK-solver: http://arnab-deka.com/posts/2010/02/installing-glpk-on-a-mac/\n\nIf you install the CBC solver via brew (highly recommended), it should work without additional configuration.\n\n\n**conda**\n\nProvided you are using a Linux or MacOS, the CBC-solver can also be installed in a `conda` environment. Please note, that it is highly recommended to `use pip after conda <https://www.anaconda.com/blog/using-pip-in-a-conda-environment>`_, so:\n\n.. code:: console\n\n    (venv) conda install -c conda-forge coincbc\n    (venv) pip install oemof.solph\n\n\n.. _check_installation_label:\n\nInstallation test\n-----------------\n\nTest the installation and the installed solver by running the installation test\nin your virtual environment:\n\n.. code:: console\n\n  (venv) oemof_installation_test\n\nIf the installation was successful, you will receive something like this:\n\n.. code:: console\n\n    *********\n    Solver installed with oemof:\n    glpk: working\n    cplex: not working\n    cbc: working\n    gurobi: not working\n    *********\n    oemof.solph successfully installed.\n\nas an output.\n\nContributing\n============\n\nA warm welcome to all who want to join the developers and contribute to\noemof.solph.\n\nInformation on the details and how to approach us can be found\n`in the oemof documentation <https://oemof.readthedocs.io/en/latest/contributing.html>`_ .\n\nCiting\n======\n\nFor explicitly citing solph, you might want to refer to\n`DOI:10.1016/j.simpa.2020.100028 <https://doi.org/10.1016/j.simpa.2020.100028>`_,\nwhich gives an overview over the capabilities of solph.\nThe core ideas of oemof as a whole are described in\n`DOI:10.1016/j.esr.2018.07.001 <https://doi.org/10.1016/j.esr.2018.07.001>`_\n(preprint at `arXiv:1808.0807 <https://arxiv.org/abs/1808.08070v1>`_).\nTo allow citing specific versions, we use the zenodo project to get a DOI for each version.\n\nExample Applications\n====================\n\nThe combination of specific modules (often including other packages) is called an\napplication (app). For example, it can depict a concrete energy system model.\nYou can find a large variety of helpful examples in the documentation.\nThe examples show the optimisation of different energy systems and are supposed\nto help new users to understand the framework's structure.\n\nYou are welcome to contribute your own examples via a `pull request <https://github.com/oemof/oemof-solph/pulls>`_\nor by e-mailing us (see `here <https://oemof.org/contact/>`_ for contact information).\n\nLicense\n=======\n\nCopyright (c) oemof developer group\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/opencarp",
            "repo_link": "https://git.opencarp.org/openCARP/openCARP",
            "readme": "",
            "project_id": "16"
        },
        {
            "software_organization": "https://helmholtz.software/software/openfuelcell2",
            "repo_link": "https://github.com/openFuelCell2/openFuelCell2",
            "readme": "# openFuelCell2\n\n[openFuelCell2](https://openfuelcell2.github.io/) is a computational fluid dynamics (CFD) toolbox for simulating electrochemical devices such as fuel cells and electrolysis. The solver is based on the open-source library, OpenFOAM®.\n\n## About the code\n\nThe source code was developed from a previous open-source repository called [openFuelCell](http://openfuelcell.sourceforge.net/). It was also inspired by the standard solver \"reactingTwoPhaseEulerFoam\" in OpenFOAM®. The solver can consider coupled problems with multi-region and multi-physics issues, including single and two phase flows, multiple species components, charge transfer, and electrochemical reactions in different regions. More applications and solvers will be available in the future.\n\n## How to use\n\nThe code is compiled with the OpenFOAM libraries, either [ORG](https://openfoam.org/) or [COM](https://www.openfoam.com/) versions. The default branch is compatable with the COM version, while the other branches are also provided for different OpenFOAM environments. The available environments will include: OpenFOAM-v2012, OpenFOAM-v2106, OpenFOAM-v2306, OpenFOAM-v6, OpenFOAM-v8. Note: the main branch is only compatible with OpenFOAM-v2306, while the others are under preparation.\n\n```bash\n# Download the source code\n# Setup the corresponding openfoam environment\n# Switch to the corresponding branch\n\n# Change dictionary to the repository\ncd openFuelCell2/src\n\n# Compile the source code with\n./Allwmake\n\n# Or compile in parallel\n./Allwmake -j n\n```\n\nYou can also clear the libraries and executable files with\n\n```bash\n\ncd openFuelCell2/src\n\n./Allwclean\n\n```\n\n## Computational domains\n\n---\n\nTake the cross-section of a fuel cell as an example. The computational domain gives,\n\n<div align=\"center\">\n  <img src=\"images/computationDomain.jpg\" height=\"70%\" width=\"70%\">\n</div>\n\nIn a PEM fuel cell or other types, there are several domains/regions: air, fuel, electrolyte, and interconnect. This can be found from the repository [openFuelCell](http://openfuelcell.sourceforge.net/). However, additional domains/regions, e.g. phiEA, phiEC, and phiI are also necessary to account for electron/ion and dissolved water transfer.\n\nTo consider the coupling transfer problems in a PEM fuel cell, a global region, also called as parent mesh, and several local regions, also called as child meshes, are used. In the global region, only the energy equation is solved. In the local regions, corresponding partial differential equations will be discretized and solved. During the simulation, material properties, e.g. density, thermal conductivity, etc., are mapped from local regions to the global region, while the temperature field is mapped from the global region to the local regions.\n\nThe local regions can be classified as three different types, namely fluid, solid, and electric regions. See the [code](src/libSrc/fuelCellSystems/regions).\n\n- Fluid region:\n\n  This region represents the space where fluid flows by. In a fuel cell or electrolyzer, it consists with gas channels and/or porous regions. In this region, the following processes are addressed:\n\n  - Fluid flow (single/two phase)\n  - Species transfer\n  - Electrochemical reaction\n  - Heat and mass transfer\n\n  For example, in a fuel cell, the following parts apply to this region,\n\n  - Air flow paths + porous electrodes\n  - Fuel flow paths + porous electrodes\n  - Cooling channels\n\n- Solid region:\n\n  This represents the solid components in fuel cell or electrolyzer. In the current solver, no equations will be solved here. However, stress analysis during assembly and thermal effects may be implemented in future applications.\n\n  For example. in a fuel cell, the following components apply to this region,\n\n  - Electrolyte/membrane\n  - Interconnect/Bipolar-plate\n  - Endplate\n\n- Electric region:\n\n  This region accounts for the electric-conductive components. It is designed to consider electron/ion transfer specifically. However, it is found that the proton transfer region is the same as the region where dissolved water transfer takes place. Therefore, a switcher is enabled in the code to turn on/off the dissolved water transfer model. The following equations will be solved,\n\n  - Potential equations (Poisson equations)\n  - Dissolved water transfer equations (diffusion and electro-osmotic-drag)\n\n  For example, in a fuel cell, the following components belong to this region:\n\n  - Bipolar-plate, GDL, MPL, CL -> electron transfer regions\n  - Catalyst coated membrane, CCM, -> proton transfer and dissolved water transfer region\n\n- Global region:\n\n  The heat source/sinks in local regions will be mapped to this region. And the obtained temperature is mapped back to the local regions. The heat source/sink include:\n\n  - Joule heat from the electron/proton regions.\n  - Condensation/evaporation in the fluid regions.\n  - Electrochemical reactions in the fluid regions.\n\n## Recent updates\n\n---\n\n- [Oct. 2020] A new branch for openFOAM-ESI\n  > The majority part of this update was conducted by Mr. Steffen Hess. The code is able to compile in the OpenFOAM-ESI environment.\n- [Nov. 2020] The new branch for openFOAM-ESI\n  > Some bugs were found and fixed:\n    1. The compiling sequence.\n    2. The locations of gravity fields, g. The files \"g\" move to constant/.\n    3. The functionObjects library is missing.\n    4. Remove some warnings: apply new functions in OpenFOAM-ESI.\n- [Nov. 2021] The new branch for openFOAM-2106\n  > Some bugs were found and fixed:\n    1. The method **heatTransfer(T, cellListIO)** in class \"TwoResistanceHeatTransferPhaseSystem\" is fixed.\n  > Dictionary structure is rearranged:\n    1. src: source files\n    2. appSrc: application source files\n    3. libSrc: libraries source files\n    4. run: test cases\n- [Jun. 2022] Clean the source code for releasing\n  > Bugs are found and fixed:\n    1. The previous solver might predict results with singularities in phiI region. This is fixed.\n  > The source code is updated:\n    1. Change the phase name to none if single-phase flow is simulated. This makes the variable names change from _A.air_ to _A_.\n    2. Moving the correction of diffusivity from MultiComponentPhaseModel to **diffusivityModelList**.\n    3. Moving the definition of phase properties from phaseProperties to regionProperties.\n    4. Avoiding redundant output of diffusivity coefficients.\n    5. Applying a different method to Update the value of phi in phiI region --> use setReference of phiEqn. This seems to make the solution more stable.\n    6. Making the \"porousZone\" flexible to read. If the file doesn't exist, no porous zones are applied.\n    7. Update the test cases: rewrite the scripts.\n    8. Change the header of each file. openFuelCell is included.\n- [Dec. 2022] Update the repository\n    1. Fixed a bug in diffusivityList\n    2. Update the tutorial\n- [Sep. 2023] Update the repository for public release\n    1. A new branch is included for OpenFOAM-v2306\n    2. The prescribed mean current density and voltage are now defined as a function of time. (Assailable functions can be found in OpenFOAM/primitives/functions/Function1).\n    3. Include the radiation model in solid region.\n    4. Copy thermoTools to the repo. (need to remove this in next update.)\n    5. In test cases, when it comes to two-phase flow, a steadyState scheme is now used, specially for ddt term of species transfer.\n    6. Update the preprocessing script for an easier usage.\n\n## Related publications\n\n- Journal\n\n  - Zhang, Shidong, Steffen Hess, Holger Marschall, Uwe Reimer, Steven Beale, and Werner Lehnert. \"openFuelCell2: A New Computational Tool for Fuel Cells, Electrolyzers, and other Electrochemical Devices and Processes.\" Computer Physics Communications, Forthcoming (2023).\n\n  - Zhang, Shidong, Shangzhe Yu, Roland Peters, Steven B. Beale, Holger Marschall, Felix Kunz, and Rüdiger-A. Eichel. \"A new procedure for rapid convergence in numerical performance calculations of electrochemical cells.\" Electrochimica Acta (2023): 143275.\n\n  - Yu, Shangzhe, Shidong Zhang, Dominik Schäfer, Roland Peters, Felix Kunz, and Rüdiger-A. Eichel. \"Numerical Modeling and Simulation of the Solid Oxide Cell Stacks and Metal Interconnect Oxidation with OpenFOAM.\" Energies 16, no. 9 (2023): 3827.\n\n  - Zhang, Shidong, Steven B. Beale, Uwe Reimer, Martine Andersson, and Werner Lehnert. \"Polymer electrolyte fuel cell modeling-A comparison of two models with different levels of complexity.\" International Journal of Hydrogen Energy 45, no. 38 (2020): 19761-19777.\n\n  - Zhang, Shidong. \"Low-Temperature Polymer Electrolyte Fuel Cells.\" In Electrochemical Cell Calculations with OpenFOAM, pp. 59-85. Springer, Cham, 2022.\n\n- Conference\n\n  - Hess, Steffen, Shidong Zhang, Thomas Kadyk, Werner Lehnert, Michael Eikerling, and Steven B. Beale. \"Numerical Two-Phase Simulations of Alkaline Water Electrolyzers.\" ECS Transactions 112, no. 4 (2023): 419.\n\n  - Zhang, Shidong, Kai Wang, Shangzhe Yu, Nicolas Kruse, Roland Peters, Felix Kunz, and Rudiger-A. Eichel. \"Multiscale and Multiphysical Numerical Simulations of Solid Oxide Cell (SOC).\" ECS Transactions 111, no. 6 (2023): 937.\n\n  - Zhang, Shidong, Steven B. Beale, Yan Shi, Holger Janßen, Uwe Reimer, and Werner Lehnert. \"Development of an Open-Source Solver for Polymer Electrolyte Fuel Cells.\" ECS Transactions 98, no. 9 (2020): 317.\n\n- Thesis\n\n  - Zhang, Shidong. Modeling and Simulation of Polymer Electrolyte Fuel Cells. No. FZJ-2020-02318. Elektrochemische Verfahrenstechnik, 2020.\n\n## Developers\n\n---\n\nThe code is firstly developed by [Shidong Zhang](s.zhang@fz-juelich.de) for the PhD thesis, supervised by Prof. [Werner Lehnert](w.lehnert@fz-juelich.de) and Prof. [Steven Beale](s.beale@fz-juelich.de). The detailed model description and simulation results can be found in the thesis, `Modeling and Simulation of Polymer Electrolyte Fuel Cells` by FZJ. The following individuals also contribute to the optimization of the code,\n\n- Steffen Hess (s.hess@fz-juelich.de), Forschungszentrum Juelich, IEK-14\n\n- Prof. Steven B. Beale (s.beale@fz-juelich.de), Forschungszentrum Juelich, IEK-13\n\nTo be continued...\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/opengeosys",
            "repo_link": "https://gitlab.opengeosys.org/ogs/ogs",
            "readme": "",
            "project_id": "120"
        },
        {
            "software_organization": "https://helmholtz.software/software/openpmd-api",
            "repo_link": "https://github.com/openPMD/openPMD-api/",
            "readme": "\nC++ & Python API for Scientific I/O with openPMD\n================================================\n\n[![Supported openPMD Standard](https://img.shields.io/badge/openPMD-1.0.0--1.1.0-blue)](https://github.com/openPMD/openPMD-standard/releases)\n[![Doxygen](https://img.shields.io/badge/API-Doxygen-blue)](https://www.openpmd.org/openPMD-api)\n[![Gitter chat](https://img.shields.io/gitter/room/openPMD/API)](https://gitter.im/openPMD/API)\n![Supported Platforms][api-platforms]\n[![License](https://img.shields.io/badge/license-LGPLv3-blue)](https://www.gnu.org/licenses/lgpl-3.0.html)\n[![DOI](https://rodare.hzdr.de/badge/DOI/10.14278/rodare.27.svg)](https://doi.org/10.14278/rodare.27)\n[![CodeFactor](https://www.codefactor.io/repository/github/openpmd/openpmd-api/badge)](https://www.codefactor.io/repository/github/openpmd/openpmd-api)\n[![Coverage Status](https://coveralls.io/repos/github/openPMD/openPMD-api/badge)](https://coveralls.io/github/openPMD/openPMD-api)\n[![Documentation Status](https://readthedocs.org/projects/openpmd-api/badge/?version=latest)](https://openpmd-api.readthedocs.io/en/latest/?badge=latest)\n[![Linux/OSX Build Status dev](https://travis-ci.com/openPMD/openPMD-api.svg?branch=dev)](https://travis-ci.com/openPMD/openPMD-api)\n[![Windows Build Status dev](https://ci.appveyor.com/api/projects/status/x95q4n620pqk0e0t/branch/dev?svg=true)](https://ci.appveyor.com/project/ax3l/openpmd-api/branch/dev)\n[![PyPI Wheel Release](https://github.com/openPMD/openPMD-api/workflows/wheels/badge.svg?branch=wheels&event=push)](https://github.com/openPMD/openPMD-api/actions?query=workflow%3Awheels)\n[![Nightly Packages Status](https://dev.azure.com/axelhuebl/openPMD-api/_apis/build/status/openPMD.openPMD-api?branchName=azure_install&label=nightly%20packages)](https://dev.azure.com/axelhuebl/openPMD-api/_build/latest?definitionId=1&branchName=azure_install)\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/17602/badge.svg)](https://scan.coverity.com/projects/openpmd-openpmd-api)\n\n[api-platforms]: https://img.shields.io/badge/platforms-linux%20|%20osx%20|%20win-blue \"Supported Platforms\"\n\nopenPMD is an open meta-data schema that provides meaning and self-description for data sets in science and engineering.\nSee [the openPMD standard](https://github.com/openPMD/openPMD-standard) for details of this schema.\n\nThis library provides a reference API for openPMD data handling.\nSince openPMD is a schema (or markup) on top of portable, hierarchical file formats, this library implements various backends such as HDF5, ADIOS2 and JSON.\nWriting & reading through those backends and their associated files are supported for serial and [MPI-parallel](https://www.mpi-forum.org/docs/) workflows.\n\n## Usage\n\n### C++\n\n[![C++17][api-cpp]](https://isocpp.org/) ![C++17 API: Beta][dev-beta]\n\n[api-cpp]: https://img.shields.io/badge/language-C%2B%2B17-yellowgreen \"C++17 API\"\n[dev-beta]: https://img.shields.io/badge/phase-beta-yellowgreen \"Status: Beta\"\n\n```cpp\n#include <openPMD/openPMD.hpp>\n#include <iostream>\n\n// ...\n\nauto s = openPMD::Series(\"samples/git-sample/data%T.h5\", openPMD::Access::READ_ONLY);\n\nfor( auto const & [step, it] : s.iterations ) {\n    std::cout << \"Iteration: \" << step << \"\\n\";\n\n    for( auto const & [name, mesh] : it.meshes ) {\n        std::cout << \"  Mesh '\" << name << \"' attributes:\\n\";\n        for( auto const& val : mesh.attributes() )\n            std::cout << \"    \" << val << '\\n';\n    }\n\n    for( auto const & [name, species] : it.particles ) {\n        std::cout << \"  Particle species '\" << name << \"' attributes:\\n\";\n        for( auto const& val : species.attributes() )\n            std::cout << \"    \" << val << '\\n';\n    }\n}\n```\n\n### Python\n\n[![Python3][api-py3]](https://www.python.org/) ![Python3 API: Beta][dev-beta]\n\n[api-py3]: https://img.shields.io/badge/language-Python3-yellowgreen \"Python3 API\"\n\n\n```py\nimport openpmd_api as io\n\n# ...\n\nseries = io.Series(\"samples/git-sample/data%T.h5\", io.Access.read_only)\n\nfor k_i, i in series.iterations.items():\n    print(\"Iteration: {0}\".format(k_i))\n\n    for k_m, m in i.meshes.items():\n        print(\"  Mesh '{0}' attributes:\".format(k_m))\n        for a in m.attributes:\n            print(\"    {0}\".format(a))\n\n    for k_p, p in i.particles.items():\n        print(\"  Particle species '{0}' attributes:\".format(k_p))\n        for a in p.attributes:\n            print(\"    {0}\".format(a))\n```\n\n### More!\n\nCurious?\nOur manual shows full [read & write examples](https://openpmd-api.readthedocs.io/en/latest/usage/firstwrite.html), both serial and MPI-parallel!\n\n## Dependencies\n\nRequired:\n* CMake 3.22.0+\n* C++17 capable compiler, e.g., g++ 7+, clang 7+, MSVC 19.15+, icpc 19+, icpx\n\nShipped internally (downloaded by CMake unless `openPMD_SUPERBUILD=OFF` is set):\n* [Catch2](https://github.com/catchorg/Catch2) 2.13.10+ ([BSL-1.0](https://github.com/catchorg/Catch2/blob/master/LICENSE.txt))\n* [pybind11](https://github.com/pybind/pybind11) 2.13.0+ ([new BSD](https://github.com/pybind/pybind11/blob/master/LICENSE))\n* [NLohmann-JSON](https://github.com/nlohmann/json) 3.9.1+ ([MIT](https://github.com/nlohmann/json/blob/develop/LICENSE.MIT))\n* [toml11](https://github.com/ToruNiina/toml11) 3.7.1+ ([MIT](https://github.com/ToruNiina/toml11/blob/master/LICENSE))\n\nI/O backends:\n* [JSON](https://en.wikipedia.org/wiki/JSON)\n* [HDF5](https://support.hdfgroup.org/HDF5) 1.8.13+ (optional)\n* [ADIOS2](https://github.com/ornladios/ADIOS2) 2.7.0+ (optional)\n\nwhile those can be built either with or without:\n* MPI 2.1+, e.g. OpenMPI 1.6.5+ or MPICH2\n\nOptional language bindings:\n* Python:\n  * Python 3.8 - 3.13\n  * pybind11 2.13.0+\n  * numpy 1.15+\n  * mpi4py 2.1+ (optional, for MPI)\n  * pandas 1.0+ (optional, for dataframes)\n  * dask 2021+ (optional, for dask dataframes)\n* CUDA C++ (optional, currently used only in tests)\n\n## Installation\n\n[![Spack Package](https://img.shields.io/badge/spack.io-openpmd--api-brightgreen)](https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api)\n[![Conda Package](https://img.shields.io/badge/conda.io-openpmd--api-brightgreen)](https://anaconda.org/conda-forge/openpmd-api)\n[![Brew Package](https://img.shields.io/badge/brew.sh-openpmd--api-brightgreen)](https://github.com/openPMD/homebrew-openPMD)\n[![PyPI Package](https://img.shields.io/badge/pypi.org-openpmd--api-brightgreen)](https://pypi.org/project/openPMD-api)\n[![From Source](https://img.shields.io/badge/from_source-CMake-brightgreen)](https://cmake.org)\n\nOur community loves to help each other.\nPlease [report installation problems](https://github.com/openPMD/openPMD-api/issues/new?labels=install&template=install_problem.md) in case you should get stuck.\n\nChoose *one* of the install methods below to get started:\n\n### [Spack](https://spack.io)\n\n[![Spack Version](https://img.shields.io/spack/v/openpmd-api)](https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api)\n[![Spack Platforms](https://img.shields.io/badge/platforms-linux%20|%20osx%20-blue)](https://spack.io)\n[![Spack Use Case](https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29,_development,_HPC-brightgreen)](https://spack.readthedocs.io/en/latest/package_list.html#openpmd-api)\n\n```bash\n# optional:               +python -adios2 -hdf5 -mpi\nspack install openpmd-api\nspack load openpmd-api\n```\n\n### [Conda](https://conda.io)\n\n[![Conda Version](https://img.shields.io/conda/vn/conda-forge/openpmd-api)](https://anaconda.org/conda-forge/openpmd-api)\n[![Conda Platforms](https://img.shields.io/badge/platforms-linux%20|%20osx%20|%20win-blue)](https://anaconda.org/conda-forge/openpmd-api)\n[![Conda Use Case](https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen)](https://anaconda.org/conda-forge/openpmd-api)\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/openpmd-api)](https://anaconda.org/conda-forge/openpmd-api)\n\n```bash\n# optional:                      OpenMPI support  =*=mpi_openmpi*\n# optional:                        MPICH support  =*=mpi_mpich*\nconda create -n openpmd -c conda-forge openpmd-api\nconda activate openpmd\n```\n\n### [Brew](https://brew.sh)\n\n[![Brew Version](https://img.shields.io/badge/brew-latest_version-orange)](https://github.com/openPMD/homebrew-openPMD)\n[![Brew Platforms](https://img.shields.io/badge/platforms-linux%20|%20osx%20-blue)](https://docs.brew.sh/Homebrew-on-Linux)\n[![Brew Use Case](https://img.shields.io/badge/use_case-desktop_%28C%2B%2B,_py%29-brightgreen)](https://brew.sh)\n\n```bash\nbrew tap openpmd/openpmd\nbrew install openpmd-api\n```\n\n### [PyPI](https://pypi.org)\n\n[![PyPI Version](https://img.shields.io/pypi/v/openPMD-api)](https://pypi.org/project/openPMD-api)\n[![PyPI Platforms](https://img.shields.io/badge/platforms-linux%20|%20osx%20|%20win-blue)](https://pypi.org/project/openPMD-api/#files)\n[![PyPI Use Case](https://img.shields.io/badge/use_case-desktop_%28py%29-brightgreen)](https://pypi.org/project/openPMD-api)\n[![PyPI Format](https://img.shields.io/pypi/format/openPMD-api)](https://pypi.org/project/openPMD-api)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/openPMD-api)](https://pypi.org/project/openPMD-api)\n\nOn very old macOS versions (<10.9) or on exotic processor architectures, this install method *compiles from source* against the found installations of HDF5, ADIOS2, and/or MPI (in system paths, from other package managers, or loaded via a module system, ...).\n\n```bash\n# we need pip 19 or newer\n# optional:                   --user\npython3 -m pip install -U pip\n\n# optional:                        --user\npython3 -m pip install openpmd-api\n```\n\nIf MPI-support shall be enabled, we always have to recompile:\n```bash\n# optional:                                    --user\npython3 -m pip install -U pip packaging setuptools wheel\npython3 -m pip install -U cmake\n\n# optional:                                                                   --user\nopenPMD_USE_MPI=ON python3 -m pip install openpmd-api --no-binary openpmd-api\n```\n\nFor some exotic architectures and compilers, you might need to disable a compiler feature called [link-time/interprocedural optimization](https://en.wikipedia.org/wiki/Interprocedural_optimization) if you encounter linking problems:\n```bash\nexport CMAKE_INTERPROCEDURAL_OPTIMIZATION=OFF\n# optional:                                                --user\npython3 -m pip install openpmd-api --no-binary openpmd-api\n```\n\nAdditional CMake options can be passed via individual environment variables, which need to be prefixed with `openPMD_CMAKE_`.\n\n### From Source\n\n[![Source Use Case](https://img.shields.io/badge/use_case-development-brightgreen)](https://cmake.org)\n\nopenPMD-api can also be built and installed from source using [CMake](https://cmake.org/):\n\n```bash\ngit clone https://github.com/openPMD/openPMD-api.git\n\nmkdir openPMD-api-build\ncd openPMD-api-build\n\n# optional: for full tests, with unzip\n../openPMD-api/share/openPMD/download_samples.sh\n\n# for own install prefix append:\n#   -DCMAKE_INSTALL_PREFIX=$HOME/somepath\n# for options append:\n#   -DopenPMD_USE_...=...\n# e.g. for python support add:\n#   -DopenPMD_USE_PYTHON=ON -DPython_EXECUTABLE=$(which python3)\ncmake ../openPMD-api\n\ncmake --build .\n\n# optional\nctest\n\n# sudo might be required for system paths\ncmake --build . --target install\n```\n\nThe following options can be added to the `cmake` call to control features.\nCMake controls options with prefixed `-D`, e.g. `-DopenPMD_USE_MPI=OFF`:\n\n| CMake Option                 | Values           | Description                                                                  |\n|------------------------------|------------------|------------------------------------------------------------------------------|\n| `openPMD_USE_MPI`            | **AUTO**/ON/OFF  | Parallel, Multi-Node I/O for clusters                                        |\n| `openPMD_USE_HDF5`           | **AUTO**/ON/OFF  | HDF5 backend (`.h5` files)                                                   |\n| `openPMD_USE_ADIOS2`         | **AUTO**/ON/OFF  | ADIOS2 backend (`.bp` files in BP3, BP4 or higher)                           |\n| `openPMD_USE_PYTHON`         | **AUTO**/ON/OFF  | Enable Python bindings                                                       |\n| `openPMD_USE_INVASIVE_TESTS` | ON/**OFF**       | Enable unit tests that modify source code <sup>1</sup>                       |\n| `openPMD_USE_VERIFY`         | **ON**/OFF       | Enable internal VERIFY (assert) macro independent of build type <sup>2</sup> |\n| `openPMD_INSTALL`            | **ON**/OFF       | Add installation targets                                                     |\n| `openPMD_INSTALL_RPATH`      | **ON**/OFF       | Add RPATHs to installed binaries                                             |\n| `Python_EXECUTABLE`          | (newest found)   | Path to Python executable                                                    |\n\n<sup>1</sup> *e.g. changes C++ visibility keywords, breaks MSVC*\n<sup>2</sup> *this includes most pre-/post-condition checks, disabling without specific cause is highly discouraged*\n\n\nAdditionally, the following libraries are downloaded via [FetchContent](https://cmake.org/cmake/help/latest/module/FetchContent.html)\nduring the configuration of the project or, if the corresponding `<PACKAGENAME>_ROOT` variable is provided, can be provided externally:\n* [Catch2](https://github.com/catchorg/Catch2) (2.13.10+)\n* [PyBind11](https://github.com/pybind/pybind11) (2.13.0+)\n* [NLohmann-JSON](https://github.com/nlohmann/json) (3.9.1+)\n* [toml11](https://github.com/ToruNiina/toml11) (3.7.1+)\n\nBy default, this will build as a shared library (`libopenPMD.[so|dylib|dll]`) and installs also its headers.\nIn order to build a static library, append `-DBUILD_SHARED_LIBS=OFF` to the `cmake` command.\nYou can only build a static or a shared library at a time.\n\nBy default, the `Release` version is built.\nIn order to build with debug symbols, pass `-DCMAKE_BUILD_TYPE=Debug` to your `cmake` command.\n\nBy default, tests, examples and command line tools are built.\nIn order to skip building those, pass ``OFF`` to these ``cmake`` options:\n\n| CMake Option                  | Values     | Description              |\n|-------------------------------|------------|--------------------------|\n| `openPMD_BUILD_TESTING`       | **ON**/OFF | Build tests              |\n| `openPMD_BUILD_EXAMPLES`      | **ON**/OFF | Build examples           |\n| `openPMD_BUILD_CLI_TOOLS`     | **ON**/OFF | Build command-line tools |\n| `openPMD_USE_CUDA_EXAMPLES`   | ON/**OFF** | Use CUDA in examples     |\n\n## Linking to your project\n\nThe install will contain header files and libraries in the path set with `-DCMAKE_INSTALL_PREFIX`.\n\n### CMake\n\nIf your project is using CMake for its build, one can conveniently use our provided `openPMDConfig.cmake` package, which is installed alongside the library.\n\nFirst set the following environment hint if openPMD-api was *not* installed in a system path:\n\n```bash\n# optional: only needed if installed outside of system paths\nexport CMAKE_PREFIX_PATH=$HOME/somepath:$CMAKE_PREFIX_PATH\n```\n\nUse the following lines in your project's `CMakeLists.txt`:\n```cmake\n# supports:                       COMPONENTS MPI NOMPI HDF5 ADIOS2\nfind_package(openPMD 0.17.0 CONFIG)\n\nif(openPMD_FOUND)\n    target_link_libraries(YourTarget PRIVATE openPMD::openPMD)\nendif()\n```\n\n*Alternatively*, add the openPMD-api repository source directly to your project and use it via:\n```cmake\nadd_subdirectory(\"path/to/source/of/openPMD-api\")\n\ntarget_link_libraries(YourTarget PRIVATE openPMD::openPMD)\n```\n\nFor development workflows, you can even automatically download and build openPMD-api from within a depending CMake project.\nJust replace the `add_subdirectory` call with:\n```cmake\ninclude(FetchContent)\nset(CMAKE_POLICY_DEFAULT_CMP0077 NEW)\nset(openPMD_BUILD_CLI_TOOLS OFF)\nset(openPMD_BUILD_EXAMPLES OFF)\nset(openPMD_BUILD_TESTING OFF)\nset(openPMD_BUILD_SHARED_LIBS OFF)  # precedence over BUILD_SHARED_LIBS if needed\nset(openPMD_INSTALL OFF)            # or instead use:\n# set(openPMD_INSTALL ${BUILD_SHARED_LIBS})  # only install if used as a shared library\nset(openPMD_USE_PYTHON OFF)\nFetchContent_Declare(openPMD\n  GIT_REPOSITORY \"https://github.com/openPMD/openPMD-api.git\"\n  GIT_TAG        \"0.17.0\")\nFetchContent_MakeAvailable(openPMD)\n```\n\n### Manually\n\nIf your (Linux/OSX) project is build by calling the compiler directly or uses a manually written `Makefile`, consider using our `openPMD.pc` helper file for `pkg-config`, which are installed alongside the library.\n\nFirst set the following environment hint if openPMD-api was *not* installed in a system path:\n\n```bash\n# optional: only needed if installed outside of system paths\nexport PKG_CONFIG_PATH=$HOME/somepath/lib/pkgconfig:$PKG_CONFIG_PATH\n```\n\nAdditional linker and compiler flags for your project are available via:\n```bash\n# switch to check if openPMD-api was build as static library\n# (via BUILD_SHARED_LIBS=OFF) or as shared library (default)\nif [ \"$(pkg-config --variable=static openPMD)\" == \"true\" ]\nthen\n    pkg-config --libs --static openPMD\n    # -L/usr/local/lib -L/usr/lib/x86_64-linux-gnu/openmpi/lib -lopenPMD -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so /usr/lib/libmpi.so /usr/lib/x86_64-linux-gnu/hdf5/openmpi/libhdf5.so /usr/lib/x86_64-linux-gnu/libsz.so /usr/lib/x86_64-linux-gnu/libz.so /usr/lib/x86_64-linux-gnu/libdl.so /usr/lib/x86_64-linux-gnu/libm.so -pthread /usr/lib/libmpi.so -pthread /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_cxx.so /usr/lib/libmpi.so\nelse\n    pkg-config --libs openPMD\n    # -L${HOME}/somepath/lib -lopenPMD\nfi\n\npkg-config --cflags openPMD\n# -I${HOME}/somepath/include\n```\n\n## Author Contributions\n\nopenPMD-api is developed by many people.\nIt was initially started by the [Computational Radiation Physics Group](https://hzdr.de/crp) at [HZDR](https://www.hzdr.de/) as successor to [libSplash](https://github.com/ComputationalRadiationPhysics/libSplash/), generalizing the [successful HDF5 & ADIOS1 implementations](https://arxiv.org/abs/1706.00522) in [PIConGPU](https://github.com/ComputationalRadiationPhysics/picongpu).\nThe following people and institutions [contributed](https://github.com/openPMD/openPMD-api/graphs/contributors) to openPMD-api:\n\n* [Axel Huebl (LBNL, previously HZDR)](https://github.com/ax3l):\n  project lead, releases, documentation, automated CI/CD, Python bindings, Dask, installation & packaging, prior reference implementations\n* [Franz Poeschel (CASUS)](https://github.com/franzpoeschel):\n  JSON & ADIOS2 backend, data staging/streaming, reworked class design\n* [Fabian Koller (HZDR)](https://github.com/C0nsultant):\n  initial library design and implementation with HDF5 & ADIOS1 backend\n* [Junmin Gu (LBNL)](https://github.com/guj):\n  non-collective parallel I/O fixes, ADIOS improvements, benchmarks\n\nMaintained by the following research groups:\n\n* [Computational Radiation Physics (CRD)](https://www.casus.science/casus/team/) at CASUS/HZDR, led by [Michael Bussmann](https://github.com/bussmann)\n* [Accelerator Modeling Program (AMP)](https://atap.lbl.gov/accelerator-modeling-program/) at LBNL, led by [Jean-Luc Vay](https://github.com/jlvay)\n* [Scientific Data Management (SDM)](https://crd.lbl.gov/divisions/scidata/sdm/) at LBNL, led by [Kesheng (John) Wu](https://github.com/john18)\n\nFurther thanks go to improvements and contributions from:\n\n* [Carsten Fortmann-Grote (EU XFEL GmbH, now MPI-EvolBio)](https://github.com/CFGrote):\n  draft of our Python unit tests\n* [Dominik Stańczak (Warsaw University of Technology)](https://github.com/StanczakDominik):\n  documentation improvements\n* [Ray Donnelly (Anaconda, Inc.)](https://github.com/mingwandroid):\n  support on conda packaging and libc++ quirks\n* [James Amundson (FNAL)](https://github.com/amundson):\n  compile fix for newer compilers\n* [René Widera (HZDR)](https://github.com/psychocoderHPC):\n  design improvements for initial API design\n* [Erik Zenker (HZDR)](https://github.com/erikzenker):\n  design improvements for initial API design\n* [Sergei Bastrakov (HZDR)](https://github.com/sbastrakov):\n  documentation improvements (windows)\n* [Rémi Lehe (LBNL)](https://github.com/RemiLehe):\n  package integration testing on macOS and Linux\n* [Lígia Diana Amorim (LBNL)](https://github.com/LDAmorim):\n  package integration testing on macOS\n* [Kseniia Bastrakova (HZDR)](https://github.com/KseniaBastrakova):\n  compatibility testing\n* [Richard Pausch (HZDR)](https://github.com/PrometheusPi):\n  compatibility testing, documentation improvements\n* [Paweł Ordyna (HZDR)](https://github.com/pordyna):\n  report on NVCC warnings\n* [Dmitry Ganyushin (ORNL)](https://github.com/dmitry-ganyushin):\n  Dask prototyping & ADIOS2 benchmarking\n* [John Kirkham (NVIDIA)](https://github.com/jakirkham):\n  Dask guidance & reviews\n* [Erik Schnetter (PITP)](https://github.com/eschnett):\n  C++ API bug fixes\n* [Jean Luca Bez (LBNL)](https://github.com/jeanbez):\n  HDF5 performance tuning\n* [Bernhard Manfred Gruber (CERN)](https://github.com/bernhardmgruber):\n  CMake fix for parallel HDF5\n* [Nils Schild (IPP)](https://github.com/DerNils-git):\n  CMake improvements for subprojects\n\n### Grants\n\nThe openPMD-api authors acknowledge support via the following programs.\nSupported by the CAMPA collaboration, a project of the U.S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research and Office of High Energy Physics, Scientific Discovery through Advanced Computing (SciDAC) program.\nPreviously supported by the Consortium for Advanced Modeling of Particles Accelerators (CAMPA), funded by the U.S. DOE Office of Science under Contract No. DE-AC02-05CH11231.\nSupported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort of two U.S. Department of Energy organizations (Office of Science and the National Nuclear Security Administration).\nThis project has received funding from the European Unions Horizon 2020 research and innovation programme under grant agreement No 654220.\nThis work was partially funded by the Center of Advanced Systems Understanding (CASUS), which is financed by Germany's Federal Ministry of Education and Research (BMBF) and by the Saxon Ministry for Science, Culture and Tourism (SMWK) with tax funds on the basis of the budget approved by the Saxon State Parliament.\nSupported by the HElmholtz Laser Plasma Metadata Initiative (HELPMI) project (ZT-I-PF-3-066), funded by the \"Initiative and Networking Fund\" of the Helmholtz Association in the framework of the \"Helmholtz Metadata Collaboration\" project call 2022.\n\n### Transitive Contributions\n\nopenPMD-api stands on the shoulders of giants and we are grateful for the following projects included as direct dependencies:\n\n* [ADIOS2](https://github.com/ornladios/ADIOS2) by [S. Klasky, N. Podhorszki, W.F. Godoy (ORNL), team, collaborators](https://csmd.ornl.gov/adios) and [contributors](https://github.com/ornladios/ADIOS2/graphs/contributors)\n* [Catch2](https://github.com/catchorg/Catch2) by [Phil Nash](https://github.com/philsquared), [Martin Hořeňovský](https://github.com/horenmar) and [contributors](https://github.com/catchorg/Catch2/graphs/contributors)\n* HDF5 by [the HDF group](https://www.hdfgroup.org) and community\n* [json](https://github.com/nlohmann/json) by [Niels Lohmann](https://github.com/nlohmann) and [contributors](https://github.com/nlohmann/json/graphs/contributors)\n* [toml11](https://github.com/ToruNiina/toml11) by [Toru Niina](https://github.com/ToruNiina) and [contributors](https://github.com/ToruNiina/toml11#Contributors)\n* [pybind11](https://github.com/pybind/pybind11) by [Wenzel Jakob (EPFL)](https://github.com/wjakob) and [contributors](https://github.com/pybind/pybind11/graphs/contributors)\n* all contributors to the evolution of modern C++ and early library preview developers, e.g. [Michael Park (Facebook)](https://github.com/mpark)\n* the [CMake build system](https://cmake.org) and [contributors](https://github.com/Kitware/CMake/blob/master/Copyright.txt)\n* packaging support by the [conda-forge](https://conda-forge.org), [PyPI](https://pypi.org) and [Spack](https://spack.io) communities, among others\n* the [openPMD-standard](https://github.com/openPMD/openPMD-standard) by [Axel Huebl (HZDR, now LBNL)](https://github.com/ax3l) and [contributors](https://github.com/openPMD/openPMD-standard/blob/latest/AUTHORS.md)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/osadcp-toolbox",
            "repo_link": "https://git.geomar.de/dam/osadcp_toolbox/",
            "readme": "DOI: [10.3289/SW_2_2024](https://doi.org/10.3289/SW_2_2024)\n\n# OSADCP_Toolbox\nVessel-mounted Acoustic Doppler Current Profilers (VMADCPs) provide velocity profiles of the upper ocean along the ship track. They are a key tool in oceanographic research to study the oceanic circulation and the associated distribution of mass, heat, contaminants and other tracers. In order to obtain high-quality ocean current data from vessel-mounted ADCP measurements, a number of requirements must be met, from system installation and data acquisition measures to certain essential processing steps. Here, we present an open-source Python toolbox called OSADCP for scientists to convert, clean, calibrate and organize binary raw vessel-mounted ADCP data for scientific use. The toolbox is designed to process VMADCP measurements in deep water by Teledyne RDI Ocean Surveyor ADCPs and the data acquisition software VMDAS. \n\n## About OSADCP\nOSADCP emerged from the MATLAB-based OSSI­ toolbox, which was developed over many years at GEOMAR, Helmholtz Centre for Ocean Research Kiel. It has been further developed for the standardized handling of VMADCP data sets collected as part of the Underway Research Data program of the [German Marine Research Alliance](https://www.allianz-meeresforschung.de/en). To facilitate access for the whole scientific community, OSADCP is written in Python. The software is designed to process ADCP raw data acquired with RDI’s data acquisition software VMDAS. A basic framework of the software is made available to the scientific community. The version described here is prepared for processing ENX files recorded by VMDAS, and requires both good ADCP and navigation data. By default, OSADCP processes ENX files, which requires both high-quality and complete ADCP raw data and navigation data. A carefully planned ADCP and data acquisition system fulfils these requirements in most cases. From our experience, working with ENX files is therefore generally preferred due to the simplicity of the handling. In the event that problems arise with either ADCP or navigation data, that require for example editing of beam-wise ADCP velocities or the manual merging of navigation data, OSADCP has special modules processing either ENR or ENS files that are not yet made publicly available.\n\nOSADCP, the underlying priciples of ADCP measurement and the workflow it is embedded in are described great detail in a separate scientific article (Kopte et al. 2024)\n\n## Installation and Setup\n\n### Prerequisites\nOSADCP is a python based toolbox which provides GUIs for the processing ADCP data as well as for interactive plots. Depending on your system, you might need to **[install QT5](https://wiki.qt.io/Main)** to be able to use it.\n\nYou also need a working and reasonably current **Python3 installation**. Although it is perfectly possible to install OSADCP in your systems main Python installation, some kind of isolation, such as a [virtual environment](https://docs.python.org/3/library/venv.html), is recommended. OSADCP is built primarily with the following open-source packages: numpy (Harris et al. 2020), scipy (Virtanen et al. 2020), [PyQt5](https://www.riverbankcomputing.com/static/Docs/PyQt5/), matplotlib (Hunter 2007), netCDF4 (Unidata 2021).\n\n### Download and installation\n\nThe OSDACP-Toolbox is published via a Git-repository at https://git.geomar.de/dam/osadcp_toolbox\n\nYou can [download it as a .zip File](https://git.geomar.de/dam/osadcp_toolbox/-/archive/main/osadcp_toolbox-main.zip) from there and extract it locally. Alternatively, if you have [git](https://git-scm.com/) installed, you can use the following command to download it:  \n```\ngit clone https://git.geomar.de/dam/osadcp_toolbox.git\n```   \nAfterwards, install OSDACPs dependencies as specified in the requirements file:\n\n```\npip install -r requirements.txt\n```\n\n### Setup\n\nAfter setting up the toolbox, meta-information on ADCPs and vessels, such as serial numbers, lever arms etc., can be added to the json-dictionary `json/vessel_adcp_library.json`. This dictionary manages ADCP and vessel-specific metadata centrally and is used by the [processing management module](#processing-management) for efficient allocation and forwarding.\n\n## Step-by-Step Instructions to use OSADCP\n\n![Figure Workflow Overview](./docs/images/01_osadcp_workflow.png)\n*Workflow of the OSADCP processing toolbox. Main Python modules are depicted by the dark blue boxes. Files storing major processing information are depicted in green boxes, ADCP data (binary pd0, intermediate netCDF files and final netCDF files) are represented by yellow boxes, while files documenting the processing are shown by orange boxes.*\n\n### os_settings.py\n![Figure `os_settings.py`](./docs/images/02_os_settings.png)\n*GUI for controlling the processing of ADCP data in OSADCP. The GUI is called via `os_settings.py`.* \n\nA central point of the toolbox is the module `os_settings.py`, which runs a basic GUI as shown above. This GUI is used to create and modify a configuration json file for the processing. It makes use of the json dictionary `json/vessel_adcp_library.json`, where meta-information on vessel-specific ADCPs are stored. \n\nThe configuration file is saved to `json/OSCONFIG.json`. A list of files to be processed is saved to the chosen processing directory, along with a copy of the configuration file for documentation purpose. Both the configuration file `json/OSCONFIG.json` and the list of files will be used by all other OSADCP processing modules (see [Workflow Figure](#step-by-step-instructions-to-use-osadcp)).\n\nIt is possible to load an existing configuration either from the working directory `json/OSCONFIG.json` or from any processing directory `[proc_dir]/ OSCONFIG_[adcp]_[vessel]_[leg].json`, which is a common step when refining a data set or resuming work on an older dataset.\n\nAn alternative way is to manually edit the file `json/OSCONFIG.json` directly and then update the list of files and the configuration copy in the processing directory by executing the Python module `os_update_filelist.py`.\n\n### os_read_enx.py\nThe Python module `os_read_enx.py` is executed to loop over all files listed in `[proc_dir]/OSFILELIST_*.txt` and extract all VMADCP raw data and navigation data from the binary ENX files. For each binary raw data file, a corresponding netCDF file (Unidata 2021) is saved to the processing directory, containing all data on the single-ping level (see [Workflow Figure](#step-by-step-instructions-to-use-osadcp)). These files can be accessed for any user-specific editing on single-ping level not covered by the OSADCP standard treatment before continuing on the ensemble-average level.\n\nA major task carried out by the module is the verification of the navigation data merged into the ENX files. Common problems include the occurrence of zero/zero positions when no real data is available due to problems of the navigation sensor and irregularities in the time allocation such as time stops, backward time jumps, time shifts etc. Affected pings are flagged accordingly and ignored in further processing. In the case of very poor navigation data, the manual insertion of external navigation data on single-ping level should be considered.\n\n### os_rm_interference.py\n\n#### Bottom Interference\n![bottom mask figure](./docs/images/03_rm_interference_01.png)\n*GUI for picking and editing a bottom mask, i.e. areas that are affected by bottom and sidelobe interference. The GUI is called via `os_rm_interference.py`.* \n\nAn important aspect of the processing concerns the scanning for echo feedback from the ground, which introduces spurious velocities in the affected cell range. This task can be automated only to a limited extent since the echo intensity profile used for the identification is rarely unambiguous. It can be affected by acoustic interference in the water column or the occurrence of strong scattering layers, for example, that may lead to false bottom detection. Furthermore, near the sea bed velocities are potentially corrupted by sidelobe interference. Depending on the beam angle $\\theta$ and the distance $z$ to the ADCP transducer (ignoring pitch and roll tilts), velocities in the range $z_{shadow}= z (1-\\cos\\theta)$ above the bottom, the so-called shadow zone, are then contaminated by the sidelobe echo returning earlier to the transducer than the slanted main lobe. The detection and removal of spurious velocities beneath the shadow zone is a prerequisite for the subsequent water-track calibration, especially if the shadow zone depth overlaps with the reference layer chosen for the calibration (see `os_watertrack.py` below).\n\nIn the GUI called by `os_rm_interference.py`, the time series of beam-averaged echo intensity and corresponding along-track velocity are displayed for each file that is part of the data set. The along-track velocity component is shown as assisting information, as the velocity bias associated with bottom and sidelobe interference is most obvious in there while the ship is underway. To visualize a potential velocity bias, the median along-track velocity is removed for each ping.\nBased on visual inspection of these fields, the user decides whether the corresponding file contains a bottom signal and requires editing. A line corresponding to the depth of bottom influence on the measured velocities can be picked and edited via button control on the left side of the GUI (see [bottom mask figure](#bottom-interference)) and finally saved as a separate netCDF file with a *_bot_mask.nc extension added to the file naming convention (see [workflow figure](#step-by-step-instructions-to-use-osadcp)). Velocity AND echo intensity information in cells below the bottom line are excluded from further processing!\n\n#### Bow Thruster Interference\n![bow thruster mask figure](./docs/images/04_rm_interference_02.png)\n*GUI for marking and editing periods of bow thruster interference. The GUI is called via `os_rm_interference.py`.* \n\nIn order to derive relative backscatter values, the measured time series of echo intensity needs to be thourougly cleaned from all kinds of interference. Especially during station work, ADCP data quality is often heavily affected by the use of the ship's bow thruster that is used to keep the ship in parking position or for on-station maneuvers. The module `os_rm_interference.py` allows for the identification, marking and editing of such periods via button control on the left side of the GUI (see [bow thruster mask figure](#bow-thruster-interference)). The correspinding mask is saved as a separate netCDF file with a *_bow_mask.nc extension added to the file naming convention (see [workflow figure](#step-by-step-instructions-to-use-osadcp)) and later applied ONLY to the fields of cleaned echo intensities that is finally used for the calculation of relative backscatter.\n\n### Alternative module: os_edit_bottom.py\n\n`os_edit_bottom.py` is the command-line alternative to `os_rm_interference.py`, that can be used for picking the bottom interference mask. It does not provide a solution for selecting periods of bow thruster interference though. The module loops through all data files and lets the user decide whether a bottom signal is present in a similar way as implemented in `os_rm_interference.py`, yet controlled via command-line queries. \n\n### Calculation of Current Velocities\n\n#### os_watertrack.py\nThe primary module of the software for deriving deep-water velocity profiles is called `os_watertrack.py`. It carries out important steps concerning the derivation of ship speed, the cleaning and averaging of single-ping data, and the estimation and application of the velocity calibration.  \n\nThe ship speed is calculated via central differences based on the GNSS position data, ignoring only pings with questionable navigation data as flagged by `os_read_enx.py`. If the configuration file `json/OSCONFIG.json` contains lever arm information for the given setup of ADCP and GNSS sensor, the GNSS positions are corrected prior to the calculation of ship speed as follows:\n\n$$lon_{add} = \\frac{1}{1.11e^5\\,m\\cdot \\cos(lat)}\\left(\\cos(H)(x_{ADCP}-x_{GPS}) + \\sin(H)(y_{ADCP} - y_{GPS})\\right)$$\n\n$$lat_{add} = \\frac{1}{1.11e^5\\,m}\\left(-\\sin(H)(x_{ADCP-x}-x_{GPS}) + \\cos(H)(y_{ADCP} - y_{GPS})\\right)$$\n\nwith $H$ being the ship’s heading, and $x_{ADCP|GPS}$  and $y_{ADCP|GPS}$ being the positions of the ADCP transducer and GNSS antenna relative to the ship’s center point along the minor and major axes of the ship, respectively ($x$: starboard, $y$: forward). This correction improves current velocities during ship maneuvers when the heading changes rapidly.\n\n`os_watertrack.py` applies a number of automated cleaning criteria to the single-ping velocity data:\n\n1.\tError velocity: Large error velocities indicate a non-homogeneous flow field or large reflectors like fish, that cannot be assumed to move passively with the current. During the cleaning all cells are masked, where the derived cell error velocity exceeds twice the standard deviation of the error velocity.\n1.\tDoubtful heading data: This criterium deals with unrealistic ship heading data by masking entire velocity profiles, where the ping-to-ping heading change exceeds 10°.\n1.\tDoubtful current velocities: For this criterium, the single-ping current velocity is approximated by subtracting the ship velocity components from the measured velocities in the reference layer. Subsequently, entire velocity profiles are masked, either where the ping-to-ping change in either velocity component exceeds 2 m/s, or where either velocity component exceeds 5 m/s.\n1.\tAcoustic interference: The vigor of the applied cleaning of acoustic interferences is controlled via `os_settings.py`.\n    1. For 'light' cleaning, `os_watertrack.py` first constructs an echo intensity anomaly field by subtracting the median echo intensity from the time series at each depth level. Cells potentially affected by interference are then determined by identifying ping-to-ping differences that either exceed or fall below +0.7 or -0.7 of the total standard deviation of ping-to-ping differences, respectively. The candidate cells are then checked if they are of single-ping duration and whether the associated intensity spikes extend over several depth cells. All cells that are identified as being affected by acoustic interference are subsequently masked.\n    1. For 'medium' and 'strong' cleaning', `os_watertrack.py` additionaly targets the heavy tails of distribution of the total echo intensity anomaly field. For this distribution, the first and third quartiles are calculated that determine the 'interquartile range' as $IQR = Q3-Q2$. The upper and lower cut-off thresholds are then determiney by $Q3 + x\\cdot IQR$ and $Q1 - x\\cdot IQR$ with $x = 1.5$ and $x = 0.75$ for 'medium' and 'strong' cleaning, respectively. Values that exceed or fall below the right-sided or left-sided heavy tail are classified as outliers and are additionally excluded from further processing.  \n1.\tBottom and sidelobe interference: To mask cells affected by the bottom return echo, `os_watertrack.py` reads the corresponding *_bot.nc files created by `os_rm_interference.py` and applies the generated bottom interference mask to the single-ping velocity data.\n\nSubsequently, single-ping data along the water column is averaged into so-called ensembles, with the velocities being vector-averaged. Using ensemble averages reduces the spread of single-ping current estimates, increasing the precision of the measurement. In `os_watertrack.py` the default average interval is 1 minute.\n\nThe water-track calibration implemented in `os_watertrack.py` addresses two different errors (Joyce 1989, Firing and Hummon 2010):\n\n2.\tMisalignment error: A deviation of the transducer alignment with respect to the heading reference of the ship introduces a bias with its main effect being a spurious cross-track velocity component proportional to ship speed.\n2.\tScaling error: Small errors in the beam geometry or a non-zero trim of the transducer or ship can cause a systematic bias affecting mostly the along-track velocity component, proportional to ship speed. \n\nThe calibration aims at minimizing these errors by determining a misalignment angle correction $\\alpha$ and a scale factor correction $\\beta$, taking advantage of ship maneuvers involving speed changes. On research campaigns, such maneuvers primarily occur when approaching or leaving scientific stations, during which the ship is in parking position. Assuming that the true water velocities below the ship are constant during such maneuvers in a small area and over a short time interval, any measured variations in the absolute currents must result from the imperfect removal of the bias introduced by misalignment and scaling errors (Joyce 1989, Fischer et al. 2003). To find possible calibration points, `os_watertrack.py` first calculates the time intervals, the distances travelled and the differences in ship speed between each ensemble and all other ensembles that are found within one hour. From this cloud of possible calibration points, all points with a distance covered of less than 5000 m and a minimum ship speed difference of 3 m/s are selected. In this way, different temporal and spatial scales are considered for the calibration. For all these points, the algorithm then minimizes the root-mean-square error between the corresponding ship velocities based on the GNSS position data and the velocities measured by the ADCP that are averaged over a certain depth range, the so-called reference layer. The upper and lower limits of this layer have to be defined via `os_settings.py`. The resulting noisy estimate of individual misalignment angles and scale factors is presented in a calibration plot (see calibration plot below). The individual estimates should cluster around some mean or median values, that represent the actual calibration values. It is the user’s decision, whether the mean values should be applied directly to the data to refine the calibration. Alternatively, the processing can be continued with the previously entered values. In any case, desired values for the misalignment angle and calibration value can be entered via `os_settings.py` at any time and are applied by subsequently calling `os_watertrack.py` again. After calibration, the optimized mean misalignment angle and the scale factor should correspond to 0 and 1, respectively (as is shown in the calibration plot below). \n\n![Figure `calibration_plot`](./docs/images/05_calibration_plot.png)\n*Results of OSADCP misalignment error and scale factor calibration for exemplary data set from 75 kHz Ocean Surveyor ADCP during R/V Meteor cruise M189 ([Dengler et al. 2023]( https://doi.pangaea.de/10.1594/PANGAEA.962916)). Left histogram shows misalignment angle estimates clustering around zero, after a correction of -0.2047° was applied, right histrogram shows corresponding results for the scale factor clustering around one, after a correction factor of 1.0035 was applied.*\n\nThe final calibration values $\\alpha$ and $\\beta$ are applied to the measured velocities $u_{ADCP},v_{ADCP}$. Taking into account the calculated ship velocities $u_s, v_s$, the horizontal water velocities $u_w, v_w$ in east and north direction are then derived using the formula provided by Joyce 1989:\n\n$$u_w = u_s + (1+\\beta) (u_{ADCP}\\cos(\\alpha) - v_{ADCP}\\sin(\\alpha))$$\n\n$$v_w = v_s + (1+\\beta) (u_{ADCP}\\sin(\\alpha) + v_{ADCP}\\cos(\\alpha))$$\n\n#### os_bottomtrack.py\nEven though bottom-track processing is not in the focus of this toolbox, a basic solution is provided by `os_bottomtrack.py` and can be used as alternative for `os_watertrack.py`. It contains a similar implementation for automated cleaning of single-ping including the application of the bottom mask to eliminate affected depth cells. \n\nTo use `os_bottomtrack.py` VMDAS needs to be configured to send bottom-track pings alternating to water-profile pings during data acquisition. The module then uses bottom-track velocities as ship speed over ground. At the single-ping level, the bottom-track velocities are directly subtracted from the water-profile velocities to obtain absolute current velocities. Because water-profile and bottom-track velocities share the instrument coordinate system, this operation does not introduce a cross-track velocity bias.\n\nHowever, the module does not contain an implementation to determine the transducer orientation relative to the ship’s heading sensor to account for a potential transducer misalignment. Here, the misalignment results in an inaccurate estimate of the current’s direction rather than introducing a cross-track velocity bias, which is not as severe given a small misalignment angle.\n\n### Calculation of Relative Backscatter\nIf selected in `os_settings.py`, relative acoustic backscatter is calculated from the cleaned echo intensity data by applying a working version of the sonar equation (Mullison, 2017):\n\n$$S_v = C + 10\\log_{10}\\left((T_x + 273.16)R^2\\right) - L_{DBM} - P_{DBW} + 2\\alpha R + 10\\log_{10}\\left(10^{k_c(E-E_r)/10}-1\\right)$$\nwhere $S_v$ is the backscatter, $C$ is a constant combining several parameters specific to each instrument, $T_x$ is the temperature measured at the transducer, $L_{DBM}$ is the $10\\log_{10}$ of the transmit pulse length, $P_{DBW}$ is the $10\\log_{10}$ of the transmit power, $R$ is the along-beam range to scatterers, $\\alpha$ is the absorption coefficient of water, $k_c$ is the conversion factor for echo intensity, $E$ is the measured echo intensity (RSSI), and $E_r$ is the measured echo intensity (RSSI) in the absence of any signal (noise).\n\nIn the calculation applied here, $E_r$ is neglected, hence the term 'relative backscatter'.\n\nThe conversion factor $k_c$ is calculated as follows:\n\n$$ k_c = \\frac{127.3}{(T_x + 273.16)}$$\n\nThe slant range $R$ is calculated as follows:\n\n$$R = \\left(\\frac{B + \\lvert P-CS \\rvert/2 + (N\\cdot CS) + CS/4}{\\cos\\theta}\\right) \\left(\\frac{c^\\prime}{c_x}\\right)$$\nwhere $B$ is the blanking distance, $P$ is the pulse length, $CS$ is the cell size, $N$ is the number of cells, $\\theta$ is the beam angle, $c'$ is the mean sound speed between the transducer depth and the depth of the cell, and $c_x$ is the sound speed at the transducer.\n\nThe absorption coefficient of water $\\alpha$ is calculated as the sum of contributions from boric acid, magnesium sulfate and pure water, following Francois and Garrison (1982). The calculation requires fields of temperature, salinity and sound speed on the ADCP cell grid. The temperature and salinity fields are extracted from the seasonal means over the 2015-2022 period on a 1°x1° grid provided by the World Ocean Atlas 2023 Data (Locarnini et al., 2023 and Reagan et al., 2023). The gridded data is interpolated on the ADCP grid along the cruise track. From the interpolated fields, sound velocity is calculated.\n\n\n### Quality Flagging\nBoth `os_watertrack.py` and `os_bottomtrack.py` contain an implementation for automated quality assessment. The flagging scheme follows the SeaDataNet vocabulary for measured qualifier flags (SeaDataNet 2022).\n\nThe central criterion for the quality assessment is the evaluation of the ensemble percent-good value. The ensemble percent-good value is a measure of the number of valid measurements contained in an ensemble-mean. The ensemble percent-good threshold is defined via `os_settings.py` and saved in `json/OSCONFIG.json`. The default value of 25% is an empirical value to achieve a reasonable compromise between noise and range, where the expected error of cells with percent-good value of 25% is twice the expected error of cells with percent-good value of 100%. For applications where high accuracies are required it is advisable to select a higher percent-good threshold. Cells with an ensemble percent-good value below the defined threshold are flagged as “bad data”.\n\nIf a bias is detected in the top cells during post-processing, which is most likely associated with ringing or reverberation of the transducer or heavy sea conditions, affected cells can be flagged as “potentially bad data” for the whole deployment. Affected cells are selected via `os_settings.py`.\n\n### Meta Data Standards, Documentation and Archiving\nThe final data product of processed and quality-controlled VMADCP velocity measurements is created as netCDF file (Unidata 2021). \n\nMetadata standards follow Climate and Forecast conventions (CF-1.6, v19), OceanSites Manual-1.3, EGO glider user manual 1.3, and Attribute Convention for Data Discovery 1.3 (ACDD-1.3). Additionally, all relevant meta information about the deployment, VMADCP system, data acquisition and processing parameters are stored as global attributes. The standard name vocabulary to identify data variables is from CF-1.6, v19. Ensemble-mean time series of horizontal velocity profiles, and corresponding quality flags are stored as 2-D arrays, while the time, position and cell depth information are saved as 1-D vectors.\n\n## Contributing\n\nOSDACP Toolbox is hosted on the GEOMAR Gitlab instance: https://git.geomar.de/dam/osadcp_toolbox/\n\nPlease feel free to submit bug reports and issues there and contact the authors if you would like to have developer access there.\n\n### Dev-dependencies\nProject dependencies needed only for development are kept in the `requirements-dev.txt` file which you can install as usual with pip:\n\n`pip install -r requirements-dev.txt`\n\n### Versioning schema\nOSDACP Toolbox follows a simplified [semantic versioning schema](https://semver.org/) with *MAJOR*.*MINOR*.*PATCH* version specifiers:\n\n- MAJOR version when you make incompatible API changes\n- MINOR version when you add functionality in a backward compatible manner\n- PATCH version when you make backward compatible bug fixes\n\nVersion information is provided throughout headers in `*.py` files and is managed using the [bump-my-version](https://callowayproject.github.io/bump-my-version/) tool.\n\nAfter installing `bump-my-version` (through pip as described in the [Dev-dependencies](#dev-dependencies) section above), you can use the command as follows:\n\n- `bump-my-version patch` creates a new patch version, e.g. \"1.0.0\"-->\"1.0.1\"\n- `bump-my-version minor` creates a new minor version, e.g. \"1.0.0\"-->\"1.1.0\"\n- `bump-my-version major` creates a new patch version, e.g. \"1.0.0\"-->\"2.0.0\"\n\n- `bump-my-version show-bump` shows available versions for a major, minor and patch bump respectively:\n\n```\n$ bump-my-version show-bump \n1.0.0 ── bump ─┬─ major ─ 2.0.0\n               ├─ minor ─ 1.1.0\n               ╰─ patch ─ 1.0.1\n```\nPlease note that by default, `bump-my-version` only works on a 'clean' repository with no uncomitted changes. It is also configured to create a new commit as well as a tag automatically. You can change the default behaviour by editing the `.bumpversion.toml` or by overriding it using command line arguments. \n\nSee  `bump-my-version --help` or the [`bump-my-version` documentation](https://callowayproject.github.io/bump-my-version/) for further information.\n\n---\nReferences\n\n- Firing & Hummon (2010): Ship-mounted acoustic Doppler current profilers. In Hood E.M, C. L. Sabine, B. M. Sloyan (Eds.): The GO-SHIP Repeat Manual: A Collection of Expert Reports and Guidelines. IOCCP Report Number 14, ICPO Publication Series Number 134.\n- Fischer et al (2003): Surveying the Upper Ocean with the Ocean Surveyor. A New Phased Array Doppler Current Profiler. J. Atmos. Oceanic Technol. 20 (5), pp. 742–751. DOI: 10.1175/1520-0426(2003)20%3C742:STUOWT%3E2.0.CO;2.\n- Francois & Garrison (1982) Sound absorption based on ocean measurements: Part II: Boric acid contribution and equation for total absorption. Journal of the Acoustical Society of America, 72(6), 1879-1890.\n- Harris et al (2020): Array programming with NumPy. Nature 585 (7825), pp. 357–362. DOI: 10.1038/s41586-020-2649-2.\n- Hunter (2007): Matplotlib: A 2D Graphics Environment. Comput. Sci. Eng. 9 (3), pp. 90–95. DOI: 10.1109/MCSE.2007.55.\n- Joyce (1989): On In Situ “Calibration” of Shipboard ADCPs. J. Atmos. Oceanic Technol. 6 (1), pp. 169–172. DOI: 10.1175/1520-0426(1989)006%3C0169:OISOSA%3E2.0.CO;2.\n- Kopte et al (2024) OSADCP - An Open-Source Python Toolbox as Integral Part of a Workflow for Standardized and FAIR Vessel-Mounted ADCP Data. Front. Mar. Sci. 11:1425086.\nDOI: 10.3389/fmars.2024.1425086\n- Locarnini et al (2023) World Ocean Atlas 2023, Volume 1: Temperature. A Mishonov Technical Ed. NOAA Atlas NESDIS 89, DOI: 10.25923/54bh-1613\n- Mullison (2017) Bachscatter Estimation Using Broadband Acoustic Doppler Current Profilers - Updated. Conference paper at 'ASCE Hydraulic Measurements & Experimental Methods Conference', Durham, NH, July 9-12, 2017.\n- Reagan et al (2023) World Ocean Atlas 2023, Volume 2: Salinity. A Mishonov, Technical Editor, NOAA Atlas NESDIS 90, DOI: 10.25923/70qt-9574\n- SeaDataNet (2022): SeaDataNet Measured Qualifier Flags. Available online at https://vocab.nerc.ac.uk/collection/L20/current/, updated on 5/14/2022, checked on 11/9/2023.\n- Unidata (2021): Network Common Data Format (netCDF) version 1.5.8 [software]. UCAR/Unidata. Boulder, CO.\n- Virtanen et al (2020): SciPy 1.0: fundamental algorithms for scientific computing in Python. Nature methods 17 (3), pp. 261–272. DOI: 10.1038/s41592-019-0686-2.\n\n---\nCopyright © 2024 Robert Kopte @ Deutsche Allianz Meeresforschung (DAM, https://www.allianz-meeresforschung.de/)  \nThis is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\nThis file is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Affero Public License for more details.\nYou should have received a copy of the GNU Affero General Public License along with this program. If not, see http://www.gnu.org/licenses/.\n",
            "project_id": "3296"
        },
        {
            "software_organization": "https://helmholtz.software/software/otter",
            "repo_link": "https://gitlab.com/qtb-hhu/marine/otter",
            "readme": "[![DOI](https://img.shields.io/badge/DOI-10.1038/s43247--024--01782--0-blue)](https://doi.org/10.1038/s43247-024-01782-0)\n\n\n[![Latest Release](https://gitlab.com/qtb-hhu/marine/otter/-/badges/release.svg)](https://gitlab.com/qtb-hhu/marine/otter/-/releases)\n# otter\n<div style=\"float: left;\">\n        <img src=\"img/otter_logo-removebg.png\" alt=\"Otter Logo\" width=\"200\" title=\"This images was created using GENAI (DALL-E 3).\"/>\n</div>\n<div style=\"text-align: right;\">\n<br>\n<br>\n<br>\n    The otter Framework combines community network analysis using Co-Occurrence networks, Louvain Clustering and Convergent Cross Mapping networks.\n<br>\n<br>\n<br>\n<br>\n</div>\n\n\n### Installation\nPython version 3.10\n```bash\npip install -r requirements.txt\n```\n\n### Pytest \n```bash\npytest\n```\n\n## Usage:\n\n### Run the app\n```bash\nstreamlit run Otter_APP.py\n```\n## Getting Started\n\n### 1. Set Prefix Path\nFill in the **Prefix Path** where the output tables will be saved.  \n- **Default**: `Tutorial/tables`  \n- This is the directory where all your results will be stored.\n\n### 2. Set Run ID\nInput the **Run ID**, which is the name for your experiment.  \n- **Default**: `MyExperimentRun`  \n- This name will be used to track the output of your experiment.\n\n### 3. Upload Abundance Table\nUpload the `abundance.csv` file, which contains the abundance time series.  \n- **Format**: The `abundance.csv` should follow the example provided in `tests/table/abundance.csv`.  \n- This table should include your time-series data for each ASV (Amplicon Sequence Variant).\n\n### 4. Upload Taxa Table\nUpload the `taxa.csv` file, which contains the taxonomic hierarchy for each ASV present in the abundance file.  \n- **Format**: Ensure this table includes the corresponding taxonomy information for each ASV.\n\n### 5. (Optional) Upload Environmental Table\nYou can optionally upload the `environmental.csv` file. This table should contain environmental parameters for each sample.  \n- **Format**: Ensure this file matches the sample names in the `abundance.csv`.\n\n### 6. Adjust Analysis Parameters\nYou can now adjust the parameters for the following calculations using the **expanding parameter cockpit**:  \n- **CON**: Co-Occurrence Network  \n- **CCM**: Convergent Cross Mapping  \n- **Permu**: Permutation tests\n\nMake sure to fine-tune these parameters based on your analysis needs.\n\n### 7. Run Calculations\nOnce parameters are set, you can create each network one by one or all at once:  \n- Use the **Create Network Buttons** from left to right to calculate each network (CON, CCM, etc.).  \n- Alternatively, click the **Run All** button to generate all networks in one go.\n\n## Visualizing Results\n\nAfter the network calculations are complete, you can switch to other tabs in the menu on the left-hand side to visualize your results.  \nEach tab provides a different visualization tool to explore the networks and clusters derived from your data.\n1. Environmental_Data\n2. Environmental_Cluster_Correlation_Heatmap\n3. Cluster Distribution \n4. Latentspace Embedding for Cluster Distances\n5. Alpha and Beta Diversity \n\n### Convergent Cross Mapping:\nThe CCM modul is based on https://github.com/PrinceJavier/causal_ccm.\n\n### Acknowledgements\nThanks to Prince Joseph Erneszer Javier for developing CCM package in python.\nThanks the Alfred-Wegener-Institute for funding parts of the development of the project.\n\n### Citation\nPlease cite Beyond blooms: the winter ecosystem reset determines microeukaryotic community dynamics in the Fram Strait. when using otter: https://www.nature.com/articles/s43247-024-01782-0 and the software https://zenodo.org/records/13840807.\n\n```\n@article{oldenburg2024beyond,\n  title={Beyond blooms: the winter ecosystem reset determines microeukaryotic community dynamics in the Fram Strait},\n  author={Oldenburg, Ellen and Kronberg, Raphael M and Metfies, Katja and Wietz, Matthias and von Appen, Wilken-Jon and Bienhold, Christina and Popa, Ovidiu and Ebenh{\\\"o}h, Oliver},\n  journal={Communications Earth \\& Environment},\n  volume={5},\n  number={1},\n  pages={643},\n  year={2024},\n  publisher={Nature Publishing Group UK London}\n}\n```\n\n\n",
            "project_id": "62009677"
        },
        {
            "software_organization": "https://helmholtz.software/software/palladio",
            "repo_link": "https://github.com/PalladioSimulator",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/training-catalogue-for-photon-neutron",
            "repo_link": "https://github.com/pan-training/training-catalogue",
            "readme": "[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7015078.svg)](https://doi.org/10.5281/zenodo.7015078)\n\n# PaN Training Catalogue (based on the TeSS Trainning Catalogue from ELIXIR)\n\nThis repository contains the sourcecode of our [PaN Training Catalogue](https://pan-training.eu). This catalogue is based on the [TeSS Trainning Catalogue](https://github.com/ElixirTeSS/TeSS) from the [ELIXIR](https://elixir-europe.org) project and is used in our Photon and Neutron (PaN) projects [ExPaNDS](https://expands.eu) and [PaNOSC](https://panosc.eu).\n \n## Setup\n\n```\nsudo apt-get install git postgresql libpq-dev imagemagick openjdk-8-jre nodejs redis-server\n```\n\nClone the TeSS source code via git:\n\n```\ngit clone https://github.com/ElixirTeSS/TeSS.git\n```\n\n### RVM, Ruby, Gems\n\nIt is typically recommended to install Ruby with RVM. With RVM, you can specify the version of Ruby you want installed, plus a whole lot more (e.g. gemsets). Full installation instructions for RVM are available online. In short:\n\n```\nsudo apt-get install software-properties-common\nsudo apt-add-repository -y ppa:rael-gc/rvm\nsudo apt-get update\nsudo apt-get install rvm\nrvm user gemsets\n```\n\nTeSS was developed using Ruby 2.4.5. We recommend using version 2.7.4 for our PaN catalague. To install recommended version of ruby and create a gemset, you can do something like the following:\n\n```\nrvm install `cat .ruby-version`\n/bin/bash --login\nrvm get stable --auto-dotfiles\nrvm use --create `cat .ruby-version`@`cat .ruby-gemset`\n```\n\nBundler provides a consistent environment for Ruby projects by tracking and installing the exact gems and versions that are needed for your Ruby application.\n\n```\ngem install bundler\n```\n\n### Redis/Sidekiq\n\nWe installed Redis before... but start Sidekiq!\n\n```\nbundle exec sidekiq\n```\n\n...or as a daemon in the background for production:\n\n```\nbundle exec sidekiq -d -L log/sidekiq.log -e production\n```\n\nNote that program 'gem' (a package management framework for Ruby called RubyGems) gets installed when you install RVM so you do not have to install it separately.\n\nOnce you have Ruby, RVM and bundler installed, from the root folder of the app do:\n\n```\nbundle install\n```\n\nFollow the steps on the official GitHub and setup PostgrSQL [repo](https://github.com/ElixirTeSS/TeSS), Solr, ... In a first development instance is is necessary to add the database login information in `secrets.yml`. \n\n### Set up environment\n\n`bin/rails db:environment:set RAILS_ENV=development or production!!!`\n\n### Solr\n\nTeSS uses Apache Solr to power its search and filtering system.\n\nTo start solr, run:\n\n```\nbundle exec rake sunspot:solr:start\n```\n\nYou can replace start with stop or restart to stop or restart solr. You can use reindex to reindex all records.\n\n```\nbundle exec rake sunspot:solr:reindex\n```\n\n### Database and Config\n\nFrom the app's root directory, create several config files by copying the example files.\n\n```\ncp config/tess.example.yml config/tess.yml\ncp config/sunspot.example.yml config/sunspot.yml\ncp config/secrets.example.yml config/secrets.yml\n```\n\nCreate Postgres DB with user `tess_user` and edit `config/secrets.yml` to configure the database name, user and password defined before.\n\nEdit `config/secrets.yml` to configure the app's secret_key_base which you can generate with:\n\n```\nbundle exec rake secret\n```\n\nCreate the databases:\n\n```\nbundle exec rake db:create:all\n```\n\nStart Solr:\n\n```\nbundle exec rake sunspot:solr:start\nbundle exec rake sunspot:solr:reindex\n```\n\nCreate the database structure and load in seed data:\n\nNote: Ensure you have started Solr before running this command!\n\n```\n$ bundle exec rake db:setup\n```\n\n\n### Dev Server\n\nThe dev server can evaluated with\n\n```\nbundle exec sidekiq\n```\n\nand\n\n```\nbundle exec rails server\n```\n\nand accessed via: http://localhost:3000\n\n#### Setup Administrators\n\nOnce you have a local TeSS succesfully running, you may want to setup administrative users. To do this register a new account in TeSS through the registration page. Then go to the applications Rails console:\n\n```\nbundle exec rails c\n```\n\nFind the user and assign them the administrative role. This can be completed by running this (where myemail@domain.co is the email address you used to register with):\n\n```\n2.2.6 :001 > User.find_by_email('myemail@domain.co').update_attributes(role: Role.find_by_name('admin'))\n```\n\n## Deployment: Providing TeSS using an Application Server\n\nAfter setting up TeSS, the configuration of an application server (**Phusion Passenger** is an application server and it is often used to power Ruby sites) is required.\n\nOr my prefered setup with Nginx:\n\nhttps://www.phusionpassenger.com/library/config/nginx/intro.html\n\nWe need additinal packages:\n\n```\napt-get install apache2-dev apt-get install libcurl4-gnutls-dev\n```\n\nAfter successfull development deployment add the Passenger Gem with:\n\n```\nsudo apt-get install -y dirmngr gnupg\nsudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 561F9B9CAC40B2F7\nsudo apt-get install -y apt-transport-https ca-certificates\n# Add our APT repository\nsudo sh -c 'echo deb https://oss-binaries.phusionpassenger.com/apt/passenger bionic main > /etc/apt/sources.list.d/passenger.list'\nsudo apt-get update\n# Install Passenger + Nginx module\nsudo apt-get install -y libnginx-mod-http-passenger\n```\n\nCheck the installation with:\n\n```\nsudo /usr/bin/passenger-config validate-install\nsudo /usr/sbin/passenger-memory-stats\n```\n\n...and add the recommended lines to your Nginx configuration file and finish the Passenger setup.\n\n\n```\nserver {\n\t# SSL configuration\n\tlisten 443;\n\tssl on;\n\tproxy_set_header X_FORWARDED_PROTO https;\n              proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;\n              proxy_set_header  Host $http_host;\n              proxy_set_header  X-Url-Scheme $scheme;\n              proxy_redirect    off;\n              proxy_max_temp_file_size 0;\n\tserver_name pan-training.hzdr.de;\n\tssl_certificate /etc/ssl/certs/pan.cert;\n    ssl_certificate_key /etc/ssl/private/pan.key;\n\tssl_session_timeout 1d;\n    ssl_session_cache shared:MozSSL:10m;  # about 40000 sessions\n    ssl_session_tickets off;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;\n    ssl_prefer_server_ciphers off;\n    root /var/www/catalogue/public;\n    passenger_enabled on;\n\tpassenger_ruby /usr/share/rvm/gems/ruby-2.4.5@tess/wrappers/ruby;\n\tpassenger_document_root /var/www/catalogue/public/;\n    passenger_sticky_sessions on; \n}\n```\n\nThen we initialize the production environment:\n\n```\nbundle exec rake db:setup RAILS_ENV=production\n```\n\nor clean init:\n\n```\nbundle exec rake db:reset RAILS_ENV=production\n```\n...and reindex Solr:\n\n```\nbundle exec rake sunspot:solr:start RAILS_ENV=production\nbundle exec rake sunspot:solr:reindex RAILS_ENV=production\n```\n\nCreate an admin user and assign it appropriate 'admin' role bu looking up that role in console in model Role (default roles should be created automatically):\n\n```\nbundle exec rails c -e production\n```\n\nThe first time and each time a css or js file is updated:\n\n```\nbundle exec rake assets:clean RAILS_ENV=production\nbundle exec rake assets:precompile RAILS_ENV=production\n```\n\nand reindexing the matadata:\n\n```\nbundle exec rake sunspot:solr:reindex RAILS_ENV=production\n```\n\nStatus Check and restart:\n\n```\nbundle exec rake sunspot:solr:start RAILS_ENV=production\nservice nginx restart\nbundle exec sidekiq -d -L log/sidekiq.log -C config/sidekiq.yml -e production\nservice redis-server restart\npassenger-memory-stats \npassenger-status\n```\n\nLogfiles:\n\n```\n/var/log/redis/redis-server.log\n/var/log/nginx/error.log\n/var/log/catalogue/passenger.log\n/var/log/catalogue/sidekiq.log\n/var/log/catalogue/production.log\n/var/log/catalogue/sunspot-solr-production.log\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pasta-bit-vector",
            "repo_link": "https://github.com/pasta-toolbox/bit_vector/",
            "readme": "# pasta::bit_vector\n\n<p align=\"center\">\n   <img width=250 height=175 src=\"https://raw.githubusercontent.com/pasta-toolbox/bit_vector/main/docs/images/logo_pasta_bit_vector.svg\" />\n</p>\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n[![DOI](https://zenodo.org/badge/419381885.svg)](https://zenodo.org/badge/latestdoi/419381885)\n[![pasta::bit_vector CI](https://github.com/pasta-toolbox/bit_vector/actions/workflows/ctest.yml/badge.svg)](https://github.com/pasta-toolbox/bit_vector/actions/workflows/ctest.yml)\n[![codecov](https://codecov.io/gh/pasta-toolbox/bit_vector/branch/main/graph/badge.svg?token=2QD6ME44SU)](https://codecov.io/gh/pasta-toolbox/bit_vector)\n\nThis header-only library contains a highly tuned (uncompressed) bit vector implementation with multiple space efficient rank and select support data structures.\nOur fastest rank and select support has a space overhead of only ~3.51% and makes use of data level parallelism via SIMD instructions.\n\nIf you use this code in a scientific context, please cite our paper.\n```bibtex\n@inproceedings{Kurpicz2022CompactRankSelect,\n  author    = {Florian Kurpicz},\n  title     = {Engineering Compact Data Structures for Rank and Select Queries on Bit Vectors},\n  booktitle = {{SPIRE}},\n  series    = {Lecture Notes in Computer Science},\n  volume    = {13617},\n  pages     = {257--272},\n  publisher = {Springer},\n  year      = {2022},\n  doi       = {10.1007/978-3-031-20643-6\\_19}\n}\n```\n\n## Contents\nThis repository contains the following algorithms and data structures.\nOur [documentation][] contains in-depth on the usage of all these algorithms and data structures including easy to follow examples.\nYou can find the example in the screenshot below as text, too.\n\n[![Screenshot Documentation](https://raw.githubusercontent.com/pasta-toolbox/bit_vector/main/docs/images/screenshot_documentation_v1.0.0.png)](https://www.pasta-toolbox.org/bit_vector/)\n\n### Bit Vectors\nBit vectors play an important role in many compressed text indices, e.g., the FM-index.\nThis repository contains the following bit vector implementations:\n\n- highly tuned [uncompressed bit vector][] with access operator\n- compact [rank](include/pasta/bit_vector/support/rank.hpp) and [select](include/pasta/bit_vector/support/rank_select.hpp) support for the uncompressed bit vector based on\n\n> Dong Zhou and David G. Andersen and Michael Kaminsky,\n> Space-Efficient, High-Performance Rank and Select Structures on Uncompressed Bit Sequences,\n> SEA 2013.\n\n- improved [rank](include/pasta/bit_vector/support/flat_rank.hpp) and [select](include/pasta/bit_vector/support/flat_rank_select.hpp) support requiring the same amount of memory but providing faster rank (up to 8% speedup) and select (up to 16.5% speedup) queries, and\n- a very fast [rank](include/pasta/bit_vector/support/wide_rank.hpp) support that can also answer [select](include/pasta/bit_vector/support/wide_rank_select.hpp) queries.\n\n[uncompressed bit vector]: include/pasta/bit_vector/bit_vector.hpp\n\n### Easy to Use\n\nSince this is a header-only library, you have to simply add it to your projects include path to use it.\nA small example can be found below.\nWe refer to the [documentation][] for more information.\n\n  ```cpp\n  #include <pasta/bit_vector/bit_vector.hpp>\n  #include <pasta/bit_vector/support/flat_rank_select.hpp>\n\n  // Create a bit vector of size 1000 containing only zeros and flip every other bit.\n  pasta::BitVector bv(1000, 0);\n  for (size_t i = 0; i < bv.size(); ++i) {\n    if (i % 2 == 0) {  bv[i] = 1; }\n  }\n  // Print the bit vector to see that everything worked ;-)\n  for (auto it = bv.begin(); it != bv.end(); ++it) {\n    std::cout << ((*it == true) ? '1' : '0');\n  }\n  std::cout << std::endl;\n\n  // Create rank and select support and print the result of some queries.\n  pasta::FlatRankSelect rs(bv);\n  std::cout << rs.rank0(250) << \", \" << rs.rank1(250)\n            << \", \"\n            << rs.select0(250) << \", \" << rs.rank1(250)\n            << std::endl;\n  ```\n\n### Benchmarks and Tests\n\nThere exist an easy to use [benchmark][], which helps to compare the implementations in this repository.\nTo build the benchmark, run the CMake command with `-DPASTA_BIT_VECTOR_BUILD_BENCHMARKS=On`.\nOur tests are contained in the folder [tests][].\nTo build the tests, run the CMake command with `-DPASTA_BIT_VECTOR_BUILD_TESTS=On`.\n\nWe also conducted an extensive experimental evaluation.\nTo this end, we use our [rank and select benchmark][] where we compare our implementations with many other compact rank and select data structures.\n\nWe refer to our paper for a full description of the results, i.e., hardware, inputs, and competitors.\nBelow, you can find some of the figures we present in the paper.\n\n![Screenshot Documentation](https://raw.githubusercontent.com/pasta-toolbox/bit_vector/main/docs/images/space_requirements_v1.0.0.png)\n\n![Screenshot Documentation](https://raw.githubusercontent.com/pasta-toolbox/bit_vector/main/docs/images/rank_times_v1.0.0.png)\n\n![Screenshot Documentation](https://raw.githubusercontent.com/pasta-toolbox/bit_vector/main/docs/images/select_times_v1.0.0.png)\n\n![Screenshot Documentation](https://raw.githubusercontent.com/pasta-toolbox/bit_vector/main/docs/images/select_times_pasta_only_v1.0.0.png)\n\n[benchmark]: benchmarks/bit_vector_benchmark.cpp\n[rank and select benchmark]: https://github.com/pasta-toolbox/bit_vector_experiments\n[tests]: tests/\n\n## How to Get This\nBelow, we list all commands that are required to build the code in this repository.\nTo this end, we provide three CMake presets (_debug_, _release_, and _release with debug information_).\n\n- The debug preset creates a `debug` folder and uses the compiler flags `-DDEBUG -O0 -g -ggdb -fsanitize=address`.\n- The release preset creates a `build` folder and uses the compiler flags `-DNDEBUG -march=native -O3`.\n- The release with debug information preset creates a `build_with_debug_info` folder and uses the compiler flags `-DDEBUG -g -march=native -O3`.\n\nPer default, we use the following compiler flags: `-Wall -Wextra -Wpedantic -fdiagnostics-color=always`.\n\n### Requirements\npasta::bit_vector is written in C++20 and requires a compiler that [supports][] it.\nWe use [Ninja][] as build system.\nFor more information on how to use this library, please refer to our [documentation][].\n\n[supports]: https://en.cppreference.com/w/cpp/compiler_support\n[Ninja]: https://ninja-build.org/\n\n### tl;dr\nTo just clone the source code, use the following.\n```bash\ngit clone git@github.com:pasta-toolbox/bit_vector\ncd bit_vector\ngit submodule update --init --recursive\n```\nIf you also want to build the test, please continue with the following commands.\n```bash\ncmake --preset=[debug|build|relwithdeb]-DPASTA_BIT_VECTOR_BUILD_TESTS=On\ncmake --build --preset=[debug|release|relwithdeb]\nctest --test-dir [debug|build|relwithdeb]\n```\n\n[documentation]: https://www.pasta-toolbox.org/bit_vector/\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pdaf",
            "repo_link": "https://github.com/PDAF/PDAF",
            "readme": "\n# PDAF (Parallel Data Assimilation Framework)\n\nCopyright 2004-2024, Lars Nerger, Alfred Wegener Institute, Helmholtz Center\nfor Polar and Marine Research, Bremerhaven, Germany. \nFor license information, please see the file LICENSE.txt.\n\nFor full documentation and tutorial, see: http://pdaf.awi.de \n\n\n## Introduction\n\nPDAF is a framework for data assimilation.\nPDAF can be used to assess data assimilation methods with small models,\nto perform real data assimilation with high-dimensional models, and to\nteach ensemble data assimilation. \n\nPDAF provides \n- A parallel infrastructure, using MPI and OpenMP, to implement a\n  parallel data assimilation system based on existing numerical\n  models (typically of components of the Earth system). \n- A selection of ensemble data assimilation algorithms based on\n  the Kalman filter or nonlinear filters (see list below)\n- A selection of 3D variational methods, both with parameterized\n  and ensemble covariance matrix\n- Functions for ensemble diagnostics\n- Functionality to generate synthetic observations for data\n  assimilation studies (e.g. OSSEs)\n\nThe PDAF release provides also\n- Tutorial codes demontrating the implementation\n- Code templates to assist in the implementation\n- Toy models fully implemented with PDAF for the study of data\n  assimilation methods.\n- Model bindings for using PDAF with different models \n\n\n## First Steps with PDAF\n\nA good starting point for using PDAF is to run a tutorial example.\nThe directory /tutorial contains files demonstrating the application \nof PDAF with a simple 2-dimensional example.\n\nThe web site  http://pdaf.awi.de/trac/wiki/FirstSteps \nprovides hints on getting started with PDAF and \n  https://pdaf.awi.de/trac/wiki/PdafTutorial\nholds the tutorial slide sets that explain the implementation\nsteps and how to compile and run the tutorial examples. \n\n\n## Models\n\nThe directory models/ contains toy models that are fully implemented\nwith PDAF. These models can be used to assess the behavior of different\nassimilation algorithms. \n- **lorenz96/**\n  This directory contains the Lorenz-96 model, which is a widely used\n  model to assess data assimilation methods. Provided is a full\n  implementation of the data assimilation with various filters and options.\n  This model can be configured to have a sufficiently large state\n  dimension to test low-rank filter algorithms.\n- **lorenz63/**\n  This directory contains the Lorenz-63 model, which is a classical\n  3-variable model with chaotic dynamics. Provided is a full\n  implementation of the data assimilation with various filters and options.\n  The small state dimension and nonlinear dynamics make it a suitable\n  test case for the standard particle filter (PF).\n- **lorenz05b/**\n  This directory contains the model Lorenz-2005 model II. Provided is a full\n  implementation of the data assimilation with various filters and options.\n- **lorenz05c/**\n  This directory contains the two-scale model Lorenz-2005 model III.\n  Provided is a full implementation of the data assimilation with various\n  filters and options.\n\nInstructions on how to run data assimilation experiments with these models\nare provided on the PDAF web site.\n\n\n## Installation of the PDAF library\n\nThe PDAF library will be automatically built when compiling a tutorial case\nor one of the models. However, one can also separately build the library.\nIn order to build the PDAF library you need a Fortran 90 compiler, and\n'make'\n\n1. Choose a suitable include file for the make process and/or edit\none. See the directory make.arch/ for several provided include files.\nThere are include files for compilation with and without MPI.\n\nNote: PDAF is generally intended for parallel computing using MPI.\nHowever, it can be compiled for serial computing. To compile PDAF\nfor this case, a simplified MPI header file is included und should be\nin the include path. In addition, a dummy implementation of MPI, which\nbehaves like MPI in the single-process case, is provided in the\ndirectory nullmpi/. For the serial case, this file should also be\ncompiled and linked when PDAF is linked to a program.\n\n2. Set the environment variable $PDAF_ARCH to the name of the include\nfile (without ending .h). Alternatively you can specify PDAF_ARCH on\nthe command line when running 'make' in step 3.\n\n3. cd into the directory src/ and execute 'make' at the prompt. This will\ncompile the sources and generate a library file that includes the \nensemble filter methods in the directory lib/. \nTo generate the PDAF library including the 3D-Var methods and the \nsolvers from the external libraries in /external/ execute\n'make pdaf-var' at the prompt.\n \n\n\n## Test suite\n\nThe directory testsuite/ contains another set of example implementations.\nThis is more for 'internal use'. We use these implementations to validate PDAF. \nThe model is trivial: At each time step simply the time step size is added \nto the state vector. In this example all available filters are implemented.\n\n\n## Verifying your installation \n\nThe tutorial implementations can be verified as follows:\n\nYou can run the script\n**runtests.sh** in the main tutorial directory **tutorial**.\n\nThis script will compile and run all tutorial implementations. Afterwards\nthe outputs at the final time step are checked against reference outputs\nfrom the directory verification using a Python script. You can also compare\n the output files like out.online_2D_parallelmodel with reference files.\n(Note: The script runtests.sh uses the generic compile definitions for\nLinux with the gfotran compiler. For other systems, you might need to\nchange the settings for the make definitions files).\n\n\nThe testsuite also provides a functionality for verification:\n\nUsing 'make' one can run test cases for the verification which are\ncompared to reference outputs provided in the sub-directories\nof the directory  testsuite/tests_dummy1D for different computers\nand compilers. In particular the online case dummymodel_1D and the\noffline test offline_1D can be run. Scripts for serial (non-parallel)\nexecution as well as example scripts for running parallel test jobs on\ncomputers with SLURM or PBS batch systems are provided.\n\nAn installation of PDAF can be verified using the test suite as follows:\n1. prepare the include file in make.arch\n2. cd to testsuite/src\n3. Build and execute the online experiments:\n   'make pdaf_dummy_online' and\n   'make test_pdaf_online > out.test_pdaf_online'\n4. Build and execute the offline experiments:\n   'make pdaf_dummy_online' and\n   'make test_pdaf_offline > out.test_pdaf_offline'\n6. Check the files out.test_pdaf_online and out.test_pdaf_offline\n   At the end of the file, you see a list of Checks done using\n   a Python script. Here the outputs are compared with reference \n   outputs produced with gfortran and MacOS.\n   You can also diff the files to corresponding files in one of the\n   example-directories in ../tests_dummy1D. Here, also reference\n   output files, like output_lestkf0.dat are stored.\n\n\n## Data Assimilation Algorithms \n\nThe filter algorithms in PDAF are:\n\n**Filters with global analysis step**\n- **EnKF** (The classical perturbed-observations Ensemble Kalman filter)\n       [G. Evensen, J. Geophys. Res. 99 C5 (1994) 10143-10162,\n        G. Burgers et al., Mon. Wea. Rev. 126 (1998) 1719-1724]\n- **ESTKF** (Error Subspace Transform Kalman filter)\n       [L. Nerger et al. Mon. Wea. Rev. 140 (2012) 2335-2345, doi:10.1175/MWR-D-11-00102.1]\n- **ETKF** (Ensemble Transform Kalman filter)\n       [C. H. Bishop et al. Mon. Wea. Rev. 129 (2001) 420-436]\n       The implementation in PDAF follows that described for the LETKF, but as a global filter. \n- **SEIK** (Singular \"Evolutive\" Interpolated Kalman) filter\n       This is the full ensemble variant of the SEIK\n       (Singular \"Interpolated\" Extended Kalman) filter.\n       [SEIK: D.-T. Pham et al., C. R. Acad Sci., Ser. III, 326 (1009)\n        255-260, for the SEIK variant in PDAF see L. Nerger et al.,\n        Tellus 57A (2005) 715-735, doi:10.3402/tellusa.v57i5.14732]\t\n- **SEEK** (Singular \"Evolutive\" Extended Kalman) filter\n       [D.-T. Pham et al., J. Mar. Syst. 16 (1998) 323-340] \n- **NETF** (Nonlinear Ensemble Transform Filter)\n       [J. Toedter, B. Ahrens, Mon. Wea. Rev. 143 (2015) 1347-1367, doi:10.1175/MWR-D-14-00108.1]\n- **PF** (Particle filter with importance resampling)\n       [see S. Vetra-Carvalho et al., Tellus A 70 (2018) 1445364, doi:10.1080/16000870.2018.1445364]\n\n**Filters with localized analysis step**\n- **LESTKF** (Local Error Subspace Transform Kalman filter)\n       [L. Nerger et al. Mon. Wea. Rev. 140 (2012) 2335-2345, doi:10.1175/MWR-D-11-00102.1]\n- **LETKF** (Local Ensemble Transform Kalman filter)\n       [B. R. Hunt et al., Physica D 230 (2007) 112-126, doi:10.1016/j.physd.2006.11.008]\n- **LSEIK** (Local Singular \"Evolutive\" Interpolated Kalman) filter\n       [L. Nerger et al., Oce. Dyn. 56 (2006) 634-649, doi:10.1007/s10236-006-0083-0]\n- **LEnKF** (The classical perturbed-observations Ensemble Kalman filter with localization)\n       [G. Evensen, J. Geophys. Res. 99 C5 (1994) 10143-10162,\n        G. Burgers et al., Mon. Wea. Rev. 126 (1998) 1719-1724]\n- **LNETF** (Nonlinear Ensemble Transform Filter with observation localization)\n       [J. Toedter, B. Ahrens, Mon. Wea. Rev. 143 (2015) 1347-1367, doi:10.1175/MWR-D-14-00108.1]\n- **LKNETF** (Local Kalman-nonlinear ensemble transform filter)\n       [L. Nerger, Q. J. R. Meteorol Soc., 148 (2022) 620-640, doi:10.1002/qj.4221]\n\nAll filter algorithms are fully parallelized with MPI and optimized. The local filters \n(LSEIK, LETKF, LESTKF, LNETF, LKNETF) are in addition parallelized using OpenMP.\n\n**Smoother extensions** are included for the filters ESTKF/LESTKF, ETKF/LETKF, EnKF, NETF/LNETF.\n\n**3D-Var methods**\n\nNext to the ensemble filter methods, different 3D-Var methods are provided:\n- **parameterized 3D-Var**\n- **3D ensemble** Var with ensemble transformation by ESTKF or LESTKF\n- **hybrid 3D-Var** with ensemble transformation by ESTKF or LESTKF\n\nThe 3D-Var methods are implemented as incremental 3D-Var schemes following\nBannister, Q. J. Royal Meteorol. Soc., 143 (2017) 607-633, doi:10.1002/qj.2982. \n\n\nPDAF is written in Fortran (mainly Fortran 90 with some features from Fortran 2003). \nThe compilation and execution has been tested on the different systems ranging from\nnotebook computers to supercomputers, e.g.:\n- Linux\n- MacOS\n- Cray CLE\n- NEC Super-UX\n- Microsoft Windows 10 with Cygwin\n\n\n## Contact Information\n\nPlease send comments, suggestions, or bug reports to pdaf@awi.de\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/peakperformance",
            "repo_link": "https://github.com/JuBiotech/peak-performance",
            "readme": "[![PyPI version](https://img.shields.io/pypi/v/peak-performance)](https://pypi.org/project/peak-performance/)\n[![pipeline](https://github.com/jubiotech/peak-performance/workflows/pipeline/badge.svg)](https://github.com/JuBiotech/peak-performance/actions)\n[![coverage](https://codecov.io/gh/jubiotech/peak-performance/branch/main/graph/badge.svg)](https://app.codecov.io/gh/JuBiotech/peak-performance)\n[![documentation](https://readthedocs.org/projects/peak-performance/badge/?version=latest)](https://peak-performance.readthedocs.io/en/latest)\n[![DOI](https://zenodo.org/badge/713469041.svg)](https://zenodo.org/doi/10.5281/zenodo.10255543)\n\n# About PeakPerformance\nPeakPerformance employs Bayesian modeling for chromatographic peak data fitting.\nThis has the innate advantage of providing uncertainty quantification while jointly estimating all peak parameters united in a single peak model.\nAs Markov Chain Monte Carlo (MCMC) methods are utilized to infer the posterior probability distribution, convergence checks and the aformentioned uncertainty quantification are applied as novel quality metrics for a robust peak recognition.\n\n# Installation\n\nIt is highly recommended to follow the following steps and install ``PeakPerformance`` in a fresh Python environment:\n1. Install the package manager [Mamba](https://github.com/conda-forge/miniforge/releases).\nChoose the latest installer at the top of the page, click on \"show all assets\", and download an installer denominated by \"Mambaforge-version number-name of your OS.exe\", so e.g. \"Mambaforge-23.3.1-1-Windows-x86_64.exe\" for a Windows 64 bit operating system. Then, execute the installer to install mamba and activate the option \"Add Mambaforge to my PATH environment variable\".\n\n⚠ If you have already installed Miniconda, you can install Mamba on top of it but there are compatibility issues with Anaconda.\n\nℹ The newest conda version should also work, just replace `mamba` with `conda` in step 2.\n\n2. Create a new Python environment in the command line using the provided [`environment.yml`](https://github.com/JuBiotech/peak-performance/blob/main/environment.yml) file from the repo.\n   Download `environment.yml` first, then navigate to its location on the command line interface and run the following command:\n```\nmamba env create -f environment.yml\n```\n\nNaturally, it is alternatively possible to just install ``PeakPerformance`` via pip:\n\n```bash\npip install peak-performance\n```\n\n# First steps\nBe sure to check out our thorough [documentation](https://peak-performance.readthedocs.io/en/latest). It contains not only information on how to install PeakPerformance and prepare raw data for its application but also detailed treatises about the implemented model structures, validation with both synthetic and experimental data against a commercially available vendor software, exemplary usage of diagnostic plots and investigation of various effects.\nFurthermore, you will find example notebooks and data sets showcasing different aspects of PeakPerformance.\n\n# How to contribute\nIf you encounter bugs while using PeakPerformance, please bring them to our attention by opening an issue. When doing so, describe the problem in detail and add screenshots/code snippets and whatever other helpful material you can provide.\nWhen contributing code, create a local clone of PeakPerformance, create a new branch, and open a pull request (PR).\n\n# How to cite\nHead over to Zenodo to [generate a BibTeX citation](https://doi.org/10.5281/zenodo.10255543) for the latest release.\nA publication has just been submitted to a scientific journal. Once published, this section will be updated.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pecon",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/pedpy",
            "repo_link": "https://github.com/PedestrianDynamics/PedPy",
            "readme": "\n<div align=\"center\">\n    <img src=\"docs/source/_static/logo_text.svg\" height=\"100px\" alt=\"PedPy Logo\">\n</div>\n\n-----------------\n[![PyPI Latest Release](https://img.shields.io/pypi/v/pedpy.svg)](https://pypi.org/project/pedpy/)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pedpy)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7194992.svg)](https://doi.org/10.5281/zenodo.7194992)\n[![License](https://img.shields.io/pypi/l/pedpy.svg)](https://github.com/PedestrianDynamics/pedpy/blob/main/LICENSE)\n![ci workflow](https://github.com/PedestrianDynamics/pedestrian-trajectory-analyzer/actions/workflows/ci.yml/badge.svg)\n[![codecov](https://codecov.io/gh/PedestrianDynamics/PedPy/graph/badge.svg?token=X5C9NTKAVK)](https://codecov.io/gh/PedestrianDynamics/PedPy)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n[![Documentation Status](https://readthedocs.org/projects/pedpy/badge/?version=latest)](http://pedpy.readthedocs.io/?badge=latest)\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/7046/badge)](https://bestpractices.coreinfrastructure.org/projects/7046)\n[![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F-green)](https://fair-software.eu)\n\n# PedPy: Analysis of pedestrian dynamics based on trajectory files.  \n\n*PedPy* is a python module for pedestrian movement analysis. \nIt implements different measurement methods for density, velocity and flow.\n\nIf you use *PedPy* in your work, please cite it using the following information from zenodo:\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7194992.svg)](https://doi.org/10.5281/zenodo.7194992)\n\n\n## Getting started\n\n### Setup Python\n\nFor setting up your Python Environment a Python version >= 3.11 is recommended (our code is tested with 3.11, 3.12, and 3.13).\nTo avoid conflicts with other libraries/applications the usage of virtual environments is recommended, see [Python Documentation](https://docs.python.org/3/library/venv.html) for more detail.\n\n### Installing PedPy\n\nTo install the latest **stable** version of *PedPy* and its dependencies from PyPI:\n```bash\npython3 -m pip install pedpy\n```\n\nYou can also install the latest version of *PedPy* directly from the repository, by following these steps:\n\n1. Uninstall an installed version of *PedPy*:\n```bash\npython3 -m pip uninstall pedpy\n```\n\n2. Install latest version of *PedPy* from repository:\n```\npython3 -m pip install git+https://github.com/PedestrianDynamics/PedPy.git\n```\n\n### Usage\n\nFor first time users, have a look at the [getting started notebook](notebooks/getting_started.ipynb), as it shows the first steps to start an analysis with *PedPy*.\nA more detailed overview of *PedPy* is demonstrated in the [user guide notebook](notebooks/user_guide.ipynb).\nThe [fundamental diagram notebook](notebooks/fundamental_diagram.ipynb) shows how to use *PedPy* for computing the fundamental diagram of a series of experiments.\n\n#### Interactive online session\n\nIf you want to try out *PedPy* for the first time, you can find an interactive online environments for both notebooks here:\n\n- Getting started: [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/PedestrianDynamics/PedPy/main?labpath=notebooks%2Fgetting_started.ipynb)\n- User guide: [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/PedestrianDynamics/PedPy/main?labpath=notebooks%2Fuser_guide.ipynb)\n- Fundamental diagram: [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/PedestrianDynamics/PedPy/main?labpath=notebooks%2Ffundamental_diagram.ipynb)\n\n**Note:** \nThe execution might be slower compared to a local usage, as only limited resources are available.\nIt is possible to also upload different trajectory files and run the analysis completely online, but this might not be advisable for long computations.\n\n#### Local usage of the notebooks\n\nFor local usage of the notebooks, you can either download the notebooks and [demo files](notebooks/demo-data) from the GitHub repository or clone the whole repository with:\n```bash \ngit clone https://github.com/PedestrianDynamics/pedpy.git\n```\n\nFor using either of the notebook some additional libraries need to be installed, mainly for plotting.\nYou can install the needed libraries with:\n\n```bash\npython3 -m pip install jupyter matplotlib\n```\n\nAfterward, you can start a jupyter server with:\n\n```bash\njupyter notebook\n```\n\nAfter navigating to one of the notebooks, you can see how the library can be used for different kinds of analysis.\n\nSome examples how the computed values can be visualized are also shown in the notebooks, e.g., density/velocity profiles, fundamental diagrams, N-T-diagrams, etc.\n\n![voronoi](figs/voronoi_diagrams.png)\n\n![density](figs/density_comparison.png)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pepc",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/SLPP/pepc/pepc",
            "readme": "# PEPC -  Pretty Efficient Parallel Coulomb-solver\n\n##### Authors:  \nPaul Gibbon, Mathias Winkel, Benedikt Steinbusch, Robert Speck, Junxian Chew,\nDirk Brömmel, Lukas Arnold  \nForschungszentrum Juelich GmbH  \nJuelich Supercomputing Centre  \n\n#### Webpage:  \n[http://www.fz-juelich.de/ias/jsc/pepc](http://www.fz-juelich.de/ias/jsc/pepc)  \n#### DOI:\n[10.5281/zenodo.7965548](https://doi.org/10.5281/zenodo.7965548)\n#### E-Mail:  \n[pepc@fz-juelich.de](mail-to:pepc@fz-juelich.de)  \n#### CI:  \n[![pipeline status](https://gitlab.jsc.fz-juelich.de/SLPP/pepc/pepc/badges/master/pipeline.svg)](https://gitlab.jsc.fz-juelich.de/SLPP/pepc/pepc/-/commits/master) \n#### CB:  \n[![Continuous Benchmarking](https://slpp.pages.jsc.fz-juelich.de/pepc/pepc/master/cb-badge.svg)](https://slpp.pages.jsc.fz-juelich.de/pepc/pepc/)\n\n# 0. LICENSE\n\nThis file is part of PEPC - The Pretty Efficient Parallel Coulomb Solver.\n\nCopyright (C) 2002-2024  \nJuelich Supercomputing Centre,   \nForschungszentrum Juelich GmbH,  \nGermany\n\nPEPC is free software: you can redistribute it and/or modify it under the terms\nof the GNU Lesser General Public License as published by the Free Software\nFoundation, either version 3 of the License, or (at your option) any later\nversion.\n\nPEPC is distributed in the hope that it will be useful, but WITHOUT ANY\nWARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public License along\nwith PEPC. If not, see [http://www.gnu.org/licenses/](http://www.gnu.org/licenses/).\n\n\n# 1. REQUIREMENTS\n\n- A reasonably modern Fortran compiler with support for Fortran 2003 object\n  orientation, e.g.:\n   * GCC >= 4.6\n   * Intel >= 12.1\n   * IBM XL Fortran >= 12\n- A C compiler and a C preprocessor with support for variadic macros.\n- An MPI library with support for MPI_THREAD_MULTIPLE. PEPC will complain\n  about missing support at run time.\n- Support for POSIX threads (pthreads).\n\n\n# 2. COMPILATION\n\nFor compiling this program, the machine-dependent compiler names and flags have\nto be set in a definition file called `makefile.defs` in the root directory.\n\nSeveral exemplary definitions are available in the subdirectory `./makefiles`.\nFor example, for GCC you can simply run\n```sh\nln -sf ./makefiles/makefile.defs.GCC ./makefile.defs\n```\nfrom the root directory to create a symbolic link the the appropriate\ndefinitions. Some compiler or machine specific hints are contained in the files\nwithin this directory, please have look there.\n\nAfter providing the makefile.defs file, you can simply call\n```\nmake help\n```\nto show information/recommendation on machine specifics.\n\nAfter setting the proper environment (modules, paths) call\n```sh\nmake pepc-mini\n```\nto build the `pepc-mini` frontend into the `./bin/` directory. Parallel make\n(i.e. `make -j <n>`) should work.\n\nThere are several different frontends available at the moment:\n\n- `pepc-b`:  \nlaser/beam-plasma with magnetic fields  \n- `pepc-essential`/`pepc-benchmark`:  \nsimple setup w/ a Coulomb explosion  \nalso used for benchmarking  \n- `pepc-darwin-2d`:  \n2D version w/ Darwin appoximation for electrodynamics\n- `pepc-mini`:  \npure electrostatics  \nsimple molecular dynamics  \nno diagnostics  \n*minimum requirements to get `PEPC` running*  \n- `pepc-neighbour`:  \ntree-based nearest neighbour search  \n- `pepc-kh`, `pepc-kh-essential`:  \nKevin-Helmholtz setup (`essential` following text-books)\n- `pepc-v`/`pepc-dvh`:  \nvortex dynamics using the vortex particle method/diffused vortex hydrodynamics method  \n- `pepc-breakup`:  \nTownsend avalanche breakdown simulation  \n\nTo build an alternative frontend, just call\n```sh\nmake pepc-essential\n```\nor\n```sh\nmake pepc-benchmark\n```\n\nAll frontends can be built using \n```sh\nmake (-j <n>) all\n```\n\nAt the current stage, there is no real documentation available for the different\nfrontends. However, you might simply want to take a look at the respective\nsourcecode to find out what they are doing.\n\n\n# 3. RUNNING THE PROGRAM\n\nUsually, the frontend's source directories contain a sample input deck for the\nfrontends. For running `pepc-essential` it is for example called `params`. It\ncontains user-adjustable parameters and can be fed to the executable as first\ncommand line parameter:\n```sh\ncd bin\nmpirun -np 32 pepc-essential ../src/frontends/pepc/essential/params\n```\n\n\n# 4. DOCUMENTATION\n\nRudimentary doxygen documentation is available by calling\n```sh\nmake doc\n```\nfrom the root directory. A users guide is in preparation. \n\n\n# 5. REPORTING PROBLEMS\n\nPlease submit an issue with PEPC's issue tracker if you encounter a problem.\nThere are a number of templates available depending on the problem you want to\nreport:\n- General problems use the [default template](https://gitlab.jsc.fz-juelich.de/SLPP/pepc/pepc/-/issues/new)\n- Questions on how to [use PEPC](https://gitlab.jsc.fz-juelich.de/SLPP/pepc/pepc/-/issues/new?issuable_template=PEPC%20usage)\n- Problems with a particular [frontend](https://gitlab.jsc.fz-juelich.de/SLPP/pepc/pepc/-/issues/new?issuable_template=frontend)\n- Putting in a [feature requests](https://gitlab.jsc.fz-juelich.de/SLPP/pepc/pepc/-/issues/new?issuable_template=feature-request)\n\nPlease note that our rescources are limited and that we will prioritise any\nrequests. We do, however, appreciate any contribution.\n\n\n# 6. DIRECTORY STRUCTURE / ADDING OWN FUNCTIONALITY\n\nInside the `./src/` directory, you will find four subdirectories:\n- \"treecode\": PEPC kernel, everything that is necessary for the pure\n  algorithmic part of the treecode\n- \"interaction_specific\": interaction specific backends. The different\n  subdirectories herein (currently mainly: coulomb, darwin, and vortex)\n  provide data structures and functions for the different applications. See\n  inline documentation in the sourcecode (especially inside the coulomb-subdir,\n  which should be well documented) to find out about what the functions should\n  do and which of them are necessary. The only files that must be provided in\n  this directory are (names may not be changed, public functions and\n  datastructures inside these files are mandatory):\n  * `module_interaction_specific.f90`: data structures and functions for\n     manipulating them\n  * `module_calc_force.f90`: functions for actual force-law and multipole\n     acceptance criterion etc.\n  * `makefile.backend`: backend specific modifications to treecode makefile,\n     may be empty\n- \"utils\": source code of utilities (mainly for treecode diagnostics,\n  vtk-output etc.)\n- \"frontends\": different applications that utilize the treecode for their\n  respective very specific purpose. The file `makefile.frontend` configures\n  which source files, interaction (\"BACKEND\" / \"BACKENDTYPE\"), and tree walk\n  (\"WALK\") will be included/used.\n\nIn case you want to use PEPC for developing a treecode-based N-body code, you\nmight start by copying and modifying the `pepc-mini` frontend, which is a very\nsimple coulomb-MD programme. It uses the coulomb backend, that implements an\nexpansion of the plummer potential 1/sqrt(r^2+eps^2) up to quadrupole order.\n\nTake care that your frontend-directory is called \"pepc-something\" with no\nfurther minus sign (\"-\") to be automatically recognized in the build system.\n\nIf you want to provide a new interaction-specific backend (for using other\nmultipole orders and/or force laws), just copy and modify the coulomb\nsubdirectory there. The backends do not have to be registered in some makefile,\nbut are selected inside the `makefile.frontend` and later included by the main\nmakefile. In case you only need to modify the interaction specific types but\nnot the functions that are dealing with them (for example for adding velocity,\nmass, etc.), take a look at the coulomb-backend how to adjust the \"type\".\nThere, this is done for the `pepc-mini` frontend, that uses other types than\nfor example `pepc-b` while still using the same force expression. See\nalso variable \"BACKENDTYPE\" in `pepc-mini`'s `makefile.include`.\n\n# 7. CONTRIBUTING\n\nPlease refer to the separate file `CONTRIBUTING.md` for more information.\n",
            "project_id": "4129"
        },
        {
            "software_organization": "https://helmholtz.software/software/perihub",
            "repo_link": "https://github.com/PeriHub/PeriHub",
            "readme": "<!--\nSPDX-FileCopyrightText: 2023 PeriHub <https://github.com/PeriHub/PeriHub>\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# PeriHub - Empowering Research with Peridynamic Modeling\n\n[![Pipeline Status](https://img.shields.io/github/actions/workflow/status/PeriHub/PeriHub/CI.yml?branch=main)](https://github.com/PeriHub/PeriLab.jl/actions)\n[![docs](https://img.shields.io/badge/docs-v1-blue.svg)](https://perihub.github.io/PeriHub/)\n[![License](https://img.shields.io/badge/License-Apache-blue.svg)](https://github.com/PeriHub/PeriHub/blob/main/LICENSE.md)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.8159334.svg)](https://doi.org/10.5281/zenodo.8159334)\n[![Docker Image](https://img.shields.io/docker/pulls/perihub/frontend)](https://hub.docker.com/r/perihub/frontend)\n[![YouTube](https://img.shields.io/youtube/channel/subscribers/UCeky7HtUGlOJ2OKknvl6YnQ)](https://www.youtube.com/@PeriHub)\n\nPeriHub is a powerful software solution that can significantly benefit research in various fields. It is an extension of the open-source PeriLab software, providing a numerical implementation of the peridynamic theory. With PeriHub, researchers gain access to a valuable tool for addressing specific challenges and exploring diverse use cases in materials science, engineering, and related disciplines.\n\n## Key Features\n\n- **Peridynamic Modeling:** PeriHub excels at facilitating peridynamic modeling, enabling researchers to analyze material behavior and complex systems. Its unique approach empowers users to explore new frontiers and deepen their understanding of material behavior.\n\n- **User-Friendly Interface:** PeriHub offers a user-friendly interface, making it accessible to both experienced researchers and newcomers in the field. The platform's ease of use ensures efficient simulations, analysis of results, and gaining valuable insights into material behavior.\n\n- **REST API and GUI Support:** Researchers can seamlessly interact with PeriHub using its REST API and GUI support, providing flexibility and convenience in conducting simulations and research tasks.\n\n- **High-Quality and Reliable:** Developed collaboratively by a dedicated group of experts, PeriHub adheres to high standards of quality, reliability, and FAIRness (Findability, Accessibility, Interoperability, and Reusability). The German Aerospace Center (DLR) has played a significant role in fostering an environment that encourages innovation and interdisciplinary collaboration throughout the software's development process.\n\n- **Portability and Scalability:** PeriHub utilizes Docker containers, ensuring seamless integration and deployment across various computing environments. This approach enhances the software's portability, scalability, and ease of use, making it even more practical for research purposes.\n\n### Overview\n\n![](docs/assets/images/PeriHub.svg)\n\n### Generate model\n\n![](docs/assets/gif/generateModel.gif)\n\n### View generated mesh\n\n![](docs/assets/gif/viewMesh.gif)\n\n### Edit input deck\n\n![](docs/assets/gif/editInputDeck.gif)\n\n### Submit model\n\n![](docs/assets/gif/runModel.gif)\n\n### Analyse results\n\n![](docs/assets/gif/analyseResults.gif)\n\n### Plot results\n\n![](docs/assets/gif/plotResults.gif)\n\n### Analyse fracture\n\n![](docs/assets/gif/analyseFracture.gif)\n\n# Getting Started with PeriHub Services\n\nTo get started with PeriHub, you can use Docker Compose to easily set up the required services. Here's a step-by-step guide:\n\n- Clone the repository\n\n```\ngit clone https://github.com/PeriHub/PeriHub.git\n```\n\n- Go into the PeriHub folder.\n\n```\ncd PeriHub\n```\n\n- Copy the .env file and edit its contents.\n\n```\ncp .env.example .env\n```\n\n- Run docker-compose.\n\n```\ndocker-compose up\n```\n\n- If docker finished building PeriHub, go to http://localhost:8080\n\n## Contact\n\n- [Jan-Timo Hesse](mailto:Jan-Timo.Hesse@dlr.de)\n\n## License\n\nPlease see the file [LICENSE.md](LICENSE.md) for further information about how the content is licensed.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/perilab",
            "repo_link": "https://github.com/PeriHub/PeriLab.jl",
            "readme": "<!--\nSPDX-FileCopyrightText: 2023 Christian Willberg <christian.willberg@dlr.de>, Jan-Timo Hesse <jan-timo.hesse@dlr.de>\n\nSPDX-License-Identifier: BSD-3-Clause\n-->\n\n# `PeriLab` - Peridynamic Laboratory\n\n[docs-dev-img]: https://img.shields.io/badge/docs-dev-blue.svg\n[docs-dev-url]: https://perihub.github.io/PeriLab.jl/dev\n\n[docs-stable-img]: https://img.shields.io/badge/docs-stable-blue.svg\n[docs-stable-url]: https://perihub.github.io/PeriLab.jl/stable\n\n[ci-img]: https://github.com/perihub/PeriLab.jl/actions/workflows/CI.yml/badge.svg\n[ci-url]: https://github.com/perihub/PeriLab.jl/actions/workflows/CI.yml\n\n[cov-img]: https://codecov.io/gh/perihub/PeriLab.jl/branch/main/graph/badge.svg\n[cov-url]: https://codecov.io/gh/perihub/PeriLab.jl\n\n[code-style-img]: https://img.shields.io/badge/code%20style-blue-4495d1.svg\n[code-style-url]: https://github.com/invenia/BlueStyle\n\n[aqua-img]: https://raw.githubusercontent.com/JuliaTesting/Aqua.jl/master/badge.svg\n[aqua-url]: https://github.com/JuliaTesting/Aqua.jl\n\n[doi-img]: https://zenodo.org/badge/DOI/10.1016/j.softx.2024.101700.svg\n[doi-url]: https://doi.org/10.1016/j.softx.2024.101700\n\n[release-img]: https://img.shields.io/github/v/release/PeriHub/PeriLab.jl\n[release-url]: https://github.com/PeriHub/PeriLab.jl/releases\n\n[docker-img]: https://img.shields.io/docker/pulls/perihub/perilab\n[docker-url]: https://hub.docker.com/r/perihub/perilab\n\n[license-img]: https://img.shields.io/badge/License-BSD-blue.svg\n[license-url]: https://github.com/PeriHub/PeriLab.jl/LICENSE\n\n[youtube-img]: https://img.shields.io/youtube/channel/subscribers/UCeky7HtUGlOJ2OKknvl6YnQ\n[youtube-url]: https://www.youtube.com/@PeriHub\n\n| **Documentation** | **Build Status** |  **Quality** |\n|:----:|:----:|:----:|\n| [![][docs-stable-img]][docs-stable-url] [![][docs-dev-img]][docs-dev-url] | [![][ci-img]][ci-url] [![][cov-img]][cov-url] | [![][aqua-img]][aqua-url] |\n| **Deployment** | **License** | **Socials** |\n| [![][release-img]][release-url]  [![][docker-img]][docker-url] | [![][license-img]][license-url] [![][doi-img]][doi-url] | [![][youtube-img]][youtube-url] |\n\nWelcome to `PeriLab`, a powerful software solution designed for tackling Peridynamic problems.\n\n<p align=\"center\" style=\"font-size:0;\"><!--\n  PeriLab_crack      --><img align=\"middle\" src=\"https://raw.githubusercontent.com/PeriHub/PeriLab.jl/main/assets/PeriLab_crack.gif\" width=\"50%\"><!--\n  PeriLab_additive      --><img align=\"middle\" src=\"https://raw.githubusercontent.com/PeriHub/PeriLab.jl/main/assets/PeriLab_additive.gif\" width=\"50%\">\n</p>\n\n## Documentation\n\nExplore the comprehensive [documentation](https://perihub.github.io/PeriLab.jl/) for `PeriLab`.\n\n## Examples\n\nA few basic examples of `PeriLab` can be found in the [examples](https://github.com/PeriHub/PeriLab.jl/tree/main/examples) directory, or if you want to have a look at results go to our growing [PeriLab-Results service](https://perilab-results.nimbus-extern.dlr.de).\n\n## Features ⭐\n\n- 🚀 **Easy Installation**: PeriLab's straightforward installation process makes it accessible for researchers and engineers without extensive computational expertise.\n\n- ✒️ **Modularization**: The software is designed with a modular architecture that allows users to easily integrate their own material and damage models.\n\n- 🎨 **Formulations**: Bond-based, bond-associated, as well as oridnary and non-ordinary state-based peridynamic formulations can be used with PeriLab.\n\n- 🔩 **Material models**: PeriLab supports various material models, such as elastic, plastic, and more, enabling simulation of complex materials and structures.\n\n- 🔨 **Damage models**: Damage models such as critical stretch or an energy based criterium are included to simulate different types of damage, such as crack propagation or delamination, in their peridynamic simulations.\n\n- 🔥 **Additive Manufacturing**: PeriLab supports additive manufacturing, allowing users to create custom additive models for their simulations.\n\n- 🧲 **Multimodels**: PeriLab supports multimodels simulations, combining different types of peridynamics and damage models to create a comprehensive simulation environment.\n\n- ⚡ **MPI**: PeriLab supports parallel computing using Message Passing Interface (MPI) technology to improve simulation performance on high-performance clusters.\n\n- 💻 **HPC capabilities**: PeriLab is designed for high-performance computing (HPC) environments, allowing users to run large-scale simulations efficiently.\n\n- 📤📥 **Exodus Input/Output**: PeriLab uses the Exodus II data format for input and output, enabling easy transfer of data between simulation tools.\n\n- 🧮 **Abaqus Input**: PeriLab supports Abaqus input files, allowing users to create custom Abaqus models for their simulations.\n\n- ➗ **Bond filter**: The bond filter feature allows users to apply specific conditions to the bonds between particles in a simulation, influencing their behavior and interaction with other particles.\n\n- 🔧 **User specified Input/Output**: PeriLab provides flexible options for users to specify custom input and output files, enabling easy data manipulation and analysis.\n\n- 🧪 **Test Pipeline**: The PeriLab Source Code will be tested in a test pipeline to ensure its correctness and performance.\n\n## Installation\n\nThe `PeriLab`  package is available through the Julia package system and can be installed using the following commands:\n\n```julia\nusing Pkg\nPkg.add(\"PeriLab\")\n```\n\nThroughout the rest of this tutorial, we will assume that you have installed the\nPeriLab package and have already typed `using PeriLab` to bring all of the\nrelevant variables into your current namespace.\n\n## Getting Started with `PeriLab`\n\nJumpstart your exploration of the PeriLab simulation core with provided examples. Run the following commands in Julia:\n\n```julia PeriLab\nusing PeriLab\n\nPeriLab.get_examples()\nPeriLab.main(\"examples/DCB/DCBmodel.yaml\")\n```\n>Note: More details about the main functionalities in the yaml input deck [here](https://github.com/PeriHub/PeriLab.jl/blob/main/src/Support/Parameters/parameter_handling.jl).\n\n## Parallel Processing with `PeriLab` (MPI)\n\nTo handle large-scale problems efficiently, install [MPI](https://juliaparallel.org/MPI.jl/stable/usage/). Run PeriLab with two processors on a **Linux** system using the following commands:\n\n```sh\n$ julia\njulia> using MPI\njulia> MPI.install_mpiexecjl()\n```\n>Note: If you work with **Windows 10 or higher** you can use the [WSL](https://learn.microsoft.com/en-us/windows/wsl/install) environment.\n\nRun PeriLab with two processors:\n```sh\n$ mpiexecjl -n 2 julia --project=./ -e \"using PeriLab; PeriLab.main()\" examples/DCB/DCBmodel.yaml -v\n```\n\n>Note: For HPC configurations please refer to [here](https://juliaparallel.org/MPI.jl/stable/configuration/#configure_jll_binarys).\n\n## Installing with Docker 🐳\n\n To install PeriLab using the official Perihub/Perilab Docker image, follow these steps:\n\n1. **Install Docker**: Before you begin, ensure that you have Docker installed on your system. You can download and install Docker from the official website (https://www.docker.com/). Make sure your system meets the minimum requirements for running Docker.\n\n2. **Pull the Perihub/Perilab Docker image**: Use the following command in a terminal or command prompt to pull the latest Perihub/Perilab Docker image from the Docker Hub repository:\n\n   ```bash\n   docker pull perihub/perilab\n   ```\n\n3. **Run the Docker container**: Once the image has been downloaded, create a new directory for your PeriLab simulations and navigate to it in the terminal or command prompt. Run the following command to start the Docker container:\n\n   ```bash\n   docker run -it --rm -v <path_to_local_simulations_directory>:/app/simulations perihub/perilab bash\n   ```\n\n   Replace `<path_to_local_simulations_directory>` with the absolute path to a local directory where you want to store your PeriLab simulations. This command will open a new terminal session inside the Docker container.\n\nNow, you've successfully installed PeriLab using the official Perihub/Perilab Docker image. You can start running your own peridynamic simulations within the container.\n\n## `PeriLab` on `JuliaHub`\n\nExperience the convenience of using PeriLab as a ready-to-use application on JuliaHub. Simply create an [account](https://juliahub.com), navigate to the [applications page](https://juliahub.com/ui/Applications), and add the repository URL: https://github.com/PeriHub/PeriLab.jl.\n\nConfigure advanced options, such as _filename_, _dryrun_, _verbosity_, _debug_, and _silence_. Click __Start__ and monitor the job progress. Results will be available in a zipped folder.\n\nHit the __Start__ button and wait for the job to finish, the results will be available in a zipped folder.\n\n>Note: The free tier on `JuliaHub` offers 20 hours of computational time per month.\n\n## What's Next? 🚀\n\nHere are some exciting tasks on our roadmap:\n\n- 🔑 **Quasi-static solver**: A future development for PeriLab is extending its capabilities with a more robust quasi-static solver for larger systems and complex boundary conditions.\n\n- 👊 **Contact**: An upcoming feature in PeriLab is enhancing contact modeling to support advanced features like friction, adhesion, and contact forces based on temperature or other variables.\n\n- ➕ **More material and damage models**: PeriLab's future development plans include adding more sophisticated material models (e.g., viscoelastic-plastic) and damage models, expanding the software's applicability to a wider range of real-world phenomena.\n\n- 👬 **FEM/PD coupling**: A future enhancement for PeriLab is improving its FEM/PD coupling functionality by implementing more advanced techniques, such as a seamless data exchange between FEM and PD domains.\n\n- ✂️ **Distribution logic**: As part of its ongoing development, PeriLab will continue to incorporate new distribution logic for improved performance and reduced computational resources.\n\n- 🏎️ **Optimizations**: As part of its ongoing development, PeriLab will continue to focus on optimizing the simulation process by incorporating new techniques like parallel optimization algorithms for improved efficiency and reduced computational resources.\n\nFeel free to contribute and help us make PeriLab even better! 🙌\n\n## Contributing\n\nWe welcome contributions in various forms, including bug reports, documentation improvements, feature suggestions, and more. To get started, follow these steps and have a look at the [Contribution Guidelines](CONTRIBUTING.md):\n\n### Development\n1. **Clone the repository:**\n```sh\ngit clone https://github.com/PeriHub/PeriLab.jl\ncd PeriLab.jl\n```\n2. **Activate the environment and install dependencies:**\n```sh\n$ julia\njulia> ]\npkg> activate .\npkg> up\n```\n3. **Run the script:**\n```sh\n$ julia --project=. src/main.jl examples/DCB/DCBmodel.yaml\n```\n\n## Questions\nFor any questions or inquiries about PeriLab.jl, feel free to reach out to the authors via email.\n\n## Authors and acknowledgment\n<p>\n\n<a href=\"https://orcid.org/0000-0003-2433-9183\"><img src=\"https://orcid.org/assets/vectors/orcid.logo.icon.svg\" style=\"height:15px;width:auto;vertical-align: top;background-color:transparent;\"> </a>[Prof. Dr.-Ing. Christian Willberg](mailto::christian.willberg@h2.de)\n\n</p>\n\n<p>\n\n<a href=\"https://orcid.org/0000-0002-3006-1520\"><img src=\"https://orcid.org/assets/vectors/orcid.logo.icon.svg\"  style=\"height:15px;width:auto;vertical-align: top;background-color:transparent;\"> [M.Sc. Jan-Timo Hesse](mailto::jan-timo.hesse@dlr.de)\n\n</p>\n\n## Project status\n`PeriLab` is currently in development.\n\n\n## How to cite\nTo cite PeriLab in your publications please use the following [paper](https://doi.org/10.1016/j.softx.2024.101700).\n\n```s\n@Article{WillbergC2024,\nauthor={Willberg, Christian\nand Hesse, Jan-Timo\nand Pernatii, Anna},\ntitle={{PeriLab - Peridynamic Laboratory}},\njournal={SoftwareX},\nyear={2024},\npublisher={Elsevier},\nvolume={26},\nissn={2352-7110},\ndoi={10.1016/j.softx.2024.101700},\nurl={https://doi.org/10.1016/j.softx.2024.101700}\n}\n```\n\n## Partner\n\n\n| <img src=\"https://raw.githubusercontent.com/PeriHub/PeriLab.jl/main/assets/dlr.jpg\" height=\"200\" title=\"German Aerospace Center\"> | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Logo_h2.svg/1280px-Logo_h2.svg.png\" height=\"200\" title=\"Magdeburg-Stendal University of Applied Science\"> |\n|:------------------------------------------------------------------------------------------------------------------------------:|:-------------------------------------------------------------------------------------------------------------------------------------:|\n| [German Aerospace Center](http://www.dlr.de/sy)                                                                               | [Magdeburg-Stendal University of Applied Science](http://www.h2.de)                                                                  |\n\n\n\n\n\n## Acknowledgments\n\n<p align=\"center\" style=\"font-size:0;\"><!--\n  <!--\n  DFG      --><img align=\"middle\" src=\"https://raw.githubusercontent.com/PeriHub/PeriLab.jl/main/assets/dfg.jpg\" height=\"120\">\n</p>\n\nThis project has benefited from funding by the [Deutsche\nForschungsgemeinschaft](https://www.dfg.de/) (DFG, German Research Foundation)\nthrough the following grant ''Gekoppelte Peridynamik-Finite-Elemente-Simulationen zur Schädigungsanalyse von Faserverbundstrukturen''. <br/><br/>Grant number: [WI 4835/5-1](https://gepris.dfg.de/gepris/projekt/456427423)\n<p align=\"center\" style=\"font-size:0;\"><!--\n  SACHSEN  --><img align=\"middle\" src=\"https://raw.githubusercontent.com/PeriHub/PeriLab.jl/main/assets/sachsen.jpg\" height=\"120\">\n</p>\n\n[M-ERA.NET](https://www.m-era.net/) funded project ''Exploring Multi-Method Analysis of composite structures and joints under consideration of uncertainties engineering and processing (EMMA)''\n\nThis measure is co-financed with tax funds on the basis of the budget passed by the [Saxon state parlament](https://www.landtag.sachsen.de/de). <br/><br/>Grant number: [3028223](https://www.m-era.net/materipedia/2020/emma).\n\n<p align=\"center\" style=\"font-size:0;\"><!--\n  HyTank  --><img align=\"middle\" src=\"https://raw.githubusercontent.com/PeriHub/PeriLab.jl/main/assets/hytank.jpg\" height=\"120\"><!--\n  -->\n</p>\n\n[Federal Ministry for Economic Affairs and Climate Action](https://www.bmwk.de/Navigation/DE/Home/home.html) funded project\n''Virtuelle Kennwertermittlung, Schadensprädiktion und Simulationsmethoden für geklebte Fügestellen eines LH2-Tanks in Faserverbundbauweise für die kommerzielle Luftfahrt (HYTANK)''.<br/><br/>\nGrant number: 20W2214G.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/perun",
            "repo_link": "https://github.com/Helmholtz-AI-Energy/perun",
            "readme": "<div align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Helmholtz-AI-Energy/perun/main/docs/images/full_logo.svg\">\n</div>\n\n&nbsp;\n&nbsp;\n\n[![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F-green)](https://fair-software.eu)\n[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/7253/badge)](https://bestpractices.coreinfrastructure.org/projects/7253)\n[![DOI](https://zenodo.org/badge/523363424.svg)](https://zenodo.org/badge/latestdoi/523363424)\n![PyPI](https://img.shields.io/pypi/v/perun)\n![PyPI - Downloads](https://img.shields.io/pypi/dm/perun)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![codecov](https://codecov.io/gh/Helmholtz-AI-Energy/perun/graph/badge.svg?token=9O6FSJ6I3G)](https://codecov.io/gh/Helmholtz-AI-Energy/perun)\n[![](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)\n[![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)\n[![Documentation Status](https://readthedocs.org/projects/perun/badge/?version=latest)](https://perun.readthedocs.io/en/latest/?badge=latest)\n\nperun is a Python package that calculates the energy consumption of Python scripts by sampling usage statistics from your Intel, Nvidia or AMD hardware components. It can handle MPI applications, gather data from hundreds of nodes, and accumulate it efficiently. perun can be used as a command-line tool or as a function decorator in Python scripts.\n\nCheck out the [docs](https://perun.readthedocs.io/en/latest/) or a working [example](https://github.com/Helmholtz-AI-Energy/perun/blob/main/examples/torch_mnist/README.md)!\n\n## Key Features\n\n - Measures energy consumption of Python scripts using Intel RAPL, ROCM-SMI, Nvidia-NVML, and psutil\n - Capable of handling MPI application, gathering data from hundreds of nodes efficiently\n - Monitor individual functions using decorators\n - Tracks energy usage of the application over multiple executions\n - Easy to benchmark applications and functions\n - Experimental!: Can monitor any non-distributed command line application\n\n## Installation\n\nFrom PyPI:\n\n```console\npip install perun\n```\n\n> Extra dependencies like nvidia-smi, rocm-smi and mpi can be installed using pip as well:\n```console\npip install perun[nvidia, rocm, mpi]\n```\n\nFrom Github:\n\n```console\npip install git+https://github.com/Helmholtz-AI-Energy/perun\n```\n\n## Quick Start\n\n### Command Line\n\nTo use perun as a command-line tool, run the monitor subcommand followed by the path to your Python script and its arguments:\n\n```console\n$ perun monitor path/to/your/script.py [args]\n```\n\nperun will output two files, and HDF5 style containing all the raw data that was gathered, and a text file with a summary of the results.\n\n\n```text\nPERUN REPORT\n\nApp name: finetune_qa_accelerate\nFirst run: 2023-08-15T18:56:11.202060\nLast run: 2023-08-17T13:29:29.969779\n\n\nRUN ID: 2023-08-17T13:29:29.969779\n\n|   Round # | Host                | RUNTIME   | ENERGY     | CPU_POWER   | CPU_UTIL   | GPU_POWER   | GPU_MEM    | DRAM_POWER   | MEM_UTIL   |\n|----------:|:--------------------|:----------|:-----------|:------------|:-----------|:------------|:-----------|:-------------|:-----------|\n|         0 | hkn0432.localdomain | 995.967 s | 960.506 kJ | 231.819 W   | 3.240 %    | 702.327 W   | 55.258 GB  | 29.315 W     | 0.062 %    |\n|         0 | hkn0436.localdomain | 994.847 s | 960.469 kJ | 235.162 W   | 3.239 %    | 701.588 W   | 56.934 GB  | 27.830 W     | 0.061 %    |\n|         0 | All                 | 995.967 s | 1.921 MJ   | 466.981 W   | 3.240 %    | 1.404 kW    | 112.192 GB | 57.145 W     | 0.061 %    |\n\nThe application has been run 7 times. In total, it has used 3.128 kWh, released a total of 1.307 kgCO2e into the atmosphere, and you paid 1.02 € in electricity for it.\n```\n\nPerun will keep track of the energy of your application over multiple runs.\n\n#### Binary support (experimental)\n\nperun is capable of monitoring simple applications written in other languages, as long as they don't make use of MPI or are distributed over multiple computational nodes.\n\n```console\n$ perun monitor --binary path/to/your/executable [args]\n```\n\n### Function Monitoring\n\nUsing a function decorator, information can be calculated about the runtime, power draw and component utilization while the function is executing.\n\n```python\n\nimport time\nfrom perun import monitor\n\n@monitor()\ndef main(n: int):\n    time.sleep(n)\n```\n\nAfter running the script with ```perun monitor```, the text report will add information about the monitored functions.\n\n```text\nMonitored Functions\n\n|   Round # | Function                    |   Avg Calls / Rank | Avg Runtime     | Avg Power        | Avg CPU Util   | Avg GPU Mem Util   |\n|----------:|:----------------------------|-------------------:|:----------------|:-----------------|:---------------|:-------------------|\n|         0 | main                        |                  1 | 993.323±0.587 s | 964.732±0.499 W  | 3.244±0.003 %  | 35.091±0.526 %     |\n|         0 | prepare_train_features      |                 88 | 0.383±0.048 s   | 262.305±19.251 W | 4.541±0.320 %  | 3.937±0.013 %      |\n|         0 | prepare_validation_features |                 11 | 0.372±0.079 s   | 272.161±19.404 W | 4.524±0.225 %  | 4.490±0.907 %      |\n```\n\n### MPI\n\nPerun is compatible with MPI applications that make use of ```mpi4py```, and requires changes in the code or in the perun configuration. Simply replace the ```python``` command with ```perun monitor```.\n\n```console\nmpirun -n 8 perun monitor path/to/your/script.py\n```\n\n## Docs\n\nTo get more information, check out our [docs page](https://perun.readthedocs.io/en/latest/) or check the [examples](https://github.com/Helmholtz-AI-Energy/perun/tree/main/examples).\n\n## Citing perun\n\nIf you found perun usefull, please consider citing the conference paper:\n\n * Gutiérrez Hermosillo Muriedas, J.P., Flügel, K., Debus, C., Obermaier, H., Streit, A., Götz, M.: perun: Benchmarking Energy Consumption of High-Performance Computing Applications. In: Cano, J., Dikaiakos, M.D., Papadopoulos, G.A., Pericàs, M., and Sakellariou, R. (eds.) Euro-Par 2023: Parallel Processing. pp. 17–31. Springer Nature Switzerland, Cham (2023). https://doi.org/10.1007/978-3-031-39698-4_2.\n\n\n```bibtex\n@InProceedings{10.1007/978-3-031-39698-4_2,\n  author=\"Guti{\\'e}rrez Hermosillo Muriedas, Juan Pedro\n  and Fl{\\\"u}gel, Katharina\n  and Debus, Charlotte\n  and Obermaier, Holger\n  and Streit, Achim\n  and G{\\\"o}tz, Markus\",\n  editor=\"Cano, Jos{\\'e}\n  and Dikaiakos, Marios D.\n  and Papadopoulos, George A.\n  and Peric{\\`a}s, Miquel\n  and Sakellariou, Rizos\",\n  title=\"perun: Benchmarking Energy Consumption of High-Performance Computing Applications\",\n  booktitle=\"Euro-Par 2023: Parallel Processing\",\n  year=\"2023\",\n  publisher=\"Springer Nature Switzerland\",\n  address=\"Cham\",\n  pages=\"17--31\",\n  abstract=\"Looking closely at the Top500 list of high-performance computers (HPC) in the world, it becomes clear that computing power is not the only number that has been growing in the last three decades. The amount of power required to operate such massive computing machines has been steadily increasing, earning HPC users a higher than usual carbon footprint. While the problem is well known in academia, the exact energy requirements of hardware, software and how to optimize it are hard to quantify. To tackle this issue, we need tools to understand the software and its relationship with power consumption in today's high performance computers. With that in mind, we present perun, a Python package and command line interface to measure energy consumption based on hardware performance counters and selected physical measurement sensors. This enables accurate energy measurements on various scales of computing, from a single laptop to an MPI-distributed HPC application. We include an analysis of the discrepancies between these sensor readings and hardware performance counters, with particular focus on the power draw of the usually overlooked non-compute components such as memory. One of our major insights is their significant share of the total energy consumption. We have equally analyzed the runtime and energy overhead perun generates when monitoring common HPC applications, and found it to be minimal. Finally, an analysis on the accuracy of different measuring methodologies when applied at large scales is presented.\",\n  isbn=\"978-3-031-39698-4\"\n}\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/petrack",
            "repo_link": "https://jugit.fz-juelich.de/ped-dyn-emp/petrack",
            "readme": "",
            "project_id": "3227"
        },
        {
            "software_organization": "https://helmholtz.software/software/php-codemeta-crosswalk",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/php-codemeta-crosswalk",
            "readme": "![GitHub top language](https://img.shields.io/github/languages/top/Ramy-Badr-Ahmed/codemetaCrosswalk)\n![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/codemetaCrosswalk)  [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12808884.svg)](https://doi.org/10.5281/zenodo.12808884)\n\n[![SWH](https://archive.softwareheritage.org/badge/swh:1:dir:8fe28098cf799244158d8204fe80c471fcf04a66/)](https://archive.softwareheritage.org/swh:1:dir:8fe28098cf799244158d8204fe80c471fcf04a66;origin=https://github.com/Ramy-Badr-Ahmed/codemetaCrosswalk;visit=swh:1:snp:7129240170329390ce30cc6819cde370f3595473;anchor=swh:1:rev:9a6b4f039e24bb96503eb8179f810ed6a4c8ed4c)\n\n# Codemeta.json Crosswalk\n\nThis repository has been developed as part of the [FAIR4CoreEOSC project](https://faircore4eosc.eu/eosc-core-components/eosc-research-software-apis-and-connectors-rsac) to address two project's pillars (Describe and Cite).\n\n> [!Note]\n>  A demonstrable version can be accessed here: <a href=\"https://1959e979-c58a-4d3c-86bb-09ec2dfcec8a.ka.bw-cloud-instance.org/\" target=\"_blank\">**Demo Version**</a>\n\nSample snapshot of the codemeta generator and converter demo:\n\n![snap.PNG](snap.PNG)\n\nIt currently addresses metadata conversions for the following use cases:\n\n| From     | To            |\n|----------|---------------|\n| CodeMeta | DataCite [^1] |\n| CodeMeta | BibLatex [^2] |\n| CodeMeta | BibTex [^3]   |\n\nThe codemeta conversion pattern to the above schemes is extendable to other metadata schemes as template classes located under `Schemes` directory. The initial keys correspondence is defined in this repository [^4].\n\n> [!Note]\n> There's a scheme template class that can help see this pattern. Please consult the crosswalk [^4] and scheme documentations to properly construct this class.\n\n## Installation Steps:\n\n    1) Clone this project.\n    \n    2) Open a console session and navigate to the cloned directory:\n    \n        Run \"composer install\"\n\n        This should involve installing the PHP REPL, PsySH\n\n    3) (optional) Add psysh to PATH\n            \n            Example, Bash: \n                    echo 'export PATH=\"$PATH:/The_Cloned_Directory/vendor/bin\"' >> ~/.bashrc\n                    source ~/.bashrc\n\n    4) (Optional) Create your local branch.\n\n## Usage:\n\n- In a console session inside the cloned directory, start the php REPL:    \n\n```php\n$ psysh     // if not added to PATH replace with: vendor/bin/psysh\n\nPsy Shell v0.12.0 (PHP 8.2.0 — cli) by Justin Hileman\n```\n\n- Define namespace:\n\n```php\n> namespace Conversions; \n> use Conversions;\n```\n\n- Specify codemeta.json path:\n\n```php\n> $codeMetaPath = 'CodeMeta/codeMeta.json'\n```\n\n> [!Note]\n> By default, codemeta.json is located under 'CodeMeta' directory where an example already exists.\n> `$codeMetaPath` can _also_ directly take codemeta.json as an array\n\n- Specify target scheme (as fully qualified class name)\n\n```php\n> $dataCite = \\Schemes\\DataCite::class\n> $bibLatex = \\Schemes\\BibLatex::class\n> $bibTex   = \\Schemes\\BibTex::class\n```\n\n> [!Note]\n> By default, scheme classes are located under 'Schemes' directory.\n\n- Get the conversion from the specified Codemeta.json:\n\n```php\n> $errors = NULL;    // initialise errors variable\n \n> $dataCiteFromCodeMeta = CodeMetaConversion::To($dataCite, $codeMetaPath, $errors)      // array-formatted\n\n> $bibLatexFromCodeMeta = CodeMetaConversion::To($bibLatex, $codeMetaPath, $errors)      // string-formatted\n\n> $bibTexFromCodeMeta = CodeMetaConversion::To($bibTex, $codeMetaPath, $errors)          // string-formatted\n```\n\n- Retrieve errors (if occurred) from the `Illuminate\\Support\\MessageBag()` instance:\n\n```php\n> $errors->messages()      // gets error messages as specified in CodeMeta/conversionsValidations.php\n\n> $errors->keys()          // gets codemeta keys where errors occurred\n\n> $errors->first()         // gets the first occurred error message\n\n> $errors->has('identifier')    // checks whether an error has occurred in the codemeta `identifier` key\n```\n\n> [!Note]\n> Validations use the `Illuminate\\Validation\\Validator` package.\n> Error messages and rules can be customised in `CodeMeta/conversionsValidations.php` as per the package syntax.\n\n\n### References\n[^1]: [DataCite Metadata Schema](https://schema.datacite.org/meta/kernel-4.3/doc/DataCite-MetadataKernel_v4.3.pdf).\n[^2]: [BibLATEX style extension for Software](https://ctan.math.washington.edu/tex-archive/macros/latex/contrib/biblatex-contrib/biblatex-software/software-biblatex.pdf).\n[^3]: [BibTex](https://en.wikipedia.org/wiki/BibTeX).\n[^4]: [Codemeta Crosswalk](https://github.com/codemeta/codemeta/blob/master/crosswalk.csv).        \n"
        },
        {
            "software_organization": "https://helmholtz.software/software/picongpu",
            "repo_link": "https://github.com/ComputationalRadiationPhysics/picongpu",
            "readme": "PIConGPU - Particle-in-Cell Simulations for the Exascale Era\n============================================================\n\n[![Code Status dev](https://gitlab.com/hzdr/crp/picongpu/badges/dev/pipeline.svg?key_text=dev)](https://gitlab.com/hzdr/crp/picongpu/pipelines/dev/latest)\n[![Documentation Status](https://readthedocs.org/projects/picongpu/badge/?version=latest)](http://picongpu.readthedocs.io)\n[![Doxygen](https://img.shields.io/badge/API-Doxygen-blue.svg)](http://computationalradiationphysics.github.io/picongpu)\n[![Language](https://img.shields.io/badge/language-C%2B%2B17-orange.svg)](https://isocpp.org/)\n[![License PIConGPU](https://img.shields.io/badge/license-GPLv3-blue.svg?label=PIConGPU)](https://www.gnu.org/licenses/gpl-3.0.html)\n[![License PMacc](https://img.shields.io/badge/license-LGPLv3-blue.svg?label=PMacc)](https://www.gnu.org/licenses/lgpl-3.0.html)\n\n[![PIConGPU Presentation Video](http://img.youtube.com/vi/nwZuG-XtUDE/0.jpg)](http://www.youtube.com/watch?v=nwZuG-XtUDE)\n[![PIConGPU Release](docs/logo/pic_logo_vert_158x360.png)](http://www.youtube.com/watch?v=nwZuG-XtUDE)\n\nIntroduction\n------------\n\nPIConGPU is a fully relativistic,\n[manycore](https://en.wikipedia.org/wiki/Manycore_processor),\n3D3V particle-in-cell ([PIC](http://en.wikipedia.org/wiki/Particle-in-cell))\ncode. The Particle-in-Cell algorithm is a central tool in plasma physics.\nIt describes the dynamics of a plasma by computing the motion of\nelectrons and ions in the plasma based on\n[Maxwell's equations](http://en.wikipedia.org/wiki/Maxwell%27s_equations).\n\nPIConGPU implements various numerical schemes to solve the PIC cycle.\nIts features for the electro-magnetic PIC algorithm include:\n- a central or Yee-lattice for fields\n- particle pushers that solve the equation of motion for charged and neutral\n  particles, e.g., the *Boris-* and the\n  [*Vay-Pusher*](http://dx.doi.org/10.1063/1.2837054)\n- Maxwell field solvers, e.g.\n  [*Yee's*](http://dx.doi.org/10.1109/TAP.1966.1138693) and\n  [*Lehe's*](http://dx.doi.org/10.1103/PhysRevSTAB.16.021301) scheme\n- rigorously charge conserving current deposition schemes, such as\n  [*Esirkepov*](http://dx.doi.org/10.1016/S0010-4655%2800%2900228-9)\n  and *EZ* (Esirkepov meets ZigZag)\n- macro-particle form factors ranging from NGP (0th order), CIC (1st),\n  TSC (2nd), PQS (3rd) to PCS (4th)\n\nand the electro-magnetic PIC algorithm is further self-consistently coupled to:\n- classical radiation reaction\n  ([DOI:10.1016/j.cpc.2016.04.002](http://dx.doi.org/10.1016/j.cpc.2016.04.002))\n- advanced field ionization methods\n  ([DOI:10.1103/PhysRevA.59.569](http://dx.doi.org/10.1103/PhysRevA.59.569),\n   [LV Keldysh](http://www.jetp.ac.ru/cgi-bin/dn/e_020_05_1307.pdf), BSI)\n\nBesides the electro-magnetic PIC algorithm and extensions to it, we developed\na wide range of tools and diagnostics, e.g.:\n- online, far-field radiation diagnostics for coherent and incoherent radiation\n  emitted by charged particles\n- full restart and output capabilities via [openPMD](http://openPMD.org),\n  including [parallel HDF5](http://hdfgroup.org/)\n- 2D and 3D live view and diagnostics tools\n- a large selection of extensible\n  [online-plugins](http://picongpu.readthedocs.io/en/latest/usage/plugins.html)\n\nAs one of our supported compute platforms, GPUs provide a computational\nperformance of several\n[TFLOP/s](http://en.wikipedia.org/wiki/FLOPS) at considerable lower invest and\nmaintenance costs compared to multi CPU-based compute architectures of similar\nperformance. The latest high-performance systems\n([TOP500](http://www.top500.org/)) are enhanced by accelerator hardware that\nboost their peak performance up to the multi-PFLOP/s level. With its\noutstanding performance and scalability to more than 18'000 GPUs,\nPIConGPU was one of the **finalists** of the 2013\n[Gordon Bell Prize](http://sc13.supercomputing.org/content/acm-gordon-bell-prize).\n\nPIConGPU is developed and maintained by the\n[Computational Radiation Physics Group](https://www.hzdr.de/db/Cms?pNid=2097)\nat the [Institute for Radiation Physics](http://www.hzdr.de/db/Cms?pNid=132)\nat [HZDR](http://www.hzdr.de/) in close collaboration with the Center\nfor Information Services and High Performance Computing\n([ZIH](http://tu-dresden.de/die_tu_dresden/zentrale_einrichtungen/zih)) of the\nTechnical University Dresden ([TUD](http://www.tu-dresden.de)). We are a\nmember of the [Dresden GPU Center of Excellence](http://ccoe-dresden.de/) that\ncooperates on a broad range of scientific GPU and manycore applications,\nworkshops and teaching efforts.\n\nAttribution\n-----------\n\nPIConGPU is a *scientific project*. If you **present and/or publish** scientific\nresults that used PIConGPU, you should set a **reference** to show your support.\n\nOur according **up-to-date publication** at **the time of your publication**\nshould be inquired from:\n- [REFERENCE.md](https://raw.githubusercontent.com/ComputationalRadiationPhysics/picongpu/master/REFERENCE.md)\n\nPlease also consider adding yourself to our [community map](https://github.com/ComputationalRadiationPhysics/picongpu-communitymap).\nWe would love to hear from you!\n\nOral Presentations\n------------------\n\nThe following slide should be part of **oral presentations**. It is intended to\nacknowledge the team maintaining PIConGPU and to support our community:\n\n(*coming soon*) presentation_picongpu.pdf\n(svg version, key note version, png version: 1920x1080 and 1024x768)\n\nSoftware License\n----------------\n\n*PIConGPU* is licensed under the **GPLv3+**. Furthermore, you can develop your\nown particle-mesh algorithms based on our general library *PMacc* that is\nshipped alongside PIConGPU. *PMacc* is *dual licensed* under both the\n**GPLv3+ and LGPLv3+**.\nFor a detailed description, please refer to [LICENSE.md](LICENSE.md)\n\n********************************************************************************\n\nInstall\n-------\n\nSee our notes in [INSTALL.rst](INSTALL.rst).\n\nUsers\n-----\n\nDear User, we hereby emphasize that we are still actively developing PIConGPU at great\nspeed and do, from time to time, break backwards compatibility.\n\nWhen using this software, please stick to the latest release or use the `dev` branch containing the\nlatest changes. It also contains a file `CHANGELOG.md` with the\nlatest changes (and how to update your simulations). Read it first before\nupdating between two versions! Also, we add a git `tag` according to a version\nnumber for each release.\n\nFor any questions regarding the usage of PIConGPU please **do not** contact the\ndevelopers and maintainers directly.\n\nInstead, please [open an issue on GitHub](https://github.com/ComputationalRadiationPhysics/picongpu/issues/new).\n\nBefore you post a question, browse the PIConGPU\n[documentation](https://github.com/ComputationalRadiationPhysics/picongpu/search?l=markdown),\n[wiki](https://github.com/ComputationalRadiationPhysics/picongpu/wiki) and the\n[issue tracker](https://github.com/ComputationalRadiationPhysics/picongpu/issues)\nto see if your question has been answered, already.\n\nPIConGPU is a collaborative project.\nWe thus encourage users to engage in answering questions of other users and post solutions to problems to the list.\nA problem you have encountered might be the future problem of another user.\n\nIn addition, please consider using the collaborative features of GitHub if you have questions or comments on code or documentation.\nThis will allow other users to see the piece of code or documentation you are referring to.\n\nMain ressources are in our [online manual](https://picongpu.readthedocs.io), the [user section](https://github.com/ComputationalRadiationPhysics/picongpu/wiki) of our wiki, documentation files in [`.md` (Markdown)](http://commonmark.org/help/) and [`.rst` (reStructuredText)](http://www.sphinx-doc.org/en/stable/rest.html) format in this repository and a [getting started video](http://www.youtube.com/watch?v=7ybsD8G4Rsk).\nFeel free to visit [picongpu.hzdr.de](http://picongpu.hzdr.de) to learn more about the PIC algorithm.\n\nSoftware Upgrades\n-----------------\n\nPIConGPU ships new and frequent changes to the code in the development branch `dev`.\n\nFrom time to time we publish a new release\nof PIConGPU. Before you pull the changes in, please read our\n[ChangeLog](CHANGELOG.md)!\nYou may have to update some of your simulation `.param` and `.cfg` files by\nhand since PIConGPU is an active project and new features often require changes\nin input files. Additionally, a full description of new features and fixed bugs\nin comparison to the previous release is provided in that file.\n\nIn case you decide to use *new, potentially buggy and experimental* features\nfrom our `dev` branch, be aware that you must participate or at least follow the development yourself. \nSyntax changes and in-development bugs will *not* be announced outside of their according pull\nrequests and issues.\n\nBefore drafting a new release, we open a new `release-*` branch from `dev` with\nthe `*` being the version number of the upcoming release. This branch only\nreceives bug fixes (feature freeze) and users are welcome to try it out\n(however, the change log and a detailed announcement might still be missing in\nit).\n\nDevelopers\n----------\n\n### How to participate\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md)\n\nIf you like to jump in right away, see  \n[![open \"good first issue\" issues](https://img.shields.io/github/issues-raw/ComputationalRadiationPhysics/picongpu/good%20first%20issue.svg?color=56cbef)](https://github.com/ComputationalRadiationPhysics/picongpu/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n\nActive Team\n-----------\n\n### Scientific Supervision\n\n- Dr. Michael Bussmann\n\n### Maintainers* and core developers\n\n- Dr. Sergei Bastrakov*\n- Finn-Ole Carstens\n- Dr. Alexander Debus\n- Dr. Marco Garten*\n- Dr. Axel Huebl*\n- Brian Edward Marre\n- Pawel Ordyna \n- Dr. Richard Pausch*\n- Franz Poeschel\n- Dr. Klaus Steiniger*\n- Rene Widera*\n\n### Former Members, Contributions and Thanks\n\nThe PIConGPU Team expresses its gratitude to:\n\nFlorian Berninger, Heiko Burau, Fabia Dietrich, Robert Dietrich, Carlchristian Eckert,\nSimeon Ehrig, Wen Fu, Ph.D., Alexander Grund, Sebastian Hahn, Anton Helm, Wolfgang Hoehnig,\nDr.-Ing. Guido Juckeland, Jeffrey Kelling, Maximilian Knespel, Dr. Remi Lehe,\nFelix Schmitt, Frank Winkler, Benjamin Schneider, Joseph Schuchart, Conrad Schumann,\nStefan Tietze, Marija Vranic, Ph.D., Benjamin Worpitz, Erik Zenker,\nSophie Rudat, Sebastian Starke, Alexander Matthes, Kseniia Bastrakova, \nBernhard Manfred Gruber, Jakob Trojok, Anton Lebedev, Nils Prinz,\nFelix Meyer, Lennert Sprenger, Manhui Wang, Maxence Thevenet, Ilja Goethel,\nMika Soren Voß, Lei Bifeng, Andrei Berceanu, Felix Meyer,\nLennert Sprenger and Nico Wrobel.\n\nKudos to everyone, mentioned or unmentioned, who contributed further in any\nway!\n\n********************************************************************************\n\n![image of an lwfa](docs/images/lwfa_iso.png \"LWFA\")\n![image of our strong scaling](docs/images/StrongScalingPIConGPU_log.png \"Strong Scaling\")\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pigx",
            "repo_link": "https://github.com/BIMSBbioinfo/pigx",
            "readme": "[![install with Guix badge](https://img.shields.io/badge/install%20with-guix-F4BB15.svg)](https://gnu.org/s/guix)\n\n<div align=\"center\">\n<img src=\"logo.svg\" alt=\"PiGx logo\" width=\"30%\" height=\"30%\" />\n</div>\n\n# What is PiGx?\n\nPiGx is a collection of genomics pipelines. More information can be found in [PiGx website](https://bioinformatics.mdc-berlin.de/pigx/)\n\nIt includes the following pipelines:\n\n- [PiGx BSseq](https://github.com/BIMSBbioinfo/pigx_bsseq) for raw\n  fastq read data of bisulfite experiments\n\n- [PiGx RNAseq](https://github.com/BIMSBbioinfo/pigx_rnaseq) for RNAseq samples\n\n- [PiGx scRNAseq](https://github.com/BIMSBbioinfo/pigx_scrnaseq) for\n  single cell dropseq analysis\n\n- [PiGx ChIPseq](https://github.com/BIMSBbioinfo/pigx_chipseq) for\n  reads from ChIPseq experiments\n\n- [PiGx CRISPR](https://github.com/BIMSBbioinfo/pigx_crispr) *(work in progress)*\n  for the analysis of sequence mutations in CRISPR-CAS9 targeted\n  amplicon sequencing data\n\nAll pipelines are easily configured with a sample sheet (in CSV\nformat) and a descriptive settings file (in YAML format).  For more\ndetailed information see the README.md file for each of the pipelines\nin the `pipelines` directory.\n\n## Publication\n\n**Wurmus R, Uyar B, Osberg B, Franke V, Gosdschan A, Wreczycka K, Ronen J,\nAkalin A**. [PiGx: Reproducible genomics analysis pipelines with GNU Guix.](https://www.ncbi.nlm.nih.gov/pubmed/30277498)\n**Gigascience**. 2018 Oct 2. doi: 10.1093/gigascience/giy123. PubMed PMID: 30277498.\n\n# Getting started\n\nTo run PiGx on your experimental data, describe your samples in a CSV\nfile `sample_sheet.csv`, provide a `settings.yaml` to override the\ndefaults defaults, and select the pipeline.\n\nTo generate a settings file template for any pipeline:\n\n```sh\npigx [pipeline] --init=settings\n```\n\nTo generate a sample sheet template for any pipeline:\n\n```sh\npigx [pipeline] --init=sample-sheet\n```\n\nHere's a simple example to run the RNAseq pipeline:\n\n```sh\npigx rnaseq my-sample-sheet.csv --settings my-settings.yaml\n```\n\nTo see all available options run `pigx --help`.\n\n\n# Install\n\nPre-built binaries for PiGx are available through GNU Guix, the\nfunctional package manager for reproducible, user-controlled software\nmanagement.  Install the complete pipeline bundle with the following\ncommand:\n\n```sh\nguix install pigx\n```\n\nIf you want to install PiGx from source, please make sure that all\nrequired dependencies are installed and then follow the common GNU\nbuild system steps after unpacking the [latest release\ntarball](https://github.com/BIMSBbioinfo/pigx/releases/latest):\n\n```sh\n./configure --prefix=/some/where\nmake install\n```\n\nYou can enable or disable each of the pipelines with the\n`--enable-PIPELINE` and `--disable-PIPELINE` arguments to the\n`configure` script.  `PIPELINE` is one of `bsseq`, `rnaseq`,\n`scrnaseq`, `chipseq`, and `crispr`.  For more options run\n`./configure --help`.\n\n\n# License\n\nAll PiGx pipelines are free software: you can redistribute PiGx and/or\nmodify it under the terms of the GNU General Public License as\npublished by the Free Software Foundation, either version 3 of the\nLicense, or (at your option) any later version.\n\nSee `LICENSE` for the full license text.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pkgndep",
            "repo_link": "https://github.com/jokergoo/pkgndep",
            "readme": "# Analyzing Dependency Heaviness of R Packages\n\n[![R-CMD-check](https://github.com/jokergoo/pkgndep/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/pkgndep/actions)\n[![CRAN](https://www.r-pkg.org/badges/version/pkgndep)](https://cran.r-project.org/web/packages/pkgndep/index.html)\n\n\nWhen developing R packages, we should try to avoid directly setting\ndependencies on \"heavy packages\". The \"heaviness\" for a package means, the\nnumber of additional dependency packages it brings to. If your package directly depends\non a heavy package, it would bring several consequences:\n\n1. Users need to install a lot of additional packages when installing your\n   package which brings the risk that installation of some packages\n   may fail and it makes your package cannot be installed. \n2. The namespaces that are loaded into your R session after loading your package will be huge (you can see the loaded namespaces by `sessionInfo()`).\n3. You package will be \"heavy\" as well and it may take long time to load your package.\n\nIn the DESCRIPTION file of your package, there are \"direct dependency\npakcages\" listed in the `Depends`, `Imports` and `LinkingTo` fields. There are\nalso \"indirect dependency packages\" that can be found recursively for each of\nthe direct dependency packages. Here what we called \"dependency packages\" are\nthe union of the direct and indirect dependency packages.\n\nThere are also packages listed in `Suggests` and `Enhances` fields in\nDESCRIPTION file, but they are not enforced to be installed when installing\nyour package. Of course, they also have \"indirect dependency packages\". To get\nrid of the heavy packages that are not often used in your package, it is\nbetter to move them into the `Suggests`/`Enhances` fields and to load/install\nthem only when they are needed.\n\nHere the **pkgndep** package checks the heaviness of the dependency packages\nof your package. For each package listed in the `Depends`, `Imports`,\n`LinkingTo` and `Suggests`/`Enhances` fields in the DESCRIPTION file,\n**pkgndep** checks how many additional packages your package requires. The\nsummary of the dependency is visualized by a customized heatmap.\n\nAs an example, I am developing a package called\n[**cola**](https://github.com/jokergoo/cola/) which depends on [a lot of other\npackages](https://github.com/jokergoo/ComplexHeatmap/blob/master/DESCRIPTION).\nThe dependency heatmap looks like follows:\n\n![](https://user-images.githubusercontent.com/449218/140655626-f2062b6e-c11f-4dc0-b6b9-d954feffc4ad.png)\n\n\nIn the heatmap, rows are the packages listed in `Depends`, `Imports` and\n`Suggests` fields, columns are the additional dependency packages required for\neach row package. The barplots on the right show the number of required\npackage, the number of imported functions/methods/classes (parsed from\nNAMESPACE file) and the quantitative measure \"heaviness\" (the definition of\nheaviness will be introduced later).\n\nWe can see if all the packages are put in the `Depends` or `Imports` field\n(i.e. movig all suggsted packages to `Imports`), in total 248\npackages are required, which are really a lot. Actually some of the heavy\npackages such as **WGCNA**, **clusterProfiler** and **ReactomePA** (the last\nthree packages in the heatmap rows) are not very frequently used in **cola**,\nmoving them to `Suggests` field and using them only when they are needed\ngreatly helps to reduce the heaviness of **cola**. Now the number of required\npackages are reduced to only 64.\n\n## Citation\n\nGu Z. et al., pkgndep: a tool for analyzing dependency heaviness of R packages. Bioinformatics 2022. https://doi.org/10.1093/bioinformatics/btac449\n\nGu Z, On the Dependency Heaviness of CRAN/Bioconductor Ecosystem. Journal of Systems and Software 2023. https://doi.org/10.1016/j.jss.2023.111610\n\n## Installation\n\nThe **pkgndep** package can be installed from CRAN by\n\n```r\ninstall.packages(\"pkgndep\")\n```\n\n## Usage\n\nTo use this package:\n\n```r\nlibrary(pkgndep)\npkg = pkgndep(\"package-name\")\ndependency_heatmap(pkg)\n```\n\nor\n\n```r\npkg = pkgndep(\"path-of-the-package\")\ndependency_heatmap(pkg)\n```\n\nAn executable example:\n\n```r\nlibrary(pkgndep)\npkg = pkgndep(\"ComplexHeatmap\")\npkg\n```\n\n```\n## ComplexHeatmap, version 2.9.4\n## 30 additional packages are required for installing 'ComplexHeatmap'\n## 117 additional packages are required if installing packages listed in all fields in DESCRIPTION\n```\n\n```r\ndependency_heatmap(pkg)\n```\n\n![](https://user-images.githubusercontent.com/449218/140655659-2ca142c5-067f-4f76-a0d2-00d0aea49c96.png)\n\n## Heaviness database\n\nThere is an integrated dependency heaviness database for all R packages for a lot of R/Bioc versions. The database can be accessed by:\n\n```r\nheaviness_database()\n```\n\n## License\n\nMIT @ Zuguang Gu\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pointneighborsjl",
            "repo_link": "https://github.com/trixi-framework/PointNeighbors.jl",
            "readme": "# PointNeighbors.jl\n\n[![Docs-stable](https://img.shields.io/badge/docs-stable-blue.svg)](https://trixi-framework.github.io/PointNeighbors.jl/stable)\n[![Docs-dev](https://img.shields.io/badge/docs-dev-blue.svg)](https://trixi-framework.github.io/PointNeighbors.jl/dev)\n[![Slack](https://img.shields.io/badge/chat-slack-e01e5a)](https://join.slack.com/t/trixi-framework/shared_invite/zt-sgkc6ppw-6OXJqZAD5SPjBYqLd8MU~g)\n[![Youtube](https://img.shields.io/youtube/channel/views/UCpd92vU2HjjTPup-AIN0pkg?style=social)](https://www.youtube.com/@trixi-framework)\n[![Build Status](https://github.com/trixi-framework/PointNeighbors.jl/workflows/CI/badge.svg)](https://github.com/trixi-framework/PointNeighbors.jl/actions?query=workflow%3ACI)\n[![Codecov](https://codecov.io/gh/trixi-framework/PointNeighbors.jl/branch/main/graph/badge.svg)](https://codecov.io/gh/trixi-framework/PointNeighbors.jl)\n[![SciML Code Style](https://img.shields.io/static/v1?label=code%20style&message=SciML&color=9558b2&labelColor=389826)](https://github.com/SciML/SciMLStyle)\n[![License: MIT](https://img.shields.io/badge/License-MIT-success.svg)](https://opensource.org/license/mit/)\n[![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.12702157.svg)](https://zenodo.org/doi/10.5281/zenodo.12702157)\n\n**PointNeighbors.jl** is a package for neighborhood search with fixed search radius in\n1D, 2D and 3D point clouds.\n\n## Features\n\n- Several implementations of neighborhood search with fixed search radius\n- Focus on fast incremental updates to be usable for particle-based simulations with\n  frequent updates\n- Designed as a \"playground\" to easily switch between different implementations and data\n  structures\n- Common API over all implementations\n- Extensive benchmark suite to study different implementations (work in progress)\n- GPU compatibility (work in progress)\n\n| Implementation  | Description | Features | Query | Update | GPU-compatible |\n| ------------- | ------------- | --- | :--: | :--: | :--: |\n| `GridNeighborhoodSearch` with `DictionaryCellList` | Grid-based NHS with Julia `Dict` backend | Infinite domain | Fast | Fast | ❌ |\n| `GridNeighborhoodSearch` with `FullGridCellList` | Grid-based NHS allocating all cells of the domain | Finite domain, but efficient memory layout for densely filled domain. | Faster | Fastest | ✅ |\n| `PrecomputedNeighborhoodSearch` | Precompute neighbor lists | Best for [TLSPH](https://trixi-framework.github.io/TrixiParticles.jl/stable/systems/total_lagrangian_sph/) without NHS updates. Not suitable for updates in every time step. | Fastest | Very slow | ❌ |\n\n## Benchmarks\n\nThe following benchmarks were conducted on an AMD Ryzen Threadripper 3990X using 128 threads.\n\nBenchmark of a single force computation step of a Weakly Compressible SPH (WCSPH) simulation:\n![wcsph](https://github.com/trixi-framework/PointNeighbors.jl/assets/44124897/ad5c378b-9ce2-4e6f-91dc-1e0da379b91f)\n\nBenchmark of an incremental update similar to a WCSPH simulation (note the log scale):\n![update](https://github.com/trixi-framework/PointNeighbors.jl/assets/44124897/71eac5c9-6aa5-4267-bc0b-4057c89f8b12)\n\nBenchmark of a full right-hand side evaluation of a WCSPH simulation (note the log scale):\n![rhs](https://github.com/trixi-framework/PointNeighbors.jl/assets/44124897/ac328a96-1b9f-4319-a785-dce9d862fd70)\n\n\n## Packages using PointNeighbors.jl\n\n- [TrixiParticles.jl](https://github.com/trixi-framework/TrixiParticles.jl)\n- [Peridynamics.jl](https://github.com/kaipartmann/Peridynamics.jl)\n- [PeriLab.jl](https://github.com/PeriHub/PeriLab.jl)\n\nIf you're using PointNeighbors.jl in your package, please feel free to open a PR adding it\nto this list.\n\n\n## Cite Us\n\nIf you use PointNeighbors.jl in your own research or write a paper using results obtained\nwith the help of PointNeighbors.jl, please cite it as\n```bibtex\n@misc{pointneighbors,\n  title={{P}oint{N}eighbors.jl: {N}eighborhood search with fixed search radius in {J}ulia},\n  author={Erik Faulhaber and Niklas Neher and Sven Berger and\n          Michael Schlottke-Lakemper and Gregor Gassner},\n  year={2024},\n  howpublished={\\url{https://github.com/trixi-framework/PointNeighbors.jl}},\n  doi={10.5281/zenodo.12702157}\n}\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/postwrf",
            "repo_link": "https://github.com/anikfal/PostWRF",
            "readme": "# PostWRF\n\n[![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.8191714.svg)](https://zenodo.org/record/8191714)\n\n### Visualization and postprocessing of the WRF and ERA5 data\n\n**Plot the WRF and ERA5 data, in the same simple way as you run the WRF model!**\n\nPostWRF is a bunch of interactive tools, written in NCL and Bash scripts, to visualize and post-process the WRF model outputs (as well as ERA5 and RTTOV data, to some extent).\n\nPostWRF is useful for both the expert and less-experienced users. Students can plot the WRF and ERA5 outputs whithout struggling with coding and syntax errors. Expert users can also carry out common postprocessing tasks in a simple and straightforward way.\n\n## Main capabilities:\n- WRF Data extraction\n- WRF horizontal contour plot\n- WRF cross-section plot\n- WRF statistical diagrams\n- RTTOV input (from WRF) and output data generation\n- WRF data conversion to Geotiff\n- WRF Skew-T and windrose diagrams\n- ERA5 horizontal contour plot\n- ERA5 data extraction\n\n## Sample visualizations and postprocessing\n![github_postwrf](https://github.com/anikfal/PostWRF/assets/11738727/16be89c3-1bb1-4245-a430-1d07876563dd)\n\n\n## Installation:\nInstall NCL on a Linux machine (e.g. Fedora):\n```bash\nsudo dnf install ncl\n```\nThat's it! Enough for most of the PostWRF's capabilities!\n\n## Run PostWRF:\n1. ``` git clone git@github.com:anikfal/PostWRF.git ```\n2. ``` cd PostWRF ```\n3. ``` chmod +x postwrf.sh modules/*.sh modules_era/*.sh ```\n4. Copy or link your WRF or ERA5 files in the PostWRF directory\n5. ``` ./postwrf.sh ```\n6. Follow the instructions and give relevant information to visualize/postprocess your data\n\n\n## HTML Documentations:\nDocumentations with practical examples: https://postwrf.readthedocs.io/en/master\n\n## YouTube Training Videos:\nhttps://youtube.com/playlist?list=PL93HaRiv5QkCOWQ4E_Oeszi9DBOYrdNXD\n\n## Paper:\nFor more detailed information about the backend structure of the software, please read https://doi.org/10.1016/j.envsoft.2022.105591\n\nIf you find PostWRF helpful, please kindly cite it in your works.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/potsdam-open-source-radio-interferometry-tool",
            "repo_link": "https://git.gfz-potsdam.de/vlbi-data-analysis/port",
            "readme": "## PORT: Potsdam Open-source Radio interferometry Tool\n\n### Abstract\n\nThe Potsdam Open-source Radio interferometry Tool (PORT) is a software package\ndedicated to the analysis of modern and historical very long baseline\ninterferometry (VLBI) observations. PORT is being developed at GFZ Potsdam and\nis utilized to perform the GFZ VLBI Analysis Center responsibilities, as well as\nstate-of-the-art research in the field of space geodesy, geophysics, and\nastrometry.\n\nPORT can estimate quantities such as station positions, quasar\npositions, Earth orientation parameters, atmospheric delay parameters, either\nemploying weighted least-squares or a Kalman filter and smoother. PORT is\ndesigned to process VGOS observations, as well as traditional S-/X-band and\nsingle-band observations, regardless of data length; PORT processes both,\nintensive and multi-hour/day sessions. Developing PORT, special care has been\ntaken to deal with issues such as the source structure. PORT abides by the\nlatest analysis standards suggested by the IERS (International Earth Rotation\nand Reference Systems Service) and the IVS (International VLBI Service for\nGeodesy and Astrometry), and supports ITRF2020.\n\nPORT is written mainly in MATLAB, with some Python modules and bash scripts.\nIt is maintained on GFZ's GitLab server. VLBI data analysis employing PORT may be\ncarried by scripting or interactively via a graphical user interface.\n\nUpon completion, PORT will be able to schedule, simulate, and analyze VLBI\nobservations, as well as to utilize VLBI observations to derive consistent\nterrestrial and celestial reference frames.\n\nFor more information about PORT visit\nhttps://git-int.gfz-potsdam.de/vlbi-data-analysis/port\nor contact gfzvlbi@gfz-potsdam.de.\n\n### Reference\n\nSchuh et al. (2021),\nThe Potsdam Open Source Radio Interferometry Tool (PORT),\nPASP 133 104503,\ndoi: 10.1088/1538-3873/ac299c\n\n### Brief Introduction for the Impatient (TL;DR)\n\n#### Preliminaries\n\nPORT requires a recent MATLAB version (e.g. 2023a or later)\nand a Python environment\nsupported by MATLAB's Python interface. See,\n\nhttps://mathworks.com/support/requirements/python-compatibility.html\n\nIn the following it is assumed that the interface has been successfully\ninitialized.\nFor help on how to do this, enter\n\n``` doc pyenv ```\n\non the MATLAB command line.\n\n#### Initialization\n\nCreate an empty directory on a disk with about 100 GB of free space.\nIf PORT should be installed in directory ```${HOME}/port-vlbi-analysis/```\nenter on the BASH command line\n\n```mkdir ${HOME}/port-vlbi-analysis/; cd ${HOME}/port-vlbi-analysis/```\n\nDownload the PORT repository\n\n```git clone --branch release-public https://git.gfz-potsdam.de/vlbi-data-analysis/port ```\n\nChange to the PORT directory created by the git clone command\n\n``` cd ./port/ ```\n\nand start the install script\n\n``` ./install.sh ${analysisCentreID} ```\n\nHere, ```${analysisCentreID}``` is to be replaced by (exactly) three uppercase letters\nwhich identify your analysis (institution).\n\nBy default, the install script sets the PORT\nsolution code to \"\"```<currentYear>a```\", i.e. \"```2024a```\" as of now.\nOf course, the user may choose\n(almost) any other solution code as the second script argument.\n\nExample:\n\n``` ./install.sh ABC 2022c ```\n\nBy default, the install script downloads the level 2 data from\nthe IVS server OPAR (ftp://ivsopar.obspm.fr)\nfor January of the previous year.\nOther time periods need to be specified as the third and fourth script\nargument, i.e.\n\n``` ./install.sh ${analysisCentreID} ${solutionCode} ${startDate} ${endDate} ```\n\nwhere ``` ${startDate} ``` and ``` ${endDate} ``` are entered\nin the form ``` YYYY-MM-DD ```. Please note, that download time\nmight get excessively large, if more than a few months of data are specified.\nAfter a few or more minutes (depending on your internet bandwidth) download will be completed.\n\n#### Starting PORT\n\nNow start MATLAB within the PORT install directory and enter\n\n``` port ```\n\non the MATLAB command line.\nFor more information see the PORT IVS Cookbook\n(${PORT_ROOT_DIR}/doc/PORT_IVS_Cookbook_GFZ.pdf).\n\nOnce PORT has been installed successfully, additional sessions\ncan be downloaded with the bash script\n\n```cd ${PORT_ROOT_DIR}; ./download-sessions.sh ${analysisCentreID} ${solutionCode} ${startDate} ${endDate} ```\n\nExample:\n\n``` cd ${PORT_ROOT_DIR}; ./download-sessions.sh ABC 2024a 2020-01-01 2020-02-01 ```\n\nHappy analyzing.\n",
            "project_id": "699"
        },
        {
            "software_organization": "https://helmholtz.software/software/profasi",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/slbio/profasi",
            "readme": "ProFASi: Protein Folding and Aggregation Simulator\n==================================================\n\n:Email: profasi@thep.lu.se\n:Home Page: http://cbbp.thep.lu.se/activities/profasi/\n:Version control (git): https://gitlab.version.fz-juelich.de/slbio/profasi\n\n\nPROFASI (PROtein Folding and Aggregation SImulator) is a C++ program\npackage for Monte Carlo simulations of protein folding and aggregation. It\nprovides an implementation of an all-atom protein model with fixed bond lengths\nand bond angles, an implicit water simplified force field, and a set of tools to\nperform Monte Carlo simulations with the model. PROFASI version 2.0 introduces\na plugins based extensible framework for Markov Chain Monte Carlo simulations\ninvolving proteins.\n\nDevelopment\n-----------\n\nProFASi is mainly developed at \n\n- Simulation Laboratory Biology, Jülich Supercomputing Centre, Forschungszentrum Jülich, Germany \n- Division of Computational Biology and Biological Physics, Department of Astronomy and \n  Theoretical Physics, Lund University Sweden.\n\n\nInstallation\n------------\n\nFor software requirements and installation procedure take a look at the `installation\ninstructions`_.\n\n\n.. _installation instructions: doc/source/installation.rst\n\n\n.. note:: Operating systems\n\n    ProFASi development takes place almost entirely on Linux, and this program is\n    most often deployed on HPC systems, where Linux is practically the only relevant\n    OS.  But we have found that the ProFASi source code compiles\n    using the same procedure described above on Mac OSX. In the tested configuration\n    for building ProFASi on the OSX, we installed clang and libc++ using macports,\n    downloaded and unpacked TBB at $HOME/local/TBB/4.4, set environment variable\n    TBB_ROOT to to $HOME/local/TBB/4.4, and continued with cmake and make as\n    described above. Although under Mac OSX, gcc is often clang in disguise, and\n    \"gcc --version\" returns some ancient version number like 4.2, the ProFASi\n    build system detects the underlying clang compiler and sets the necessary build\n    options. ProFASi needs significant changes to compile under Microsoft Windows,\n    but it has not been a priority. It is our aim to eventually also support Windows,\n    at least for the parts of ProFASi meant to run on a laptop.\n\n",
            "project_id": "185"
        },
        {
            "software_organization": "https://helmholtz.software/software/propulate",
            "repo_link": "https://github.com/Helmholtz-AI-Energy/propulate",
            "readme": "![Propulate Logo](https://raw.githubusercontent.com/Helmholtz-AI-Energy/propulate/refs/heads/main/LOGO_light.svg#gh-light-mode-only)\n![Propulate Logo](https://raw.githubusercontent.com/Helmholtz-AI-Energy/propulate/refs/heads/main/LOGO_dark.svg#gh-dark-mode-only)\n\n\n# Parallel Propagator of Populations\n\n[![DOI](https://zenodo.org/badge/495731357.svg)](https://zenodo.org/badge/latestdoi/495731357)\n[![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F-green)](https://fair-software.eu)\n[![License: BSD-3](https://img.shields.io/badge/License-BSD--3-blue)](https://opensource.org/licenses/BSD-3-Clause)\n![PyPI](https://img.shields.io/pypi/v/propulate)\n![PyPI - Downloads](https://img.shields.io/pypi/dm/propulate)\n[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)[![](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/7785/badge)](https://www.bestpractices.dev/projects/7785)\n[![](https://img.shields.io/badge/Contact-propulate%40lists.kit.edu-orange)](mailto:propulate@lists.kit.edu)\n[![Documentation Status](https://readthedocs.org/projects/propulate/badge/?version=latest)](https://propulate.readthedocs.io/en/latest/?badge=latest)\n[![codecov](https://codecov.io/gh/Helmholtz-AI-Energy/propulate/graph/badge.svg?token=ZG6PEXJOIO)](https://codecov.io/gh/Helmholtz-AI-Energy/propulate)[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/Helmholtz-AI-Energy/propulate/main.svg)](https://results.pre-commit.ci/latest/github/Helmholtz-AI-Energy/propulate/main)\n\n# **Click [here](https://www.scc.kit.edu/en/aboutus/16956.php) to watch our 3 min introduction video!**\n\n## What `Propulate` can do for you\n\n`Propulate` is an HPC-tailored software for solving optimization problems in parallel. It is openly accessible and easy\nto use. Compared to a widely used competitor, `Propulate` is consistently faster - at least an order of magnitude for a\nset of typical benchmarks - and in some cases even more accurate.\n\nInspired by biology, `Propulate` borrows mechanisms from biological evolution, such as selection, recombination, and\nmutation. Evolution begins with a population of solution candidates, each with randomly initialized genes. It is an\niterative \"survival of the fittest\" process where the population at each iteration can be viewed as a generation. For\neach generation, the fitness of each candidate in the population is evaluated. The genes of the fittest candidates are\nincorporated in the next generation.\n\nLike in nature, `Propulate` does not wait for all compute units to finish the evaluation of the current generation.\nInstead, the compute units communicate the currently available information and use that to breed the next candidate\nimmediately. This avoids waiting idly for other units and thus a load imbalance.\nEach unit is responsible for evaluating a single candidate. The result is a fitness level corresponding with that\ncandidate’s genes, allowing us to compare and rank all candidates. This information is sent to other compute units as\nsoon as it becomes available.\nWhen a unit is finished evaluating a candidate and communicating the resulting fitness, it breeds the candidate for the\nnext generation using the fitness values of all candidates it evaluated and received from other units so far.\n\n`Propulate` can be used for hyperparameter optimization and neural architecture search at scale.\nIt was already successfully applied in several accepted scientific publications. Applications include grid load\nforecasting, remote sensing, and structural molecular biology:\n\n> J. Debus, C. Debus, G. Dissertori, et al. **PETNet–Coincident Particle Event Detection using Spiking Neural Networks**.\n> 2024 Neuro Inspired Computational Elements Conference (NICE), La Jolla, CA, USA, pp. 1-9 ( 2024).\n> https://doi.org/10.1109/NICE61972.2024.10549584\n\n> D. Coquelin, K. Flügel, M. Weiel, et al. **AB-Training: A Communication-Efficient Approach for Distributed Low-Rank\n> Learning**. arXiv preprint (2024). https://doi.org/10.48550/arXiv.2405.01067\n\n> D. Coquelin, K. Flügel, M. Weiel, et al. **Harnessing Orthogonality to Train Low-Rank Neural Networks**. arXiv\n> preprint (2024). https://doi.org/10.48550/arXiv.2401.08505\n\n> A. Weyrauch, T. Steens, O. Taubert, et al. **ReCycle: Fast and Efficient Long Time Series Forecasting with Residual\n> Cyclic Transformers**. 2024 IEEE Conference on Artificial Intelligence (CAI), Singapore, pp. 1187-1194 (2024).\n> https://doi.org/10.1109/CAI59869.2024.00212\n\n> O. Taubert, F. von der Lehr, A. Bazarova, et al. **RNA contact prediction by data efficient deep learning**.\n> Communications Biology 6(1), 913 (2023). https://doi.org/10.1038/s42003-023-05244-9\n\n> D. Coquelin, K. Flügel, M. Weiel, et al. **Harnessing Orthogonality to Train Low-Rank Neural Networks**. arXiv\n> preprint (2023). https://doi.org/10.48550/arXiv.2401.08505\n\n> Y. Funk, M. Götz, and H. Anzt. **Prediction of optimal solvers for sparse linear systems using deep learning**.\n> Proceedings of the 2022 SIAM Conference on Parallel Processing for Scientific Computing (pp. 14-24). Society for\n> Industrial and Applied Mathematics (2022). https://doi.org/10.1137/1.9781611977141.2\n\n> D. Coquelin, R. Sedona, M. Riedel, and M. Götz. **Evolutionary Optimization of Neural Architectures in Remote Sensing\n> Classification Problems**. IEEE International Geoscience and Remote Sensing Symposium IGARSS, Brussels, Belgium,\n> pp. 1587-1590 (2021). https://doi.org/10.1109/IGARSS47720.2021.9554309\n\n## In more technical terms\n\n``Propulate`` is a massively parallel evolutionary hyperparameter optimizer based on the island model with asynchronous\npropagation of populations and asynchronous migration.\nIn contrast to classical GAs, ``Propulate`` maintains a continuous population of already evaluated individuals with a\nsoftened notion of the typically strictly separated, discrete generations.\nOur contributions include:\n- A novel parallel genetic algorithm based on a fully asynchronized island model with independently processing workers.\n- Massive parallelism by asynchronous propagation of continuous populations and migration via efficient communication using the message passing interface.\n- Optimized use efficiency of parallel hardware by minimizing idle times in distributed computing environments.\n\nTo be more efficient, the generations are less well separated than they usually are in evolutionary algorithms.\nNew individuals are generated from a pool of currently active, already evaluated individuals that may be from any\ngeneration.\nIndividuals may be removed from the breeding population based on different criteria.\n\nYou can find the corresponding publication [here](https://doi.org/10.1007/978-3-031-32041-5_6):\n> Taubert, O. *et al.* (2023). Massively Parallel Genetic Optimization Through Asynchronous Propagation of Populations.\n> In: Bhatele, A., Hammond, J., Baboulin, M., Kruse, C. (eds) High Performance Computing. ISC High Performance 2023.\n> Lecture Notes in Computer Science, vol 13948. Springer, Cham.\n> [doi.org/10.1007/978-3-031-32041-5_6](https://doi.org/10.1007/978-3-031-32041-5_6)\n\n## Documentation\n\nCheck out the full documentation at [https://propulate.readthedocs.io/](https://propulate.readthedocs.io/) :rocket:! Here you can find installation\ninstructions, tutorials, theoretical background, and API references.\n\n**:point_right: If you have any questions or run into any challenges while using `Propulate`, don't hesitate to post an\n[issue](https://github.com/Helmholtz-AI-Energy/propulate/issues) :bookmark:, reach out via [GitHub\ndiscussions](https://github.com/Helmholtz-AI-Energy/propulate/discussions) :octocat:, or contact us directly via e-mail\n:email: to [propulate@lists.kit.edu](mailto:propulate@lists.kit.edu).**\n\n## Installation\n\n- You can install the **latest stable release** from PyPI: ``pip install propulate``\n- If you need the **latest updates**, you can also install ``Propulate`` directly from the master branch.\nPull and run ``pip install .``.\n- If you want to run the **tutorials**, you can install the required dependencies via: ``pip install .\"[tutorials]\"``\n- If you want to **contribute** to ``Propulate`` as a developer, you need to install the required dependencies with the package:\n``pip install -e .\"[dev]\"``.\n\n``Propulate`` depends on [``mpi4py``](https://mpi4py.readthedocs.io/en/stable/) and requires an MPI implementation under\nthe hood. Currently, it is only tested with [OpenMPI](https://www.open-mpi.org/).\n\n## Quickstart\n*Below, you can find a quick recipe for how to use `Propulate` in general. Check out the official\n[ReadTheDocs](https://propulate.readthedocs.io/en/latest/tut_propulator.html) documentation for more detailed tutorials\nand explanations.*\n\nLet's minimize the sphere function $f_\\text{sphere}\\left(x,y\\right)=x^2 +y^2$ with `Propulate` as a quick example. The\nminimum is at $\\left(x, y\\right)=\\left(0,0\\right)$ at the orange star.\n![](./docs/images/sphere.png)\nFirst, we need to define the key ingredients that define our optimization problem:\n- The **search space** of the parameters to be optimized as a `Python` dictionary. `Propulate` can handle three different\n  parameter types:\n    - A tuple of `float` for a continuous parameter, e.g., `{\"learning_rate\": (0.0001, 0.01)}`\n    - A tuple of `int` for an ordinal parameter, e.g., `{\"conv_layers\": (2, 10)}`\n    - A tuple of `str` for a categorical parameter, e.g., `{\"activation\": (\"relu\", \"sigmoid\", \"tanh\")}`\n\n  Thus, an exemplary search space might look like this:\n  ```python\n  search_space = {\n      \"learning_rate\": (0.0001, 0.01),  # Search a continuous space between 0.0001 and 0.01.\n      \"num_layers\": (2, 10),  # Search the integer space between 2 and 10 (inclusive).\n      \"activation\": (\"relu\", \"sigmoid\", \"tanh\"),  # Search the categorical space with the specified possibilities.\n  }\n  ```\n\n  The sphere function has two continuous parameters, $x$ and $y$, and we consider $x,y\\in\\left[-5.12,5.12\\right]$. The\n  search space in our example thus looks like this:\n  ```python\n  limits = {\n      \"x\": (-5.12, 5.12),\n      \"y\": (-5.12, 5.12)\n  }\n  ```\n- The **loss function**. This is the function we want to minimize in order to find the best parameters. It can be any\n  `Python` function that\n  - takes a set of parameters as a `Python` dictionary as an input.\n  - returns a scalar loss value that determines how good the tested parameter set is.\n\n  In this example, the loss function whose minimum we want to find is the sphere function:\n  ```python\n  def sphere(params: Dict[str, float]) -> float:\n    \"\"\"\n    Sphere function: continuous, convex, separable, differentiable, unimodal\n\n    Input domain: -5.12 <= x, y <= 5.12\n    Global minimum 0 at (x, y) = (0, 0)\n\n    Parameters\n    ----------\n    params: Dict[str, float]\n        The function parameters.\n\n    Returns\n    -------\n    float\n        The function value.\n    \"\"\"\n    return numpy.sum(numpy.array(list(params.values())) ** 2).item()\n  ```\nNext, we need to define the **evolutionary operator** or propagator that we want to use to breed new individuals during the\noptimization process. `Propulate` provides a reasonable default propagator via a utility function:\n```python\n# Set up logger for Propulate optimization.\npropulate.set_logger_config()\n# Set up separate random number generator for Propulate optimization. DO NOT USE SOMEWHERE ELSE!\nrng = random.Random(\n    <your-random-seed> + mpi4py.MPI.COMM_WORLD.rank\n)\n# Set up evolutionary operator.\npropagator = propulate.get_default_propagator(\n    pop_size=config.pop_size,  # The breeding population size\n    limits=limits,  # The search-space limits\n    rng=rng,  # Random number generator\n)\n```\nWe also need to set up the asynchronous parallel evolutionary **optimizer**, that is a so-called ``Propulator`` instance:\n```python\n# Set up Propulator performing actual optimization.\npropulator = propulate.Propulator(\n    loss_fn=sphere,\n    propagator=propagator,\n    rng=rng,\n    generations=config.generations,\n    checkpoint_path=config.checkpoint,\n)\n```\nNow we can run the actual optimization. Overall, ``generations * mpi4py.MPI.COMM_WORLD.size`` evaluations will be\nperformed:\n```python\n# Run optimization and print summary of results.\npropulator.propulate()\npropulator.summarize()\n```\nThe output should look something like this:\n```text\n#################################################\n# PROPULATE: Parallel Propagator of Populations #\n#################################################\n\n[2024-03-12 14:37:01,374][propulate.propulator][INFO] - No valid checkpoint file given. Initializing population randomly...\n[2024-03-12 14:37:01,374][propulate.propulator][INFO] - Island 0 has 4 workers.\n[2024-03-12 14:37:01,374][propulate.propulator][INFO] - Island 0 Worker 0: In generation 0...\n[2024-03-12 14:37:01,374][propulate.propulator][INFO] - Island 0 Worker 3: In generation 0...\n[2024-03-12 14:37:01,374][propulate.propulator][INFO] - Island 0 Worker 2: In generation 0...\n[2024-03-12 14:37:01,374][propulate.propulator][INFO] - Island 0 Worker 1: In generation 0...\n[2024-03-12 14:37:01,377][propulate.propulator][INFO] - Island 0 Worker 3: In generation 10...\n[2024-03-12 14:37:01,377][propulate.propulator][INFO] - Island 0 Worker 1: In generation 10...\n[2024-03-12 14:37:01,378][propulate.propulator][INFO] - Island 0 Worker 0: In generation 10...\n[2024-03-12 14:37:01,378][propulate.propulator][INFO] - Island 0 Worker 2: In generation 10...\n\n...\n[2024-03-12 14:37:02,197][propulate.propulator][INFO] - Island 0 Worker 1: In generation 960...\n[2024-03-12 14:37:02,206][propulate.propulator][INFO] - Island 0 Worker 2: In generation 990...\n[2024-03-12 14:37:02,206][propulate.propulator][INFO] - Island 0 Worker 1: In generation 970...\n[2024-03-12 14:37:02,215][propulate.propulator][INFO] - Island 0 Worker 1: In generation 980...\n[2024-03-12 14:37:02,224][propulate.propulator][INFO] - Island 0 Worker 1: In generation 990...\n[2024-03-12 14:37:02,232][propulate.propulator][INFO] - OPTIMIZATION DONE.\nNEXT: Final checks for incoming messages...\n[2024-03-12 14:37:02,244][propulate.propulator][INFO] - ###########\n# SUMMARY #\n###########\nNumber of currently active individuals is 4000.\nExpected overall number of evaluations is 4000.\n[2024-03-12 14:37:03,703][propulate.propulator][INFO] - Top 1 result(s) on island 0:\n(1): [{'a': '2.91E-3', 'b': '-3.05E-3'}, loss 1.78E-5, island 0, worker 0, generation 956]\n```\n### Let's get your hands dirty\nDo the following to run the [example script](https://github.com/Helmholtz-AI-Energy/propulate/blob/master/tutorials/propulator_example.py):\n\n- Make sure you have a working MPI installation on your machine.\n- If you have not already done this, create a fresh virtual environment with ``Python``: ``$ python3 -m venv best-venv-ever``\n- Activate it: ``$ source best-venv-ever/bin/activate``\n- Upgrade ``pip``: ``$ pip install --upgrade pip``\n- Install ``Propulate``: ``$ pip install propulate``\n- Run the example script ``propulator_example.py``: ``$ mpirun --use-hwthread-cpus python propulator_example.py``\n\n## Acknowledgments\n*This work is supported by the Helmholtz AI platform grant.*\n![](./.figs/hai_kit_logos.svg)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pia",
            "repo_link": "https://github.com/hzi-braunschweig/pia-system",
            "readme": "# PIA-System\n\n![logo](psa.app.web/src/assets/images/pia_logo.png)\n\n[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\n[![DOI](https://zenodo.org/badge/319654384.svg)](https://zenodo.org/badge/latestdoi/319654384)\n\n[**P**rospective Mon**i**toring and Management - **A**pp](https://info-pia.de/) (PIA).\n\nPIA facilitates the data acquisition in health studies and takes into account the wishes of the participants, the study center and the research institution and thereby also supports the long-term motivation of the participants.\n\nPIA consists of a web application as well as mobile apps for Android and iOS that enables the participants to conduct health studies and study management, as well it can be used as a symptom diary for contact tracing.\nThe main goals of this project are:\n\n- Simplify the data collection process\n- (Long-term) motivation of users through persuasive technology\n- Focus on usability and user centered design\n- Focus on data protection and security\n\n### Built with\n\nIn the backend PIA is composed of [Node.js](https://nodejs.org/) microservices that are using [PostgreSQL](https://www.postgresql.org/) as a database.\nThe microservices are containerized using [Docker](https://www.docker.com/) and deployed with [Kubernetes](https://kubernetes.io/).\nAs frontends an [Angular](https://angular.io/) web app and a [Ionic](https://ionicframework.com/) powered iOS and Android mobile app are provided.\n\n## Getting started\n\n### Local development\n\nTo set up PIA for local development, please follow the [development guide](./docs/development.md).\n\n### Deployment\n\nTo deploy PIA to a (production) Kubernetes cluster, please follow the [deployment guide](./docs/deployment.md).\n\n<!--\n## Roadmap\n*TODO*\n-->\n\n## Contributing\n\nAny contributions you make are **greatly appreciated**.\nPlease fork the [gitlab repository](https://gitlab.com/pia-eresearch-system/pia).\n\n1. Fork the [PIA GitLab repository](https://gitlab.com/pia-eresearch-system/pia)\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n3. Make sure your Changes are formatted using [prettier](https://github.com/prettier/prettier) (`npx prettier --write .`)\n4. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n5. Push to the Branch (`git push origin feature/AmazingFeature`)\n6. Open a Pull Request\n\n## Licence\n\nDistributed under the AGPL-3.0 license. See [LICENSE](./LICENSES/AGPL-3.0-or-later.txt) for more information.\n\n## Contact\n\n[PiaPost@helmholtz-hzi.de](mailto:PiaPost@helmholtz-hzi.de)\n\n![HZI](psa.app.web/src/assets/images/hzi_logo.jpg)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ptylab",
            "repo_link": "https://github.com/PtyLab/PtyLab.py",
            "readme": "# PtyLab.py\n![Python 3.9+](https://img.shields.io/badge/python-3.9+-green.svg)\n\nPtyLab is an inverse modeling toolbox for Conventional (CP) and Fourier (FP) ptychography in a unified framework. For more information please check the [paper](https://opg.optica.org/oe/fulltext.cfm?uri=oe-31-9-13763&id=529026).\n\n## Getting started\n\nThe simplest way to get started is to check the below demo in Google Colab.\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PtyLab/PtyLab.py/blob/main/demo.ipynb)\n![demo](assets/recon.gif)\n\nTo explore more use cases of PtyLab, check the [example_scripts](example_scripts) and [jupyter_tutorials](jupyter_tutorials) directories. However, please install the package first as described in the below sections.\n\n## Installation\n\nTo install the package from source,\n\n```bash\npip install git+https://github.com/PtyLab/PtyLab.py.git\n```\n\nThis package uses `cupy` to utilize GPU for faster reconstruction. Please check their [instructions](https://docs.cupy.dev/en/stable/install.html) for installing this dependency.\n\n### Development\n \nPlease clone this repository and navigate to the root folder\n```bash\ngit clone git@github.com:PtyLab/PtyLab.py.git\ncd PtyLab.py\n```\n\nInside a virtual environment (preferably with conda), please install `ptylab` and its dependencies from the pinned versions specified under `requirements.txt`:\n```bash\nconda create --name ptylab_venv python=3.11.5 # or python version satisfying \">=3.9, <3.12\"\nconda activate ptylab_venv\npip install -e . -r requirements.txt\n```\n\nTo use the GPU, `cupy` can be additionally installed in this environment.\n\n```bash\nconda install -c conda-forge cupy\n```\n\nIf you would like to contribute to this package, especially if it involves modifying dependencies, please checkout the [`CONTRIBUTING.md`](CONTRIBUTING.md) file.\n\n## Citation\n\nIf you use this package in your work, cite us as below. \n\n```tex\n@article{Loetgering:23,\n        author = {Lars Loetgering and Mengqi Du and Dirk Boonzajer Flaes and Tomas Aidukas and Felix Wechsler and Daniel S. Penagos Molina and Max Rose and Antonios Pelekanidis and Wilhelm Eschen and J\\\"{u}rgen Hess and Thomas Wilhein and Rainer Heintzmann and Jan Rothhardt and Stefan Witte},\n        journal = {Opt. Express},\n        number = {9},\n        pages = {13763--13797},\n        publisher = {Optica Publishing Group},\n        title = {PtyLab.m/py/jl: a cross-platform, open-source inverse modeling toolbox for conventional and Fourier ptychography},\n        volume = {31},\n        month = {Apr},\n        year = {2023},\n        doi = {10.1364/OE.485370},\n}\n```\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pyapi-rts",
            "repo_link": "https://github.com/KIT-IAI/PyAPI-RTS",
            "readme": "# PyAPI-RTS\n\n**A Python library to read and manipulate RSCAD draft files.**\n\nSee <a href=\"examples/simple_example/simple_example.ipynb\">examples/simple_example/simple_example.ipynb</a> for a short preview of the API or take a look into our <a href=\"docs/pyapi_rts.pdf\">documentation</a>.\n\n## Installation\n\nTo install this project, perform the following steps:\n\n1. Clone the project\n2. `cd` into the cloned directory\n3. `pip install poetry`\n4. `poetry install`\n\n## Generate classes from RSCAD components\n\nBefore the first use of the project, the classes for the components in the RSCAD master library need to be generated.\n\n1. Copy the files from the `COMPONENTS` directory into `pyapi_rts/pyapi_rts/class_extractor/COMPONENTS`.\n\n2. Run `poetry run python ./pyapi_rts/class_extractor/main.py`\n\nOther options for the class generation:\n\n- \\-d: Set to delete the output folder before new classes are generated\n- \\-o: Set to include the OBSOLETE folder in the generation. Recommended if you use .dfx files converted from older versions\n- \\-p: Set path to COMPONENTS folder\n- \\-t: Set thread count used to parse the files. Default: 8 \n\n! The progress bar is not accurate due to optimizations applied during generation.\n\n## Run tests\n\n`poetry run pytest`\n\n## Citing\n\n> M. Weber, J. Enzinger, H. K. Çakmak, U. Kühnapfel and V. Hagenmeyer, \"PyAPI-RTS: A Python-API for RSCAD Modeling,\" 2023 Open Source Modelling and Simulation of Energy Systems (OSMSES), Aachen, Germany, 2023, pp. 1-7, doi: [10.1109/OSMSES58477.2023.10089671](https://doi.org/10.1109/OSMSES58477.2023.10089671).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pycomlink",
            "repo_link": "https://github.com/pycomlink/pycomlink",
            "readme": "[![CI](https://github.com/pycomlink/pycomlink/actions/workflows/main.yml/badge.svg?branch=master)](https://github.com/pycomlink/pycomlink/actions/workflows/main.yml)\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/pycomlink/pycomlink/master)\n[![Documentation Status](https://readthedocs.org/projects/pycomlink/badge/?version=latest)](https://pycomlink.readthedocs.io/en/latest/)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4810169.svg)](https://doi.org/10.5281/zenodo.4810169)\n\nAnaconda Version [![Anaconda Version](https://anaconda.org/conda-forge/pycomlink/badges/version.svg)](https://anaconda.org/conda-forge/pycomlink) [![Anaconda-Server Badge](https://anaconda.org/conda-forge/pycomlink/badges/latest_release_date.svg)](https://anaconda.org/conda-forge/pycomlink)\n\npycomlink\n=========\n\nA python toolbox for deriving rainfall information from commercial microwave link (CML) data.\n\nInstallation\n------------\n\n`pycomlink` is tested with Python 3.9, 3.10 and 3.11. There have been problems with Python 3.8, see https://github.com/pycomlink/pycomlink/pull/120. Many things might work with older version, but there is no support for this.\n\nIt can be installed via [`conda-forge`](https://conda-forge.org/):\n\n    $ conda install -c conda-forge pycomlink\n\nIf you are new to `conda` or if you are unsure, it is recommended to [create a new conda environment, activate it](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands), [add the conda-forge channel](https://conda-forge.org/) and then install.\n\nInstallation via `pip` is also possible:\n\n    $ pip install pycomlink\n\nAt the time of writing, with `pycomlink v0.4.0` which dropped `tensorflow` as dependency, `pip` install works fine. But, if we add new dependencies in the future, we might again run into issues with `pip` install.\n\nTo run the example notebooks you will also need the [Jupyter Notebook](https://jupyter.org/)\nand `ipython`, both also available via `conda` or `pip`.\n\nIf you want to clone the repository for developing purposes follow these steps (installation of Jupyter Notebook included):\n\n    $ git clone https://github.com/pycomlink/pycomlink.git\n    $ cd pycomlink\n    $ conda env create -f environment_dev.yml\n    $ conda activate pycomlink-dev\n    $ cd ..\n    $ pip install -e pycomlink\n\nUsage\n-----\n\nThe following jupyter notebooks showcase some use cases of `pycomlink`\n\n * [Basic example CML processing workflow](http://nbviewer.jupyter.org/github/pycomlink/pycomlink/blob/master/notebooks/Basic%20CML%20processing%20workflow.ipynb)\n * [Compare interpolation methods](https://nbviewer.org/github/pycomlink/pycomlink/blob/master/notebooks/Compare%20interpolation%20methods.ipynb)\n * [Get radar data along CML paths](https://nbviewer.org/github/pycomlink/pycomlink/blob/master/notebooks/Get%20radar%20rainfall%20along%20CML%20paths.ipynb)\n * [Nearby-link approach for rain event detection from RAINLINK](https://nbviewer.org/github/pycomlink/pycomlink/blob/master/notebooks/Nearby%20link%20approach%20processing%20example.ipynb)\n * [Compare different WAA methods](https://nbviewer.org/github/pycomlink/pycomlink/blob/master/notebooks/Wet%20antenna%20attenuation.ipynb)\n * [Detect data gaps stemming from heavy rainfall events that cause a loss of connection along a CML](https://nbviewer.org/github/pycomlink/pycomlink/blob/master/notebooks/Blackout%20gap%20detection%20examples.ipynb)\n\nNote that the links point to static versions of the example notebooks. You can run all these notebook online via mybinder if you click on the \"launch binder\" buttom at the top.\n\nFeatures\n--------\n\n * Perform all required CML data processing steps to derive rainfall information from raw signal levels:\n    * data sanity checks\n    * ~~anomaly detection~~ (removed because using outdated `tensorflow` code)\n    * wet/dry classification\n    * baseline calculation\n    * wet antenna correction\n    * transformation from attenuation to rain rate\n * Generate rainfall maps from the data of a CML network\n * Validate you results against gridded rainfall data or rain gauges networks\n \nDocumentation\n-------------\nThe documentation is hosted by readthedocs.org: [https://pycomlink.readthedocs.io/en/latest/](https://pycomlink.readthedocs.io/en/latest/)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pygms",
            "repo_link": "https://github.com/cmeessen/pyGMS",
            "readme": "# pyGMS\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n[![DOI](https://zenodo.org/badge/194238991.svg)](https://zenodo.org/badge/latestdoi/194238991)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/50e5df33317949d58e8d7bf7c40a336b)](https://www.codacy.com?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=cmeessen/pyGMS&amp;utm_campaign=Badge_Grade)\n[![Codacy Badge](https://api.codacy.com/project/badge/Coverage/50e5df33317949d58e8d7bf7c40a336b)](https://www.codacy.com?utm_source=github.com&utm_medium=referral&utm_content=cmeessen/pyGMS&utm_campaign=Badge_Coverage)\n\n`pyGMS` is a Python 3 module designed to analyse the rheological behaviour of\nlithosphere-scale 3D structural models that were created with the\n[GeoModellingSystem](https://www.gfz-potsdam.de/en/section/basin-modeling/infrastructure/gms/)\n(GMS, GFZ Potsdam). `pyGMS` was originally written for the\npurpose of plotting yield strength envelope cross sections for my PhD thesis.\n\n## Installation\n\nThis is a short version of the installation instructions. For a more detailed\nversion visit the\n[documentation](https://cmeessen.github.io/pyGMS/installation.html).\n\n```bash\n# Clone the repository\ngit clone git@github.com:cmeessen/pyGMS.git\n\n# Create an Anaconda environment\ncd pyGMS\nconda env create -f environment.yml\n\n# Install with pip\nconda activate pygms\npip install -e .\n\n# Install some dependencies to be able to see the kernel in Jupyter notebooks\nconda install -c conda-forge nb_conda_kernels\n```\n\n## Documentation\n\nPlease have a look at the\n[documentation](https://cmeessen.github.io/pyGMS/index.html) for information\non how to install and use pyGMS.\n\n## Contributing\n\nIf you find bugs, have a feature wish or a pull request, please open an\n[issue](https://github.com/cmeessen/pyGMS/issues).\n\n### Preparing a pull request\n\nBefore preparing a pull request make sure to\n\n- comment the code\n- update CHANGELOG\n- check code style (`make pycodestyle`)\n- add a test if the contribution adds a new feature or fixes a bug\n- update the documentation (`cd docs/sphinx && make html && make gh-pages`)\n- run `make coverage` (maintainers only)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pyquickmaps",
            "repo_link": "https://git.geomar.de/open-source/pyquickmaps",
            "readme": "# Overview\n*PyQuickMaps* is a slim python library to link (seafloor) maps and sampling data with prediction methods. Can do interpolation (with scipy.interpolate.griddata), kriging (with pykrige) and random forest regression (with sklearn.ensemble.RandomForestRegressor). Also features plotting nice geographical maps with matplotlib and storing to geotiff with rasterio. Coordinate transforms are managed internally with osgeo/gdal.\n\n## License\nPyQuickMaps is released under LGPLv3.\n\n## Contact\nDr. Timm Schoening\nDeepSea Monitoring Group\nGEOMAR Helmholtz Centre for Ocean Research Kiel\ntschoening@geomar.de\n",
            "project_id": "2825"
        },
        {
            "software_organization": "https://helmholtz.software/software/pysdc",
            "repo_link": "https://github.com/Parallel-in-Time/pySDC",
            "readme": "[![badge-ga](https://github.com/Parallel-in-Time/pySDC/actions/workflows/ci_pipeline.yml/badge.svg?branch=master)](https://github.com/Parallel-in-Time/pySDC/actions/workflows/ci_pipeline.yml)\n[![badge-ossf](https://bestpractices.coreinfrastructure.org/projects/6909/badge)](https://bestpractices.coreinfrastructure.org/projects/6909)\n[![badge-cc](https://codecov.io/gh/Parallel-in-Time/pySDC/branch/master/graph/badge.svg?token=hpP18dmtgS)](https://codecov.io/gh/Parallel-in-Time/pySDC)\n[![zenodo](https://zenodo.org/badge/26165004.svg)](https://zenodo.org/badge/latestdoi/26165004)\n[![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F-green)](https://fair-software.eu)\n[![SQAaaS badge shields.io](https://img.shields.io/badge/sqaaas%20software-silver-lightgrey)](https://api.eu.badgr.io/public/assertions/aS8J0NDTTjCyYP6iVufviQ \"SQAaaS silver badge achieved\")\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/pySDC?logo=pypi)](https://pypistats.org/packages/pysdc)\n\n# Welcome to pySDC!\n\nThe `pySDC` project is a Python implementation of the\nspectral deferred correction (SDC) approach and its flavors, esp. the\nmultilevel extension MLSDC and PFASST. It is intended for rapid\nprototyping and educational purposes. New ideas like e.g. sweepers or\npredictors can be tested and first toy problems can be easily\nimplemented.\n\n## Features\n\n-   Variants of SDC: explicit, implicit, IMEX, multi-implicit, Verlet,\n    multi-level, diagonal, multi-step\n-   Variants of PFASST: virtual parallel or MPI-based parallel,\n    classical of multigrid perspective\n-   8 tutorials: from setting up a first collocation problem to SDC,\n    PFASST and advanced topics\n-   Projects: many documented projects with defined and tested outcomes\n-   Many different examples, collocation types, data types already\n    implemented\n-   Works with [FEniCS](https://fenicsproject.org/),\n    [mpi4py-fft](https://mpi4py-fft.readthedocs.io/en/latest/) and\n    [PETSc](http://www.mcs.anl.gov/petsc/) (through\n    [petsc4py](https://bitbucket.org/petsc/petsc4py))\n-   Continuous integration via [GitHub\n    Actions](https://github.com/Parallel-in-Time/pySDC/actions) and\n    [Gitlab CI](https://gitlab.hzdr.de/r.speck/pysdc/-/pipelines) (through the [GitHub2Gitlab Action](https://github.com/jakob-fritz/github2lab_action))\n-   Fully compatible with Python 3.9 - 3.12, runs at least on Ubuntu\n\n## Getting started\n\nThe code is hosted on GitHub, see\n<https://github.com/Parallel-in-Time/pySDC>, and PyPI, see\n<https://pypi.python.org/pypi/pySDC>. While using `pip install pySDC`\nwill give you a core version of `pySDC` to work with,\nworking with the developer version is most often the better choice. We\nthus recommend to checkout the code from GitHub and install the\ndependencies e.g. by using a [conda](https://conda.io/en/latest/)\nenvironment. For this, `pySDC` ships with environment files\nwhich can be found in the folder `etc/`. Use these as e.g.\n\n``` bash\nconda env create -f etc/environment-base.yml\n```\n\nIf you want to install the developer version using `pip` directly from the GitHub repository, use this:\n\n```\n# optionally use venv\npython3 -m venv name_of_pySDC_env\n. ./name_of_pySDC_env/bin/activate\n# drop @5.5.0 if you want to install the develop version\npip install git+https://github.com/Parallel-in-Time/pySDC@5.5.0\n```\n\nTo check your installation, run\n\n``` bash\npytest pySDC/tests -m NAME\n```\n\nwhere `NAME` corresponds to the environment you chose (`base` in the\nexample above). You may need to update your `PYTHONPATH` by running\n\n``` bash\nexport PYTHONPATH=$PYTHONPATH:/path/to/pySDC/root/folder\n```\n\nin particular if you want to run any of the playgrounds, projects or\ntutorials. All `import` statements there assume that the\n`pySDC`\\'s base directory is part of `PYTHONPATH`.\n\nFor many examples, `LaTeX` is used for the plots, i.e. a\ndecent installation of this is needed in order to run those examples.\nWhen using `fenics` or `petsc4py`, a C++\ncompiler is required (although installation may go through at first).\n\nFor more details on `pySDC`, check out http://www.parallel-in-time.org/pySDC.\n\n## How to cite\n\nIf you use pySDC or parts of it for your work, great! Let us know if we\ncan help you with this. Also, we would greatly appreciate a citation of\n[this paper](https://doi.org/10.1145/3310410):\n\n> Robert Speck, **Algorithm 997: pySDC - Prototyping Spectral Deferred\n> Corrections**, ACM Transactions on Mathematical Software (TOMS),\n> Volume 45 Issue 3, August 2019, <https://doi.org/10.1145/3310410>\n\nThe current software release can be cited using Zenodo:\n[![zenodo](https://zenodo.org/badge/26165004.svg)](https://zenodo.org/badge/latestdoi/26165004)\n\n## Contributing\n\n`pySDC` code was originally developed by [Robert Speck (@pancetta)](https://github.com/pancetta),\nand is now maintained and developed by a small community of scientists interested in SDC methods.\nCheckout the [Changelog](./CHANGELOG.md) to see pySDC's evolution since 2016. It has a\nsoftware management plan (SWP), too, see [here](https://smw.dsw.elixir-europe.org/wizard/projects/c3dda921-b7b0-4f4d-b5dc-778b9780552d).\n\nAny contribution is dearly welcome! If you want to contribute, please take the time to read our [Contribution Guidelines](./CONTRIBUTING.md)\n(and don't forget to take a peek at our nice [Code of Conduct](./CODE_OF_CONDUCT.md) :wink:).\n\n## Acknowledgements\n\nThis project has received funding from the [European High-Performance\nComputing Joint Undertaking](https://eurohpc-ju.europa.eu/) (JU) under\ngrant agreement No 955701 ([TIME-X](https://www.time-x-eurohpc.eu/))\nand grant agreement No 101118139.\nThe JU receives support from the European Union's Horizon 2020 research\nand innovation programme and Belgium, France, Germany, and Switzerland.\nThis project also received funding from the [German Federal Ministry of\nEducation and Research](https://www.bmbf.de/bmbf/en/home/home_node.html)\n(BMBF) grants  16HPC047 and 16ME0679K. Supported by the European Union - NextGenerationEU. \nThe project also received help from the [Helmholtz Platform for Research Software Engineering - Preparatory Study (HiRSE_PS)](https://www.helmholtz-hirse.de/).\n\n<p align=\"center\">\n  <img src=\"./docs/img/EuroHPC.jpg\" height=\"105\"/> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <img src=\"./docs/img/LogoTime-X.png\" height=\"105\" /> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n  <img src=\"./docs/img/BMBF_gefoerdert_2017_en.jpg\" height=\"105\" />\n</p>\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/python-icat",
            "repo_link": "https://github.com/icatproject/python-icat",
            "readme": "|doi| |rtd| |pypi|\n\n.. |doi| image:: https://zenodo.org/badge/37250056.svg\n   :target: https://zenodo.org/badge/latestdoi/37250056\n\n.. |rtd| image:: https://img.shields.io/readthedocs/python-icat/latest\n   :target: https://python-icat.readthedocs.io/en/latest/\n   :alt: Documentation build status\n\n.. |pypi| image:: https://img.shields.io/pypi/v/python-icat\n   :target: https://pypi.org/project/python-icat/\n   :alt: PyPI version\n\npython-icat – Python interface to ICAT and IDS\n==============================================\n\nThis package provides a collection of modules for writing Python\nprograms that access an `ICAT`_ service using the SOAP interface.  It\nis based on Suds and extends it with ICAT specific features.\n\nDownload\n--------\n\nThe latest release version can be found at the\n`release page on GitHub`__.\n\n.. __: `GitHub release`_\n\n\nDocumentation\n-------------\n\nSee the `online documentation`__.\n\nExample scripts can be found in doc/examples.  This is mostly an\nunsorted collection of test scripts that I initially wrote for myself\nto try things out.\n\nAlmost all scripts use example_data.yaml as input for test data.  Of\ncourse for real production, the input will come from different\nsources, out of some workflow from the site.  But this would be\ndynamic and site specific and thus not suitable, neither for testing\nnor for the inclusion into example scripts.  So its easier to have\njust one blob of dummy input data in one single file.  That is also\nthe reason why the example scripts require PyYAML.\n\n.. __: `Read the Docs site`_\n\n\nCopyright and License\n---------------------\n\nCopyright 2013–2024\nHelmholtz-Zentrum Berlin für Materialien und Energie GmbH\n\nLicensed under the `Apache License`_, Version 2.0 (the \"License\"); you\nmay not use this file except in compliance with the License.\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\nimplied.  See the License for the specific language governing\npermissions and limitations under the License.\n\n\n.. _ICAT: https://icatproject.org/\n.. _GitHub release: https://github.com/icatproject/python-icat/releases/latest\n.. _Read the Docs site: https://python-icat.readthedocs.io/\n.. _Apache License: https://www.apache.org/licenses/LICENSE-2.0\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/pyxmake",
            "repo_link": "https://gitlab.com/dlr-sy/pyxmake",
            "readme": "[![PyPi](https://img.shields.io/pypi/v/pyx-core?label=PyPi)](https://pypi.org/project/pyx-core)\n[![doi](https://img.shields.io/badge/DOI-10.5281%2Fzenodo.13352143-red.svg)](https://zenodo.org/records/13352143)\n\n# PyXMake\n> This subpackage belongs to [PyXMake](https://gitlab.com/dlr-sy/pyxmake) and contains all core functionalities. It is installed automatically with the parent project. However, it is also separately available as a build system dependency. Please refer to the linked [repository](https://gitlab.com/dlr-sy/pyxmake) for documentation and application examples.\n\n## Downloading\nUse GIT to get the latest code base. From the command line, use\n```\ngit clone https://gitlab.dlr.de/dlr-sy/pyxmake pyxmake\n```\nIf you check out the repository for the first time, you have to initialize all submodule dependencies first. Execute the following from within the repository. \n```\ngit submodule update --init --recursive\n```\nTo update all refererenced submodules to the latest production level, use\n```\ngit submodule foreach --recursive 'git pull origin $(git config -f $toplevel/.gitmodules submodule.$name.branch || echo master)'\n```\n## Installation\nPyXMake can be installed from source using [poetry](https://python-poetry.org). If you don't have [poetry](https://python-poetry.org) installed, run\n```\npip install poetry --pre --upgrade\n```\nto install the latest version of [poetry](https://python-poetry.org) within your python environment. Use\n```\npoetry update\n```\nto update all dependencies in the lock file or directly execute\n```\npoetry install\n```\nto install all dependencies from the lock file. Last, you should be able to import PyXMake as a python package.\n```python\nimport PyXMake\n```\n## Contact\n* [Marc Garbade](mailto:marc.garbade@dlr.de)",
            "project_id": "60958920"
        },
        {
            "software_organization": "https://helmholtz.software/software/quast",
            "repo_link": "https://github.com/ablab/quast/",
            "readme": "[![GitHub release (latest by date)](https://img.shields.io/github/v/release/ablab/quast)](https://github.com/ablab/quast/releases/)\n[![BioConda Install](https://img.shields.io/conda/dn/bioconda/quast.svg?style=flag&label=BioConda%20install)](https://anaconda.org/bioconda/quast)\n[![SourceForge Download QUAST](https://img.shields.io/sourceforge/dt/quast.svg?style=flag&label=SourceForge%20download)](https://sourceforge.net/projects/quast/files/latest/download)\n[![PyPI version](https://badge.fury.io/py/quast.svg)](https://badge.fury.io/py/quast)\n[![GitHub Downloads](https://img.shields.io/github/downloads/ablab/quast/total.svg?style=social&logo=github&label=Download)](https://github.com/ablab/quast/releases)\n[![License](https://img.shields.io/badge/licence-GPLv2-blue)](https://www.gnu.org/licenses/old-licenses/gpl-2.0)\n\n<img src=\"quast_libs/html_saver/static/img/quast_logo_black.png\" width=\"300\" title=\"QUAST\">\n\n### Genome assembly evaluation tool\n\nQUAST stands for QUality ASsessment Tool. It evaluates genome/metagenome assemblies by computing various metrics.\nThe current QUAST toolkit includes the general QUAST tool for genome assemblies, \nMetaQUAST, the extension for metagenomic datasets, \nQUAST-LG, the extension for large genomes (e.g., mammalians), and Icarus, the interactive visualizer for these tools.\n\nThe QUAST package works both with and without reference genomes. \nHowever, it is much more informative if at least a close reference genome is provided along with the assemblies.\nThe tool accepts multiple assemblies, thus is suitable for comparison.\n\nThis README file gives a brief introduction into installation, basic usage and parsing of output of QUAST. \nA much more detailed description of these and many other topics is available in the\n[online manual](http://quast.sf.net/manual.html). \nThere are also many more installation methods for the latest stable release of the QUAST toolkit, \nall of them are discussed [here](http://quast.sf.net/install.html). For the cutting-edge version, \nplease clone our [GitHub repo](https://github.com/ablab/quast).\n\nThe [Gurevich Lab](https://helmholtz-hips.de/en/hmsb) at the [Helmholtz Institute for Pharmaceutical Research Saarland (HIPS)](https://helmholtz-hips.de/en/) \ncurrently maintains and develops the tool. For copyright information and citation instructions, \nplease refer to [LICENSE.txt](LICENSE.txt). We warmly welcome external contributions to the QUAST project. \nIf you would like to contribute, please review our [Contributor Covenant](CODE_OF_CONDUCT.md).\n\n#### System requirements\n\nLinux 64-bit and macOS are supported.\n\nFor the main pipeline:\n- Python3 (3.3 or higher)\n- Perl 5.6.0 or higher\n- GCC 4.7 or higher\n- GNU make and ar\n- zlib development files\n\nFor the optional submodules:\n- Time::HiRes perl module for GeneMark-ES (needed when using `--gene-finding --eukaryote`)\n- Java 1.8 or later for GRIDSS (needed for the structural variation detection)\n- R for GRIDSS (needed for the structural variation detection)\n\nMost of those tools are usually preinstalled on Linux. MacOS, however, requires to install\nthe Command Line Tools for Xcode to make them available. \n\nQUAST draws plots in two formats: HTML and PDF. If you need the PDF versions, make sure that you have installed \n[Matplotlib](https://matplotlib.org/). We recommend to use Matplotlib version 1.1 or higher. QUAST is fully tested with Matplotlib v.1.3.1.\nInstallation on Ubuntu (tested on Ubuntu 20.04):\n\n    sudo apt-get update && sudo apt-get install -y pkg-config libfreetype6-dev libpng-dev python3-matplotlib\n\n#### Installation\n\nQUAST automatically compiles all its sub-parts when needed (on the first use). \nThus, installation is not required. However, if you want to precompile everything and add quast.py to your `PATH`, you may choose either:\n\nBasic installation (about 120 MB):\n\n    ./setup.py install\n\nFull installation (about 540 MB, includes (1) tools for SV detection based on read pairs, which is used for more precise misassembly detection, \n(2) and tools/data for reference genome detection in metagenomic datasets):\n\n    ./setup.py install_full\n\nThe default installation location is `/usr/local/bin/` for the executable scripts, and `/usr/local/lib/` for \nthe python modules and auxiliary files. If you are getting a permission error during the installation, consider running setup.py with\n`sudo`, or create a virtual python environment and [install into it](http://docs.python-guide.org/en/latest/dev/virtualenvs/). \nAlternatively, you may use old-style installation scripts (`./install.sh` or `./install_full.sh`), which build QUAST package inplace.\n\n#### Usage\n\n    ./quast.py test_data/contigs_1.fasta \\\n               test_data/contigs_2.fasta \\\n            -r test_data/reference.fasta.gz \\\n            -g test_data/genes.txt \\\n            -1 test_data/reads1.fastq.gz -2 test_data/reads2.fastq.gz \\\n            -o quast_test_output\n\n#### Output\n\n    report.txt      summary table\n    report.tsv      tab-separated version, for parsing, or for spreadsheets (Google Docs, Excel, etc)  \n    report.tex      Latex version\n    report.pdf      PDF version, includes all tables and plots for some statistics\n    report.html     everything in an interactive HTML file\n    icarus.html     Icarus main menu with links to interactive viewers\n    contigs_reports/        [only if a reference genome is provided]\n      misassemblies_report  detailed report on misassemblies\n      unaligned_report      detailed report on unaligned and partially unaligned contigs\n    k_mer_stats/            [only if --k-mer-stats is specified]\n      kmers_report          detailed report on k-mer-based metrics\n    reads_stats/            [only if reads are provided]\n      reads_report          detailed report on mapped reads statistics\n\nMetrics based only on contigs:\n\n* Number of large contigs (i.e., longer than 500 bp) and total length of them.  \n* Length of the largest contig.  \n* N50 (length of a contig, such that all the contigs of at least the same length together cover at least 50% of the assembly).\n* Number of predicted genes, discovered either by GeneMark.hmm (for prokaryotes), GeneMark-ES or GlimmerHMM (for eukaryotes), \nor MetaGeneMark (for metagenomes).\n\nWhen a reference is given:\n\n* Numbers of misassemblies of different kinds (inversions, relocations, translocations, interspecies translocations (metaQUAST only) or local).\n* Number and total length of unaligned contigs.  \n* Numbers of mismatches and indels, over the assembly and per 100 kb.  \n* Genome fraction %, assembled part of the reference.  \n* Duplication ratio, the total number of aligned bases in the assembly divided by the total number of those in the reference. \nIf the assembly contains many contigs that cover the same regions, its duplication ratio will significantly exceed 1. \nThis occurs due to multiple reasons, including overestimating repeat multiplicities and overlaps between contigs.  \n* Number of genes in the assembly, completely or partially covered, based on a user-provided list of gene positions in the reference.  \n* NGA50, a reference-aware version of N50 metric. It is calculated using aligned blocks instead of contigs. \nSuch blocks are obtained after removing unaligned regions, and then splitting contigs at misassembly breakpoints. \nThus, NGA50 is the length of a block, such that all the blocks of at least the same length together cover at least 50% of the reference.  \n\n\n#### Contact & Info \n\n* Support email: [alexey.gurevich@helmholtz-hips.de](alexey.gurevich@helmholtz-hips.de)\n* Issue tracker: [https://github.com/ablab/quast/issues](https://github.com/ablab/quast/issues)\n* Website: [http://quast.sf.net](http://quast.sf.net)\n* Latest news: [https://x.com/quast_bioinf](https://x.com/quast_bioinf)\n    \n"
        },
        {
            "software_organization": "https://helmholtz.software/software/radiative-forcing-of-hypersonic-aircraft-trajectories",
            "repo_link": "https://github.com/johannespletzer/rf-of-hypersonic-trajectories/",
            "readme": "# Radiative forcing of hypersonic aircraft emission inventories\nThe software quantifies climate impact of hypersonic aircraft emission inventories as a number and within seconds instead of very long numerical simulations that produce Petabytes of data. The input requires water vapor, hydrogen and nitrogen oxide emission data along flight trajectories.\nThe repository provides a Python package, examples and an executable to calculate the climate impact (stratosphere adjusted radiative forcing) of hypersonic aircraft emission inventories. The radiative forcing of water vapour changes and ozone changes are calculated on the basis of water vapour, hydrogen and nitrogen oxide emissions. The current version is able to read in mat- and nc-files. NetCDF read in is currently optimised for data published online, e.g. for the aircraft design [STRATOFLY-MR3](https://zenodo.org/records/10818082).\n\nLatest software release: [![DOI](https://zenodo.org/badge/518852238.svg)](https://zenodo.org/badge/latestdoi/518852238)\n\n# Limitations\nInterpolation (30-38 km) and extrapolation surface-30 km are used. It is recommended to note the following:\n- The atmospheric and radiative sensitivites are based on results from [Pletzer et al (2024)](https://acp.copernicus.org/articles/24/1743/2024/). The atmospheric composition of the numerical climate model is based on surface emission inventories for 2050. \n- The class includes a function (`drop_vertical_levels()`) that drops emission in the troposphere or below specified altitude levels and excludes it from the climate calculation. Its use is strongly recommended as long as sensitivities are not yet extended to altitudes below 30 km.\n- The climate impact of emission inventories where the average flight altitude does not correspond to the typical hypersonic flight altitudes (about 24-40 km) should not be estimated.\n- Meaningful results can be expected for the radiative effect of water vapour changes due to water vapour emissions. This explicitly excludes the radiative effect of water vapour changes due to hydrogen and nitrogen oxide emissions.\n- Meaningful results can be expected for the radiative effect of ozone changes due to water vapour, hydrogen and nitrogen oxide emissions.\n\nPlease keep these limitations in mind when using the software.\n\n# Python environment requirements\nThe software requires various functions from the following python modules:\n\n- numpy\n- pandas\n- xarray\n- scipy\n- xlsxwriter\n- netcdf4\n- aerocalc3\n\nInstall the required packages with `pip install numpy pandas xarray scipy xlsxwriter netcdf4 aerocalc3`.\n\n# Getting started\nThe repo contains two example notebooks for processing of emission inventories in mat- and nc-format. Otherwise, the user can run the main.py executable which reads all emission inventory files within the folder and returns the calculated radiative forcing in an xlsx file. Execute main.py with `python3 main.py <path_to_your_emission_files>`. Please contact Johannes Pletzer for any questions.\n\n# Code quality\nThe code was formatted according to PEP 8 style with the help of the modules 'flake8', 'isort', 'pylint' and 'black'.\n\n# Acknowledgements\nDaniel Bodmer contributed with validation of model results by offering current state of the art hypersonic aircraft emission inventories on trajectory and route network level: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10818082.svg)](https://doi.org/10.5281/zenodo.10818082)\n\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/radplanbio",
            "repo_link": "https://github.com/ddRPB/rpb",
            "readme": "# ddRPB\n\n## Radiotherapy clinical research IT infrastructure\n\nRadiationDosePlan- Image/Biomarker-Outcome-platform (RPB) is a collection of open source software systems integrated via portal to deliver a core software infrastructure necessary to support the operation of non-commercial trials unit.\n\nThe RPB platform is a web-based solution which supports collection and exchange of radiotherapy specific research data in large scale multi-centre clinical and pre-clinical studies. It delivers a study management and electronic data capture system with special extensions dedicated to secure upload of medical imaging and treatment plans in DICOM format. These tools allow the trial personnel to handle multi-modal data conduction activities that yield to finalised patient cohort datasets.\n\n## Platform features\n\n* Managing multi-centre clinical trials\n* Patient identity management and pseudonymisation\n* Study subject randomisation (permuted block + strata)\n* Electronic case report forms (eCRFs) for clinical data collection\n* Patient reported outcomes (ePRO)\n* Linked medical imaging (DICOM) and treatment plans (DICOM-RT)\n* DICOM data de-identification and RTSTRUCT ROI naming harmonisation\n* DICOM viewer with DICOM-RT plugin\n* WebDAV access to DICOM data collected in particular project\n* Storage for laboratory assays and other tabulated data\n\n## Acknowledgment\n\nFor people who do use the RPB software platform as managed or self-operated solution supporting the conduction of their trials, when it is possible, we would appreciate your acknowledgement in publications and citation of the relevant papers:\n\n* \"This work was conducted in part using the RadPlanBio software platform.\"           \n\n```\n@article{skripcak_toward_2016,\n    title = {Toward {Distributed} {Conduction} of {Large}-{Scale} {Studies} in {Radiation} {Therapy} and {Oncology}: {Open}-{Source} {System} {Integration} {Approach}},\n    volume = {20},\n    issn = {2168-2194, 2168-2208},\n    shorttitle = {Toward {Distributed} {Conduction} of {Large}-{Scale} {Studies} in {Radiation} {Therapy} and {Oncology}},\n    url = {http://ieeexplore.ieee.org/document/7138574/},\n    doi = {10.1109/JBHI.2015.2450833},\n    number = {5},\n    urldate = {2017-12-08},\n    journal = {IEEE Journal of Biomedical and Health Informatics},\n    author = {Skripcak, Tomas and Just, Uwe and Simon, Monique and Buttner, Daniel and Luhr, Armin and Baumann, Michael and Krause, Mechthild},\n    month = sep,\n    year = {2016},\n    pages = {1397--1403}\n}\n```\nNote: In case RPB managed service utilisation (such as dedicated Institute/Department operating RPB platform instance used by others) additional acknowledgements/citations usually defined by service provider may apply.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/rafcon",
            "repo_link": "https://github.com/DLR-RM/RAFCON",
            "readme": "\nRAFCON\n======\n\n.. figure:: documents/assets/Screenshot_Drill_Skill_Scaled.png\n   :figwidth: 100%\n   :width: 800px\n   :align: left\n   :alt: Screenshot showing RAFCON with a big state machine\n   :target: documents/assets/Screenshot_Drill_Skill_Scaled.png?raw=true\n\n* Documentation: Hosted on `Read the Docs <http://rafcon.readthedocs.io/en/latest/>`_\n* Homepage: `DLR-RM.github.io/RAFCON/ <https://dlr-rm.github.io/RAFCON/>`_\n* License: `EPL <https://github.com/DLR-RM/RAFCON/blob/master/LICENSE>`_\n\nDevelop your robotic tasks using an intuitive graphical user interface\n----------------------------------------------------------------------\n\nRAFCON uses hierarchical state machines, featuring concurrent state execution, to represent robot programs.\nIt ships with a graphical user interface supporting the creation of state machines and\ncontains IDE like debugging mechanisms. Alternatively, state machines can programmatically be generated\nusing RAFCON's API.\n\nUniversal application\n\n  RAFCON is written in Python, can be extended with plugins and is hard- and middleware independent.\n\nVisual programming\n\n  The sophisticated graphical editor can be used for the creation, execution and debugging of state machines.\n\nCollaborative working\n\n  Share and reuse your state machines in form of libraries, stored as JSON strings in text files.\n\n.. figure:: https://raw.githubusercontent.com/DLR-RM/RAFCON/master/documents/assets/RAFCON-sm-creation-preview.gif\n   :figwidth: 100%\n   :width: 570px\n   :align: left\n   :alt: Example on how to create a simple state machine\n\n\nInstallation preparations\n-------------------------\n\nBefore installing RAFCON, Python >=3.7, pip and setuptools are required on your system. Most of the other dependencies\nare automatically resolved by pip/setuptools, but not all of them. Those need be be installed manually, too:\n\nInstallation requirements\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n.. code-block:: bash\n\n   sudo apt-get install python-dev python-pip build-essential glade python-gi-cairo\n   sudo -H pip install --upgrade pip\n   sudo -H pip install --upgrade setuptools\n\nGeneral requirements\n^^^^^^^^^^^^^^^^^^^^\n\n* Python >=3.7\n* pip (recent version required: v23 known to be working)\n* pdm (recent version required: v2.9.3 known to be working)\n\n\nInstalling RAFCON\n-----------------\n\n.. code-block:: bash\n\n   pip install rafcon --user\n\nThe ``--user`` flag is optional. If not set, RAFCON is installed globally (in this case you normaly need to have root privileges).\n\nIf during the installation the error ``ImportError: No module named cairo`` occurs, please install pycairo directly\nvia:\n\n.. code-block:: bash\n\n   pip install --user \"pycairo==1.19.1\"\n\nOf course you can also directly use the RAFCON sources from GitHub.\n\n.. code-block:: bash\n\n   cd /install/directory\n   git clone https://github.com/DLR-RM/RAFCON rafcon\n\n\nStart RAFCON\n------------\n\nNo matter which installation option you choose, RAFCON can be started from any location using (make sure\n``/usr/local/bin`` or ``~/.local/bin`` is in your ``PATH`` environment variable):\n\n.. code-block:: bash\n\n   rafcon\n\nOn a multi-python setup start rafcon using:\n\n.. code-block:: bash\n\n   python<your-version> -m rafcon\n\n\nUninstallation\n--------------\n\nIf you want to uninstall RAFCON, all you need to do is call\n\n.. code-block:: bash\n\n   pip uninstall rafcon\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/random-simplex",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/Random-Simplex",
            "readme": "![MATLAB](https://img.shields.io/badge/MATLAB-%23D00000.svg?style=plastic&logo=mathworks&logoColor=white)   ![Fortran](https://img.shields.io/badge/Fortran-%23734F96.svg?style=plastic&logo=fortran&logoColor=white) ![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/random-simplex?style=plastic)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12808899.svg)](https://doi.org/10.5281/zenodo.12808899)\n\n\n# Random Simplex Matrix\n\n## Overview\n\nThis repository contains a function that utilises the Dirichlet distribution method to generate points on the `(n−1)`-dimensional simplex. The `randomSimplexMatrix.m` generates `m x n` matrices where each row is a random sample from the `(n−1)`-dimensional simplex, i.e., it produces vectors where each element is a non-negative number and the sum of all elements in each vector is 1.\n\n### About\n\n[Mathematica Link](https://reference.wolfram.com/language/ref/Simplex.html)\n\n## Methodology\n\n1. **Generation of K Unit-Exponential Distributed Random Draws**:\n    - In each row (sample), the function generates K uniform random numbers `y_i` from the open interval `(0,1]`.\n    - These are transformed to unit-exponential distributed random numbers `x_i = -log(y_i)`.\n\n2. **Normalization**:\n    - Compute the sum `S` of all `x_i` values.\n\n3. **Calculation of Simplex Coordinates**:\n    - The coordinates `t_1, ..., t_K` of the final point on the unit simplex are computed as `t_i = x_i / S`.\n\n4. **Output**:\n    - Returns a matrix, where each row is a vector on the `(n-1)`-dimensional simplex.\n\n\n## Some Applications\n\n#### Stability Analysis\n\n- Polynomial Stability/Stability of discrete-time control systems: \n\n    > Use simplex sampling to generate coefficients for polynomials and analyse their stability by checking if all roots lie within the unit circle.\n\n- Lyapunov Functions: \n\n    > Construct Lyapunov functions with randomly sampled coefficients to study the stability of equilibrium points in dynamical systems.\n\n#### Bifurcation Analysis\n\n- Parameter Space Exploration:\n\n    > Investigate the behavior of dynamical systems under different parameter regimes by sampling parameters from a simplex. Identify bifurcation points where system behavior changes qualitatively.\n\n- Nonlinear Dynamics: \n\n    > Model/simulate nonlinear systems to study chaos, where initial conditions or parameters are sampled from a simplex.\n\n## Additional Scripts\n\n1. `simplexSpace.m`\n\n   > Demonstrates various plots and visualisations of simplex sampling.\n\n2. `MultivariateND.m`\n\n   > Showcases an application of simplex sampling for sampling from a multivariate normal distribution.\n\n3. `VoronoiDiagram.m`\n\n   > Visualise the Voronoi diagram of random points on a 2-dimensional simplex, divides regions based on proximity.\n\n\n## Example Usage\n\n```matlab\nn = 100;  % Number of columns (dimensionality of simplex)\nm = 1500;  % Number of rows (number of samples)\ny = randomSimplexMatrix(n, m);\ndisp('Generated simplex matrix:');\ndisp(y);\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/rankings-reloaded",
            "repo_link": "https://github.com/wiesenfa/challengeR",
            "readme": "Methods and open-source toolkit for analyzing and visualizing challenge\nresults\n================\n\n-   [Introduction](#introduction)\n-   [Installation](#installation)\n-   [Terms of use](#terms-of-use)\n-   [Usage](#usage)\n-   [Troubleshooting](#troubleshooting)\n-   [Changes](#changes)\n-   [Team](#team)\n-   [Reference](#reference)\n\n# Introduction\n\nThe current framework is a tool for analyzing and visualizing challenge\nresults in the field of biomedical image analysis and beyond.\n\nBiomedical challenges have become the de facto standard for benchmarking\nbiomedical image analysis algorithms. While the number of challenges is\nsteadily increasing, surprisingly little effort has been invested in\nensuring high quality design, execution and reporting for these\ninternational competitions. Specifically, results analysis and\nvisualization in the event of uncertainties have been given almost no\nattention in the literature.\n\nGiven these shortcomings, the current framework aims to enable fast and\nwide adoption of comprehensively analyzing and visualizing the results\nof single-task and multi-task challenges. This approach offers an\nintuitive way to gain important insights into the relative and absolute\nperformance of algorithms, which cannot be revealed by commonly applied\nvisualization techniques.\n\n# Installation\n\nRequires R version &gt;= 3.5.2 (<https://www.r-project.org>).\n\nFurther, a recent version of Pandoc (&gt;= 1.12.3) is required. RStudio\n(<https://rstudio.com>) automatically includes this so you do not need\nto download Pandoc if you plan to use rmarkdown from the RStudio IDE,\notherwise you’ll need to install Pandoc for your platform\n(<https://pandoc.org/installing.html>). Finally, if you want to generate\na PDF report you will need to have LaTeX installed (e.g. MiKTeX, MacTeX\nor TinyTeX).\n\nTo get the latest released version (master branch) of the R package from\nGitHub:\n\n``` r\nif (!requireNamespace(\"devtools\", quietly = TRUE)) install.packages(\"devtools\")\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\")\nBiocManager::install(\"Rgraphviz\", dependencies = TRUE)\ndevtools::install_github(\"wiesenfa/challengeR\", dependencies = TRUE)\n```\n\nIf you are asked whether you want to update installed packages and you\ntype “a” for all, you might need administrator permissions to update R\ncore packages. You can also try to type “n” for updating no packages. If\nyou are asked “Do you want to install from sources the packages which\nneed compilation? (Yes/no/cancel)”, you can safely type “no”.\n\nIf you get *warning* messages (in contrast to *error* messages), these\nmight not be problematic and you can try to proceed. If you encounter\nerrors during the setup, looking into the “Troubleshooting” section\nmight be worth it.\n\nFor Linux users: Some system libraries might be missing. Check the\noutput in the R console for further hints carefully during the\ninstallation of packages.\n\n# Terms of use\n\nCopyright (c) German Cancer Research Center (DKFZ). All rights reserved.\n\nchallengeR is available under license GPLv2 or any later version.\n\nIf you use this software for a publication, please cite:\n\nWiesenfarth, M., Reinke, A., Landman, B.A., Eisenmann, M., Aguilera\nSaiz, L., Cardoso, M.J., Maier-Hein, L. and Kopp-Schneider, A. Methods\nand open-source toolkit for analyzing and visualizing challenge results.\n*Sci Rep* **11**, 2369 (2021).\n<https://doi.org/10.1038/s41598-021-82017-6>\n\n# Usage\n\nEach of the following steps has to be run to generate the report: (1)\nLoad package, (2) load data, (3) perform ranking, (4) perform\nbootstrapping and (5) generation of the report\n\nYou can find R scripts for quickstart in the directory “vignettes”. An\noverview of all available plots is provided in the “Visualizations”\nvignette demonstrating the use of their corresponding plot functions as\nwell.\n\nHere, we provide a step-by-step guide that leads you to your final\nreport.\n\n## 1. Load package\n\nLoad package\n\n``` r\nlibrary(challengeR)\n```\n\n## 2. Load data\n\n### Data requirements\n\nData requires the following *columns*:\n\n-   *task identifier* in case of multi-task challenges (string or\n    numeric)\n-   *test case identifier* (string or numeric)\n-   *algorithm identifier* (string or numeric)\n-   *metric value* (numeric)\n\nIn case of missing metric values, a missing observation has to be\nprovided (either as blank field or “NA”).\n\nFor example, in a challenge with 2 tasks, 2 test cases and 2 algorithms,\nwhere in task “T2”, test case “case2”, algorithm “A2” didn’t give a\nprediction (and thus NA or a blank field for missing value is inserted),\nthe data set might look like this:\n\n| Task | TestCase | Algorithm | MetricValue |\n|:-----|:---------|:----------|------------:|\n| T1   | case1    | A1        |       0.266 |\n| T1   | case1    | A2        |       0.202 |\n| T1   | case2    | A1        |       0.573 |\n| T1   | case2    | A2        |       0.945 |\n| T2   | case1    | A1        |       0.372 |\n| T2   | case1    | A2        |       0.898 |\n| T2   | case2    | A1        |       0.908 |\n| T2   | case2    | A2        |          NA |\n\n### 2.1 Load data from file\n\nIf you have assessment data at hand stored in a csv file (if you want to\nuse simulated data, skip the following code line) use\n\n``` r\ndata_matrix <- read.csv(file.choose()) # type ?read.csv for help\n```\n\nThis allows to choose a file interactively, otherwise replace\n*file.choose()* by the file path (in style “/path/to/dataset.csv”) in\nquotation marks.\n\n### 2.2 Simulate data\n\nIn the following, simulated data is generated *instead* for illustration\npurposes (skip the following code chunk if you have already loaded\ndata). The data is also stored as “inst/extdata/data\\_matrix.csv” in the\nrepository.\n\n``` r\nif (!requireNamespace(\"permute\", quietly = TRUE)) install.packages(\"permute\")\n\nn <- 50\n\nset.seed(4)\nstrip <- runif(n,.9,1)\nc_ideal <- cbind(task=\"c_ideal\",\n            rbind(\n              data.frame(alg_name=\"A1\",value=runif(n,.9,1),case=1:n),\n              data.frame(alg_name=\"A2\",value=runif(n,.8,.89),case=1:n),\n              data.frame(alg_name=\"A3\",value=runif(n,.7,.79),case=1:n),\n              data.frame(alg_name=\"A4\",value=runif(n,.6,.69),case=1:n),\n              data.frame(alg_name=\"A5\",value=runif(n,.5,.59),case=1:n)\n            ))\n\nset.seed(1)\nc_random <- data.frame(task=\"c_random\",\n                       alg_name=factor(paste0(\"A\",rep(1:5,each=n))),\n                       value=plogis(rnorm(5*n,1.5,1)),case=rep(1:n,times=5)\n                       )\n\nstrip2 <- seq(.8,1,length.out=5)\na <- permute::allPerms(1:5)\nc_worstcase <- data.frame(task=\"c_worstcase\",\n                     alg_name=c(t(a)),\n                     value=rep(strip2,nrow(a)),\n                     case=rep(1:nrow(a),each=5)\n                     )\nc_worstcase <- rbind(c_worstcase,\n                data.frame(task=\"c_worstcase\",alg_name=1:5,value=strip2,case=max(c_worstcase$case)+1)\n          )\nc_worstcase$alg_name <- factor(c_worstcase$alg_name,labels=paste0(\"A\",1:5))\n\ndata_matrix <- rbind(c_ideal, c_random, c_worstcase)\n```\n\n## 3. Perform ranking\n\n### 3.1 Define challenge object\n\nCode differs slightly for single- and multi-task challenges.\n\nIn case of a single-task challenge use\n\n``` r\n# Use only task \"c_random\" in object data_matrix\ndataSubset <- subset(data_matrix, task==\"c_random\")\n\nchallenge <- as.challenge(dataSubset,\n                          # Specify which column contains the algorithms, \n                          # which column contains a test case identifier \n                          # and which contains the metric value:\n                          algorithm = \"alg_name\", case = \"case\", value = \"value\", \n                          # Specify if small metric values are better\n                          smallBetter = FALSE)\n```\n\n*Instead*, for a multi-task challenge use\n\n``` r\n# Same as above but with 'by=\"task\"' where variable \"task\" contains the task identifier\nchallenge <- as.challenge(data_matrix, \n                          by = \"task\", \n                          algorithm = \"alg_name\", case = \"case\", value = \"value\", \n                          smallBetter = FALSE)\n```\n\n### 3.2 Configure ranking\n\nDifferent ranking methods are available, choose one of them:\n\n-   for “aggregate-then-rank” use (here: take mean for aggregation)\n\n``` r\nranking <- challenge%>%aggregateThenRank(FUN = mean, # aggregation function, \n                                                     # e.g. mean, median, min, max, \n                                                     # or e.g. function(x) quantile(x, probs=0.05)\n                                         na.treat = 0, # either \"na.rm\" to remove missing data, \n                                                       # set missings to numeric value (e.g. 0) \n                                                       # or specify a function, \n                                                       # e.g. function(x) min(x)\n                                         ties.method = \"min\" # a character string specifying \n                                                             # how ties are treated, see ?base::rank\n                                        )  \n```\n\n-   *alternatively*, for “rank-then-aggregate” with arguments as above\n    (here: take mean for aggregation)\n\n``` r\nranking <- challenge%>%rankThenAggregate(FUN = mean,\n                                         ties.method = \"min\"\n                                        )\n```\n\n-   *alternatively*, for test-then-rank based on Wilcoxon signed rank\n    test\n\n``` r\nranking <- challenge%>%testThenRank(alpha = 0.05, # significance level\n                                    p.adjust.method = \"none\", # method for adjustment for\n                                                              # multiple testing, see ?p.adjust\n                                    na.treat = 0, # either \"na.rm\" to remove missing data,\n                                                  # set missings to numeric value (e.g. 0)\n                                                  # or specify a function, e.g. function(x) min(x)\n                                    ties.method = \"min\" # a character string specifying\n                                                        # how ties are treated, see ?base::rank\n                                   )\n```\n\n## 4. Perform bootstrapping\n\nPerform bootstrapping with 1000 bootstrap samples using one CPU\n\n``` r\nset.seed(123, kind = \"L'Ecuyer-CMRG\")\nranking_bootstrapped <- ranking%>%bootstrap(nboot = 1000)\n```\n\nIf you want to use multiple CPUs (here: 8 CPUs), use\n\n``` r\nlibrary(doParallel)\nlibrary(doRNG)\nregisterDoParallel(cores = 8)  \nregisterDoRNG(123)\nranking_bootstrapped <- ranking%>%bootstrap(nboot = 1000, parallel = TRUE, progress = \"none\")\nstopImplicitCluster()\n```\n\n## 5. Generate the report\n\nGenerate report in PDF, HTML or DOCX format. Code differs slightly for\nsingle- and multi-task challenges.\n\n### 5.1 For single-task challenges\n\n``` r\nranking_bootstrapped %>% \n  report(title = \"singleTaskChallengeExample\", # used for the title of the report\n         file = \"filename\", \n         format = \"PDF\", # format can be \"PDF\", \"HTML\" or \"Word\"\n         latex_engine = \"pdflatex\", #LaTeX engine for producing PDF output. Options are \"pdflatex\", \"lualatex\", and \"xelatex\"\n         clean = TRUE #optional. Using TRUE will clean intermediate files that are created during rendering.\n        ) \n```\n\nArgument *file* allows for specifying the output file path as well,\notherwise the working directory is used. If file is specified but does\nnot have a file extension, an extension will be automatically added\naccording to the output format given in *format*. Using argument\n*clean=FALSE* allows to retain intermediate files, such as separate\nfiles for each figure.\n\nIf argument “file” is omitted, the report is created in a temporary\nfolder with file name “report”.\n\n### 5.2 For multi-task challenges\n\nSame as for single-task challenges, but additionally consensus ranking\n(rank aggregation across tasks) has to be given.\n\nCompute ranking consensus across tasks (here: consensus ranking\naccording to mean ranks across tasks)\n\n``` r\n# See ?relation_consensus for different methods to derive consensus ranking\nmeanRanks <- ranking%>%consensus(method = \"euclidean\") \nmeanRanks # note that there may be ties (i.e. some algorithms have identical mean rank)\n```\n\nGenerate report as above, but with additional specification of consensus\nranking\n\n``` r\nranking_bootstrapped %>% \n  report(consensus = meanRanks,\n         title = \"multiTaskChallengeExample\",\n         file = \"filename\", \n         format = \"PDF\", # format can be \"PDF\", \"HTML\" or \"Word\"\n         latex_engine = \"pdflatex\"#LaTeX engine for producing PDF output. Options are \"pdflatex\", \"lualatex\", and \"xelatex\"\n        )\n```\n\nThe consensus ranking is given according to mean ranks across tasks if\nmethod=“euclidean” where in case of ties (equal ranks for multiple\nalgorithms) the average rank is used, i.e. ties.method=“average”.\n\n# Troubleshooting\n\nIn this section we provide an overview of issues that the users reported\nand how they were solved.\n\n## Issues related to RStudio\n\n### Issue: Rtools is missing\n\nWhile trying to install the current version of the repository:\n\n``` r\ndevtools::install_github(\"wiesenfa/challengeR\", dependencies = TRUE)\n```\n\nThe following warning showed up in the output:\n\n``` r\nWARNING: Rtools is required to build R packages, but is not currently installed.\n```\n\nTherefore, Rtools was installed via a separate executable:\n<https://cran.r-project.org/bin/windows/Rtools/> and the warning\ndisappeared.\n\n#### Solution:\n\nActually there is no need of installing Rtools, it is not really used in\nthe toolkit. Insted, choose not to install it when it is asked. See\ncomment in the installation section:\n\n“If you are asked whether you want to update installed packages and you\ntype “a” for all, you might need administrator rights to update R core\npackages. You can also try to type “n” for updating no packages. If you\nare asked “Do you want to install from sources the packages which need\ncompilation? (Yes/no/cancel)”, you can safely type “no”.”\n\n### Issue: Package versions are mismatching\n\nInstalling the current version of the tool from GitHub failed.\n\nThe error message was:\n\n``` r\nbyte-compile and prepare package for lazy loading\nError: (converted from warning) package 'ggplot2' was built under R version 3.6.3\nExecution halted\nERROR: lazy loading failed for package 'challengeR'\n* removing 'C:/Users/.../Documents/R/win-library/3.6/challengeR'\n* restoring previous 'C:/Users/.../Documents/R/win-library/3.6/challengeR'\nError: Failed to install 'challengeR' from GitHub:\n  (converted from warning) installation of package 'C:/Users/.../AppData/Local/Temp/Rtmp615qmV/file4fd419555eb4/challengeR_0.3.1.tar.gz' had non-zero exit status\n```\n\nThe problem was that some of the packages that were built under R3.6.1\nhad been updated, but the current installed version was still R3.6.1.\n\n#### Solution:\n\nThe solution was to update R3.6.1 to R3.6.3. Another way would have been\nto reset the single packages to the versions built under R3.6.1.\n\n### Issue: Package is missing\n\nInstalling the current version of the tool from GitHub failed.\n\n``` r\n devtools::install_github(\"wiesenfa/challengeR\", dependencies = TRUE)\n```\n\nThe error message was:\n\n``` r\nError: .onLoad failed in loadNamespace() for 'pkgload', details:\n  call: loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])\n  error: there is no package called ‘backports’\n```\n\nThe problem was that the packages ‘backports’ had not been installed.\n\n#### Solution:\n\nThe solution was to install ‘backports’ manually.\n\n``` r\n install.packages(\"backports\")\n```\n\n### Issue: Packages are not detected correctly\n\nWhile trying to install the package after running the following\ncommands:\n\n``` r\nif (!requireNamespace(\"devtools\", quietly = TRUE)) install.packages(\"devtools\")\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\")\nBiocManager::install(\"Rgraphviz\", dependencies = TRUE)\ndevtools::install_github(\"wiesenfa/challengeR\", dependencies = TRUE)\n```\n\nThe error message was:\n\n``` r\nERROR:\n1: In file(con, \"r\") :\n URL 'https://bioconductor.org/config.yaml': status was 'SSL connect error'\n2: packages ‘BiocVersion’, ‘Rgraphviz’ are not available (for R version 3.6.1)\n```\n\n#### Solution:\n\nThe solution was to restart RStudio.\n\n## Issues related to MiKTeX\n\n### Issue: Missing packages\n\nWhile generating the PDF with MiKTeX (2.9), the following error showed\nup:\n\n``` r\nfatal pdflatex - gui framework cannot be initialized\n```\n\nThere is an issue with installing missing packages in LaTeX.\n\n##### Solution:\n\nOpen your MiKTeX Console –&gt; Settings, select “Always install missing\npackages on-the-fly”. Then generate the report. Once the report is\ngenerated, you can reset the settings to your preferred ones.\n\n### Issue: Unable to generate report\n\nWhile generating the PDF with MiKTeX (2.9):\n\n``` r\nranking_bootstrapped %>% \n  report(title = \"singleTaskChallengeExample\", # used for the title of the report\n         file = \"filename\", \n         format = \"PDF\", # format can be \"PDF\", \"HTML\" or \"Word\"\n         latex_engine = \"pdflatex\", #LaTeX engine for producing PDF output. Options are \"pdflatex\", \"lualatex\", and \"xelatex\"\n         clean = TRUE #optional. Using TRUE will clean intermediate files that are created during rendering.\n        ) \n```\n\nThe following error showed up:\n\n``` r\noutput file: filename.knit.md\n\n\"C:/Program Files/RStudio/bin/pandoc/pandoc\" +RTS -K512m -RTS filename.utf8.md --to latex --from markdown+autolink_bare_uris+tex_math_single_backslash --output filename.tex --self-contained --number-sections --highlight-style tango --pdf-engine pdflatex --variable graphics --lua-filter \"C:/Users/adm/Documents/R/win-library/3.6/rmarkdown/rmd/lua/pagebreak.lua\" --lua-filter \"C:/Users/adm/Documents/R/win-library/3.6/rmarkdown/rmd/lua/latex-div.lua\" --variable \"geometry:margin=1in\" \n\nError: LaTeX failed to compile filename.tex. See https://yihui.org/tinytex/r/#debugging for debugging tips.\n\n  Warning message:\nIn system2(..., stdout = if (use_file_stdout()) f1 else FALSE, stderr = f2) :\n  '\"pdflatex\"' not found\n```\n\n#### Solution:\n\nThe solution was to restart RStudio.\n\n# Changes\n\n#### Version 1.0.5\n\n-   Ensure reproducibility with parallel bootstrapping\n    ([T29361](https://phabricator.mitk.org/T29361))\n\n#### Version 1.0.4\n\n-   Fix NaN values cause error\n    ([T28746](https://phabricator.mitk.org/T28746))\n-   Fix Bars and dots don’t match in podium plot\n    ([T29167](https://phabricator.mitk.org/T29167))\n-   Fix y-axis of blob plots always scaled to 5\n    ([T28966](https://phabricator.mitk.org/T28966))\n\n#### Version 1.0.3\n\n-   Fix ggplot warning in various places of the report\n    ([T28710](https://phabricator.mitk.org/T28710))\n\n#### Version 1.0.2\n\n-   Fix error when all metric values are the same\n    ([T28453](https://phabricator.mitk.org/T28453))\n-   Fix wrong number of algorithms shown in report summary\n    ([T28465](https://phabricator.mitk.org/T28465))\n\n#### Version 1.0.1\n\n-   Fix error raised in case there are more tasks than algorithms\n    contained in the dataset\n    ([T28193](https://phabricator.mitk.org/T28193))\n-   Drop restriction that at least three algorithms are required for\n    bootstrapping ([T28194](https://phabricator.mitk.org/T28194))\n-   Avoid blank pages in PDF report when bootstrapping is disabled\n    ([T28201](https://phabricator.mitk.org/T28201))\n-   Handle tasks having only one case for bootstrapping\n    ([T28202](https://phabricator.mitk.org/T28202))\n-   Update citation ([T28210](https://phabricator.mitk.org/T28210))\n\n#### Version 1.0.0\n\n-   Revision of the underlying data structure\n-   Roxygen documentation for main functionality\n-   Vignettes for quickstart and overview of available plots\n    demonstrating the use of their corresponding plot functions\n-   Introduction of unit tests (package coverage &gt;70%)\n-   Troubleshooting section covering potential issues during setup\n-   Finally: Extensive bug fixes and improvements (for a complete\n    overview please check the [Phabricator\n    tasks](https://phabricator.mitk.org/search/query/vtj0qOqH5qL6/))\n\n#### Version 0.3.3\n\n-   Force line break to avoid that authors exceed the page in generated\n    PDF reports\n\n#### Version 0.3.2\n\n-   Correct names of authors\n\n#### Version 0.3.1\n\n-   Refactoring\n\n#### Version 0.3.0\n\n-   Major bug fix release\n\n#### Version 0.2.5\n\n-   Bug fixes\n\n#### Version 0.2.4\n\n-   Automatic insertion of missings\n\n#### Version 0.2.3\n\n-   Bug fixes\n-   Reports for subsets (top list) of algorithms: Use\n    e.g. `subset(ranking_bootstrapped, top=3) %>% report(...)` (or\n    `subset(ranking, top=3) %>% report(...)` for report without\n    bootstrap results) to only show the top 3 algorithms according to\n    the chosen ranking methods, where `ranking_bootstrapped` and\n    `ranking` objects as defined in the example. Line plot for ranking\n    robustness can be used to check whether algorithms performing well\n    in other ranking methods are excluded. Bootstrapping still takes\n    entire uncertainty into account. Podium plot and ranking heatmap\n    neglect excluded algorithms. Only available for single-task\n    challenges (for multi-task challenges not sensible because each task\n    would contain a different set of algorithms).\n-   Reports for subsets of tasks: Use\n    e.g. `subset(ranking_bootstrapped, tasks=c(\"task1\", \"task2\",\"task3\")) %>% report(...)`\n    to restrict report to tasks “task1”, “task2”,\"task3. You may want to\n    recompute the consensus ranking before using\n    `meanRanks=subset(ranking, tasks=c(\"task1\", \"task2\", \"task3\"))%>%consensus(method = \"euclidean\")`\n\n#### Version 0.2.1\n\n-   Introduction in reports now mentions e.g. ranking method, number of\n    test cases,…\n-   Function `subset()` allows selection of tasks after bootstrapping,\n    e.g. `subset(ranking_bootstrapped,1:3)`\n-   `report()` functions gain argument `colors` (default:\n    `default_colors`). Change e.g. to `colors=viridisLite::inferno`\n    which “is designed in such a way that it will analytically be\n    perfectly perceptually-uniform, both in regular form and also when\n    converted to black-and-white. It is also designed to be perceived by\n    readers with the most common form of color blindness.” See package\n    `viridis` for further similar functions.\n\n#### Version 0.2.0\n\n-   Improved layout in case of many algorithms and tasks (while probably\n    still not perfect)\n-   Consistent coloring of algorithms across figures\n-   `report()` function can be applied to ranked object before\n    bootstrapping (and thus excluding figures based on bootstrapping),\n    i.e. in the example `ranking %>% report(...)`\n-   bug fixes\n\n# Team\n\nThe developer team includes members from both division of Intelligent\nMedical Systems (IMSY) and Biostatistics at the German Cancer Research\nCenter (DKFZ):\n\n-   Manuel Wiesenfarth\n-   Annette Kopp-Schneider\n-   Annika Reinke\n-   Matthias Eisenmann\n-   Laura Aguilera Saiz\n-   Elise Récéjac\n-   Lena Maier-Hein\n-   Ali Emre Kavur\n\n# Reference\n\nWiesenfarth, M., Reinke, A., Landman, B.A., Eisenmann, M., Aguilera\nSaiz, L., Cardoso, M.J., Maier-Hein, L. and Kopp-Schneider, A. Methods\nand open-source toolkit for analyzing and visualizing challenge results.\n*Sci Rep* **11**, 2369 (2021).\n<https://doi.org/10.1038/s41598-021-82017-6>\n\n</br> <img src=\"Helmholtz_Imaging_Logo.svg\" height=\"70px\" /> </br></br>\n<img src=\"DKFZ_Logo.png\" height=\"100px\" />\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/rayx",
            "repo_link": "https://github.com/hz-b/rayx",
            "readme": "# RAYX\n\n<table>\n  <tr>\n    <td>\n      <img src=\"https://github.com/user-attachments/assets/d12229b0-7820-475f-8f02-6b2f253c5081\" alt=\"RAYX Logo\" width=\"600\">\n    </td>\n    <td>\n      <strong>RAYX</strong> is a powerful, multi-component simulation platform designed to streamline the design and optimization of beamlines in synchrotron light source facilities. At the core of the platform is <i>rayx-core</i>, a high-performance library that delivers precise light tracing capabilities on both CPUs and GPUs. This core library ensures that users can achieve detailed and accurate simulations at high speeds, making it an ideal solution for complex beamline designs.\n    </td>\n  </tr>\n</table>\n\nTo simplify the usage of _rayx-core_, the platform includes rayx, a command-line interface (CLI) tool designed for fast, one-shot tracing of beamlines. It provides comprehensive data on every ray-element intersection, making it especially valuable for generating large datasets efficiently. With its focus on ease of use, _rayx_ empowers users to quickly run simulations and retrieve detailed ray-tracing results.\n\nFor users who prefer a more visual approach, _rayx-ui_ offers a graphical user interface (GUI) that includes a 3D viewport of the beamline, enabling interactive design and exploration. This GUI provides an intuitive interface to construct and modify beamlines, allowing users to visualize their designs in real-time. _rayx-ui_ not only enhances the design process but also allows users to iteratively optimize configurations based on immediate visual feedback.\n\n## RAYX vs RAY-UI\n\nRAYX offers several advanced features, including:\n- Global (not sequential) tracing of beamlines\n- GPU utilization for accelerated tracing performance\n- A dedicated mode for tracing multiple beamlines with ease\n- Objects in RAYX can be grouped for simplified group transformations\n- A GUI for intuitive beamline design\n\n## Installing or Building RAYX\n\n[![testUbuntu](https://github.com/hz-b/rayx/actions/workflows/testUbuntu.yml/badge.svg?branch=master)](https://github.com/hz-b/rayx/actions/workflows/testUbuntu.yml) [![testWindows](https://github.com/hz-b/rayx/actions/workflows/testWindows.yml/badge.svg?branch=master)](https://github.com/hz-b/rayx/actions/workflows/testWindows.yml) [![testUbuntuClang](https://github.com/hz-b/rayx/actions/workflows/testUbuntuClang.yml/badge.svg?branch=master)](https://github.com/hz-b/rayx/actions/workflows/testUbuntuClang.yml) [![MDBookDeploy](https://github.com/hz-b/rayx/actions/workflows/mdBookDeploy.yml/badge.svg)](https://github.com/hz-b/rayx/actions/workflows/mdBookDeploy.yml)\n\nFor additional information, please visit our [Wiki](https://hz-b.github.io/rayx/). We are committed to delivering stable releases, which can be found [here](https://github.com/hz-b/rayx/releases). Please note that the `master` branch and other branches might be unstable, and building RAYX from the source could lead to unstable software. We recommend this only for developers and experienced users. If you experience issues with our distributed binaries or API, do not hesitate to [open an issue](https://github.com/hz-b/rayx/issues/new/choose). We are keen to provide assistance and develop features as the need arises.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/rce",
            "repo_link": "https://github.com/rcenvironment/rce",
            "readme": "RCE is a distributed, workflow-driven integration environment.\nIt is used by engineers and scientists to analyze, optimize, and design complex systems (e.g., aircraft, ships, or satellites).\nUsing RCE, they can combine their specialized design and simulation tools into distributed workflows.\n\nSoftware website: [https://rcenvironment.de](https://rcenvironment.de)\n\n##### Issue Tracker\n\nSee the [main issue tracker](https://mantis.sc.dlr.de/roadmap_page.php) for the complete set of issues and an up-to-date roadmap.\nIt is currently read-only.\nPlease use the [GitHub issue tracker](https://github.com/rcenvironment/rce/issues) to report new issues.\n\n##### Changelog\n\nThe most relevant changes and new features in each release are listed on [this page](https://github.com/rcenvironment/rce/releases).\nSimilar information for older releases is available [here](https://github.com/rcenvironment/rce/wiki/Changelog-Overview).\nFor a more detailed, but also more technical list of changes, see the [main issue tracker](https://mantis.sc.dlr.de/changelog_page.php).\n\n##### Get RCE (as a ready-to-run software)\n\nFor Windows, a simple .zip file is provided to set up both client and server installations.\n\nOn Linux, .deb/.rpm packages as well as a simple .zip file are provided to set up both client and server installations.\n\n[Download latest release](https://software.dlr.de/updates/rce/10.x/products/standard/releases/latest/) | [Update site of latest release](https://software.dlr.de/updates/rce/10.x/repositories/standard/releases/latest/)\n\n##### License\n\nRCE is Open Source Software provided under the terms of the [Eclipse Public License (EPL)](http://opensource.org/licenses/EPL-1.0).\nThis source repository as well as related releases also contain software covered by other open source licenses.\nMore information is available in embedded licensing files.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/reflectorch",
            "repo_link": "https://github.com/schreiber-lab/reflectorch",
            "readme": "# Reflectorch\n\n[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)](https://pytorch.org/)\n[![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)](https://numpy.org/)\n[![SciPy](https://img.shields.io/badge/SciPy-%230C55A5.svg?style=for-the-badge&logo=scipy&logoColor=%white)](https://scipy.org/)\n[![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)](https://matplotlib.org/)\n[![YAML](https://img.shields.io/badge/yaml-%23ffffff.svg?style=for-the-badge&logo=yaml&logoColor=151515)](https://yaml.org/)\n[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-%23FFD700.svg?style=for-the-badge&logo=huggingface&logoColor=black)](https://huggingface.co/valentinsingularity/reflectivity)\n\n[![Python version](https://img.shields.io/badge/python-3.7%7C3.8%7C3.9%7C3.10%7C3.11%7C3.12-blue.svg)](https://www.python.org/)\n![CI workflow status](https://github.com/schreiber-lab/reflectorch/actions/workflows/ci.yml/badge.svg)\n![Repos size](https://img.shields.io/github/repo-size/schreiber-lab/reflectorch)\n[![CodeFactor](https://www.codefactor.io/repository/github/schreiber-lab/reflectorch/badge)](https://www.codefactor.io/repository/github/schreiber-lab/reflectorch)\n[![Jupyter Book Documentation](https://jupyterbook.org/badge.svg)](https://jupyterbook.org/)\n[![Documentation Page](https://img.shields.io/badge/Documentation%20Page-%23FFDD33.svg?style=flat&logo=read-the-docs&logoColor=black)](https://schreiber-lab.github.io/reflectorch/)\n<!-- [![Code style: Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff) -->\n\n\n**Reflectorch** is a machine learning Python package for the analysis of X-ray and neutron reflectometry data, written by [Vladimir Starostin](https://github.com/StarostinV/) & [Valentin Munteanu](https://github.com/valentinsingularity) at the University of Tübingen. It provides functionality for the fast simulation of reflectometry curves on the GPU, customizable setup of the physical parameterization model and neural network architecture via YAML configuration files, and prior-aware training of neural networks as described in our paper [Neural network analysis of neutron and X-ray reflectivity data incorporating prior knowledge](https://doi.org/10.1107/S1600576724002115).\n\n## Installation\n\n**Reflectorch** can be installed from [![PyPi](https://img.shields.io/badge/PyPi-3776AB.svg?style=flat&logo=pypi&logoColor=white)](https://pypi.org/project/reflectorch/) via ``pip``:\n\n<!-- or from [![conda-forge](https://img.shields.io/badge/conda--forge-44A833.svg?style=flat&logo=conda-forge&logoColor=white)](https://anaconda.org/conda-forge/reflectorch/) via ``conda``: -->\n\n```bash\npip install reflectorch\n```\n\n<!-- or\n\n```bash\nconda install -c conda-forge reflectorch\n``` -->\n\nAlternatively, one can clone the entire Github repository and install the package in editable mode:\n\n```bash\ngit clone https://github.com/schreiber-lab/reflectorch.git\npip install -e .\n```\n\nFor development purposes, the package can be installed together with the optional dependencies for building the distribution, testing and documentation:\n\n```bash\ngit clone https://github.com/schreiber-lab/reflectorch.git\npip install -e .[tests,docs,build]\n```\n\nUsers with Nvidia **GPU**s need to additionally install **Pytorch with CUDA support** corresponding to their hardware and operating system according to the instructions from the [Pytorch website](https://pytorch.org/get-started/locally/)\n\n## Get started\n\n[![Documentation Page](https://img.shields.io/badge/Documentation%20Page-%23FFDD33.svg?style=flat&logo=read-the-docs&logoColor=black)](https://schreiber-lab.github.io/reflectorch/)\n The full documentation of the package, containing tutorials and the API reference, was built with [Jupyter Book](https://jupyterbook.org/) and [Sphinx](https://www.sphinx-doc.org) and it is hosted at the address: [https://schreiber-lab.github.io/reflectorch/](https://schreiber-lab.github.io/reflectorch/).\n\n[![Interactive Notebook](https://img.shields.io/badge/Interactive%20Notebook-%23F9AB00.svg?style=flat&logo=google-colab&logoColor=black)](https://colab.research.google.com/drive/1rf_M8S_5kYvUoK0-9-AYal_fO3oFl7ck?usp=sharing)\nWe provide an interactive Google Colab notebook for exploring the basic functionality of the package: [![Explore reflectorch in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1rf_M8S_5kYvUoK0-9-AYal_fO3oFl7ck?usp=sharing)<br>\n\n[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-%23FFD700.svg?style=flat&logo=huggingface&logoColor=black)](https://huggingface.co/valentinsingularity/reflectivity)\nConfiguration files and the corresponding pretrained model weights are hosted on Huggingface: [https://huggingface.co/valentinsingularity/reflectivity](https://huggingface.co/valentinsingularity/reflectivity).\n\n[![Docker](https://img.shields.io/badge/Docker-2496ED.svg?style=flat&logo=docker&logoColor=white)](https://hub.docker.com/)\nDocker images for reflectorch *will* be hosted on Dockerhub.\n\n\n## Citation\nIf you find our work useful in your research, please cite as follows:\n```\n@Article{Munteanu2024,\n  author    = {Munteanu, Valentin and Starostin, Vladimir and Greco, Alessandro and Pithan, Linus and Gerlach, Alexander and Hinderhofer, Alexander and Kowarik, Stefan and Schreiber, Frank},\n  journal   = {Journal of Applied Crystallography},\n  title     = {Neural network analysis of neutron and X-ray reflectivity data incorporating prior knowledge},\n  year      = {2024},\n  issn      = {1600-5767},\n  month     = mar,\n  number    = {2},\n  volume    = {57},\n  doi       = {10.1107/s1600576724002115},\n  publisher = {International Union of Crystallography (IUCr)},\n}\n```"
        },
        {
            "software_organization": "https://helmholtz.software/software/remix",
            "repo_link": "https://gitlab.com/dlr-ve/esy/remix/framework",
            "readme": "# REMix\n\nREMix is addressing research questions in the field of energy system analysis.\nThe main focus is on the broad techno-economical assessment of possible future\nenergy system designs and analysis of interactions between technologies. This\nwill allow system analysts to inform policy makers and technology researchers\nto gain a better understanding of both the system and individual components.\n\nThe documentation of REMix is hosted online: [REMix docu](https://dlr-ve.gitlab.io/esy/remix/framework/).\n\nDo not hesitate to ask questions about REMix in the [openmod forum](https://forum.openmod.org/tag/remix).\n\n## Key Features\n\nTo know if REMix is apt for your project take into account these key features:\n\n**Large Models**:\nREMix is developed with large models in mind.\nThis means high spatial and technological resolutions.\n\n**Path Optimization**:\nMulti-year analyses are built into the framework.\n\n**Custom accounting approaches**:\nThe indicator module allows for a very flexible definition of what contributes\nto the objective functions.\n\n**Flexible modeling**:\nThere is not a single way of modeling technologies in REMix.\nWith the flexible [modelling concept](https://dlr-ve.gitlab.io/esy/remix/framework/dev/documentation/modeling-concept/index.html) you can find the best way of integrating your modeling needs.\n\n**Multi-criteria optimization**:\nApart from running a cost minimization, also other criteria like ecological or\nresilience indicators can be taken into account in the objective function.\n\n## How to use\n\nTo run a REMix model, users need a recent [GAMS](https://www.gams.com/)\ninstallation (version 37 or above).\n\nTo use REMix, clone this repository, create a new Python environment and\ninstall remix.framework through pip.\n\nEither clone with ssh:\n\n```bash\ngit clone git@gitlab.com:dlr-ve/esy/remix/framework.git\n```\n\nOr clone with https:\n\n```bash\ngit clone https://gitlab.com/dlr-ve/esy/remix/framework.git\n```\n\nFor the installation of the `remix.framework` package, you have two options:\n\n1. install from PyPI:\n\n```bash\nmamba create -n remix-env python  # make sure the Python version matches your GAMS version\nmamba activate remix-env\npip install remix.framework\n```\n\n2. install from the cloned repository:\n\n```bash\ncd framework\nconda create -n remix-env python\nconda activate remix-env\npip install -e .[dev]\n```\n\nPlease find the extensive [installation instructions in the online documentation](https://dlr-ve.gitlab.io/esy/remix/framework/dev/getting-started/install-remix.html).\n\nAdditionally, a data project is required which contains the parametrization of\nthe model scope and technologies. We provide\n[example projects](https://gitlab.com/dlr-ve/esy/remix/projects), which can be used\nto gain first experience with running the REMix optimization model.\n\nTo run your model, you can use the command line interface:\n\n```bash\nconda activate remix-env\nremix run --datadir=/path/to/data/folder/of/your/model/data\n```\n\nAll configuration options available with the command line tool are documented\nin the [technical documentation](https://dlr-ve.gitlab.io/esy/remix/framework/dev/documentation/tech-docs/index.html).\n\n## Citing REMix\n\n* [Wetzel et al. (2024): \"REMix: A GAMS-based framework for optimizing energy system models\"](https://doi.org/10.21105/joss.06330)\n\n\n## Latest publications using REMix\n\n* [Nitsch et al. (2024): \"The future role of Carnot batteries in Central Europe: Combining energy system and market perspective\"](https://doi.org/10.1016/j.est.2024.110959)\n* [Wetzel et al. (2023): \"Green energy carriers and energy sovereignty in a climate neutral European energy system\"](https://doi.org/10.1016/j.renene.2023.04.015)\n* [Gils et al. (2022): \"Model-related outcome differences in power system models with sector coupling - quantification and drivers\"](https://doi.org/10.1016/j.rser.2022.112177)[^1]\n* [Gils et al. (2021): \"Interaction of hydrogen infrastructures with other sector coupling options towards a zero-emission energy system in Germany\"](https://doi.org/10.1016/j.renene.2021.08.016)[^1]\n* [Sasanpour et al. (2021): \"Strategic policy targets and the contribution of hydrogen in a 100% renewable European power system\"](https://doi.org/10.1016/j.egyr.2021.07.005)[^1]\n\n## Contribute to REMix\n\nContributions are welcome, and they are greatly appreciated! Every bit\nhelps, and credit will always be given. To learn how to contribute to REMix we\nhave included a respective section in our\n[online documentation](https://dlr-ve.gitlab.io/esy/remix/framework/dev/contributing/index.html).\n\n## Acknowledgments\n\nThe preparation of the open source version of REMix was financed by the Helmholtz Association's Energy System Design research programme, which also enables the continuous maintenance of the framework. The methodological and content-related development of REMix was made possible by funding from the German Federal Ministries for Economic Affairs and Climate Protection (BMWK) and for Education and Research (BMBF) as part of the projects UNSEEN (BMWK, FKZ 03EI1004A), Sesame Seed (BMWK, FKZ 03EI1021B), Fahrplan Gaswende (BMWK, FKZ 03EI1030B), ReMoDigital (BMWK, FKZ 03EI1020B), and HINT (BMBF, FKZ 03SF0690) as well as the DLR-internal projects NaGsys and CarnotBat, which were also funded by the Helmholtz Association's Energy System Design research programme. The development of earlier REMix versions, which provided the basis for the published version, was made possible by funding from the projects MuSeKo (BMWK, FKZ 03ET4038B), INTEEVER-II (BMWK, FKZ 03ET4069A), START (BMBF, FKZ 03EK3046D), BEAM-ME (BMWK, FKZ 03ET4023A), INTEEVER (BMWK, FKZ 03ET4020A), Plan-DelyKaD (BMWK, FKZ 0325501), “Lastausgleich” (BMWK, FKZ 0328009), and “Elektromobilitaet” (BMWK, FKZ 0328005A) as well as the Helmholtz Association's Energy System Design research programme and its predecessors.\n\n## Footnotes\n\n[^1]: These papers were still using a non-open legacy version of the REMix framework\n",
            "project_id": "41232429"
        },
        {
            "software_organization": "https://helmholtz.software/software/restore",
            "repo_link": "https://github.com/ReStoreCpp/ReStore",
            "readme": "# ReStore: In-Memory REplicated STORagE for Rapid Recovery in Fault-Tolerant Algorithms\n\nFault-tolerant distributed applications require mechanisms to recover data lost via a process failure.\nOn modern cluster systems it is typically impractical to request replacement resources after such a failure.\nTherefore, applications have to continue working with the remaining resources.\nThis requires redistributing the workload and that the non-failed processes reload the lost data.\nReStore is a C++ header-only library for MPI programs that enables recovery of lost data after (a) process failure(s).\nBy storing all required data in memory via an appropriate data distribution and replication, recovery is substantially faster than with standard checkpointing schemes that rely on a parallel file system.\nAs you as the application programmer can specify which data to load ReStore also supports shrinking recovery instead of recovery using spare compute nodes.\n\n## Including ReStore into your application\n\nTo use ReStore, first add the repository as a submodule into your project:\n```Bash\ngit submodule add --recursive https://github.com/ReStoreCpp/ReStore.git extern/ReStore\n```\n\nThen, include the following into your CMakeLists.txt:\n```CMake\n# Configure and link ReStore\nset(ReStore_BUILD_TESTS Off)\nset(ReStore_BUILD_BENCHMARKS Off)\nset(ReStore_ID_RANDOMIZATION On)\n\nadd_subdirectory(extern/ReStore)\ntarget_link_libraries(${YOUR_TARGETS_NAME} ReStore)\n```\n\nYou can use ID-randomization to break up access patterns in your `load` requests.\nIf enabled, the block IDs you provide will be permuted using a pseudorandom-projection.\nIf you then for example access a range of consecutive blocks IDs, e.g. after the PE which worked on these IDs failed; more PEs will be able to serve the request, resulting in a speedup.\nIf you request most or all of the data `submitted` in each `load`, turning ID-randomization of will be faster.\nSee Hespe and Hübner et al. (2022) [1] for details.\n\n## Code examples\n\n### The general use case\n\nThis example shows the general usage of ReStore.\n\n```cpp\n#include <core.hpp>\n\n// First, create the restore object.\nReStore::ReStore<YourAwesomeDatatype> store(\n    MPI_COMM_WORLD, // MPI communicator to use. ULFM currently supports only MPI_COMM_WORLD.\n    4,              // Replication level, 3 or 4 are sane defaults.\n    ReStore::OffsetMode::constant, // Currently, the only supported mode.\n    sizeof(YourAwesomeDatatype)    // Your block size, use at least 64 bytes.\n);\n\n// Next, submit you data to the ReStore, if a failure happened between creation of the ReStore\n// and the submission of the data, please re-create the ReStore.\nReStore::block_id_t localBlockId = 0;\nstore.submitBlocks(\n    // The serialization function; your can stream your data to the provided stream using\n    // the << operator.\n    [](const YourAwesomeDatatype& value, ReStore::SerializedBlockStoreStream& stream) {\n        // Either use:\n        stream << value;\n        // or, for big, already consecutively stored data:\n        stream.writeBytes(constBytePtr, sizeof(YourAwesomeDatatype));\n        },\n    // The enumerator function; should return nullopt if there are no more blocks to submit\n    // on this PE.\n    [localBlockId, ...]() {\n        auto ret = numberOfBlocksOnThisPE == localBlockId\n                        ? std::nullopt\n                        : std::make_optional(ReStore::NextBlock<YourAwesomeDatatype>(\n                            {globalBlockId(localBlockId), constRefToYourDataForThisBlock}));\n        localBlockId++;\n        return ret;\n    },\n    globalNumberOfBlocks\n);\n\n// A failure occurred; set ReStore's communicator to the fixed communicator obtained by\n// MPIX_Comm_shrink()\nstore.updateComm(newComm);\n\n// Next, request the data you need on each PE.\n// requestedBlocks is of type\n// std::vector<std::pair<ReStore::block_id_t, size_t>>\n// [ (firstBlockIdOfRange1, numberOfBlocks1), (firstBlockIdOfRange2, numberOfBlocks2), ...]\nstore.pullBlocks(\n    requestedBlocks,\n    //  De-serialization function.\n    [...] (const std::byte* dataPtr, size_t size, ReStore::block_id_t blockId) {\n        // ...\n});\n\n```\n### Data stored in a std::vector\n\nIf your data resides in a `std::vector`, you can use the ReStore-provided wrapper.\n\n```cpp\n#include <restore/core.hpp>\n#include <restore/restore_vector.hpp>\n\n// Create the ReStoreVector wrapper.\nReStore::ReStoreVector<YourAwesomeDatatype>> reStoreVectorWrapper(\n    blockSizeInBytes, // Can for example be used to group all dimensions of a single data point.\n    MPI_COMM_WORLD,\n    replicationLevel,\n    blocksPerPermutationRange, // defaults to 4096\n    paddingValue, // The value used to pad the data; defaults to 0\n);\n\n// Submit your data to the ReStore.\nconst auto numBlocksLocal = reStoreVectorWrapper->submitData(referenceToYourDataVector);\n\n// After a failure\nreStoreVectorWrapper.updateComm(newComm); // see above\n\nreStoreVectorWrapper.restoreDataAppendPullBlocks(\n    referenceToVectorContainingYourData, // ReStore will append the new data points at the end.\n    requestedBlocks, // see above\n);\n```\n\n### A simple load-balancer\n\nYou can use the ReStore-provided LoadBalancer.\nIf a PE fails, it will help you with calculating the new distribution of blocks to PEs.\nEach surviving PE will get an equal share of the blocks residing on each PE that failed.\nThis of course works for multiple rounds of failing PEs, too.\n\n```cpp\n#include <restore/core.hpp>\n#include <restore/equal_load_balancer.hpp>\n\n// Describes, which block range (firstBlockId, numberOfBlocks) resides on which PE.\nusing BlockRange     = std::pair<std::pair<ReStore::block_id_t, size_t>, ReStoreMPI::original_rank_t>;\nusing BlockRangeList = std::vector<BlockRange>;\n\n// Create the LoadBalancer object.\nReStore::EqualLoadBalancer loadBalancer(blockRangeList, numberOfPEs)\n\n// After a failure, let the LoadBalancer decide which PE gets which data points:\nconst auto newBlocks = _loadBalancer.getNewBlocksAfterFailureForPullBlocks(\n    ranksDiedSinceLastCall, myRankWhenCreatingTheLoadBalancer\n);\n// You can hand newBlocks to restore.pullBlocks() or the ReStoreVector wrapper.\n\n// If everyone completed the restoration successfully, we can commit to the new data distribution. If\n// there was another PE failure in the meantime, you can re-call getNewBlocksAfterFailureForPullBlocks.\n_loadBalancer.commitToPreviousCall();\n\n// Further failures, repeat the above steps.\n```\n\n## Publication\nIf you use ReStore in your research, please cite the following paper:\n\n```bibtex\n@inproceedings{restore,\n  author={Hübner, Lukas and Hespe, Demian and Sanders, Peter and Stamatakis, Alexandros},\n  booktitle={2022 IEEE/ACM 12th Workshop on Fault Tolerance for HPC at eXtreme Scale (FTXS)}, \n  title={ReStore: In-Memory REplicated STORagE for Rapid Recovery in Fault-Tolerant Algorithms}, \n  year={2022},\n  volume={},\n  number={},\n  pages={24-35},\n  doi={10.1109/FTXS56515.2022.00008}\n}\n```\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/rgreat",
            "repo_link": "https://github.com/jokergoo/rGREAT",
            "readme": "# GREAT Analysis - Functional Enrichment on Genomic Regions\n\n[![R-CMD-check](https://github.com/jokergoo/rGREAT/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/rGREAT/actions)\n[![codecov](https://img.shields.io/codecov/c/github/jokergoo/rGREAT.svg)](https://codecov.io/github/jokergoo/rGREAT)\n[![bioc](https://bioconductor.org/shields/downloads/devel/rGREAT.svg)](https://bioconductor.org/packages/stats/bioc/rGREAT/) \n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/rGREAT.svg)](http://bioconductor.org/packages/devel/bioc/html/rGREAT.html)\n\n\n**GREAT** ([Genomic Regions Enrichment of Annotations Tool](http://great.stanford.edu)) is a type of\nfunctional enrichment analysis directly performed on genomic regions. This package \nimplements the GREAT algorithm (the local GREAT analysis), also it supports directly \ninteracting with the GREAT web service (the online GREAT analysis). Both analysis \ncan be viewed by a Shiny application.\n\n## Install\n\n**rGREAT** is available on Bioconductor (http://bioconductor.org/packages/devel/bioc/html/rGREAT.html)\n\n```r\nif(!requireNamespace(\"BiocManager\", quietly = TRUE)) {\n    install.packages(\"BiocManager\")\n}\nBiocManager::install(\"rGREAT\")\n```\n\nIf you want the latest version, install it directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/rGREAT\")\n```\n\n## Citation\n\nZuguang Gu, et al., rGREAT: an R/Bioconductor package for functional enrichment on genomic regions. \nBioinformatics, https://doi.org/10.1093/bioinformatics/btac745\n\n## Online GREAT analysis\n\nWith online GREAT analysis, the input regions will be directly submitted to GREAT server, and the results\nare automatically retrieved from GREAT server.\n\n```r\nset.seed(123)\ngr = randomRegions(nr = 1000, genome = \"hg19\")\n\njob = submitGreatJob(gr)\ntbl = getEnrichmentTables(job)\n```\n\n## Local GREAT analysis\n\n**rGREAT** also implements the GREAT algorithms locally and it can be seamlessly integrated\nto the Bioconductor annotation ecosystem. This means, theoretically, with **rGREAT**, it is possible to perform GREAT analysis\nwith any organism and with any type of gene set collection / ontology\n\n```r\nres = great(gr, \"MSigDB:H\", \"TxDb.Hsapiens.UCSC.hg19.knownGene\")\ntb = getEnrichmentTable(res)\n```\n\nTo apply `great()` on other organisms, set the `biomart_dataset` argument:\n\n```r\n# giant panda\ngreat(gr, \"GO:BP\", biomart_dataset = \"amelanoleuca_gene_ensembl\")\n```\n\n## License\n\nMIT @ Zuguang Gu\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ribodetector",
            "repo_link": "https://github.com/hzi-bifo/RiboDetector",
            "readme": "## RiboDetector - Accurate and rapid RiboRNA sequences Detector based on deep learning\n\n### About Ribodetector\n<img src=\"RiboDetector_logo.png\" width=\"600\" />\n\n`RiboDetector` is a software developed to accurately yet rapidly detect and remove rRNA sequences from metagenomeic, metatranscriptomic, and ncRNA sequencing data. It was developed based on LSTMs and optimized for both GPU and CPU usage to achieve a **10** times on CPU and **50** times on a consumer GPU faster runtime compared to the current state-of-the-art software. Moreover, it is very accurate, with ~**10** times fewer false classifications. Finally, it has a low level of bias towards any GO functional groups. \n\n\n### Prerequirements\n\n#### 1. Create `conda` env and install `Python v3.8`\n\nTo be able to use `RiboDetector`, you need to install `Python v3.8` or `v3.9` (make sure you have version `3.8` because `3.7` cannot serialize a string larger than 4GiB) with `conda`:\n```shell\nconda create -n ribodetector python=3.8\nconda activate ribodetector\n```\n\n#### 2. Install `pytorch` in the ribodetector env if GPU is available\n\nTo install `pytorch` compatible with your CUDA version, please fellow this instruction:\nhttps://pytorch.org/get-started/locally/. Our code was tested with `pytorch v1.7`, `v1.7.1`, `v1.10.2`.\n\nNote: you can skip this step if you don't use GPU\n\n### Installation\n\n#### Using pip\n\n```shell\npip install ribodetector\n```\n\n#### Using conda\n```shell\nconda install -c bioconda ribodetector\n```\n\n### Usage\n\n#### GPU mode\n\n#### Example\n```shell\nribodetector -t 20 \\\n  -l 100 \\\n  -i inputs/reads.1.fq.gz inputs/reads.2.fq.gz \\\n  -m 10 \\\n  -e rrna \\\n  --chunk_size 256 \\\n  -o outputs/reads.nonrrna.1.fq outputs/reads.nonrrna.2.fq\n```\nThe command lind above excutes ribodetector for paired-end reads with mean length 100 using GPU and 20 CPU cores. The input reads do not need to be same length. RiboDetector supports reads with variable length. Setting `-l` to the mean read length is recommended. \n\n#### Full help\n```shell\nusage: ribodetector [-h] [-c CONFIG] [-d DEVICEID] -l LEN -i [INPUT [INPUT ...]]\n  -o [OUTPUT [OUTPUT ...]] [-r [RRNA [RRNA ...]]] [-e {rrna,norrna,both,none}] \n  [-t THREADS] [-m MEMORY] [--chunk_size CHUNK_SIZE] [-v]\n\nrRNA sequence detector\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -c CONFIG, --config CONFIG\n                        Path of config file\n  -d DEVICEID, --deviceid DEVICEID\n                        Indices of GPUs to enable. Quotated comma-separated device ID numbers. (default: all)\n  -l LEN, --len LEN     Sequencing read length (mean length). Note: the accuracy reduces for reads shorter than 40.\n  -i [INPUT [INPUT ...]], --input [INPUT [INPUT ...]]\n                        Path of input sequence files (fasta and fastq), the second file will be considered \n                        as second end if two files given.\n  -o [OUTPUT [OUTPUT ...]], --output [OUTPUT [OUTPUT ...]]\n                        Path of the output sequence files after rRNAs removal (same number of files as input).\n                        (Note: 2 times slower to write gz files)\n  -r [RRNA [RRNA ...]], --rrna [RRNA [RRNA ...]]\n                        Path of the output sequence file of detected rRNAs (same number of files as input)\n  -e {rrna,norrna,both,none}, --ensure {rrna,norrna,both,none}\n                        Ensure which classificaion has high confidence for paired end reads.\n                        norrna: output only high confident non-rRNAs, the rest are clasified as rRNAs;\n                        rrna: vice versa, only high confident rRNAs are classified as rRNA and the rest output as non-rRNAs;\n                        both: both non-rRNA and rRNA prediction with high confidence;\n                        none: give label based on the mean probability of read pair.\n                              (Only applicable for paired end reads, discard the read pair when their predicitons are discordant)\n  -t THREADS, --threads THREADS\n                        number of threads to use. (default: 10)\n  -m MEMORY, --memory MEMORY\n                        Amount (GB) of GPU RAM. (default: 12)\n  --chunk_size CHUNK_SIZE\n                        Use this parameter when having low memory. Parsing the file in chunks.\n                        Not needed when free RAM >=5 * your_file_size (uncompressed, sum of paired ends).\n                        When chunk_size=256, memory=16 it will load 256 * 16 * 1024 reads each chunk (use ~20 GB for 100bp paired end).\n  --log LOG             Log file name\n  -v, --version         Show program's version number and exit\n```\n\n#### CPU mode\n\n#### Example\n```shell\nribodetector_cpu -t 20 \\\n  -l 100 \\\n  -i inputs/reads.1.fq.gz inputs/reads.2.fq.gz \\\n  -e rrna \\\n  --chunk_size 256 \\\n  -o outputs/reads.nonrrna.1.fq outputs/reads.nonrrna.2.fq\n```\nThe above command line excutes ribodetector for paired-end reads with mean length 100 using 20 CPU cores. The input reads do not need to be same length. RiboDetector supports reads with variable length. Setting `-l` to the mean read length is recommended. If you need to save the log into a file, you can specify it with `--log <logfile>`\n\nNote: when using **SLURM** job submission system, you need to specify `--cpus-per-task` to the number you CPU cores you need and set `--threads-per-core` to 1.\n\n#### Full help\n\n```shell\n\nusage: ribodetector_cpu [-h] [-c CONFIG] -l LEN -i [INPUT [INPUT ...]] \n  -o [OUTPUT [OUTPUT ...]] [-r [RRNA [RRNA ...]]] [-e {rrna,norrna,both,none}] \n  [-t THREADS] [--chunk_size CHUNK_SIZE] [-v]\n\nrRNA sequence detector\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -c CONFIG, --config CONFIG\n                        Path of config file\n  -l LEN, --len LEN     Sequencing read length (mean length). Note: the accuracy reduces for reads shorter than 40.\n  -i [INPUT [INPUT ...]], --input [INPUT [INPUT ...]]\n                        Path of input sequence files (fasta and fastq), the second file will be considered as \n                        second end if two files given.\n  -o [OUTPUT [OUTPUT ...]], --output [OUTPUT [OUTPUT ...]]\n                        Path of the output sequence files after rRNAs removal (same number of files as input).\n                        (Note: 2 times slower to write gz files)\n  -r [RRNA [RRNA ...]], --rrna [RRNA [RRNA ...]]\n                        Path of the output sequence file of detected rRNAs (same number of files as input)\n  -e {rrna,norrna,both,none}, --ensure {rrna,norrna,both,none}\n                        Ensure which classificaion has high confidence for paired end reads.\n                        norrna: output only high confident non-rRNAs, the rest are clasified as rRNAs;\n                        rrna: vice versa, only high confident rRNAs are classified as rRNA and the rest output as non-rRNAs;\n                        both: both non-rRNA and rRNA prediction with high confidence;\n                        none: give label based on the mean probability of read pair.\n                              (Only applicable for paired end reads, discard the read pair when their predicitons are discordant)\n  -t THREADS, --threads THREADS\n                        number of threads to use. (default: 20)\n  --chunk_size CHUNK_SIZE\n                        chunk_size * 1024 reads to load each time.\n                        When chunk_size=1000 and threads=20, consumming ~20G memory, better to be multiples of the number of threads..\n  --log LOG             Log file name\n  -v, --version         Show program's version number and exit\n```\n\n**Note**: RiboDetector uses multiprocessing with shared memory, thus the memory use of a single process indicated in `htop` or `top` is actually the total memory used by RiboDector. Some job submission system like SGE mis-calculated the total memory use by adding up the memory use of all process. If you see this do not worry it will cause out of memory issue. \n\n<!-- ### Benchmarks\n\nWe benchmarked five different rRNA detection methods including RiboDetector on 8 benchmarking datasets as following: \n\n- 20M paired end reads simulated based on  rRNA sequences from Silva database, those sequences are distinct from sequences used for training and validation.\n\n- 20M paired end reads simulated based on 500K CDS sequences from OMA databases.\n\n- 27,206,792 paired end reads simulated based on 13,848 viral gene sequences downloaded from ENA database.\n\n- 7,917,920 real paired end amplicon sequencing reads targeting V1-V2 region  of  16s rRNA genes from oral microbiome study.\n\n- 6,330,381 paired end reads simulated from 106,880 human noncoding RNA sequences.\n\n- OMA_Silva dataset in figure C contains 1,027,675 paired end reads simulated on CDS sequences which share similarity to rRNA genes, the sequences with identity >=98% and query coverage >=90% to rRNAs were excluded.\n\n- HOMD dataset in figure C has 100,558 paired end reads simulated on CDS sequences from HOMD database which share similarity to the FP sequences of three tools, again sequences with identity >=98% and query coverage >=90% to rRNAs were excluded.\n\n- GO_FP_N_02 in figure C consisting of 678,250 paired end reads was simulated from OMA sequences which have the GO with FP reads ratio >=0.2 on 20M mRNA reads dataset for BWA, RiboDetector or SortMeRNA.\n\n![Benchmarking the performance and runtime of different rRNA sequences detection methods](./benchmarks/benchmarks.jpg)\n\nIn the above figures, the definitions of *FPNR* and *FNR* are:\n\n<img src=\"https://render.githubusercontent.com/render/math?math=\\large FPNR=100\\frac{false \\:predictions}{total \\: sequences}\">\n\n<img src=\"https://render.githubusercontent.com/render/math?math=\\large FNR=100\\frac{false \\:negatives}{total \\:positives}\">\n\nRiboDetector has a very high generalization ability and is capable of detecting novel rRNA sequences (Fig. C). -->\n\n### FAQ\n1. What should I set for `-l` when I have reads with variable length?\n> You can set the `-l` parameter to the mean read length if you have reads with variable length. The mean read length can be computed with `seqkit stats`. This parameter tells how many bases will be used to capture the sequences patterns for classification.  \n\n2. How does `-e` parameter work? What should I set (`rrna`, `norrna`, `none`, `both`)?\n> This parameter is only necessary for paired end reads. When setting to `rrna`, the paired read ends will be predicted as rRNA only if both ends were classified as rRNA. If you want to identify or remove rRNAs with high confidence, you should set it to `rrna`. Conversely, `norrna` will predict the read pair as nonrRNA only if both ends were classified as nonrRNA. This setting will only output nonrRNAs with high confidence. `both` will discard the read pairs with two ends classified inconsistently, only pairs with concordant prediction will be reported in the corresponding output. `none` will take the mean of the probabilities of both ends and decide the final prediction. This is also the default setting. \n\n3. I have very large input file but limited memory, what should I do?\n> You can set the `--chunk_size` parameter which specifies how many reads the software load into memory once.\n\n4. What should I do if RiboDetector hangs with SLURM?\n> The most likely cause is that the requested computational resource is not sufficient for the input file. You need to make sure you specified `--cpus-per-task` to the number you CPU cores you want to use and set `--threads-per-core` to 1 in the SLURM submission script or command. If the issue remains, you can try to reduce the memory use by setting `--chunk_size` parameter in `ribodetector` or `ribodetector_cpu` command.\n\n### Citation\nDeng ZL, Münch PC, Mreches R, McHardy AC. Rapid and accurate detection of ribosomal RNA sequences using deep learning. <i>Nucleic Acids Research</i>. 2022. (https://doi.org/10.1093/nar/gkac112)\n\n### Acknowledgements\nThe scripts from the `base` dir were from the template [pytorch-template\n](https://github.com/victoresque/pytorch-template) by [Victor Huang](https://github.com/victoresque) and other [contributors](https://github.com/victoresque/pytorch-template/graphs/contributors).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/rtlola-frontend",
            "repo_link": "https://github.com/reactive-systems/RTLola-Frontend",
            "readme": "# RTLola Frontend\n[![Crate](https://img.shields.io/crates/v/rtlola-frontend.svg)](https://crates.io/crates/rtlola-frontend)\n[![API](https://docs.rs/rtlola-frontend/badge.svg)](https://docs.rs/rtlola-frontend)\n[![License](https://img.shields.io/crates/l/rtlola-frontend)](https://crates.io/crates/rtlola-frontend)\n\nRTLola is a stream-based runtime verification framework.  It parses an RTLola specification, analyses it, and generates executable monitors for it.\nThe framework is separated into a front-end and several back-ends.\n\nThis crate summarizes the entire RTLola front-end, which includes several sub-modules:\n* A parser for RTLola specifications: [rtlola-parser](https://crates.io/crates/rtlola-parser) \n* The RTLola high-level intermediate representation including a strong static analysis: [rtlola-hir](https://crates.io/crates/rtlola-hir)\n* The RTLola error reporting: [rtlola-reporting](https://crates.io/crates/rtlola-reporting)\n* Procedural macros: [rtlola-macros](https://crates.io/crates/rtlola-macros)\n\n# Copyright\n\nCopyright (C) CISPA - Helmholtz Center for Information Security 2021-2023.  Authors: Jan Baumeister, Florian Kohn, Stefan Oswald, Frederik Scheerer, Malte Schledjewski, Maximilian Schwenger.\nBased on original work at Universität des Saarlandes (C) 2020.  Authors: Jan Baumeister, Florian Kohn, Malte Schledjewski, Maximilian Schwenger, Marvin Stenger, and Leander Tentrup.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/rtlola-interpreter",
            "repo_link": "https://github.com/reactive-systems/RTLola-Interpreter",
            "readme": "![RTLola logo](https://pages.cispa.de/rtlola/assets/img/logos/rtlola-logo-ultrawide-blue.png)\n# RTLola Interpreter Repository\n\nRTLola is a runtime monitoring framework.  It consists of a parser, analyzer, and interpreter for the RTLola specification language.\n\nThe project is split into two crates. The interpreter crate provides a library for interpreting RTLola specifications.\nThe CLI crate provides a command line interface to the interpreter.\n\n## RTLola Interpreter\n[![Crate](https://img.shields.io/crates/v/rtlola-interpreter.svg)](https://crates.io/crates/rtlola-interpreter)\n[![API](https://docs.rs/rtlola-interpreter/badge.svg)](https://docs.rs/rtlola-interpreter)\n[![License](https://img.shields.io/crates/l/rtlola-interpreter)](https://crates.io/crates/rtlola-interpreter)\n\nThis library crate provides two APIs to evaluate RTLola specifications through interpretation.\n\n## RTLola Interpreter Input Plugins\n[![Crate](https://img.shields.io/crates/v/rtlola-input-plugins.svg)](https://crates.io/crates/rtlola-input-plugins)\n[![API](https://docs.rs/rtlola-input-plugins/badge.svg)](https://docs.rs/rtlola-input-plugins)\n[![License](https://img.shields.io/crates/l/rtlola-input-plugins)](https://crates.io/crates/rtlola-input-plugins)\n\nThis crate contains the different input methods like the csv and pcap parser for the interpreter.\n\n## RTLola Interpreter CLI\n[![Crate](https://img.shields.io/crates/v/rtlola-cli.svg)](https://crates.io/crates/rtlola-cli)\n[![API](https://docs.rs/rtlola-cli/badge.svg)](https://docs.rs/rtlola-cli)\n[![License](https://img.shields.io/crates/l/rtlola-cli)](https://crates.io/crates/rtlola-cli)\n\nThis crate contains a CLI interface to the interpreter capable of reading csv and pcap files.\n\n# Copyright\n\nCopyright (C) CISPA - Helmholtz Center for Information Security 2024.  Authors: Jan Baumeister, Florian Kohn, Stefan Oswald, Frederik Scheerer, Maximilian Schwenger.\nBased on original work at Universität des Saarlandes (C) 2020.  Authors: Jan Baumeister, Florian Kohn, Malte Schledjewski, Maximilian Schwenger, Marvin Stenger, and Leander Tentrup.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/s2downloader",
            "repo_link": "https://git.gfz-potsdam.de/fernlab/products/data-portal/s2downloader",
            "readme": "======================\n|s2logo| S2Downloader\n======================\n\n.. |s2logo| image:: https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/s2downloader/images/s2downloader_logo.svg\n  :target: https://git.gfz-potsdam.de/fernlab/products/data-portal/s2downloader\n  :width: 50px\n\n* Free software: EUPL 1.2\n* **Documentation:** https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/s2downloader/doc/\n* Information on how to **cite the S2Downloader Python package** can be found in the\n  `CITATION <https://git.gfz-potsdam.de/fernlab/products/data-portal/s2downloader/-/blob/main/CITATION>`__ file.\n* Submit feedback by filing an issue `here <https://git.gfz-potsdam.de/fernlab/products/data-portal/s2downloader/issues>`__\n\n===============================\nDownloader for Sentinel-2 data.\n===============================\n\n.. image:: https://git.gfz-potsdam.de/fernlab/products/data-portal/s2downloader/badges/main/pipeline.svg\n        :target: https://git.gfz-potsdam.de/fernlab/products/data-portal/s2downloader/pipelines\n        :alt: Pipelines\n.. image:: https://git.gfz-potsdam.de/fernlab/products/data-portal/s2downloader/badges/main/coverage.svg\n        :target: https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/s2downloader/coverage/\n        :alt: Coverage\n.. image:: https://img.shields.io/static/v1?label=Documentation&message=GitLab%20Pages&color=orange\n        :target: https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/s2downloader/doc/\n        :alt: Documentation\n.. image:: https://zenodo.org/badge/832612594.svg\n        :target: https://zenodo.org/doi/10.5281/zenodo.13123060\n        :alt: DOI\n\n\nFeature overview\n----------------\n\nThe **S2Downloader** allows to download Sentinel-2 L2A data from the cost-free `element84 AWS <https://registry.opendata.aws/sentinel-2-l2a-cogs/>`_ Amazon Cloud server. It specifically serves the purpose to download data for user-defined area of interests (AOI), defined by a bounding box or whole tiles which are the original data product provided by ESA.\n\nFeatures\n########\n\n**Features on Sentinel-2 tile level**\n\n* download atmospheric corrected L2A Sentinel-2 thumbnail, overview, and data from AWS\n* provide single date or time range for finding data at the server\n* select which individual bands to download, all bands are supported: ``\"coastal\"``, ``\"blue\"``, ``\"green\"``, ``\"red\"``, ``\"rededge1\"``, ``\"rededge2\"``, ``\"rededge3\"``, ``\"nir\"``, ``\"nir08\"``, ``\"nir09\"``, ``\"cirrus\"``, ``\"swir16\"``, ``\"swir22\"``\n* provide UTM zone, latitude band and grid square to download whole tiles\n\n\n**Features on AOI level**\n\n* input data: configuration json file\n* customizable filtering for noData\n* optional: customizable mask SCL classes (default masked classes: clouds shadow, clouds, cirrus -> 3, 7, 8, 9, 10), all available classes:\n\n  * 0 - No data\n  * 1 - Saturated / Defective\n  * 2 - Dark Area Pixels\n  * 3 - Cloud Shadows\n  * 4 - Vegetation\n  * 5 - Bare Soils\n  * 6 - Water\n  * 7 - Clouds low probability / Unclassified\n  * 8 - Clouds medium probability\n  * 9 - Clouds high probability\n  * 10 - Cirrus\n  * 11 - Snow / Ice\n\n\n* mosaic data from different tiles (same utm zone) into one tif file\n* resample bands to user-defined target resolution\n* select resampling method\n\n**Features for saving the results**\n\n* define output location\n* save thumbnails for the available scenes\n* save overviews for the available scenes\n\n\nInstallation\n------------\n\n`Install <https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/s2downloader/doc/installation.html>`_ S2Downloader\n\n\nUsage\n-----\n\nRun with relative or absolute path to config json file:\n::\n\n    S2Downloader --filepath \"path/to/config.json\"\n\nRelative paths in the config file are supposed to be relative to the location of the repository.\n\nSee `usage <https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/s2downloader/doc/usage.html>`_ for more details about the config file.\n\nExpected Output\n---------------\n\nThe downloaded raster files and overviews are saved in .tif format, the thumbnails are saved as .jpg. Additional information is saved in a.json and a logging file.\n\nSee `usage <https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/s2downloader/doc/usage.html>`_ for more details about the output files.\n\nHistory / Changelog\n-------------------\n\nYou can find the protocol of recent changes in the S2Downloader package\n`here <https://git.gfz-potsdam.de/fernlab/products/data-portal/s2downloader/-/blob/main/HISTORY.rst>`__.\n\n\nContribution\n------------\n\nContributions are always welcome. Please contact us, if you wish to contribute to the S2Downloader.\n\n\nDeveloped by\n------------\n\n.. image:: https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/s2downloader/images/fernlab_logo.svg\n  :target: https://fernlab.gfz-potsdam.de/\n  :width: 10 %\n\nS2Downloader has been developed by `FERN.Lab <https://fernlab.gfz-potsdam.de/>`_, the Helmholtz Innovation Lab \"Remote sensing for sustainable use of resources\", located at the `Helmholtz Centre Potsdam, GFZ German Research Centre for Geosciences <https://www.gfz-potsdam.de/en/>`_. FERN.Lab is funded by the `Initiative and Networking Fund of the Helmholtz Association <https://www.helmholtz.de/en/about-us/structure-and-governance/initiating-and-networking/>`_.\n\n\nCredits\n------------\n\nThis package was created with Cookiecutter_ and the `fernlab/cookiecutter-pypackage`_ project template.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`fernlab/cookiecutter-pypackage`: https://github.com/fernlab/cookiecutter-pypackage\n.. _coverage: https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/sentinel2_portal/coverage/\n.. _pytest: https://fernlab.git-pages.gfz-potsdam.de/products/data-portal/sentinel2_portal/test_reports/report.html\n.. _default_config.json: https://git.gfz-potsdam.de/fernlab/products/data-portal/s2downloader/-/blob/main/data/default_config.json\n\n",
            "project_id": "2637"
        },
        {
            "software_organization": "https://helmholtz.software/software/sampledb",
            "repo_link": "https://github.com/sciapp/sampledb",
            "readme": "<img src=\"https://raw.githubusercontent.com/sciapp/sampledb/develop/docs/static/img/logo.svg\" align=\"right\" width=\"60\" height=\"60\" />\n\n# SampleDB\n\n[![MIT license](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n[![DOI](https://zenodo.org/badge/221237572.svg)](https://zenodo.org/badge/latestdoi/221237572)\n[![DOI](https://joss.theoj.org/papers/10.21105/joss.02107/status.svg)](https://doi.org/10.21105/joss.02107)\n\nSampleDB is a web-based sample and measurement metadata database.\n\n## Documentation\n\nYou can find the documentation for the current release at https://scientific-it-systems.iffgit.fz-juelich.de/SampleDB/.\n\n## Getting Started\n\nWe recommend using our pre-built Docker images for setting up `SampleDB`. You will need two containers, one for a PostgreSQL database and another for SampleDB itself, and a directory to store all files in.\n\nIf you would like to set up a development version of SampleDB instead, please see the [contribution guide](https://github.com/sciapp/sampledb/blob/develop/CONTRIBUTING.md).\n\nIf you do not have Docker installed yet, please [install Docker](https://docs.docker.com/engine/install/).\n\n### Using docker-compose\n\nFirst, get the [docker-compose.yml](https://raw.githubusercontent.com/sciapp/sampledb/develop/docker-compose.yml.dist) configuration file. You can git clone this repo or just get the file:\n\n```bash\ncurl https://raw.githubusercontent.com/sciapp/sampledb/develop/docker-compose.yml.dist --output docker-compose.yml\n```\n\nThen simply bring everything up with:\n\n```bash\ndocker compose up -d\n```\n\n### Using docker commands\n\nFirst, start your database container:\n\n```bash\ndocker run \\\n    -d \\\n    -e POSTGRES_PASSWORD=password \\\n    -e PGDATA=/var/lib/postgresql/data/pgdata \\\n    -v `pwd`/pgdata:/var/lib/postgresql/data/pgdata:rw \\\n    --restart=always \\\n    --name sampledb-postgres \\\n    postgres:15\n```\n\nNext, start the SampleDB container:\n\n```bash\ndocker run \\\n    -d \\\n    --link sampledb-postgres \\\n    -e SAMPLEDB_CONTACT_EMAIL=sampledb@example.com \\\n    -e SAMPLEDB_MAIL_SERVER=mail.example.com \\\n    -e SAMPLEDB_MAIL_SENDER=sampledb@example.com \\\n    -e SAMPLEDB_ADMIN_PASSWORD=password \\\n    -e SAMPLEDB_SQLALCHEMY_DATABASE_URI=postgresql+psycopg2://postgres:password@sampledb-postgres:5432/postgres \\\n    --restart=always \\\n    --name sampledb \\\n    -p 8000:8000 \\\n    sciapp/sampledb:0.30.0\n```\n\n### Once it's started\n\nThis will start a minimal SampleDB installation at `http://localhost:8000` and allow you to sign in with the username `admin` and the password `password` (which you should change immediately after signing in).\n\nTo learn how to further set up SampleDB, please follow the rest of the [Getting Started guide](https://scientific-it-systems.iffgit.fz-juelich.de/SampleDB/administrator_guide/getting_started.html).\n\n## Contributing\n\nIf you want to improve SampleDB, please read the [contribution guide](https://github.com/sciapp/sampledb/blob/develop/CONTRIBUTING.md) for a few notes on how to report issues or submit changes.\n\n## Support\n\nIf you run into any issues setting up or running SampleDB, please [open an issue on GitHub](https://github.com/sciapp/sampledb/issues/new).\n\nYou can also subscribe to the [SampleDB mailing list](https://lists.fz-juelich.de/mailman/listinfo/sampledb) to learn about new features and to discuss any questions regarding SampleDB.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/saqc",
            "repo_link": "https://git.ufz.de/rdm-software/saqc",
            "readme": "<!--\nSPDX-FileCopyrightText: 2021 Helmholtz-Zentrum für Umweltforschung GmbH - UFZ\n\nSPDX-License-Identifier: GPL-3.0-or-later\n-->\n\n<br>\n<div align=\"center\">\n  <img src=\"https://git.ufz.de/rdm-software/saqc/raw/develop/docs/resources/images/representative/SaQCLogo.png\" width=\"300\">\n</div>\n\n-----------------\n[![Project Status: Active – The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)\n\n#  SaQC: System for automated Quality Control\n\n`SaQC` is a tool/framework/application to quality control time series data.\nIt provides\na growing collection of algorithms and methods to analyze, annotate and\nprocess timeseries data. It supports the end to end enrichment of metadata\nand provides various user interfaces: 1) a Python API, 2) a command line interface\nwith a text based configuration system and a\n[web based user interface](https://webapp.ufz.de/saqc-config-app/)\n\n`SaQC` is designed with a particular focus on the needs of active data professionals,\nincluding sensor hardware-oriented engineers, domain experts, and data scientists,\nall of whom can benefit from its capabilities to improve the quality standards of given data products.\n\nFor a (continously improving) overview of features, typical usage patterns,\nthe specific system components and how to customize `SaQC` to your own\nneeds, please refer to our\n[online documentation](https://rdm-software.pages.ufz.de/saqc/index.html).\n\n\n## Installation\n\n`SaQC` is available on the Python Package Index ([PyPI](https://pypi.org/)) and\ncan be installed using [pip](https://pip.pypa.io/en/stable/):\n```sh\npython -m pip install saqc\n```\nAdditionally `SaQC` is available via conda and can be installed with:\n\n```sh\nconda create -c conda-forge -n saqc saqc\n```\n\nFor more details, see the [installation guide](https://rdm-software.pages.ufz.de/saqc/gettingstarted/InstallationGuide.html).\n\n\n## Usage\n\n`SaQC` is both, a command line application controlled by a text based configuration\nand a python module with a simple API.\n\n### SaQC as a command line application\nThe command line application is controlled by a semicolon-separated text\nfile listing the variables in the dataset and the routines to inspect,\nquality control and/or process them. The content of such a configuration\ncould look like [this](https://git.ufz.de/rdm-software/saqc/raw/develop/docs/resources/data/config.csv):\n\n```\nvarname    ; test\n#----------; ---------------------------------------------------------------------\nSM2        ; align(freq=\"15Min\")\n'SM(1|2)+' ; flagMissing()\nSM1        ; flagRange(min=10, max=60)\nSM2        ; flagRange(min=10, max=40)\nSM2        ; flagZScore(window=\"30d\", thresh=3.5, method='modified', center=False)\nDummy      ; flagGeneric(field=[\"SM1\", \"SM2\"], func=(isflagged(x) | isflagged(y)))\n```\n\nAs soon as the basic inputs, dataset and configuration file, are\nprepared, run `SaQC`:\n```sh\nsaqc \\\n    --config PATH_TO_CONFIGURATION \\\n    --data PATH_TO_DATA \\\n    --outfile PATH_TO_OUTPUT\n```\n\nA full `SaQC` run against provided example data can be invoked with:\n```sh\nsaqc \\\n    --config https://git.ufz.de/rdm-software/saqc/raw/develop/docs/resources/data/config.csv \\\n    --data https://git.ufz.de/rdm-software/saqc/raw/develop/docs/resources/data/data.csv \\\n    --outfile saqc_test.csv\n```\n\n### SaQC as a python module\n\nThe following snippet implements the same configuration given above through\nthe Python-API:\n\n```python\nimport pandas as pd\nfrom saqc import SaQC\n\ndata = pd.read_csv(\n    \"https://git.ufz.de/rdm-software/saqc/raw/develop/docs/resources/data/data.csv\",\n    index_col=0, parse_dates=True,\n)\n\nqc = SaQC(data=data)\nqc = (qc\n      .align(\"SM2\", freq=\"15Min\")\n      .flagMissing(\"SM(1|2)+\", regex=True)\n      .flagRange(\"SM1\", min=10, max=60)\n      .flagRange(\"SM2\", min=10, max=40)\n      .flagZScore(\"SM2\", window=\"30d\", thresh=3.5, method='modified', center=False)\n      .flagGeneric(field=[\"SM1\", \"SM2\"], target=\"Dummy\", func=lambda x, y: (isflagged(x) | isflagged(y))))\n```\n\nA more detailed description of the Python API is available in the\n[respective section](https://rdm-software.pages.ufz.de/saqc/gettingstarted/TutorialAPI.html)\nof the documentation.\n\n## Get involved\n\n### Contributing\nYou found a bug or you want to suggest new features? Please refer to our [contributing guidelines](CONTRIBUTING.md) to see how you can contribute to SaQC.\n\n### User support\nIf you need help or have questions, send us an email to [saqc-support@ufz.de](mailto:saqc-support@ufz.de)\n\n## Copyright and License\nCopyright(c) 2021, [Helmholtz-Zentrum für Umweltforschung GmbH -- UFZ](https://www.ufz.de). All rights reserved.\n\n- Documentation: [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/) <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/80x15.png\" /></a>\n- Source code: [GNU General Public License 3](https://www.gnu.org/licenses/gpl-3.0.html)\n\nFor full details, see [LICENSE](LICENSE.md).\n\n## Publications\n> Lennart Schmidt, David Schäfer, Juliane Geller, Peter Lünenschloss, Bert Palm, Karsten Rinke, Corinna Rebmann, Michael Rode, Jan Bumberger, System for automated Quality Control (SaQC) to enable traceable and reproducible data streams in environmental science, Environmental Modelling & Software, 2023, 105809, ISSN 1364-8152, https://doi.org/10.1016/j.envsoft.2023.105809. (https://www.sciencedirect.com/science/article/pii/S1364815223001950)\n\n## How to cite SaQC\nIf SaQC is advancing your research, please cite as:\n\n> Schäfer, David, Palm, Bert, Lünenschloß, Peter, Schmidt, Lennart, & Bumberger, Jan. (2023). System for automated Quality Control - SaQC (2.3.0). Zenodo. https://doi.org/10.5281/zenodo.5888547\n\nor\n\n> Lennart Schmidt, David Schäfer, Juliane Geller, Peter Lünenschloss, Bert Palm, Karsten Rinke, Corinna Rebmann, Michael Rode, Jan Bumberger, System for automated Quality Control (SaQC) to enable traceable and reproducible data streams in environmental science, Environmental Modelling & Software, 2023, 105809, ISSN 1364-8152, https://doi.org/10.1016/j.envsoft.2023.105809. (https://www.sciencedirect.com/science/article/pii/S1364815223001950)\n\n-----------------\n\n<a href=\"https://www.ufz.de/index.php?en=33573\">\n    <img src=\"https://git.ufz.de/rdm-software/saqc/raw/develop/docs/resources/images/representative/UFZLogo.png\" width=\"400\"/>\n</a>\n\n<a href=\"https://www.ufz.de/index.php?en=45348\">\n    <img src=\"https://git.ufz.de/rdm-software/saqc/raw/develop/docs/resources/images/representative/RDMLogo.png\" align=\"right\" width=\"220\"/>\n</a>\n",
            "project_id": "1535"
        },
        {
            "software_organization": "https://helmholtz.software/software/scalasca",
            "repo_link": "https://gitlab.jsc.fz-juelich.de/perftools/scalasca",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/scanpy",
            "repo_link": "https://github.com/scverse/scanpy",
            "readme": "[![Stars](https://img.shields.io/github/stars/scverse/scanpy?style=flat&logo=GitHub&color=yellow)](https://github.com/scverse/scanpy/stargazers)\n[![PyPI](https://img.shields.io/pypi/v/scanpy?logo=PyPI)](https://pypi.org/project/scanpy)\n[![Downloads](https://static.pepy.tech/badge/scanpy)](https://pepy.tech/project/scanpy)\n[![Conda](https://img.shields.io/conda/dn/conda-forge/scanpy?logo=Anaconda)](https://anaconda.org/conda-forge/scanpy)\n[![Docs](https://readthedocs.com/projects/icb-scanpy/badge/?version=latest)](https://scanpy.readthedocs.io)\n[![Build Status](https://dev.azure.com/scverse/scanpy/_apis/build/status/scverse.scanpy?branchName=main)](https://dev.azure.com/scverse/scanpy/_build)\n[![Discourse topics](https://img.shields.io/discourse/posts?color=yellow&logo=discourse&server=https%3A%2F%2Fdiscourse.scverse.org)](https://discourse.scverse.org/)\n[![Chat](https://img.shields.io/badge/zulip-join_chat-%2367b08f.svg)](https://scverse.zulipchat.com)\n[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](https://numfocus.org/)\n\n# Scanpy – Single-Cell Analysis in Python\n\nScanpy is a scalable toolkit for analyzing single-cell gene expression data\nbuilt jointly with [anndata][].  It includes\npreprocessing, visualization, clustering, trajectory inference and differential\nexpression testing.  The Python-based implementation efficiently deals with\ndatasets of more than one million cells.\n\nDiscuss usage on the scverse [Discourse][]. Read the [documentation][].\nIf you'd like to contribute by opening an issue or creating a pull request, please take a look at our [contribution guide][].\n\n[anndata]: https://anndata.readthedocs.io\n[discourse]: https://discourse.scverse.org/\n[documentation]: https://scanpy.readthedocs.io\n\n[//]: # (numfocus-fiscal-sponsor-attribution)\n\nscanpy is part of the scverse project ([website](https://scverse.org), [governance](https://scverse.org/about/roles)) and is fiscally sponsored by [NumFOCUS](https://numfocus.org/).\nIf you like scverse and want to support our mission, please consider making a [donation](https://numfocus.org/donate-to-scverse) to support our efforts.\n\n<div align=\"center\">\n<a href=\"https://numfocus.org/project/scverse\">\n  <img\n    src=\"https://raw.githubusercontent.com/numfocus/templates/master/images/numfocus-logo.png\"\n    width=\"200\"\n  >\n</a>\n</div>\n\n\n## Citation\n\nIf you use `scanpy` in your work, please cite the `scanpy` publication as follows:\n\n> **SCANPY: large-scale single-cell gene expression data analysis**\n>\n> F. Alexander Wolf, Philipp Angerer, Fabian J. Theis\n>\n> _Genome Biology_ 2018 Feb 06. doi: [10.1186/s13059-017-1382-0](https://doi.org/10.1186/s13059-017-1382-0).\n\nYou can cite the scverse publication as follows:\n\n> **The scverse project provides a computational ecosystem for single-cell omics data analysis**\n>\n> Isaac Virshup, Danila Bredikhin, Lukas Heumos, Giovanni Palla, Gregor Sturm, Adam Gayoso, Ilia Kats, Mikaela Koutrouli, Scverse Community, Bonnie Berger, Dana Pe’er, Aviv Regev, Sarah A. Teichmann, Francesca Finotello, F. Alexander Wolf, Nir Yosef, Oliver Stegle & Fabian J. Theis\n>\n> _Nat Biotechnol._ 2023 Apr 10. doi: [10.1038/s41587-023-01733-8](https://doi.org/10.1038/s41587-023-01733-8).\n\n\n[contribution guide]: CONTRIBUTING.md\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/scits",
            "repo_link": "https://github.com/jalalmostafa/SciTS",
            "readme": "# SciTS v2, 2023 update\n\nA tool to benchmark Time-series on different databases\n\n- reworked architecture\n- adds mixed, online workloads\n- adds regular and irregular ingestion modes.\n- adds multiple values per time series (\"Dimensions\")\n- adds limited queries\n- adds CLI arguments\n- adds ClientLatency metric to measure differences in local processing.\n\nfor questions on these features, please contact info@saninfo.de\n\nRequires .NET 7.x cross-platform framework.\n\n## Citation \n\n[![DOI](https://zenodo.org/badge/429005385.svg)](https://zenodo.org/badge/latestdoi/429005385)\n\nPlease cite our work:\n\n> Jalal Mostafa, Sara Wehbi, Suren Chilingaryan, and Andreas Kopmann. 2022. SciTS: A Benchmark for Time-Series Databases in Scientific Experiments and Industrial Internet of Things. In 34th International Conference on Scientific and Statistical Database Management (SSDBM 2022). Association for Computing Machinery, New York, NY, USA, Article 12, 1–11. https://doi.org/10.1145/3538712.3538723\n\n\n### Bibtex\n\n```bibtex\n@inproceedings{10.1145/3538712.3538723,\n    author = {Mostafa, Jalal and Wehbi, Sara and Chilingaryan, Suren and Kopmann, Andreas},\n    title = {SciTS: A Benchmark for Time-Series Databases in Scientific Experiments and Industrial Internet of Things},\n    year = {2022},☺\n    isbn = {9781450396677},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    url = {https://doi.org/10.1145/3538712.3538723},\n    doi = {10.1145/3538712.3538723},\n    abstract = {Time-series data has an increasingly growing usage in Industrial Internet of Things (IIoT) and large-scale scientific experiments. Managing time-series data needs a storage engine that can keep up with their constantly growing volumes while providing an acceptable query latency. While traditional ACID databases favor consistency over performance, many time-series databases with novel storage engines have been developed to provide better ingestion performance and lower query latency. To understand how the unique design of a time-series database affects its performance, we design SciTS, a highly extensible and parameterizable benchmark for time-series data. The benchmark studies the data ingestion capabilities of time-series databases especially as they grow larger in size. It also studies the latencies of 5 practical queries from the scientific experiments use case. We use SciTS to evaluate the performance of 4 databases of 4 distinct storage engines: ClickHouse, InfluxDB, TimescaleDB, and PostgreSQL.},\n    booktitle = {Proceedings of the 34th International Conference on Scientific and Statistical Database Management},\n    articleno = {12},\n    numpages = {11},\n    keywords = {time-series databases, database management systems, industrial internet of things, scientific experiments, sensor data, time-series},\n    location = {Copenhagen, Denmark},\n    series = {SSDBM '22}\n}\n```\n\n# How to run\n\n1. Create your workload as `App.config` (case-sensitive) in `BenchmarkTool`.\n2. Edit the connection strings to your database servers in the workload file.\n3. Choose the target database in the workload file using `TargetDatabase` element.\n4. run `dotnet run --project BenchmarkTool write` if it's an ingestion workload,\nand `dotnet run --project BenchmarkTool read` if it's a query workload.\nx. Use `Scripts/ccache.sh <database-service-name>` to clear the cache between query tests.\n\n## Additional Command Line options:\n\n`dotnet run --project BenchmarkTool [action] [regular/irregular] [DatabaseNameDB]`\n\nAvailable Actions:\n\n* read: start the specified retrieval and aggregation workloads.\n* write: start the ingestion across specified batchsize, number of clients, dimensions.\n* mixed-AggQueries: start the online, mixed workload benchmark as a mixture of aggregated quieries and Ingestion-Parameters\n* mixed-LimitedQueries: start the online, mixed workload benchmark as a mixture of queried and ingested datapoints according the specified percentage parameter and the requested Ingestion-Parameters. E.g. 100% means that as much datapoints are retrieved as ingested.\n\n\n## System Metrics using Glances\n\nThis tool uses [glances](https://github.com/nicolargo/glances/).\n1. Install glances with all plugins on the database server using `pip install glances[all]`\n2. Run glances REST API on the database server using `glances -w --disable-webui`\n\n## Workload Definition Files\n\nyou can open Default-App.config edit it and save it as App.config.\nIt has following content:\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n\n<configuration>\n    <appSettings>\n<!-- Attention: This file \"AppDefault.config\" is to be renamed in \"App.config\", after updating the \"###\" and other fields.  -->\n  \n    <!-- Datalayerts connection settings -->\n        <add key=\"DatalayertsConnection\" value=\"https://datalayerts.com\" />\n        <add key=\"DatalayertsUser\" value=\"###\" />\n        <add key=\"DatalayertsPassword\" value=\"###\" />\n\n    <!-- Postgres connection settings -->\n        <add key=\"PostgresConnection\" value=\"Server=localhost;Port=5432;Database=postgres;User Id=postgres;Password=###;\" />\n\n    <!-- Timescale connection settings -->\n        <add key=\"TimescaleConnection\" value=\"Server=localhost;Port=6432;Database=postgres;User Id=postgres;Password=###;CommandTimeout=300\" />\n\n    <!-- InfluxDB connection settings --> \n        <add key=\"InfluxDBHost\" value=\"http://localhost:8086\" />  \n        <add key=\"InfluxDBToken\" value=\"u7Ek4P5s0Nle61QQF1nNA3ywL1JYZky6rHRXxkPBX5bY4H3YFJ6T4KApWSRhaKNj_kHgx70ZLBowB6Di4t2YXg==\" />\n        <add key=\"InfluxDBBucket\" value=\"scitsdb\" />\n        <add key=\"InfluxDBOrganization\" value=\"scits\" />  \n\n    <!-- Clickhouse connection settings -->\n        <add key=\"ClickhouseHost\" value=\"localhost\" />\n        <add key=\"ClickhousePort\" value=\"9000\" />\n        <add key=\"ClickhouseUser\" value=\"default\" />\n        <add key=\"ClickhouseDatabase\" value=\"default\" />\n \n    <!-- General Settings-->\n          <add key=\"PrintModeEnabled\" value=\"false\" />\n          <add key=\"TestRetries\" value=\"2\" />\n          <add key=\"DaySpan\" value=\"1\" />\n        <!-- Could be: DummyDB,  PostgresDB , DatalayertsDB , ClickhouseDB , TimescaleDB , InfluxDB -->\n          <add key=\"TargetDatabase\" value=\"DummyDB\" />\n          <add key=\"StartTime\" value=\"2022-01-01T00:00:00.00\" />\n          <add key=\"RegularTsScaleMilliseconds\" value=\"1000\" /> \n        <!-- Where to store metrics files: The Programm will split the files in \"[...]Read.csv\" and \"[...]Write.csv\" -->\n          <add key=\"MetricsCSVPath\" value=\"Metrics_Source_Month-Day\" />\n          \n    <!-- System Metrics Options -->\n          <add key=\"GlancesOutput\" value=\"Glances_Source_Month-Day.csv\"/>\n          <add key=\"GlancesUrl\" value=\"http://localhost:61208\" />\n          <add key=\"GlancesDatabasePid\" value=\"1\" />\n          <add key=\"GlancesPeriod\" value=\"1\" />\n          <add key=\"GlancesNIC\" value=\"lo\" />\n          <add key=\"GlancesDisk\" value=\"sda1\" />\n          <add key=\"GlancesStorageFileSystem\" value=\"/\" />\n        <!-- Insert multiple dimensionnrs, e.g.  1,6 ,12 ,50, 100, -->\n          <add key=\"DataDimensionsNrOptions\" value=\"1,6\" />  \n\n    <!-- Read Query Options -->\n        <!-- Could be: Agg, All, RangeQueryRawData, RangeQueryRawAllDimsData, RangeQueryRawLimitedData, RangeQueryRawAllDimsLimitedData  RangeQueryAggData, OutOfRangeQuery, DifferenceAggQuery, STDDevQuery -->\n          <add key=\"QueryType\" value=\"All\" />\n          <add key=\"AggregationIntervalHour\" value=\"1\" />\n          <add key=\"DurationMinutes\" value=\"60\" />\n          <add key=\"SensorsFilter\" value=\"1,2,3,4\" /> <!--  or \"All\" -->\n          <add key=\"SensorID\" value=\"1\" />\n          <add key=\"MaxValue\" value=\"0.9\" />\n          <add key=\"MinValue\" value=\"0.1\" />\n          <add key=\"FirstSensorID\" value=\"1\" />\n          <add key=\"SecondSensorID\" value=\"2\" />\n\n    <!-- Ingestion -->\n        <!-- Could be: regular, irregular -->\n          <add key=\"IngestionType\" value=\"regular\" /> \n        <!-- Coulde be:  33, 100 , 300  -->\n          <add key=\"MixedWLPercentageOptions\" value=\"33, 100,300\" />\n        <!-- Could be: array, column. Array is not fully implemented in all DBMS. -->\n          <add key=\"MultiDimensionStorageType\" value=\"column\" />\n        <!-- 10, 1000, 5000, 10000 , 50000 -->\n          <add key=\"BatchSizeOptions\" value=\" 100 , 1000, 6000 \" />\n        <!-- Number of concurrent clients e.g.(1,8,16) must be less than sensors. BatchSizes will be shared out between the clients -->\n          <add key=\"ClientNumberOptions\" value=\"1 , 8\" />\n          <add key=\"SensorNumber\" value=\"100\" />   \n\n    </appSettings>\n\n</configuration>\n```\n\n### Workload Files\n\nYou can choose from the available workloads by choosing a `*.config` file from `Workloads` folder.\nThe file to workload mapping is as follow:\n\n| Workload    | Workload file                      |\n| ----------- | ---------------------------------- |\n| 2022 WLs    |                                    |\n| ----------- |                                    |\n| Q1          | query-q1.config                    |\n| Q2          | query-q2.config                    |\n| Q3          | query-q3.config                    |\n| Q4          | query-q4.config                    |\n| Q5          | query-q5.config                    |\n| Batching    | ingestion-batching-1client.config  |\n| Concurrency | ingestion-batching-nclients.config |\n| Scaling     | ingestion-scaling.config           |\n|.............|....................................|\n|Collection   |                                    |\n|of 2023 WLs  | test2023.sh                        |\n\n\n#### Timescale\nWe discovered abnormal high latencies and other failures with NPGSQL, so we embedded a python script which does the queries.\nTherefore you need to configure the python location. In case of python 3.10, e.g.\nuse \"whereis libpython3.10.so\", and copy this path.\nThen you go into TimescaleDB.cd, and edit the string in line 134 [ Runtime.PythonDLL = \"/usr/lib/_Architecture_-linux-gnu/libpython3.10.so\"; ]\n\nSo it points to your python location"
        },
        {
            "software_organization": "https://helmholtz.software/software/score-p",
            "repo_link": "https://gitlab.com/score-p/scorep",
            "readme": "",
            "project_id": "41231240"
        },
        {
            "software_organization": "https://helmholtz.software/software/sdaas",
            "repo_link": "https://github.com/rizac/sdaas",
            "readme": "# <img align=\"left\" height=\"30\" src=\"https://www.gfz-potsdam.de/fileadmin/gfz/medien_kommunikation/Infothek/Mediathek/Bilder/GFZ/GFZ_Logo/GFZ-Logo_eng_RGB.svg\"> Sdaas <img align=\"right\" height=\"50\" src=\"https://www.gfz-potsdam.de/fileadmin/gfz/GFZ_Wortmarke_SVG_klein_en_edit.svg\">\n\n|Jump to: | [Installation](#installation) | [Usage](#usage) |  [Maintenance](#maintenance) | [Citation](#citation) |\n| - | - | - | - | - |\n\n<!-- **S**eismic **D**ata (and metadata) **A**mplitude **A**nomaly **S**core -->\n\nSimple, general and flexible tool for the identification of anomalies in \nseismic waveform amplitude, e.g.:\n\n - recording artifacts (e.g., anomalous noise, peaks, gaps, spikes)\n - sensor problems (e.g. digitizer noise)\n - metadata field errors (e.g. wrong stage gain in StationXML)\n\n**For any waveform analyzed, the program computes an amplitude anomaly \nscore in [0, 1] representing \nthe degree of belief of a waveform to be an outlier**. The score\ncan be used:\n - in any processing pipeline to\n   - pre-filter malformed data via a user-defined threshold\n   - assign robustness weights\n - as station installation / metadata checker, exploiting the scores\n   temporal trends. See e.g. Channel (a) in the figure: the abrupt onset/offset of persistently high anomaly scores roughly between March and May 2018 clearly indicates an installation problem that has been fixed\n\n![anomaly_scores_image](https://github.com/rizac/sdaas/blob/6b1dca95f4a5f931874c4aaedd278f4692dc0f96/outlierspaper-img008.png?raw=true)\nAnomaly scores for four different channels (a) to (d). Each dot represents a recorded waveform segment of variable length\n\nNotes:\n\nThis program uses a machine learning algorithm specifically designed\nfor outlier detection (Isolation forest) where\n\n  - scores <= 0.5 can be safely interpreted in all applications as \"no significant anomaly\" (see Isolation Forest original paper - Liu et al. 2008 - for theoretical details)\n    \n  - extreme score values are virtually impossible [by design](https://scikit-learn.org/stable/modules/calibration.html).\n    This has to be considered when setting a user defined threshold T to \n    discard malformed waveforms. In many application, setting T between 0.7 and \n    0.75 has proven to be a good compromise between \n    [precision and recall (F1 score)](https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics)\n\n  - (Disclaimer) \"False positives\", i.e. relatively high anomaly scores even for well formed recordings have been sometimes observed in two specific cases: \n    \n      - recordings from stations with extremely and abnormaly low noise level (e.g. borhole installations)\n      - recordings containing strong and close earthquakes. This is not a problem to check metadata errors, as the scores trend of several recordings from a given sensor / station will not be affected (except maybe for few sparse slightly higer scores), but has to be considered when filtering out segments in specific studies (e.g. with strong motion data): in this cases, setting a higher threshold is advisable. A model trained for accelerometers only (usually employed with these kind of recordings) is under study\n   \n<!--\n<img align=\"right\" width=\"27%\" src=\"outlierspaper-img004.png\"><img align=\"right\"  width=\"29%\" src=\"outlierspaper-img005.png\">\n\nSimple program to compute amplitude anomaly scores (in [0, 1]) of seismic \ndata and metadata.\nGiven a set of waveforms and their metadata, it removes the waveform response\nand returns the anomaly score of the waveforms amplitudes.\n\nThis program can be used to filter out a set of malformed waveforms,\nassign robustness weights\nor to check the correctness of the metadata fields (e.g. Station inventory xml)\nby checking the anomaly score on a set of station recordings. \n-->\n\n\n## Installation\n\nAlways work within a virtual environment. From a terminal, in the directory\nwhere you cloned this repository (last argument of `git clone`),\n\n1. create a virtual environment (once). **Be sure you use Python>=3.7 (Type `python3 --version` to check)**:\n\n    ```bash\n    python3 -m venv .env\n    ```\n\n2. activate it (**to be done also every time you use this program**):\n    ```bash\n    source .env/bin/activate\n    ```\n   (then to deactivate, simply type ... `deactivate` on the terminal). \n   \n   Update `pip` and `setuptools` (not mandatory, but in rare cases it\n   could prevent errors during the installation):\n   ```\n   pip install --upgrade pip setuptools\n   ```\n\n3. Install the program (one line command):\n\n    with [requirements file](https://pip.pypa.io/en/stable/user_guide/#requirements-files):\n    ```\n    pip install -r ./requirements.txt && pip install -e .\n    ```\n    \n    or standard (use this mainly if you install sdaas on an already existing \n    virtualenv and you are concerned about breaking existing code):\n    \n    ```\n    pip install \"numpy>=1.15.4\" && pip install -e .\n    ```\n    \n    Notes:\n    \n    - The \"standard\" install actually checks the `setup.py` file \n      and avoids overwriting libraries already matching the required version. \n      The downside is that you might use library version that were not tested\n    \n    - `-e` is optional. With -e, you can update the installed program to the \n      latest release by simply issuing a `git pull`\n      \n    - although used to train, test and generate the underlying model,\n      `scikit learn` is not required for Security & maintainability \n      limitations. If you want to install it, type \n      `pip install scikit-learn>=0.21.3` or, in the\n      standard installation you can include scikit learn\n      with `pip install .[dev]` instead of `pip install .`\n\n      <details>\n      <summary>Reported scikit learn installation problems (click for details)</summary>\n      \n      Due to the specific version to be installed,\n      scikit might have problems installing. \n      \n      Few hints here:\n      - you might need to preinstall `cython` (`pip install cython`)\n      - you might need to `brew install libomp`, set the follwing env variables:\n        ```\n        export CC=/usr/bin/clang;export CXX=/usr/bin/clang++;export CPPFLAGS=\"$CPPFLAGS -Xpreprocessor -fopenmp\";export CFLAGS=\"$CFLAGS -I/usr/local/opt/libomp/include\";export CXXFLAGS=\"$CXXFLAGS -I/usr/local/opt/libomp/include\";export LDFLAGS=\"$LDFLAGS -Wl,-rpath,/usr/local/opt/libomp/lib -L/usr/local/opt/libomp/lib -lomp\"\n        ```\n      - and then install with the following flags:\n        ```\n        pip install --verbose --no-build-isolation \"scikit-learn==0.21.3\"\n        ```\n      \n      **(For any further detail, see\n      [scikit-learn installation page](https://scikit-learn.org/dev/developers/advanced_installation.html))**\n      \n      </details>\n\n#### Run tests (optional)\n\n```bash\npython -m unittest -fv\n```\n\n(`-f` is optional and means: stop at first failure, `-v`: verbose)\n\n\n## Usage\n\n`sdaas` can be used as command line application or as library in your Python code\n\n### As command line application\n\nAfter activating your virtual environment (see above) you can access the program as\ncommand line application in your terminal by typing `sdaas`. The application\ncan compute the score(s) of a single miniSEED file, a directory of miniSEED files, or \na FDSN url ([dataselect or station](https://www.fdsn.org/webservices/) url).\n\n**Please type `sdaas --help` for details and usages not covered in the examples below,\nsuch as computing scores from locally stored files**\n\n\n**Examples**\n\nCompute scores of waveforms fetched from a FDSN URL:\n\n```bash\n>>> sdaas \"http://geofon.gfz-potsdam.de/fdsnws/dataselect/1/query?net=GE&sta=EIL&cha=BH?&start=2019-01-01T00:00:00&end=2019-01-01T00:02:00\" -v\n[████████████████████████████████████████████████████████████████████████████████████████████████████████]100%  0d 00:00:00\nid start end anomaly_score\nGE.EIL..BHN 2019-01-01T00:00:09.100 2019-01-01T00:02:12.050 0.45\nGE.EIL..BHE 2019-01-01T00:00:22.350 2019-01-01T00:02:00.300 0.45\nGE.EIL..BHZ 2019-01-01T00:00:02.250 2019-01-01T00:02:03.550 0.45\n```\n*(note: The paremeter `-v` / verbose \nprints additional info before the scores table)*\n\nCompute scores from randomly selected segments of a given station and channel,\nand provide also a user-defined threshold (parameter `-th`) which will also \nappend a column \"class_label\" (1 = outlier - assigned to the scores \ngreater than the threshold and 0 = inlier)\n\n```bash\n>>> sdaas \"http://geofon.gfz-potsdam.de/fdsnws/station/1/query?net=GE&sta=EIL&cha=BH?&start=2019-01-01\" -v -th 0.7\n[██████████████████████████████████████████████████████████]100%  0d 00:00:00\nid start end anomaly_score class_label\nGE.EIL..BHN 2019-01-01T00:00:09.100 2019-01-01T00:02:12.050 0.45 0\nGE.EIL..BHN 2019-10-16T18:48:11.700 2019-10-16T18:51:02.300 0.83 1\nGE.EIL..BHN 2020-07-31T13:37:19.299 2020-07-31T13:39:41.299 0.45 0\nGE.EIL..BHN 2021-05-16T08:25:38.100 2021-05-16T08:28:03.150 0.53 0\nGE.EIL..BHN 2022-03-01T03:14:23.300 2022-03-01T03:17:01.750 0.45 0\nGE.EIL..BHE 2019-01-01T00:00:22.350 2019-01-01T00:02:00.300 0.45 0\nGE.EIL..BHE 2019-10-16T18:48:18.050 2019-10-16T18:51:09.650 0.83 1\nGE.EIL..BHE 2020-07-31T13:37:08.599 2020-07-31T13:39:28.499 0.45 0\nGE.EIL..BHE 2021-05-16T08:25:49.150 2021-05-16T08:28:14.800 0.49 0\nGE.EIL..BHE 2022-03-01T03:14:26.050 2022-03-01T03:16:41.900 0.45 0\nGE.EIL..BHZ 2019-01-01T00:00:02.250 2019-01-01T00:02:03.550 0.45 0\nGE.EIL..BHZ 2019-10-16T18:48:24.800 2019-10-16T18:50:47.300 0.45 0\nGE.EIL..BHZ 2020-07-31T13:37:08.249 2020-07-31T13:39:30.199 0.45 0\nGE.EIL..BHZ 2021-05-16T08:25:47.250 2021-05-16T08:28:10.850 0.47 0\nGE.EIL..BHZ 2022-03-01T03:14:40.800 2022-03-01T03:16:53.900 0.45 0\n```\n\nCompute scores from randomly selected segments of a given station and channel,\nbut aggregating scores per channel and returning their median:\n\n```bash\n>>> sdaas \"http://geofon.gfz-potsdam.de/fdsnws/station/1/query?net=GE&sta=EIL&cha=BH?&start=2019-01-01\" -v -agg median\n[██████████████████████████████████████████████████████████]100%  0d 00:00:00\nid start end median_anomaly_score\nGE.EIL..BHN 2019-01-01T00:00:09.100 2022-03-01T03:17:45.950 0.46\nGE.EIL..BHE 2019-01-01T00:00:22.350 2022-03-01T03:17:48.700 0.45\nGE.EIL..BHZ 2019-01-01T00:00:02.250 2022-03-01T03:17:39.300 0.45\n```\n\nSame as above, but save the scores table to CSV via the parameter `-sep` and\n`>` (normal redirection of the standard output `stdout` to file)\n\n```bash\n>>> sdaas \"http://geofon.gfz-potsdam.de/fdsnws/station/1/query?net=GE&sta=EIL&cha=BH?&start=2019-01-01\" -v -sep \",\" > /path/to/myfile.csv\n[████████████████████████████████████████████████████████████]100%  0d 00:00:00\n```\n*in this case, providing `-v` / verbose will also redirect the header row to\nCSV. Note that only the scores table is output to `stdout`, everything else is \nprinted to `stderr` and thus should still be visible on the terminal, as in the \nexample above*\n\n### As library in your Python code\n\nThis software can also be used as library in Python code (e.g. Jupyter Notebook)\nto work with [ObsPy](https://docs.obspy.org/) objects (ObsPy is already included \nin the installation): assuming you have one or more \n[Stream](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.html)\nor [Trace](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.html),\nwith relative [Inventory](https://docs.obspy.org/packages/obspy.core.inventory.html), \nthen\n\n<!-- IMPORTANT: -->\n<!-- EACH \"```python...```\" code snippet is executed also in \n`test_and_create_code_snippet` to check that it works. If you implement new \nsnippets here, add them in the test file as well -->\n\nCompute the scores in a stream or iterable of traces (e.g. list. tuple, generator),\nreturning the score of each Trace:\n\n```python\nfrom obspy.core.inventory.inventory import read_inventory\nfrom obspy.core.stream import read\n\nfrom sdaas.core import traces_scores\n\n# Load a Stream object and its inventory\n# (use as example the test directory of the package):\nstream = read('./tests/data/GE.FLT1..HH?.mseed')\ninventory = read_inventory('./tests/data/GE.FLT1.xml')\n\n# Compute the Stream anomaly score (3 scores, one for each Trace):\noutput = traces_scores(stream, inventory)\n```\nThen `output` is:\n```\n[0.45729656,  0.45199387,  0.45113142]\n```\n\nCompute the scores in a stream or iterable of traces, getting also the traces id (by \ndefault the tuple `(seed_id, start, end)`, where seed_id is the \n[Trace SEED identifier](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.get_id.html)):\n\n```python\nfrom obspy.core.inventory.inventory import read_inventory\nfrom obspy.core.stream import read\n\nfrom sdaas.core import traces_idscores\n\n# Load a Stream object and its inventory\n# (use as example the test directory of the package):\nstream = read('./tests/data/GE.FLT1..HH?.mseed')\ninventory = read_inventory('./tests/data/GE.FLT1.xml')\n\n# Compute the Stream anomaly score:\noutput = traces_idscores(stream, inventory)\n```\nThen `output` is:\n```\n([('GE.FLT1..HHE', datetime.datetime(2011, 9, 3, 16, 38, 5, 550001), datetime.datetime(2011, 9, 3, 16, 42, 12, 50001)), ('GE.FLT1..HHN', datetime.datetime(2011, 9, 3, 16, 38, 5, 760000), datetime.datetime(2011, 9, 3, 16, 42, 9, 670000)), ('GE.FLT1..HHZ', datetime.datetime(2011, 9, 3, 16, 38, 8, 40000), datetime.datetime(2011, 9, 3, 16, 42, 9, 670000))], array([ 0.45729656,  0.45199387,  0.45113142]))\n```\n\nSame as above, with custom traces id (their SEED identifier only):\n\n```python\nfrom obspy.core.inventory.inventory import read_inventory\nfrom obspy.core.stream import read\n\nfrom sdaas.core import traces_idscores\n\n# Load a Stream object and its inventory\n# (use as example the test directory of the package):\nstream = read('./tests/data/GE.FLT1..HH?.mseed')\ninventory = read_inventory('./tests/data/GE.FLT1.xml')\n\n# Compute the Stream anomaly score:\noutput = traces_idscores(stream, inventory, idfunc=lambda t: t.get_id())\n```\nThen `output` is:\n```\n(['GE.FLT1..HHE', 'GE.FLT1..HHN', 'GE.FLT1..HHZ'], array([ 0.45729656,  0.45199387,  0.45113142]))\n```\n\nYou can also compute scores and ids from iterables of streams (e.g., when \nreading from files)...\n\n```python\nfrom sdaas.core import streams_scores\nfrom sdaas.core import streams_idscores\n```\n\n... or from a single trace:\n\n```python\nfrom sdaas.core import trace_score\n```\n\nFor instance, to compute the anomaly score of several streams\n(for each stream and for each trace therein, return the trace anomaly score):\n\n```python\nfrom obspy.core.inventory.inventory import read_inventory\nfrom obspy.core.stream import read\n\nfrom sdaas.core import streams_scores\n\n# Load a Stream objects and its inventory\n# (use as example the test directory of the package\n# and mock a list of streams by loading twice the same Stream):\nstreams = [read('./tests/data/GE.FLT1..HH?.mseed'),\n           read('./tests/data/GE.FLT1..HH?.mseed')]\ninventory = read_inventory('./tests/data/GE.FLT1.xml')\n\n# Compute Streams scores:\noutput = streams_scores(streams, inventory)\n```\nThen `output` is:\n```\n[ 0.45729656  0.45199387  0.45113142  0.45729656  0.45199387  0.45113142]\n```\n\nSame as above, computing the features and the scores separately for more \ncontrol:\n\n```python\nfrom obspy.core.inventory.inventory import read_inventory\nfrom obspy.core.stream import read\n\nfrom sdaas.core import trace_features, aa_scores\n\n# Load a Stream object and its inventory\n# (use as example the test directory of the package\n# and mock a list of streams by loading twice the same Stream):\nstreams = [read('./tests/data/GE.FLT1..HH?.mseed'),\n           read('./tests/data/GE.FLT1..HH?.mseed')]\ninventory = read_inventory('./tests/data/GE.FLT1.xml')\n\n# Compute Streams scores:\nfeats = []\nfor stream in streams:\n    for trace in stream:\n        feats.append(trace_features(trace, inventory))\noutput = aa_scores(feats)\n```\nThen `output` is:\n```\n[0.45729656, 0.45199387, 0.45113142, 0.45729656, 0.45199387, 0.45113142]\n```\n\n## Maintenance\n\nAlthough scikit learn is not used anymore for\n[maintainability limitations](https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations), \nyou can always consult the [README](./sdaas/core/models) \nexplaining how to manage create new scikit-learn models.\n\n\n## Citation\n\n**Software:**\n\n> Zaccarelli, Riccardo (2022). sdas - a Python tool computing an amplitude anomaly score of seismic data and metadata using simple machine‐Learning models. GFZ Data Services. https://doi.org/10.5880/GFZ.2.6.2023.009\n\n**Research article:**\n\n> Riccardo Zaccarelli, Dino Bindi, Angelo Strollo; Anomaly Detection in Seismic Data–Metadata Using Simple Machine‐Learning Models. Seismological Research Letters 2021; 92 (4): 2627–2639. doi: https://doi.org/10.1785/0220200339\n\n\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/seisbench",
            "repo_link": "https://github.com/seisbench/seisbench",
            "readme": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/seisbench/seisbench/main/docs/_static/seisbench_logo_subtitle_outlined.svg\" />\n</p>\n\n---\n\n[![PyPI - License](https://img.shields.io/pypi/l/seisbench)](https://github.com/seisbench/seisbench/blob/main/LICENSE)\n[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/seisbench/seisbench/main_push.yml?branch=main)](https://github.com/seisbench/seisbench)\n[![Read the Docs](https://img.shields.io/readthedocs/seisbench)](https://seisbench.readthedocs.io/en/latest/)\n[![PyPI](https://img.shields.io/pypi/v/seisbench)](https://pypi.org/project/seisbench/)\n[![Python 3.9](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5568813.svg)](https://doi.org/10.5281/zenodo.5568813)\n\nThe Seismology Benchmark collection (*SeisBench*) is an open-source python toolbox for\nmachine learning in seismology.\nIt provides a unified API for accessing seismic datasets and both training and applying machine learning algorithms to seismic data.\nSeisBench has been built to reduce the overhead when applying or developing machine learning techniques for seismological tasks.\n\n## Getting started\n\nSeisBench offers three core modules, `data`, `models`, and `generate`.\n`data` provides access to benchmark datasets and offers functionality for loading datasets.\n`models` offers a collection of machine learning models for seismology.\nYou can easily create models, load pretrained models or train models on any dataset.\n`generate` contains tools for building data generation pipelines.\nThey bridge the gap between `data` and `models`.\n\nThe easiest way of getting started is through our colab notebooks.\n\n| Examples                                         |  |\n|--------------------------------------------------|---|\n| Dataset basics                                   | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/01a_dataset_basics.ipynb) |\n| Model API                                        | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/01b_model_api.ipynb) |\n| Generator Pipelines                              | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/01c_generator_pipelines.ipynb) |\n| Applied picking                                  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/02a_deploy_model_on_streams_example.ipynb) |\n| Using DeepDenoiser                               | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/02b_deep_denoiser.ipynb) |\n| Depth phases and earthquake depth                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/02c_depth_phases.ipynb) |\n| Training PhaseNet (advanced)                     | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/03a_training_phasenet.ipynb) |\n| Creating a dataset (advanced)                    | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/03b_creating_a_dataset.ipynb) |\n| Building an event catalog with GaMMA (advanced)  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/03c_catalog_seisbench_gamma.ipynb) |\n| Building an event catalog with PyOcto (advanced) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seisbench/seisbench/blob/main/examples/03d_catalog_seisbench_pyocto.ipynb)        |\n\nAlternatively, you can clone the repository and run the same [examples](https://github.com/seisbench/seisbench/tree/main/examples) locally.\n\nFor more detailed information on Seisbench check out the [SeisBench documentation](https://seisbench.readthedocs.io/).\n\n## Installation\n\nSeisBench can be installed in two ways.\nIn both cases, you might consider installing SeisBench in a virtual environment, for example using [conda](https://docs.conda.io/en/latest/).\n\nThe recommended way is installation through pip.\nSimply run:\n```\npip install seisbench\n```\n\nAlternatively, you can install the latest version from source.\nFor this approach, clone the repository, switch to the repository root and run:\n```\npip install .\n```\nwhich will install SeisBench in your current python environment.\n\n### CPU only installation\n\nSeisBench is built on pytorch, which in turn runs on CUDA for GPU acceleration.\nSometimes, it might be preferable to install pytorch without CUDA, for example, because CUDA will not be used and the CUDA binaries are rather large.\nTo install such a pure CPU version, the easiest way is to follow a two-step installation.\nFirst, install pytorch in a pure CPU version [as explained here](https://pytorch.org/).\nSecond, install SeisBench the regular way through pip.\nExample instructions would be:\n```\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\npip install seisbench\n```\n\n## Contributing\nThere are many ways to contribute to SeisBench and we are always looking forward to your contributions.\nCheck out the [contribution guidelines](https://github.com/seisbench/seisbench/blob/main/CONTRIBUTING.md) for details on how to contribute.\n\n## Known issues\n\n- Some institutions and internet providers are blocking access to our data and model repository, as it is running on a non-standard port (2880).\n  This usually manifests in timeouts when trying to download data or model weights.\n  To verify the issue, try accessing [https://hifis-storage.desy.de:2880/](https://hifis-storage.desy.de:2880/) directly from the same machine.\n  As a mitigation, you can use our backup repository. Just run `seisbench.use_backup_repository()`.\n  Please note that the backup repository will usually show lower download speeds.\n  We recommend contacting your network administrator to allow outgoing access to TCP port 2880 on our server as a higher performance solution.\n- We've recently changed the URL of the SeisBench repository. To use the new URL update to SeisBench 0.4.1.\n  It this is not possible, you can use the following commands within your runtime to update the URL manually:\n  ```python\n  import seisbench\n  from urllib.parse import urljoin\n\n  seisbench.remote_root = \"https://hifis-storage.desy.de:2880/Helmholtz/HelmholtzAI/SeisBench/\"\n  seisbench.remote_data_root = urljoin(seisbench.remote_root, \"datasets/\")\n  seisbench.remote_model_root = urljoin(seisbench.remote_root, \"models/v3/\")\n  ```\n- On the Apple M1 and M2 chips, pytorch seems to not always work when installed directly within `pip install seisbench`.\n  As a workaround, follow the instructions at (https://pytorch.org/) to install pytorch and then install SeisBench as usual through pip.\n- EQTransformer model weights \"original\" in version 1 and 2 are incompatible with SeisBench >=0.2.3. Simply use `from_pretrained(\"original\", version=\"3\")` or `from_pretrained(\"original\", update=True)`. The weights will not differ in their predictions.\n\n## References\nReference publications for SeisBench:\n\n---\n\n* [SeisBench - A Toolbox for Machine Learning in Seismology](https://doi.org/10.1785/0220210324)\n\n  _Reference publication for software._\n\n---\n\n* [Which picker fits my data? A quantitative evaluation of deep learning based seismic pickers](https://doi.org/10.1029/2021JB023499)\n\n  _Example of in-depth bencharking study of deep learning-based picking routines using the SeisBench framework._\n\n---\n\n## Acknowledgement\n\nThe initial version of SeisBench has been developed at [GFZ Potsdam](https://www.gfz-potsdam.de/) and [KIT](https://www.gpi.kit.edu/) with funding from [Helmholtz AI](https://www.helmholtz.ai/).\nThe SeisBench repository is hosted by [HIFIS - Helmholtz Federated IT Services](https://www.hifis.net/).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/seiscomp",
            "repo_link": "https://github.com/SeisComP",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/sensor-management-system",
            "repo_link": "https://codebase.helmholtz.cloud/hub-terra/sms/orchestration",
            "readme": "<!--\nSPDX-FileCopyrightText: 2021 - 2024\n- Kotyba Alhaj Taha <kotyba.alhaj-taha@ufz.de>\n- Nils Brinckmann <nils.brinckmann@gfz-potsdam.de>\n- Tobias Kuhnert <tobias.kuhnert@ufz.de>\n- Norman Ziegner <norman.ziegner@ufz.de>\n- Helmholtz Centre Potsdam - GFZ German Research Centre for Geosciences (GFZ, https://www.gfz-potsdam.de)\n- Helmholtz Centre for Environmental Research GmbH - UFZ (UFZ, https://www.ufz.de)\n\nSPDX-License-Identifier: EUPL-1.2\n-->\n\n![alt text](logos/RGB/PNG/ufz-sms_logo_name+abkuerzung_primaer_50_percent.png \"Sensor Management System\")\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.13329925.svg)](https://doi.org/10.5281/zenodo.13329925)\n\n# Helmholtz Earth & Environment Sensor Management System\n\nThe Sensor Management System (SMS) allows the comprehensive\nacquisition, administration and export of metadata of platforms,\nsensors and measurement configurations by stations and campaigns\noperated in the Helmholtz research field Earth & Environment.\n\nInformation on specific setups can be summarized and made available\nas metadata together with the data for scientific evaluations,\nmaking the data genesis permanently traceable and transparent via\nprovenance tracking. In the data management cycle, the service\nparticularly supports the acquisition of additional information\nduring data collection and prepares the publication of research\ndata with associated metadata by capturing and providing relevant\ninformation about the measurement setup during data generation.\nThe service is targeted at the work of scientists and technicians\nin the earth and environmental sciences, but also offers sufficient\nflexibility for use in other domains as well as individual extension\nand customization possibilities due to the use of common standards.\n\n## License\n\n[EUPL-1.2](https://joinup.ec.europa.eu/sites/default/files/custom-page/attachment/2020-03/EUPL-1.2%20EN.txt)\n\n## Authors\n\n- [Nils Brinckmann](https://orcid.org/0000-0001-8159-3888)\n- Kotyba Alhaj Taha\n- Tobias Kuhnert\n- [Marc Hanisch](https://orcid.org/0000-0001-5272-4674)\n- Maximilian Schaldach\n- Florian Gransee\n- [Daniel Sielaff](https://orcid.org/0009-0002-8606-9385)\n- [Tim Eder](https://orcid.org/0009-0005-1965-931X)\n- Luca Johannes Nendel\n- [Norman Ziegner](https://orcid.org/0000-0001-7579-216X)\n- [Hannes Bohring](https://orcid.org/0009-0007-5103-5886)\n- [Rubankumar Moorthy](https://orcid.org/0000-0002-3567-1475)\n- Wilhelm Becker\n- [Martin Abbrent](https://orcid.org/0000-0003-1252-9107)\n- Erik Pongratz\n- [Dirk Ecker](https://orcid.org/0000-0003-4241-9208)\n- [Christof Lorenz](https://orcid.org/0000-0001-5590-5470)\n- [Paul Remmler](https://orcid.org/0000-0001-8900-9009)\n- [Vivien Rosin](https://orcid.org/0009-0003-9261-6696)\n- Marie Schaeffer\n- [Jannes Breier](https://orcid.org/0000-0002-9055-6904)\n\n## Development\n\nThe development of this project takes place in\nhttps://codebase.helmholtz.cloud/hub-terra/sms/orchestration\nin the Helmholtz Gitlab.\n\nThere is also a mirrored version https://github.com/sensor-management-system/orchestration\non GitHub.\n\nIn case you have problems or questions, please use https://codebase.helmholtz.cloud/hub-terra/sms/orchestration/-/issues/new\nto create an issue.\n\n## Used By\n\nThis project is used by the following research centers:\n\n- GFZ Potsdam: https://sensors.gfz-potsdam.de\n- UFZ Leipzig: https://web.app.ufz.de/sms/\n- Karlsruhe Institute of Technology: https://sms.atmohub.kit.edu/\n- Research Centre Jülich: https://ibg3sms.ibg.kfa-juelich.de/ (FZJ intranet only)\n\n## Changelog\n\nYou can find the versions and their changes in [CHANGELOG.md](./CHANGELOG.md).\n\n## Architecture\n\n![SMS work flow](docs/images/sms.png)\n\n## Deployment\n\nThe SMS is usually run within a Docker Container according to the following steps.\n\n### Set up Controlled Vocabulary\n\nBefore we can start the SMS-Container, we have to set up the SMS Controlled Vocabulary (which contains terms and defintions used for filling the SMS) as a Git Submodule:\n\n```bash\ngit submodule init\ngit submodule update\n```\n\n### Run the application\n\n```bash\ndocker compose up -d\n```\n\nVisit http://localhost\n\nUse one of the users specified in [keycloak/docs/Specification for sms.md](./keycloak/docs/Specification for sms.md) to login.\n\n### Integrate demonstrator data for faster deployment\n\nYou can use your own test data to be inserted directly into the database during your development process. For this, please follow these steps:\n\n1. __Make sure that you `db` service is up and running__\n2. `chmod +x preset-database.sh`\n3. `cp ./sql/preset-development-and-test-data.sql.example ./sql/preset-development-and-test-data.sql`\n4. Update the `./sql/preset-development-and-test-data.sql` file to your needs (__HINT__: If you use hard coded IDs make sure to update the corresponding sequences or you'll encounter problems)\n5. run `./preset-database.sh`\n\n### More information\n\nFor more advanced institute specific information, please take a look [here](docs/deployments/).\n## Demo\n\nIf you just want to try out the Sensor Management System, you are welcome to do\nso on [our test instance](https://sensors-sandbox.gfz-potsdam.de).\n\n⚠️ Please be aware that the data you enter there will not be stored permanently\nand the instance should not be used for productive work!\n\n## API Reference\n\nThe OpenAPI specification can be explored interactively on the SMS instances.\nFor example on [sensors.gfz-potsdam.de](https://sensors.gfz-potsdam.de/backend/api/v1/openapi).\n\n## Environment Variables\n\nA list of all supported Environment Variables can be found in ```./docker/env.template```.\n\nIf you want to change any of these variables, rename the ```env.template``` to ```env.dev``` via\n\n```bash\ncp ./docker/env.template ./docker/env.dev\n```\n\nand re-start the container using\n\n```bash\ndocker compose --env-file ./docker/env.dev  up -d\n```\n\n## User documentation\n\nIn the [wiki](https://codebase.helmholtz.cloud/hub-terra/sms/service-desk/-/wikis/home)\nwe wrote some information on how the users can interact with the system, the structure\nof the different pages and some best practices.\n\n## FAQ\n\n### What is the connection between the user subject and the username from the IDL?\n\nWe use the users subject entry as a user readable unque identifier for our\nusers. It looks like\n\n```\nusername@institute.org\n```\n\nIn past it was identical to the `sub` entry in the userinfo response of\nthe IDP instances (both at UFZ and GFZ).\n\nWith the switch to the Helmholtz AAI, this changed.\nWe introducted the `OIDC_USERNAME_CLAIM` environment variable for the backend\n(default to `sub`) to make it configurable from which attribute of the user\nresponse we want to fill our subject entry in the user table.\n\nThe Helmholtz AAI fills `sub` with cryptic uuid, which is unique, but not\nuser friendly readable. However it gives the `eduperson_principal_name`\nwhich is exactly what we used for subject in the past.\n\nIn any case the interaction with the IDL will use the subject from our\nusers table to search for usernames within the IDL.\nSo both should be identical.\n\nIn case you want to use the `gfz-idl` implementation, as well as the\nHelmholtz AAI, make sure that you set the `OIDC_USERNAME_CLAIM` variable\nto `eduperson_principal_name`.\n\n## Appendix\n\n### TSM Endpoints\n\nWe include all the tsm endpoints in the database and can use the `manage.py loaddata <path>` command to add or\nupdate those.\n\nThe current approach is to store them in the TSM_ENDPOINTS env variable as an json array, to write it to an temporary file\nand to load it with the `loaddata` command:\n\n```\n    - docker compose -f docker/deployment/gfz/staging-dev/docker-compose.yml exec -T backend sh -c \"echo '$TSM_ENDPOINTS' > /tmp/tsm_endpoint_fixture.json\"\n    - docker compose -f docker/deployment/gfz/staging-dev/docker-compose.yml exec -T backend python3 manage.py loaddata /tmp/tsm_endpoint_fixture.json\n```\n\nThe content of the TSM_ENDPOINTS variable looks like this:\n\n```javascript\n[\n  {\n    \"pk\": 1,\n    \"model\": \"TsmEndpoint\",\n    \"fields\": {\n      \"name\": \"Specific tsm endpoint\",\n      \"url\": \"https://somewhere.in.the/web\"\n    }\n  }\n]\n```\n\nFeel free to add your tsm endpoint here.\n\nPlease note: Regarding that we may want to provide a central instance in the future, it makes sense to keep the ids of the\nids of the endpoints distinct. So to have pk=1 for GFZ, pk=2 for UFZ, pk=3 for FZJ, pk=4 for KIT and so on. Doing so can\nmake an merge of the data much easier (but it is also possible to work around it).\n\n### Export control\n\nThe export control workflow implemented in the SMS is there to allow export control\nofficers on the centres to store information if a device or a platform can be\nused for military uses (dual use) and requires extra documents when transported\nto different countries.\n\nWhile the usual handling in the SMS is based on physical devices, the export control\nworks on their device types - in this case the combination of manufacturer & model - so\nthat the check needs to be done just once for a group of devices or platforms.\n\nThe permission to handle those information is bound to the `EXPORT_CONTROL_VO_LIST`\nenv variable. It is a comma seperated list that points to the full qualified name\nof a virtual organization (VO). If you use a sub group of your VO it will look like this: `urn:geant:helmholtz.de:group:<VO Name>:<Group Name>#login.helmholtz.de`.\nThe full name of the group muss be added to the `EXPORT_CONTROL_VO_LIST`.\n\nFor the GFZ we have a `sensor-management-system-export-control` group within myprofile.\nThis is visible as `urn:geant:helmholtz.de:gfz:group:sensor-management-system-export-control#idp.gfz-potsdam.de` within the Helmholtz AAI - and this is the value that is\nused in the `EXPORT_CONTROL_VO_LIST` variable.\n\n## How to cite\n\n> Brinckmann, N., Alhaj Taha, K., Kuhnert, T., Abbrent, M., Becker, W., Bohring, H., Breier, J., Bumberger, J., Ecker, D., Eder, T., Gransee, F., Hanisch, M., Lorenz, C., Moorthy, R., Nendel, L. J., Pongratz, E., Remmler, P., Rosin, V., Schaeffer, M., … Ziegner, N. (2024). Sensor Management System - SMS (1.16.1). Zenodo. [https://doi.org/10.5281/zenodo.13329926](https://doi.org/10.5281/zenodo.13329926)\n",
            "project_id": "3268"
        },
        {
            "software_organization": "https://helmholtz.software/software/serghei",
            "repo_link": "https://gitlab.com/serghei-model/serghei",
            "readme": "# SERGHEI\n\nSimulation Environment for Geomorphology, Hydrodynamics and Ecohydrology in Integrated form\n\n[![doi](https://zenodo.org/badge/DOI/10.5281/zenodo.8159947.svg)](https://doi.org/10.5281/zenodo.8159947)\n[![BSD3 License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)\n[![doi](https://img.shields.io/badge/rsd-serghei-00a3e3.svg)](https://helmholtz.software/software/serghei)\n[![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8B-yellow)](https://fair-software.eu)\n\n\n# Dependencies\n\nSERGHEI has the following dependencies:\n\n+ [Kokkos](https://github.com/kokkos/kokkos) handles the\nparallelization\n+ [Parallel NetCDF](https://github.com/Parallel-NetCDF/PnetCDF) writes\noutput files\n+ We use [R](https://www.r-project.org/) scripts for postprocessing (optional)\n\nBoth Kokkos and PNetCDF are linked as git submodules in this project. If you are unfamiliar with submodules, you can simply clone this repo together with the submodules with the `git clone --recurse-submodules` command.\n\nPnetCDF is often available in Linux distributions via package managers, and also as software modules in HPC systems. It is recommended to use these system wide installations, and only fall back on building the PNetCDF from source if there's no other option.\n\n# Building SERGHEI with CMake\nThe CMake workflow is the recommended approach to build SERGHEI. This assumes you have cloned the Kokkos submodule.\n\n1. Build Kokkos\n```\nbash buildKokkos [GPU_ARCHITECTURE]\n``` \nThe `GPU_ARCHITECTURE` argument is optional (it defaults to a shared memory CPU architecture). If provided it must be a valid [GPU architecture string as defined by Kokkos](https://kokkos.org/kokkos-core-wiki/keywords.html?highlight=ampere80#architectures), and matching your GPU architecture. \n\nThis configures and builds Kokkos with the target backend and architecture.\n\n2. Configure and build SERGHEI\n```\ncmake . [-DSERGHEI_OPTION -DSERGHEI_OPTION ...]\nmake\n```\n\nNote that when builing SERGHEI, there is no backend/architecture selection (this was done in the Kokkos build step).\n\nBuild options for SERGHEI are passed to CMake as usual, e.g., `-DSERGHEI_WRITE_HZ=ON`. Read the [documentation on the available build options](https://gitlab.com/serghei-model/serghei/-/wikis/CMake-build-options).\n\n# Non-Cmake installation\n\nThis procedure is deprecated, and only partially maintained for legacy reasons. It will be progressively phased-out.\n\n## Environment configuration\nThe environment needs to be configured properly for this procedure to be consistent.\n\n### Automatic configuration\nSERGHEI provides the `scripts/configure.sh` script to help you configure your environment for SERGHEI, including setting up environment variables. You can simply run\n```bash\nbash ./scripts/configure.sh -a\n```\nwhich will fetch the dependencies and install them in your local SERGEHI directory.\nIn case you have already the dependencies and wish to use existing paths, take a look at\n```\nbash ./scripts/configure.sh --help\n```\n\n### Understanding the (manual) environment configuration \nYou need to set the SERGHEIPATH environment variable to your local SERGHEI root path. \n```\nexport SERGHEIPATH=/path/to/serghei\n```\nKeep in mind doing so is not a persisting configuration.\nFor persisting configuration, you can set this in your `.bashrc` file. \n\nPaths in the build scripts, but also in other workflows in SERGHEI use the `SERGHEIPATH` environment variable.\n\n## Building SERGHEI with Make\nSERGHEI can be built through `make`. Before attempting to compile, the correct paths pointing to `Kokkos` and `PNetCDF` must be included in the `src/Makefile`. The default paths for these are `$SERGHEIPATH/Kokkos` and `$SERGHEIPATH/PnetCDF` or system paths. If you have these dependencies elsewhere, point the variable `PNETCDF_PATH` to the `PNetCDF` base folder and the variable `KOKKOS_PATH` to the `Kokkos` base folder. The automatic environment configuration should also do this for you.\n\nTo build SERGHEI, use either one of these:\n\n+ `make arch=cpu`: compiles the code for CPU (OpenMP + MPI)\n+ `make arch=gpu device=DEVICESM`: compiles the code for GPU (CudaUVM + MPI). DEVICESM is the keyword for the device architecture for your GPUs. The list of architecture keywords can be found \n[here](https://github.com/kokkos/kokkos/wiki/Compiling#table-43-architecture-variables). Commonly used may be, for example Ampere80, Volta70, Pascal61, etc.\n\nThis places an executable `serghei` into the directory `$SERGHEITPATH/bin` directory.\n\nFurther commands:\n+ `make clean`: cleans the program objects and the exe file\n+ `make kclean`: cleans the prgram objects, the exe file and the Kokkos\nobjects\n\n### Model component compilation flags\nSERHGEI's Makefile includes flags to control which model components are compiled. The default configuration of SERGHEI components is hardcoded. These flags allow you to control which model components are actually compiled. The possible flags are commented inside the Makefile, therefore, unless you either uncomment some of them, or pass them to Make through the command line, you will get the default compilation configuration.\nYou can control through the command line the setup, for example \n```\n$ make arch=cpu SERGHEI_SUBSURFACE_MODEL=1\n``` \nwill compile SERGHEI for CPUs, including the subsurface solver. \n\nAnother example, to compile for Volta GPUs, including subsurface and particle tracking modules is\n```\n$ make arch=gpu device=Volta70 SERGHEI_SUBSURFACE_MODEL=1 SERGHEI_PARTICLE_TRACKING=1\n``` \nTake a look at the [full list of compilation flags](https://gitlab.com/serghei-model/serghei/-/wikis/User-Guide/Build-flags).\n\n\n# Running SERGHEI\n\nOnce installed, SERGHEI can be invoked by:\n\n```\n$ mpirun -n N ./serghei inputDir/ outputDir/ M\n```\n\nwhere\n\n+ `N`: number of MPI tasks (subdomains). This must be in accordance\nwith the partition chosen in `parameters.input`\n+ `inputDir`: directory where the input files are located\n+ `outputDir`: directory where the output files will be located\n+ `M`: number of threads (OpenMP) or number of GPUs per resource set\n(GPUs)\n\n## Examples and test cases\n\nTake a look at the [collection of test cases](https://gitlab.com/serghei-model/serghei-tests).\n\nTo run the test case located at `cases/paraboloid2`, execute SERGHEI with \n\n```\n$ mpirun -n 2 /path/to/serghei/bin/serghei ../cases/paraboloid2/ output/ 4\n```\n\nDepending on the architecture, this command causes different things to\nhappen:\n\n1. If the code has been compiled for CPU, this means that it would be\n2 subdomains (MPI tasks) parallelized with 4 threads per subdomain\n(OpenMP).\n2. If the code has been compiled for GPU, this means that it would be\n8 subdomains (MPI tasks). The code is run on 2 nodes, each of them\ncontaining 4 GPUs.\n\nSimilarly, the use of `mpirun` is conditioned to the execution with\nMPI and the corresponding architecture. For example, the code can be\nrun just using:\n\n```\n/path/to/serghei/bin/serghei ./cases/paraboloid2/ output/ 1\n```\n\n# Known issues\n\n+ The `clang` compiler may fail to correctly load the OpenMP\nlibrary. Thus, if SERGHEI is compiled with `clang`, OpenMP may not be\navailable.\n+ `gcc-10` has trouble compiling Parallel NetCDF and throws a type\n  mismatch errors. The errors can be turned into warnings by passing\n  ```\n  FCFLAGS=\"-fallow-argument-mismatch\" FFLAGS=\"-fallow-argument-mismatch\"\n  ```\n  to `configure` and `make`. See [this github issue](https://github.com/Unidata/netcdf-fortran/issues/212).\n\n# How to cite \nPlease cite the software using the corresponding [SERGHEI Zenodo DOI](https://doi.org/10.5281/zenodo.8159947), and if necessary with the specific release DOI.\n\nYou can refer to the [SERGHEI-SWE paper](https://gmd.copernicus.org/articles/16/977/2023/) for the shallow water module SERGHEI-SWE.\n```\n@Article{Caviedes2023,\nAUTHOR = {Caviedes-Voulli\\`eme, D. and Morales-Hern\\'andez, M. and Norman, M. R. and \\\"Ozgen-Xian, I.},\nTITLE = {SERGHEI (SERGHEI-SWE) v1.0: a performance portable high-performance parallel-computing shallow-water solver for hydrology and environmental hydraulics},\nJOURNAL = {Geoscientific Model Development Discussions},\nVOLUME = {16}\nYEAR = {2023},\nPAGES = {977--1008},\nURL = {https://gmd.copernicus.org/articles/16/977/2023/},\nDOI = {10.5194/gmd-16-977-2023}\n}\n```\n",
            "project_id": "22784574"
        },
        {
            "software_organization": "https://helmholtz.software/software/sfctools",
            "repo_link": "https://gitlab.com/dlr-ve/esy/sfctools/framework",
            "readme": "# sfctools - A toolbox for stock-flow consistent, agent-based models\n\nSfctools is a lightweight and easy-to-use Python framework for agent-based macroeconomic, stock-flow consistent (ABM-SFC) modeling. It concentrates on agents in economics and helps you to construct agents, helps you to manage and document your model parameters, assures stock-flow consistency, and facilitates basic economic data structures (such as the balance sheet). For more documentation, see https://sfctools-framework.readthedocs.io/en/latest/.\n\n## Installation\n\nWe recommend to install sfctools in a fresh Python 3.8 environment. For example, with conda, do\n\n    conda create --name sfcenv python=3.8\n    conda activate sfcenv\n    conda install pip\n\nThen, in a terminal of your choice, type:\n\n    pip install sfctools\n\nsee https://pypi.org/project/sfctools/\n\n## Usage with Graphical User Interface 'Attune'\n\nType\n\n    python -m sfctools attune\n\nto start the GUI.\n\n## Usage inside Python\n\nTry out this simple example:\n\n```python\nfrom sfctools import Agent, World \n\nclass SomeAgent(Agent):\n    def __init__(self, a):\n        super().__init__()\n        self.some_attribute = a\n\nmy_agent = SomeAgent(a='Hello')\nyour_agent = SomeAgent(a='World')\n\nmy_agents = World().get_agents_of_type(\"SomeAgent\")\nmy_message = my_agents[0].some_attribute\nyour_message = my_agents[1].some_attribute\n\nprint(\"%s says %s, %s says %s\" % (my_agent, my_message, your_agent, your_message))\n```\n\nThe resulting output will be\n\n```console \nSomeAgent__00001 says Hello, SomeAgent__00002 says World\n```\n\n## More Examples\n\nHave a look at the [documentation page](https://sfctools-framework.readthedocs.io/en/latest/doc_api_examples/examples_framework.html) for more examples. \n\n\n## Cite this Software\n\nYou can cite the software as follows: \n\nBaldauf, T., (2023). sfctools - A toolbox for stock-flow consistent, agent-based models. Journal of Open Source Software, 8(87), 4980, https://doi.org/10.21105/joss.04980\n\n\nYou can cite the software repository as follows:\n\nThomas Baldauf. (2023). sfctools - A toolbox for stock-flow consistent, agent-based models (1.1.0.2b). Zenodo. https://doi.org/10.5281/zenodo.8118870\n\n\n-----------------------------------\n\n| Corresponding author: Thomas Baldauf, German Aerospace Center (DLR), Curiestr. 4 70563 Stuttgart | thomas.baldauf@dlr.de |\n\n",
            "project_id": "34038269"
        },
        {
            "software_organization": "https://helmholtz.software/software/shepard",
            "repo_link": "https://gitlab.com/dlr-shepard",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/shockhash",
            "repo_link": "https://github.com/ByteHamster/ShockHash",
            "readme": "# ShockHash\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n![Build status](https://github.com/ByteHamster/ShockHash/actions/workflows/build.yml/badge.svg)\n\nA minimal perfect hash function (MPHF) maps a set S of n keys to the first n integers without collisions.\nPerfect hash functions have applications in databases, bioinformatics, and as a building block of various space-efficient data structures.\n\nShockHash (**s**mall, **h**eavily **o**verloaded **c**uc**k**oo **hash** tables) is an MPHF that achieves space very close to the lower bound,\nwhile still being fast to construct.\nIn contrast to the simple brute-force approach that needs to try e^n = 2.72^n different hash function seeds,\nShockHash significantly reduces the search space.\nInstead of sampling hash functions hoping for them to be minimal perfect, it samples random graphs,\nhoping for them to be a pseudoforest.\nIn its most space-efficient variant, it can reduce the running time to just 1.16^n,\nwhile still being asymptotically space optimal.\n\nStill being an exponential time algorithm, we integrate ShockHash into several partitioning frameworks.\nOur implementation inside the [RecSplit](https://github.com/vigna/sux/blob/master/sux/function/RecSplit.hpp) framework achieves the best space efficiency.\nUsing ShockHash inside our novel k-perfect hash function achieves fast queries\nwhile still being faster to construct and more space efficient than any previous approaches.\n\n### Library Usage\n\nClone this repo and add the following to your `CMakeLists.txt`.\nNote that the repo has submodules, so either use `git clone --recursive` or `git submodule update --init --recursive`.\n\n```cmake\nadd_subdirectory(path/to/ShockHash)\ntarget_link_libraries(YourTarget PRIVATE ShockHash)\n```\n\nThen use one of the following classes:\n\n- [ShockHash](https://github.com/ByteHamster/ShockHash/blob/main/include/ShockHash.h) is the original ShockHash algorithm integrated into the RecSplit framework.\n- [SIMDShockHash](https://github.com/ByteHamster/ShockHash/blob/main/include/SIMDShockHash.hpp) is the SIMD-parallel version of the original ShockHash algorithm. Both ShockHash and the RecSplit framework are SIMD-parallelized. If this implementation is used on a machine without SIMD support, it is slower than the non-SIMD version because SIMD operations are emulated.\n- [ShockHash2](https://github.com/ByteHamster/ShockHash/blob/main/include/ShockHash2.h) is the bipartite ShockHash algorithm. Only the inner ShockHash loop is SIMD-parallel, the RecSplit framework is not. If this implementation is used on a machine without SIMD support, the implementation uses sequential operations without explicitly emulating SIMD. To turn off SIMD, change to SIMD lanes of size 1 in [ShockHash2-internal.h](https://github.com/ByteHamster/ShockHash/blob/main/include/ShockHash2-internal.h).\n\nConstructing a ShockHash perfect hash function is then straightforward:\n\n```cpp\nstd::vector<std::string> keys = {\"abc\", \"def\", \"123\", \"456\"};\nshockhash::ShockHash<30, false> shockHash(keys, 2000); // ShockHash base case size n=30, bucket size b=2000\nstd::cout << shockHash(\"abc\") << \" \" << shockHash(\"def\") << \" \"\n          << shockHash(\"123\") << \" \" << shockHash(\"456\") << std::endl;\n// Output: 1 3 2 0\n```\n\nWe also give the base-case implementations without the RecSplit framework, which makes it easier to understand the main idea.\n\n- Original [ShockHash](https://github.com/ByteHamster/ShockHash/blob/main/benchmark/bijections/ShockHash1.h).\n- [Bipartite ShockHash](https://github.com/ByteHamster/ShockHash/blob/main/include/ShockHash2-internal.h). The outer loop that is also given in the pseudocode of the paper is given in `BijectionsShockHash2::findSeed`.\n\n### Construction performance\n\n[![Plots preview](https://raw.githubusercontent.com/ByteHamster/ShockHash/main/plots.png)](https://arxiv.org/abs/2310.14959)\n\n### Licensing\nShockHash is licensed exactly like `libstdc++` (GPLv3 + GCC Runtime Library Exception), which essentially means you can use it everywhere, exactly like `libstdc++`.\nYou can find details in the [COPYING](/COPYING) and [COPYING.RUNTIME](/COPYING.RUNTIME) files.\n\nIf you use [ShockHash](https://arxiv.org/abs/2308.09561) or [bipartite ShockHash](https://arxiv.org/abs/2310.14959) in an academic context or publication, please cite our papers:\n\n```\n@inproceedings{lehmann2023shockhash,\n  author = {Hans-Peter Lehmann and\n    Peter Sanders and\n    Stefan Walzer},\n  title = {{ShockHash}: Towards Optimal-Space Minimal Perfect Hashing Beyond Brute-Force},\n  booktitle = {{ALENEX}},\n  pages = {194--206},\n  publisher = {{SIAM}},\n  year = {2024},\n  doi = {10.1137/1.9781611977929.15}\n}\n\n@article{lehmann2023towardsArxiv,\n  author = {Hans-Peter Lehmann and\n    Peter Sanders and\n    Stefan Walzer},\n  title = {{ShockHash}: Towards Optimal-Space Minimal Perfect Hashing Beyond Brute-Force},\n  journal = {CoRR},\n  volume = {abs/2308.09561},\n  year = {2023},\n  doi = {10.48550/ARXIV.2308.09561}\n}\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/sichash",
            "repo_link": "https://github.com/ByteHamster/SicHash",
            "readme": "# SicHash\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\n![Build status](https://github.com/ByteHamster/SicHash/actions/workflows/build.yml/badge.svg)\n\nA perfect hash function (PHF) maps a set S of n keys to the first m integers without collisions.\nIt is called _minimal_ perfect (MPHF) if m=n.\nPerfect hash functions have applications in databases, bioinformatics, and as a building block of various space-efficient data structures.\n\nSicHash is a (minimal) perfect hash function based on irregular cuckoo hashing, retrieval, and overloading.\nEach input key has a small number of choices for output positions.\nUsing cuckoo hashing, SicHash determines a mapping from each key to one of its choices,\nsuch that there are no collisions between keys.\nIt then stores the mapping from keys to their candidate index space-efficiently using\nthe [BuRR](https://github.com/lorenzhs/BuRR) retrieval data structure.\n\nSicHash offers a very good trade-off between construction performance, query performance, and space consumption.\n\n### Library Usage\n\nClone this repo and add the following to your `CMakeLists.txt`.\nNote that the repo has submodules, so either use `git clone --recursive` or `git submodule update --init --recursive`.\n\n```\nadd_subdirectory(path/to/SicHash)\ntarget_link_libraries(YourTarget PRIVATE SicHash)\n```\n\nConstructing a SicHash perfect hash function is then straightforward:\n\n```cpp\nstd::vector<std::string> keys = {\"abc\", \"def\", \"123\", \"456\"};\nsichash::SicHashConfig config;\nsichash::SicHash<true> hashFunc(keys, config);\nstd::cout << hashFunc(\"abc\") << std::endl;\n```\n\n### Construction Performance\n\n[![Plots preview](https://raw.githubusercontent.com/ByteHamster/SicHash/main/plots-construction.png)](https://arxiv.org/pdf/2210.01560)\n\n### Query Performance\n\n[![Plots preview](https://raw.githubusercontent.com/ByteHamster/SicHash/main/plots-query.png)](https://arxiv.org/pdf/2210.01560)\n\n### Reproducing Experiments\n\nThis repository contains the source code and our reproducibility artifacts for the benchmarks specific to SicHash.\nBenchmarks that compare SicHash to competitors are available in a different repository: https://github.com/ByteHamster/MPHF-Experiments\n\nWe provide an easy to use Docker image to quickly reproduce our results.\nAlternatively, you can look at the `Dockerfile` to see all libraries, tools, and commands necessary to compile SicHash.\n\n#### Building the Docker Image\n\nRun the following command to build the Docker image.\nBuilding the image takes about 5 minutes, as some packages (including LaTeX for the plots) have to be installed.\n\n```bash\ndocker build -t sichash --no-cache .\n```\n\nSome compiler warnings (red) are expected when building competitors and will not prevent building the image or running the experiments.\nPlease ignore them!\n\n#### Running the Experiments\nDue to the long total running time of all experiments in our paper, we provide run scripts for a slightly simplified version of the experiments.\nThey run fewer iterations and output fewer data points.\n\nYou can modify the benchmarks scripts in `scripts/dockerVolume` if you want to change the number of runs or data points.\nThis does not require the Docker image to recompile.\nDifferent experiments can be started by using the following command:\n\n```bash\ndocker run --interactive --tty -v \"$(pwd)/scripts/dockerVolume:/opt/dockerVolume\" sichash /opt/dockerVolume/figure-1.sh\n```\n\nThe number also refers to the figure in the paper.\n\n| Figure in paper | Launch command                | Estimated runtime  |\n| :-------------- | :---------------------------- | :----------------- |\n| 1               | /opt/dockerVolume/figure-1.sh | 10 minutes         |\n\nThe resulting plots can be found in `scripts/dockerVolume` and are called `figure-<number>.pdf`.\nMore experiments comparing SicHash with competitors can be found in a different repository: https://github.com/ByteHamster/MPHF-Experiments\n\n### License\n\nThis code is licensed under the [GPLv3](/LICENSE).\nIf you use the project in an academic context or publication, please cite [our paper](https://doi.org/10.1137/1.9781611977561.ch15):\n\n```\n@inproceedings{lehmann2023sichash,\n  author       = {Hans{-}Peter Lehmann and\n                  Peter Sanders and\n                  Stefan Walzer},\n  title        = {SicHash - Small Irregular Cuckoo Tables for Perfect Hashing},\n  booktitle    = {{ALENEX}},\n  pages        = {176--189},\n  publisher    = {{SIAM}},\n  year         = {2023},\n  doi          = {10.1137/1.9781611977561.CH15}\n}\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/signal-processor",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/Signal-Processor",
            "readme": "![Python](https://img.shields.io/badge/Python-3670A0?style=plastic&logo=python&logoColor=ffdd54) ![SciPy](https://img.shields.io/badge/SciPy-%230C55A5.svg?style=plastic&logo=scipy&logoColor=%white) ![NumPy](https://img.shields.io/badge/Numpy-777BB4.svg?style=plastic&logo=numpy&logoColor=white) ![Plotly](https://img.shields.io/badge/Plotly-239120.svg?style=plastic&logo=plotly&logoColor=white) ![Matplotlib](https://img.shields.io/badge/Matplotlib-%233F4F75.svg?style=plastic&logo=plotly&logoColor=white)  ![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/SignalProcessor?style=plastic)\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.13286179.svg)](https://doi.org/10.5281/zenodo.13286179)\n\n# SignalProcessor\n\nThis repository provides a Python package for generating, filtering, fitting, and analyzing signals. The package includes functionalities for creating noisy signals, applying filters, fitting damped sine waves, and performing statistical analysis.\n\n### Overview\n\n- Generate noisy sine wave signals (or import custom signals)\n- Apply Butterworth low-pass filters\n- Fit damped sine waves to filtered signals\n- Perform t-tests between filtered signals and fitted models\n- Compute and visualize Fourier Transforms\n\n### Installation\n\n1) Create and source virtual environment:\n```shell\npython -m venv env\nsource env/bin/activate  # On Windows use `env\\Scripts\\activate`\n```\n2) Install the dependencies:\n```shell\npip install -r requirements.txt\n```\n\n### Running Tests\nUsing unittest\n\n```shell\npython -m unittest discover -s tests\n```\n\n### Example\nAn example demonstrating generating a signal, applying filters, fitting models, and performing analysis, exists in the `main.py`.\n\n>[!Note]\n> An example plot has been uploaded to the `plots` directory.\n\n### Example Usage\n\nGenerate a Noisy Signal\n\n```shell\nimport numpy as np\nfrom src.signal_processor import SignalProcessor\n\ntimeVector = np.linspace(0, 1, 1000, endpoint = False)  # Or consider importing or modifying your time vector\n\ngenerator = SignalGenerator(timeVector)\n   \ngenerator.generateNoisySignal(frequency = 20, noiseStdDev = 0.6)\n\n  # or with defaults:\n    processor.generateNoisySignal()   # frequency = 10, noiseStdDev = 0.5\n```\n\nApply a Filter (`butter`, `bessel`, `highpass`). Default is `butter`.\n\n```shell\nfrom src.signal_filter import SignalFilter\n\nfilteredInstance = generator.generateNoisySignal() \\\n                            .applyFilter(filterType = 'butter', \n                                         filterOrder = 4, \n                                         cutOffFrequency = 0.2, \n                                         bType = 'lowpass')\n    # Or with different filter parameters:\n      filteredInstance.setFilterParameters('bessel', 5, 0.5, 'highpass').applyFilter()    \n```\n\nFit a damped sine wave to the filtered signal\n\n```shell    \nfrom src.signal_fitter import SignalFitter\n\n    # default sine wave parameters: amplitudeParam = 1.0, frequencyParam = 10.0, phaseParam = 0.0, decayRateParam = 0.1\nfittedInstance = filteredInstance.fitDampedSineWave()\n\n    # Or with custom parameters:\n      fittedInstance.setDampedSineWaveParameters(3.0, 12.0, np.pi / 6, 0.3)\n      fittedInstance.setDampedSineWaveBounds([0, 0, -np.pi/2, 0], [10, 20, np.pi/2, 1])\n      fittedInstance.fitDampedSineWave()      \n```\n\nPerform a t-test between the filtered signal and the fitted damped sine wave\n\n```shell\nfrom src.statistical_analyzer import StatisticalAnalyzer\n\nanalyzedInstance = fittedInstance.analyzeFit()\ntTestResults = analyzedInstance.getTTestResults()\nprint(f\"T-test result: statistic={tTestResults[0]}, p-value={tTestResults[1]}\")\n```\n\nPlot and save the results (will be saved under `plots` directory)\n\n```shell\nfrom src.signal_visualizer import SignalVisualizer\n\nvisualizer = SignalVisualizer(timeVector, generator.getNoisySignal(), \n                              filteredInstance.getFilteredSignal(), \n                              fittedInstance.getFittedSignal()\n                              )\nvisualizer.plotResults()\nvisualizer.plotInteractiveResults()\n```\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/simcats",
            "repo_link": "https://github.com/f-hader/SimCATS/",
            "readme": "<h1 align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/f-hader/SimCATS/main/SimCATS_symbol.svg\" alt=\"SimCATS logo\">\n  <br>\n</h1>\n\n<div align=\"center\">\n  <a href=\"https://github.com/f-hader/SimCATS/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg\" alt=\"License: CC BY-NC-SA 4.0\"/>\n  </a>\n  <a href=\"https://pypi.org/project/simcats/\">\n    <img src=\"https://img.shields.io/pypi/v/simcats.svg\" alt=\"PyPi Latest Release\"/>\n  </a>\n  <a href=\"https://simcats.readthedocs.io/en/latest/\">\n    <img src=\"https://img.shields.io/readthedocs/simcats\" alt=\"Read the Docs\"/>\n  </a>\n  <a href=\"https://doi.org/10.1109/TQE.2024.3445967\">\n    <img src=\"https://img.shields.io/badge/DOI (Paper)-10.1109/TQE.2024.3445967-007ec6.svg\" alt=\"DOI Paper\"/>\n  </a>\n  <a href=\"https://doi.org/10.5281/zenodo.13805205\">\n    <img src=\"https://img.shields.io/badge/DOI (Code)-10.5281/zenodo.13805205-007ec6.svg\" alt=\"DOI Code\"/>\n  </a>\n</div>\n\n# SimCATS\n\nSimulation of CSDs for Automated Tuning Solutions (`SimCATS`) is a Python framework for simulating charge stability \ndiagrams (CSDs) typically measured during the tuning process of qubits.\n\n## Installation\n\nThe framework supports Python versions 3.7 - 3.11 and installs via pip:\n```\npip install simcats\n```\n\nAlternatively, the `SimCATS` package can be installed by cloning the GitHub repository, navigating to the folder \ncontaining the `setup.py` file and executing\n\n```\npip install .\n```\n\nFor the installation in development/editable mode, use the option `-e`.\n\n## Examples / Tutorials\nAfter installing the package, a good starting point is a look into the Jupyter Notebook \n`example_SimCATS_simulation_class.ipynb`, which provides an overview of the usage of the simulation class offered by \nthe framework. \nFor more detailed examples and explanations of the geometric ideal CSD simulation using Total Charge Transitions (TCTs), look at the Jupyter Notebook `example_SimCATS_IdealCSDGeometric.ipynb`. This notebook also includes a hint\nregarding the generation of required labels for training algorithms that might need line labels defined as start and\nend points or require semantic information about particular transitions.\n\n## Tests\n\nThe tests are written for the `PyTest` framework but should also work with the `unittest` framework.\n\nTo run the tests, install the packages `pytest`, `pytest-cov`, and `pytest-xdist` with\n\n```\npip install pytest pytest-cov pytest-xdist\n```\n\nand run the following command:\n\n```\npytest --cov=simcats -n auto --dist loadfile .\\tests\\\n```\n\nThe argument \n- `--cov=simcats` enables a coverage summary of the `SimCATS` package,\n- `-n auto` enables the test to run with multiple threads (auto will choose as many threads as possible, but can be replaced with a specific number of threads to use), and\n- `--dist loadfile` specifies that each file should be executed only by one thread.\n\n<!-- start sec:documentation -->\n## Documentation\n\nThe official documentation is hosted on [ReadtheDocs](https://simcats.readthedocs.io), but can also be built locally.\nTo do this, first install the packages `sphinx`, `sphinx-rtd-theme`, `sphinx-autoapi`, `myst-nb `, and `jupytext` with\n\n```\npip install sphinx sphinx-rtd-theme sphinx-autoapi myst-nb jupytext\n```\n\nand then, in the `docs` folder, execute the following command:\n\n```\n.\\make html\n```\n\nTo view the generated HTML documentation, open the file `docs\\build\\html\\index.html`.\n<!-- end sec:documentation -->\n\n## Structure of SimCATS\n\nThe primary user interface for `SimCATS` is the class `Simulation`, which combines all the necessary functionalities to\nmeasure (simulate) a CSD and adjust the parameters for the simulated measurement. The class `Simulation` and default\nconfigurations for the simulation (`default_configs`) can be imported directly from `simcats`. Aside from that,\n`SimCATS` contains the subpackages `ideal_csd`, `sensor`, `distortions`, and `support_functions`, described in\nthe following sections.\n\n### Module `simulation`\n\nAn instance of the simulation class requires\n\n-   an implementation of the `IdealCSDInterface` for the simulation of ideal CSD data,\n-   an implementation of the `SensorInterface` for the simulation of the sensor (dot) reaction based on the ideal CSD\ndata, and\n-   (optionally) implementations of the desired types of distortions, which can be implementations from `OccupationDistortionInterface`, `SensorPotentialDistortionInterface`, or `SensorResponseDistortionInterface`.\n\nWith an initialized instance of the `Simulation` class, it is possible to run simulations using the `measure` function\n(see `example_SimCATS_simulation_class.ipynb`).\n\n### Subpackage `ideal_csd`\n\nThis subpackage contains the `IdealCSDInterface` used by the `Simulation` class  and an implementation of\nthe `IdealCSDInterface` (`IdealCSDGeometric`) based on our geometric simulation approach.\nAdditionally, it contains in the subpackage `geometric` the functions used by `IdealCSDGeometric`, including the\nimplementation of the total charge transition (TCT) definition and functions for calculating the occupations using TCTs.\n\n### Subpackage `distortions`\n\nThe distortions subpackage contains the `DistortionInterface` from which the `OccupationDistortionInterface`, the \n`SensorPotentialDistortionInterface`, and the `SensorResponseDistortionInterface` are derived. Distortion functions used\nin the `Simulation` class have to implement these specific interfaces. Implemented distortions included in the\nsubpackage are:\n\n-   white noise, generated by sampling from a normal distribution,\n-   pink noise, generated using the package colorednoise ([https://github.com/felixpatzelt/colorednoise](https://github.com/felixpatzelt/colorednoise)),\n-   random telegraph noise (RTN), generated using the algorithm described in [\"Toward Robust Autotuning of Noisy Quantum Dot Devices\" by Ziegler et al.](https://doi.org/10.1103/PhysRevApplied.17.024069) (RTN is called sensor jumps there),\n-   dot jumps, simulated using the algorithm described in [\"Toward Robust Autotuning of Noisy Quantum Dot Devices\" by Ziegler et al.](https://doi.org/10.1103/PhysRevApplied.17.024069) (In the `Simulation` class, this is applied to a whole block of rows or columns, but there is also a function for applying it linewise.), and\n-   lead transition blurring, simulated using Gaussian or Fermi-Dirac blurring.\n\nThe implementations also offer the option to set ratios (parameter `ratio`) for the occurrence of the distortion (e.g. dot jumps may only happen sometimes and not in every measurement). Moreover, it is also possible to sample the\nnoise parameters from a given sampling range using an object of type `ParameterSamplingInterface`.\nClasses for randomly sampling from a normal distribution or a uniform distribution within a given range are available in\nthe subpackage `support_functions`.\nIn this case, the strength is randomly chosen from the given range for every measurement.\nAdditionally, it is possible to specify that this range should be a smaller subrange of the provided range.\nThis allows restricting distortion fluctuations during a simulation while enabling a large variety of different strengths\nfor the initialization of the objects. <br>\nRTN, dot jumps, and lead transition blurring are applied in the pixel domain. However, the jump length or the blurring strength should be consistent in the voltage domain even if the resolution changes. Therefore, the parameters\nare given in the voltage domain and adjusted according to the resolution in terms of pixel per voltage. <br>\nFor a simulated measurement with a continuous voltage sweep involving an averaging for each pixel, the noise strength of the\nwhite and pink noise should be adjusted if the resolution (volt per pixel) changes, due to smoothing out the noise. This smoothing depends on the type of averaging used and is not incorporated in the default implementation.\n\n### Subpackage `sensor`\n\nThis subpackage contains the `SensorInterface` that defines how a sensor simulation must be implemented to be used by the `Simulation` class. The `SensorPeakInterface` provides the desired representation for the definition of the Coulomb peaks the sensor uses. `SensorGeneric` implements the `SensorInterface` and offers functions for simulating the sensor response and potential. It offers the possibility to simulate with a single peak or multiple sensor peaks. Current implementations of the `SensorPeakInterface` are `SensorPeakGaussian` and `SensorPeakLorentzian`.\n\n### Subpackage `support_functions`\n\nThis subpackage contains support functions, which are used by the end user and by different functions of the framework.  \n- `fermi_filter1d` is an implementation of a one-dimensional Fermi-Dirac filter.\n- `plot_csd` plots one and two-dimensional CSDs. The function can also plot ground truth data (see `example_SimCATS_simulation_class.ipynb` for examples).  \n- `rotate_points` simply rotates coordinates (stored in a (n, 2) shaped array) by a given angle. It is especially used during the generation of the ideal data.\n- `ParameterSamplingInterface` defines an interface for randomly sampled (fluctuated) strengths of distortions.\n  - `NormalSamplingRange` and `UniformSamplingRange` are implementations of the `ParameterSamplingInterface`.\n\n## Citations\n\n```bibtex\n@article{hader2024simcats,\n  author={Hader, Fabian and Fleitmann, Sarah and Vogelbruch, Jan and Geck, Lotte and Waasen, Stefan van},\n  journal={IEEE Transactions on Quantum Engineering}, \n  title={Simulation of Charge Stability Diagrams for Automated Tuning Solutions (SimCATS)}, \n  year={2024},\n  volume={5},\n  pages={1-14},\n  doi={10.1109/TQE.2024.3445967}\n}\n```\n\n## License, CLA, and Copyright\n\n[![CC BY-NC-SA 4.0][cc-by-nc-sa-shield]][cc-by-nc-sa]\n\nThis work is licensed under a\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License][cc-by-nc-sa].\n\n[![CC BY-NC-SA 4.0][cc-by-nc-sa-image]][cc-by-nc-sa]\n\n[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/\n[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png\n[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg\n\nContributions must follow the Contributor License Agreement. For more information, see the CONTRIBUTING.md file at the top of the GitHub repository.\n\nCopyright © 2024 Forschungszentrum Jülich GmbH - Central Institute of Engineering, Electronics and Analytics (ZEA) - Electronic Systems (ZEA-2)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/simona",
            "repo_link": "https://github.com/jokergoo/simona",
            "readme": "# simona: Semantic Similarity on Bio-Ontologies\n\n\n## Introduction\n\nThis package implements infrastructures for ontology analysis by offering \nefficient data structures, fast ontology traversal methods, and elegant visualizations. \nIt provides a robust toolbox supporting over 70 methods for semantic similarity analysis.\n\nMost methods implemented in **simona** are from\nthe [supplementary file](https://academic.oup.com/bib/article/18/5/886/2562801#supplementary-data)\nof the paper [\"Mazandu et al., Gene Ontology semantic similarity tools: survey\non features and challenges for biological knowledge discovery. Briefings in\nBioinformatics 2017\"](https://doi.org/10.1093/bib/bbw067).\n\n## Citation\n\nZuguang Gu. simona: a comprehensive R package for semantic similarity analysis on bio-ontologies. bioRxiv, 2023. https://doi.org/10.1101/2023.12.03.569758\n\n## Install\n\n**simona** is available on [Bioconductor](https://bioconductor.org/packages/release/bioc/html/simona.html).\nIt can be installed by:\n\n```r\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"simona\")\n```\n\nOr the devel version:\n\n```r\ndevtools::install_github(\"jokergoo/simona\")\n```\n\n## Usage\n\nCreat an ontology object:\n\n```r\nlibrary(simona)\nparents  = c(\"a\", \"a\", \"b\", \"b\", \"c\", \"d\")\nchildren = c(\"b\", \"c\", \"c\", \"d\", \"e\", \"f\")\ndag = create_ontology_DAG(parents, children)\ndag\n```\n\n```\nAn ontology_DAG object:\n  Source: Ontology \n  6 terms / 6 relations\n  Root: a \n  Terms: a, b, c, d, ...\n  Max depth: 3 \n  Aspect ratio: 0.67:1 (based on the longest distance from root)\n                0.68:1 (based on the shortest distance from root)\n```\n\nFrom GO:\n\n```r\ndag = create_ontology_DAG_from_GO_db(\"BP\", org_db = \"org.Hs.eg.db\")\ndag\n```\n\n```\nAn ontology_DAG object:\n  Source: GO BP / GO.db package\n  28140 terms / 56449 relations\n  Root: GO:0008150\n  Terms: GO:0000001, GO:0000002, GO:0000003, GO:0000011, ...\n  Max depth: 18\n  Aspect ratio: 342.43:1 (based on the longest distance from root)\n                780.22:1 (based on the shortest distance from root)\n  Relations: is_a, part_of\n  Annotations are available.\n\nWith the following columns in the metadata data frame:\n  id, name, definition\n```\n\nImport from an `.obo` file:\n\n```r\ndag = import_obo(\"https://purl.obolibrary.org/obo/po.obo\")\ndag\n```\n\n```\nAn ontology_DAG object:\n  Source: po, releases/2023-07-13 \n  1656 terms / 2512 relations\n  Root: _all_ \n  Terms: PO:0000001, PO:0000002, PO:0000003, PO:0000004, ...\n  Max depth: 13 \n  Aspect ratio: 25.08:1 (based on the longest distance from root)\n                39.6:1 (based on the shortest distance from root)\n  Relations: is_a, part_of\n\nWith the following columns in the metadata data frame:\n  id, short_id, name, namespace, definition\n```\n\nThe following IC methods are provided:\n\n```\n> all_term_IC_methods()\n [1] \"IC_offspring\"     \"IC_height\"        \"IC_annotation\"    \"IC_universal\"\n [5] \"IC_Zhang_2006\"    \"IC_Seco_2004\"     \"IC_Zhou_2008\"     \"IC_Seddiqui_2010\"\n [9] \"IC_Sanchez_2011\"  \"IC_Meng_2012\"     \"IC_Wang_2007\"\n```\n\nThe following semantic similarity methods are provided:\n\n```\n> all_term_sim_methods()\n [1] \"Sim_Lin_1998\"         \"Sim_Resnik_1999\"      \"Sim_FaITH_2010\"      \n [4] \"Sim_Relevance_2006\"   \"Sim_SimIC_2010\"       \"Sim_XGraSM_2013\"     \n [7] \"Sim_EISI_2015\"        \"Sim_AIC_2014\"         \"Sim_Zhang_2006\"      \n[10] \"Sim_universal\"        \"Sim_Wang_2007\"        \"Sim_GOGO_2018\"       \n[13] \"Sim_Rada_1989\"        \"Sim_Resnik_edge_2005\" \"Sim_Leocock_1998\"    \n[16] \"Sim_WP_1994\"          \"Sim_Slimani_2006\"     \"Sim_Shenoy_2012\"     \n[19] \"Sim_Pekar_2002\"       \"Sim_Stojanovic_2001\"  \"Sim_Wang_edge_2012\"  \n[22] \"Sim_Zhong_2002\"       \"Sim_AlMubaid_2006\"    \"Sim_Li_2003\"         \n[25] \"Sim_RSS_2013\"         \"Sim_HRSS_2013\"        \"Sim_Shen_2010\"       \n[28] \"Sim_SSDD_2013\"        \"Sim_Jiang_1997\"       \"Sim_Kappa\"           \n[31] \"Sim_Jaccard\"          \"Sim_Dice\"             \"Sim_Overlap\"         \n[34] \"Sim_Ancestor\" \n```\n\nThe following group similarity methods are provided:\n\n```\n> all_group_sim_methods()\n [1] \"GroupSim_pairwise_avg\"            \"GroupSim_pairwise_max\"           \n [3] \"GroupSim_pairwise_BMA\"            \"GroupSim_pairwise_BMM\"           \n [5] \"GroupSim_pairwise_ABM\"            \"GroupSim_pairwise_HDF\"           \n [7] \"GroupSim_pairwise_MHDF\"           \"GroupSim_pairwise_VHDF\"          \n [9] \"GroupSim_pairwise_Froehlich_2007\" \"GroupSim_pairwise_Joeng_2014\"    \n[11] \"GroupSim_SimALN\"                  \"GroupSim_SimGIC\"                 \n[13] \"GroupSim_SimDIC\"                  \"GroupSim_SimUIC\"                 \n[15] \"GroupSim_SimUI\"                   \"GroupSim_SimDB\"                  \n[17] \"GroupSim_SimUB\"                   \"GroupSim_SimNTO\"                 \n[19] \"GroupSim_SimCOU\"                  \"GroupSim_SimCOT\"                 \n[21] \"GroupSim_SimLP\"                   \"GroupSim_Ye_2005\"                \n[23] \"GroupSim_SimCHO\"                  \"GroupSim_SimALD\"                 \n[25] \"GroupSim_Jaccard\"                 \"GroupSim_Dice\"                   \n[27] \"GroupSim_Overlap\"                 \"GroupSim_Kappa\" \n```\n\nThere is also a visualization on the complete DAG:\n\n```r\nsig_go_ids = readRDS(system.file(\"extdata\", \"sig_go_ids.rds\", package = \"simona\"))\ndag_circular_viz(dag, highlight = sig_go_ids, reorder_level = 3, \n  legend_labels_from = \"name\")\n```\n\n![](https://github.com/jokergoo/simona/assets/449218/ada30534-182e-4513-93bf-9819e84b8604)\n\n\n## License\n\nMIT @ Zuguang Gu\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/simpa",
            "repo_link": "https://github.com/IMSY-DKFZ/simpa",
            "readme": "<div align=\"center\">\n\n![Logo](https://github.com/IMSY-DKFZ/simpa/raw/main/docs/source/images/simpa_logo.png?raw=true \"SIMPA Logo\")\n\n[![Documentation Status](https://readthedocs.org/projects/simpa/badge/?version=develop)](https://simpa.readthedocs.io/en/develop/?badge=develop)\n![Build Status](https://github.com/IMSY-DKFZ/simpa/actions/workflows/automatic_testing.yml/badge.svg)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/IMSY-DKFZ/simpa/blob/main/LICENSE.md)\n[![Pypi Badge](https://img.shields.io/pypi/v/simpa)](https://pypi.org/project/simpa/)\n[![PyPI downloads](https://img.shields.io/pypi/dw/simpa?color=gr&label=pypi%20downloads)](https://pypi.org/project/simpa/)\n\n</div>\n\n# The toolkit for Simulation and Image Processing for Photonics and Acoustics (SIMPA)\n\nSIMPA aims to facilitate realistic image simulation for optical and acoustic imaging modalities by\nproviding adapters to crucial modelling steps, such as volume generation; optical modelling; acoustic\nmodelling; and image reconstruction. SIMPA provides a communication layer between various modules\nthat implement optical and acoustic forward and inverse models.\nNon-experts can use the toolkit to create sensible simulations from default parameters in an end-to-end fashion. Domain experts are provided with the functionality to set up a highly customisable\npipeline according to their specific use cases and tool requirements.\nThe paper that introduces SIMPA including visualisations and explanations can be found here: [https://doi.org/10.1117/1.JBO.27.8.083010](https://doi.org/10.1117/1.JBO.27.8.083010)\n\n* [Getting started](#getting-started)\n* [Simulation examples](#simulation-examples)\n* [Documentation](#documentation)\n* [Reproducibility](#reproducibility)\n* [Contributing](#how-to-contribute)\n* [Performance profiling](#performance-profiling)\n* [Troubleshooting](#troubleshooting)\n* [Citation](#citation)\n* [Funding](#funding)\n\nThe toolkit is still under development and is thus not fully tested and may contain bugs. \nPlease report any issues that you find in our Issue Tracker: https://github.com/IMSY-DKFZ/simpa/issues. \nAlso make sure to double check all value ranges of the optical and acoustic tissue properties \nand to assess all simulation results for plausibility.\n\n# Getting started\n\nIn order to use SIMPA in your project, SIMPA has to be installed as well as the external tools that make the actual simulations possible.\nFinally, to connect everything, SIMPA has to find all the binaries of the simulation modules you would like to use.\nThe SIMPA path management takes care of that.\n\n* [SIMPA installation instructions](#simpa-installation-instructions)\n* [External tools installation instructions](#external-tools-installation-instructions)\n* [Path Management](#path-management)\n* [Testing](#run-manual-tests)\n\n## SIMPA installation instructions\n\nThe recommended way to install SIMPA is a manual installation from the GitHub repository, please follow steps 1 - 3:\n\n1. `git clone https://github.com/IMSY-DKFZ/simpa.git`\n2. `cd simpa`\n3. `git checkout main`\n4. `git pull`\n\nNow open a python instance in the 'simpa' folder that you have just downloaded. Make sure that you have your preferred\nvirtual environment activated (we also recommend python 3.10)\n1. `pip install .` or `pip install -e .` for an editable mode. \n2. Test if the installation worked by using `python` followed by `import simpa` then `exit()`\n\nIf no error messages arise, you are now setup to use SIMPA in your project.\n\nYou can also install SIMPA with pip. Simply run:\n\n`pip install simpa`\n\nYou also need to manually install the pytorch library to use all features of SIMPA.\nTo this end, use the pytorch website tool to figure out which version to install:\n[https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)\n\n## External tools installation instructions\n\nIn order to get the full SIMPA functionality, you should install all third party toolkits that make the optical and \nacoustic simulations possible. \n\n### mcx (Optical Forward Model)\n\nDownload the latest nightly build of [mcx](http://mcx.space/) on [this page](http://mcx.space/nightly/github/) for your operating system:\n\n- Linux: `mcx-linux-x64-github-latest.zip`\n- MacOS: `mcx-macos-x64-github-latest.zip`\n- Windows: `mcx-windows-x64-github-latest.zip`\n\nThen extract the files and set `MCX_BINARY_PATH=/.../mcx/bin/mcx` in your path_config.env.\n\n### k-Wave (Acoustic Forward Model)\n\nPlease follow the following steps and use the k-Wave install instructions \nfor further (and much better) guidance under:\n\n[http://www.k-wave.org/](http://www.k-wave.org/)\n\n1. Install MATLAB with the core, image processing and parallel computing toolboxes activated at the minimum.\n2. Download the kWave toolbox (version >= 1.4)\n3. Add the kWave toolbox base path to the toolbox paths in MATLAB\n4. If wanted: Download the CPP and CUDA binary files and place them in the k-Wave/binaries folder\n5. Note down the system path to the `matlab` executable file.\n\n## Path management\n\nAs a pipelining tool that serves as a communication layer between different numerical forward models and\nprocessing tools, SIMPA needs to be configured with the paths to these tools on your local hard drive.\nYou have a couple of options to define the required path variables. \n### Option 1: \nEnsure that the environment variables defined in `simpa_examples/path_config.env.example` are accessible to your script during runtime. This can be done through any method you prefer, as long as the environment variables are accessible through `os.environ`. \n### Option 2:\nImport the `PathManager` class to your project using\n`from simpa.utils import PathManager`. If a path to a `.env` file is not provided, the `PathManager` looks for a `path_config.env` file (just like the\none we provided in the `simpa_examples/path_config.env.example`) in the following places, in this order:\n1. The optional path you give the PathManager\n2. Your $HOME$ directory\n3. The current working directory\n4. The SIMPA home directory path\n   \nFor this option, please follow the instructions in the `simpa_examples/path_config.env.example` file. \n\n## Run manual tests\nTo check the success of your installation ot to assess how your contributions affect the Simpa simulation outcomes, you can run the manual tests automatically. Install the testing requirements by doing `pip install .[testing]` and run the `simpa_tests/manual_tests/generate_overview.py` file. This script runs all manual tests and generates both a markdown and an HTML file that compare your results with the reference results.\n\n# Simulation examples\n\nTo get started with actual simulations, SIMPA provides an [example package](simpa_examples) of simple simulation \nscripts to build your custom simulations upon. The [minimal optical simulation](simpa_examples/minimal_optical_simulation.py)\nis a nice start if you have MCX installed.\n\nGenerally, the following pseudo code demonstrates the construction and run of a simulation pipeline:\n\n```python\nimport simpa as sp\n\n# Create general settings \nsettings = sp.Settings(general_settings)\n\n# Create specific settings for each pipeline element \n# in the simulation pipeline\nsettings.set_volume_creation_settings(volume_creation_settings)\nsettings.set_optical_settings(optical_settings)\nsettings.set_acoustic_settings(acoustic_settings)\nsettings.set_reconstruction_settings(reconstruction_settings)\n\n# Set the simulation pipeline\nsimulation_pipeline = [sp.VolumeCreationModule(settings),\n                       sp.OpticalModule(settings),\n                       sp.AcousticModule(settings),\n                       sp.ReconstructionModule(settings)]\n    \n# Choose a PA device with device position in the volume\ndevice = sp.CustomDevice()\n\n# Simulate the pipeline\nsp.simulate(simulation_pipeline, settings, device)\n```\n\n# Reproducibility\n\nFor reproducibility, we provide the exact version number including the commit hash in the simpa output file.\nThis can be accessed via `simpa.__version__` or by checking the tag `Tags.SIMPA_VERSION` in the output file.\nThis way, you can always trace back the exact version of the code that was used to generate the simulation results.\n\n# Documentation\n\nThe updated version of the SIMPA documentation can be found at [https://simpa.readthedocs.io/en/develop](https://simpa.readthedocs.io/en/develop).\n\n## Building the documentation\n\nIt is also easily possible to build the SIMPA documentation from scratch.\nWhen the installation succeeded, and you want to make sure that you have the latest documentation\nyou should do the following steps in a command line:\n\n1. Make sure that you've installed the optional dependencies needed for the documentation by running `pip install .[docs]`\n2. Navigate to the `simpa/docs` directory\n2. If you would like the documentation to have the https://readthedocs.org/ style, type `pip install sphinx-rtd-theme`\n3. Type `make html`\n4. Open the `index.html` file in the `simpa/docs/build/html` directory with your favourite browser.\n\n# How to contribute\n\nPlease find a more detailed description of how to contribute as well as code style references in our\n[contribution guidelines](CONTRIBUTING.md).\n\nTo contribute to SIMPA, please fork the SIMPA github repository and create a pull request with a branch containing your \nsuggested changes. The core developers will then review the suggested changes and integrate these into the code \nbase.\n\nPlease make sure that you have included unit tests for your code and that all previous tests still run through. Please also run the pre-commit hooks and make sure they are passing.\nDetails are found in our [contribution guidelines](CONTRIBUTING.md).\n\nThere is a regular SIMPA status meeting every Friday on even calendar weeks at 10:00 CET/CEST, and you are very welcome to participate and\nraise any issues or suggest new features. If you want to join this meeting, write one of the core developers.\n\nPlease see the github guidelines for creating pull requests: [https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests)\n\n\n# Performance profiling\n\nWhen changing the SIMPA core, e.g., by refactoring/optimizing, or if you are curious about how fast your machine runs\nSIMPA, you can run the SIMPA [benchmarking scripts](simpa_examples/benchmarking/run_benchmarking.sh). Make sure to install the necessary dependencies via \n`pip install .[profile]` and then run:\n\n```bash\nbash ./run_benchmark.sh\n```\n\nonce for checking if it works and then parse [--number 100] to run it at eg 100 times for actual benchmarking.\nPlease see [benchmarking.md](docs/source/benchmarking.md) for a complete explanation.\n\n\n# Understanding SIMPA\n\n**Tags** are identifiers in SIMPA used to categorize settings and components within simulations, making configurations\nmodular, readable, and manageable. Tags offer organizational, flexible, and reusable benefits by acting as keys in\nconfiguration dictionaries.\n\n**Settings** in SIMPA control simulation behavior. They include:\n\n- **Global Settings**: Apply to the entire simulation, affecting overall properties and parameters.\n- **Component Settings**: Specific to individual components, allowing for detailed customization and optimization of\neach part of the simulation.\n\nSettings are defined in a hierarchical structure, where global settings are established first, followed by\ncomponent-specific settings. This approach ensures comprehensive and precise control over the simulation process.\nFor detailed information, users can refer to the [understanding SIMPA documentation](./docs/source/understanding_simpa.md).\n\n# Troubleshooting\n\nIn this section, known problems are listed with their solutions (if available):\n\n## 1. Error reading hdf5-files when using k-Wave binaries:\n   \nIf you encounter an error similar to:\n\n    Error using h5readc\n    The filename specified was either not found on the MATLAB path or it contains unsupported characters.\n\nLook up the solution in [this thread of the k-Wave forum](http://www.k-wave.org/forum/topic/error-reading-h5-files-when-using-binaries).  \n\n## 2. KeyError: 'time_series_data'\n\nThis is the error which will occur for ANY k-Wave problem. For the actual root of the problem, please either look above in\nthe terminal for the source of the bug or run the scripts in Matlab to find it manually.\n      \n# Citation\n\nIf you use the SIMPA tool, we would appreciate if you cite our Journal publication in the Journal of Biomedical Optics:\n\nGröhl, Janek, Kris K. Dreher, Melanie Schellenberg, Tom Rix, Niklas Holzwarth, Patricia Vieten, Leonardo Ayala, Sarah E. Bohndiek, Alexander Seitel, and Lena Maier-Hein. *\"SIMPA: an open-source toolkit for simulation and image processing for photonics and acoustics.\"* **Journal of Biomedical Optics** 27, no. 8 (2022).\n\n```Bibtex\n@article{2022simpatoolkit,\n  title={SIMPA: an open-source toolkit for simulation and image processing for photonics and acoustics},\n  author={Gr{\\\"o}hl, Janek and Dreher, Kris K and Schellenberg, Melanie and Rix, Tom and Holzwarth, Niklas and Vieten, Patricia and Ayala, Leonardo and Bohndiek, Sarah E and Seitel, Alexander and Maier-Hein, Lena},\n  journal={Journal of Biomedical Optics},\n  volume={27},\n  number={8},\n  year={2022},\n  publisher={SPIE}\n}\n```\n\n# Funding\n\nThis project has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No. [101002198]).\n\n![ERC](https://github.com/IMSY-DKFZ/simpa/raw/main/docs/source/images/LOGO_ERC-FLAG_EU_.jpg \"ERC\")\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/simplifyenrichment",
            "repo_link": "https://github.com/jokergoo/simplifyEnrichment",
            "readme": "# Simplify Functional Enrichment Results\n\n[![R-CMD-check](https://github.com/jokergoo/simplifyEnrichment/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/simplifyEnrichment/actions)\n[![bioc](http://www.bioconductor.org/shields/downloads/devel/simplifyEnrichment.svg)](https://bioconductor.org/packages/stats/bioc/simplifyEnrichment/) \n[![bioc](http://www.bioconductor.org/shields/years-in-bioc/simplifyEnrichment.svg)](http://bioconductor.org/packages/devel/bioc/html/simplifyEnrichment.html)\n\n### Features\n\n- A new method (binary cut) is proposed to efficiently cluster functional terms (_e.g._ GO terms) into groups from the semantic similarity matrix.\n- Summaries of functional terms in each cluster are visualized by word clouds.\n\n### Citation\n\nZuguang Gu, et al., simplifyEnrichment: an R/Bioconductor package for Clustering and Visualizing Functional Enrichment Results, _Genomics, Proteomics & Bioinformatics 2022_. [https://doi.org/10.1016/j.gpb.2022.04.008](https://doi.org/10.1016/j.gpb.2022.04.008).\n\n### Install\n\n`simplifyEnrichment` is available on [Bioconductor](http://www.bioconductor.org/packages/devel/bioc/html/simplifyEnrichment.html), you can install it by:\n\n```r\nif (!requireNamespace(\"BiocManager\", quietly=TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"simplifyEnrichment\")\n```\n\nIf you want to try the latest version, install it directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/simplifyEnrichment\")\n```\n\n### Usage\n\nAs an example, I first generate a list of random GO IDs.\n\n```r\nlibrary(simplifyEnrichment)\nset.seed(888)\ngo_id = random_GO(500)\nhead(go_id)\n# [1] \"GO:0003283\" \"GO:0060032\" \"GO:0031334\" \"GO:0097476\" \"GO:1901222\"\n# [6] \"GO:0018216\"\n```\n\nThen generate the GO similarity matrix, split GO terms into clusters and visualize it.\n\n```r\nmat = GO_similarity(go_id)\nsimplifyGO(mat)\n```\n\n![](https://user-images.githubusercontent.com/449218/89673686-133c8600-d8e7-11ea-89fe-5221cb64d819.png)\n\n\n### License\n\nMIT @ Zuguang Gu\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/smash",
            "repo_link": "https://github.com/smash-transport/smash",
            "readme": "# SMASH\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3484711.svg)](https://doi.org/10.5281/zenodo.3484711)\n\nSMASH (Simulating Many Accelerated Strongly-interacting Hadrons) is a relativistic hadronic transport approach for the dynamical description of heavy-ion reactions.\nPlease see [Phys. Rev. C 94, 054905 (2016)](https://arxiv.org/abs/1606.06642) for details and, if you are using SMASH, cite this reference together with the [software DOI](https://doi.org/10.5281/zenodo.3484711) for the specific code version employed.\nA BibTeX entry for the software DOI is found on the respective Zenodo pages.\n\nSee [CONTRIBUTING](CONTRIBUTING.md) for development hints.\nA complete [User Guide](https://theory.gsi.de/~smash/userguide/current/) as well as a more detailed [development documentation](http://theory.gsi.de/~smash/doc/current/) are available for the latest version of the code.\nFor documentation of older versions, refer to links in the [releases pages](https://github.com/smash-transport/smash/releases).\n\nIf Pythia is used, please cite the following references (both article and the codebase release you used):\n* [_A comprehensive guide to the physics and usage of PYTHIA 8.3_](https://scipost.org/SciPostPhysCodeb.8), C. Bierlich et al; SciPost Phys. Codebases 8 (2022), DOI: `10.21468/SciPostPhysCodeb.8`, also available on [arXiv](https://arxiv.org/abs/2203.11601);\n* [SciPost Phys. Codebases 8-r8.3](https://scipost.org/SciPostPhysCodeb.8-r8.3) (2022), DOI: `10.21468/SciPostPhysCodeb.8-r8.3`.\n\nReport issues [on GitHub](https://github.com/smash-transport/smash/issues) or contact us by  [✉️ email](mailto:elfner@itp.uni-frankfurt.de).\n\n## How to build and install SMASH\n\nIn the following you can find a minimal quick start guide.\nRefer to the [INSTALL](INSTALL.md) file for more detailed information.\n\n### Prerequisites\n\nSMASH is known to compile and work on 64-bit little endian machines (most CPUs are such) with UNIX-like operating systems (e.g. GNU/Linux, MacOS) and one of the following compilers (which have the required C++17 features):\n\n| Compiler   | Required version |\n|  :---:     |       :---:      |\n| GCC        |  8.0 or higher   |\n| Clang      |  7.0 or higher   |\n| Apple clang| 11.0 or higher   |\n\nAny different operating system and/or compiler and/or endianness is not officially supported and SMASH will ask you to continue at your own risk before compilation.\n\nSMASH requires the following tools and libraries:\n\n| Software | Required version |\n|  :---:   |       :---:      |\n| [CMake](https://cmake.org) | 3.16 or higher |\n| [GNU Scientific Library (GSL)](https://www.gnu.org/software/gsl/) | 2.0  or higher |\n| [Eigen3 library](http://eigen.tuxfamily.org) | 3.0  or higher |\n| [Pythia](https://pythia.org) | 8.310 |\n\nSupport for ROOT, HepMC3 and Rivet output is automatically enabled if a suitable version is found on the system:\n\n| Software | Required version |\n|  :---:   |       :---:      |\n| ROOT     | 5.34 or higher   |\n| HepMC3   | 3.2.3 or higher  |\n| Rivet    | 3.1.4 or higher  |\n\n### Compilation and installation\n\nFrom within the SMASH repository, use the following commands to build the codebase in a separate directory:\n```console\nmkdir build\ncd build\ncmake -DPythia_CONFIG_EXECUTABLE=/path/to/pythia8310/bin/pythia8-config ..\nmake\n```\nPlease note that the `make` command builds everything (executables, tests and libraries) and might take a while.\nYou can use `make smash` if you are interest in the SMASH executable only or use `make smash_shared` to exclusively build the libraries (needed e.g. in another project using SMASH as library).\n\nYou can run SMASH with specific settings (e.g. at a given collision energy or impact parameter) by modifying the config.yaml file, for example with\n```console\nvi config.yaml\n./smash\n```\nRefer to the [section below](README.md#running-smash-with-example-input-files) for more information.\n\nIf you want to install SMASH system-wide (into `/usr/local`) use\n```console\nmake install\n```\n\n⚠️ **NOTE:** All commands above are the bare minimum needed for an installation.\nIt is not guaranteed that this minimum setup is appropriate for your needs or your specific computing environment.\nFor example, several different options can be passed e.g. to the `cmake` command.\nWe strongly advise you to further refer to the [INSTALL](INSTALL.md) file for more guidance, especially if you encounter any issues.\n\n\n## Using the Docker containers\n\nAs an alternative to building or installing SMASH, a Docker image of the latest or recently tagged version can be pulled from the Github container registry.\nGet the newest version with\n```console\ndocker pull ghcr.io/smash-transport/smash:newest\n```\n\nStart the container with\n```console\ndocker run -it ghcr.io/smash-transport/smash:newest\n```\n\nA ready-to-use executable of SMASH is found in the `smash_bin` directory.\nRun it as explained below.\nIf needed, SMASH can also be built inside the container as explained in the previous section (the SMASH source files and Pythia are also found in the `/SMASH` directory).\n\nTwo container versions of SMASH are offered:\n* a small version (`ghcr.io/smash-transport/smash`) with a minimal set of dependencies\npre-installed and\n* a large version with all possible external dependencies, e.g. ROOT, HepMC and Rivet, already included (`ghcr.io/smash-transport/smash-max`).\n\nNote that running SMASH inside of a Docker container might negatively affect performance.\nMore information about containers usage can be found [here](containers/README.md).\n\n#### Note for users with ARM CPUs (e.g. Apple M1/M2 chips)\n\nOur Docker images are prepared for the x86-64 CPU architecture.\nTo make them compatible with computers with ARM CPUs (like in the case of Apple M1 and M2 chips),\n`docker` must be launched with the `--platform=linux/amd64` option.\nFor example:\n```console\ndocker run --platform=linux/amd64 -it ghcr.io/smash-transport/smash:newest\n```\nHowever, this is not always guaranteed to work and it might be necessary to build an image for the ARM architecture, as described [here](containers/README.md).\n\n## Running SMASH with Example Input Files\n\nSMASH ships example configuration files for running in the collider, box, sphere, and list mode (`Modus` in the configuration jargon).\nBy default, i.e. by running `./smash`, the simulation is set up from the collider configuration file, called _config.yaml_, and using the default particles and decay modes files (_particles.txt_ and _decaymodes.txt_, respectively).\nThey are located in the repository ***input*** folder.\n\nAdditionally, example configuration files for the box, sphere and list modus can be found in the respective directories ***input/{box,sphere,list}***.\nIf needed, e.g. in the case of a box simulation, different default particles and decay modes files can be used.\nExamples for these are also provided in ***input/box***.\n\nFinally, for the list modus, an input list file to be read in is required and an example is provided as _input/list/example_list0_.\n\nIn general, to run SMASH with a non-default configuration file, use the `-i` command.\nFor example, for the sphere or list example file, from the ***build*** folder, use:\n```console\n    ./smash -i ../input/sphere/config.yaml\n    ./smash -i ../input/list/config.yaml\n```\n\nFurthermore, if using non-default particles and decay modes files is necessary, these can be specified through the `-p` and `-d` options.\nIn the box and the dileptons example, always from the ***build*** folder, this means:\n```console\n./smash -i ../input/box/config.yaml -p ../input/box/particles.txt -d ../input/box/decaymodes.txt\n./smash -i ../input/dileptons/config.yaml -d ../input/dileptons/decaymodes.txt\n```\n\nAll available command line options for SMASH can be viewed with\n```console\n./smash -h\n```\nTo run SMASH completely silently for production runs, we recommend to suppress the standard output via e.g.\n```console\n./smash > /dev/null\n```\nand it might be useful to redirect warnings and error messages, that will still be displayed, to a file:\n```console\n./smash > /dev/null 2> /path/to/error-and-warnings-file\n```\n\n\n## License\n\nSMASH is licensed under the terms of the GNU General Public License, Version 3 or above.\nThe build scripts are licensed under terms of the BSD 3-clause license.\nFor more information, see [LICENSE](LICENSE).\n\n\n## Projects Using SMASH\n\nSMASH source and documentation are provided to check and reproduce published results of the authors.\nCooperation and joint projects with outside researchers are encouraged and comparison to results by experimental collaborations is supported.\nIf you are interested in starting a project, please contact us to avoid interference with current thesis topics.\nIf your project involves changes to the code, please refer to [CONTRIBUTING](CONTRIBUTING.md) for coding guidelines and helpful tools.\nSMASH can also be used as a 3rd party library, for examples see the ***examples*** folder in the repository.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/smg2s",
            "repo_link": "https://github.com/SMG2S/SMG2S",
            "readme": "# Sparse Matrix Generator with Given Spectrum\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.2692117.svg)](https://doi.org/10.5281/zenodo.2692117)\n\n-------------------------------------------------------------------------------\n\n\n* [Overview](#overview)\n    * [What is SMG2S?](#what-is-smg2s?)\n    * [Cite SMG2S](#cite-smg2s)\n    * [Gallery: Sparsity Patterns](#some-sparsity-patterns)\n    * [Contact and Contributation](#contact-and-contributation)\n* [Documentation](#documentation)\n    * [Getting SMG2S](#getting-smg2s)\n    * [Dependencies](#dependencies)\n    * [Quick start](#quick-start)\n    * [Installation](#installation)\n    * [Use SMG2S with own project](#use-smg2s-with-own-project)\n        * [header-only](#header-only)\n        * [CMake](#cmake)\n    * [Usage](#usage)\n        * [Parallel vector and sparse matrix](#parallel-vector-and-sparse-matrix)\n            * [parVectorMap class](#parvectormap-class)\n            * [parVector class](#parvector-class)\n            * [parMatrixSparse class](#parmatrixsparse-class)\n        * [Building blocks of SMG2S](#building-blocks-of-smg2s)\n        * [Assembling the building blocks](#assembling-the-building-blocks)\n        * [Mini-app](#mini-app)\n    * [Format of Given Spectrum Files](#format-of-given-spectrum-files)\n        * [Real eigenvalues for non-Symmetric matrices](#real-eigenvalues-for-non-symmetric-matrices)\n        * [Complex eigenvalues for non-Hermtian matrices](#complex-eigenvalues-for-non-hermtian-matrices)\n        * [Conjugate eigenvalues for non-Symmetric matrices](#conjugate-eigenvalues-for-non-symmetric-matrices)\n    * [Parallel I/O](#parallel-i/o)\n        * [I/O for parallel vector](#i/o-for-parallel-vector)\n        * [I/O for parallel sparse matrix](#i/o-for-parallel-sparse-matrix)\n    * [Interface](#interface)\n      * [Interface to C](#interface-to-c)\n    * [Plotting and Validation](#plotting-and-validation)\n\n-------------------------------------------------------------------------------\n## Overview\n\nAuthor [Xinzhe Wu](https://brunowu.github.io) @ [Maison de la Simulation](http://www.maisondelasimulation.fr), France (2016-2019).\n\n                                  @ [SDL Quantum Materials](https://www.fz-juelich.de/en/ias/jsc/about-us/structure/simulation-and-data-labs/sdl-quantum-materials), Forschungszentrum Juelich GmbH, Germany (2019-present).\n\n****\n\n### What is SMG2S?\n\n**SMG2S** is able to generate large-scale non-Hermitian and non-Symmetric matrices in parallel with the spectral distribution functions or eigenvalues given by users, and the spectrum of generated matrix is the same as the one specified by the users. SMG2S can be used to benchmark the iterative solvers for both linear systems and eigenvalue problems on supercomputers using the generated very large test matrices with customized spectral properties.\n\nAs a matrix generator, SMG2S provides:\n\n- generating of both Non-Hermitian and Non-Symmetric sparse matrix\n\n- generated matrices are naturally sparse with non-trivial sparsity pattern\n\n- Given Spectrum: the spectrum of generated matrix is the same as the one specified by the users\n\n- Sparsity patterns are diverse and controllable\n\nAs a software, SMG2S provides:\n\n* a collection of C++ header only files\n* C++ templated implementation for different data type\n* parallel implementation based on [MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface) which is able to efficiently generate very large sparse matrices in parallel on supercomputers\n* an easy-to-use C interface\n* a verification module based on Python for the sparsity pattern plotting and spectrum verification of small size of generated matrix.\n* Efficient parallel IO to store the generated matrix into [MatrixMarket format](https://math.nist.gov/MatrixMarket/formats.html)\n\n### Cite SMG2S\n\nIf you find SMG2S useful in your project, we kindly request that you cite the following paper:\n\n*Wu, Xinzhe, Serge G. Petiton, and Yutong Lu. \"A Parallel Generator of Non-Hermitian Matrices computed from Given Spectra.\" Concurrency and Computation: Practice and Experience, 32(20), e5710, 2020. [[DOI]](https://doi.org/10.1002/cpe.5710) [[PDF]](https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cpe.5710?casa_token=UUntHdbHvo4AAAAA:CHJa3O1_B-15_eHKY09LuWdh5TNs_trh_IXa_qDuNZLeTKcxa4CQt9WzrNsU1XSWxunknU8GeXP9Ihv9)*\n\n### Some Sparsity Patterns\n\nHere are some sparsity patterns of matrices generated by SMG2S.\n\n![Matrix Generation Pattern](docs/figure/pattern.png)\n\n### Contact and Contribution\n\nFeel free to contact by email address: **xin DOT wu AT fz BAR juelich DOT de**.\n\n## Documentation\n\n### Getting SMG2S\n\nSMG2S is able to available on the Github. The most updated version of SMG2S can be gotten either by the following `git` command:\n\n```bash\ngit clone https://github.com/SMG2S/SMG2S.git\n```\n\nMoreover a released version can be downloaded [here](https://github.com/SMG2S/SMG2S/releases)\n\n### Dependencies\n\nSMG2S is developed in `C++14` and `MPI`, and it is compiled with `CMake`. So the following software and compiler should be available before the installation of SMG2S.\n\n1. a `C++` compiler with `C++14` support\n\n2. `MPI`: message passing interface\n\n3. `CMake`: version >= `3.8`\n\n### Quick start\n\nSMG2S provides an executable `smg2s.exe` that the users can compile and start to play with SMG2S without installation as follows. \n\n```bash\ncd SMG2S\nmkdir build & cd build\ncmake .. \nmake -j\n```\n\nThen the executable `smg2s.exe`is available, and it can be run as follows:\n\n```bash\n  mpirun -np ${PROCS} ./smg2s.exe -D ${dim} -L ${diag_l} -U ${diag_u} -O ${offset} -C ${nbOne} -S ${sparsity} -M {no-herm or non-symm}\n```\n\nin which the command line parsers provides the customization of following parameters:\n\n```bash\nusage: ./smg2s.exe [options] ...\noptions:\n  -D, --dim           Dimension of matrix to be generated (int [=1000])\n  -L, --diagL         offset of lower diagonal of initial matrix (int [=-10])\n  -U, --diagU         offset of upper diagonal of initial matrix (int [=-5])\n  -O, --nilpOffset    offset of diagonal of a nilpotent (int [=5])\n  -C, --continous     Continuous length in Nilpotent matrix (int [=2])\n  -S, --sparsity      sparsity of initial matrix (NOT THE FINAL GENERATED ONES) (double [=0.95])\n  -M, --mattype       Matrix type to be generated: non-symmetric or non-Hermitian (string [=non-herm])\n  -?, --help          print this message\n```\n\n### Installation\n\nSMG2S relies on CMake for compiling and installation. A CMake flag `CMAKE_INSTALL_PREFIX` should be provided for the path of installation.\n\n```bash\ncd SMG2S\nmkdir build & cd build\ncmake .. -DCMAKE_INSTALL_PREFIX=${PATH_TO_INSTALL}\nmake -j install\n```\n\n### Use SMG2S with own project\n\n#### header-only\n\nSMG2S is a collection of C++ header files. If users want to use SMG2S with C++, they can just copy SMG2S headers into their project.\n\n#### CMake\n\nSMG2S is installed as a CMake package, and it can be detected by the CMake `find_package` command. If the installation path is not in the default searching path of CMake, a CMake flag `CMAKE_PREFIX_PATH` should be provided which links to the installation path of SMG2S.\n\nSo in your own project which want to use SMG2S:\n\n```bash\nmkdir build & cd build\ncmake .. -DCMAKE_PREFIX_PATH=${INSTALLED_PATH_OF_SMG2S}\nmake -j\n```\n\nand in the `CMakeLists.txt` of own project, it should provide some content as follows:\n\n```cmake\ncmake_minimum_required(VERSION 3.8)\nproject(YOUR-OWN-PROJECT)\n#find installation of SMG2S\nfind_package( smg2s REQUIRED CONFIG)\n# for C++ code\nadd_executable(smg2s-app test_parMatrix.cpp)\ntarget_link_libraries(smg2s-app PUBLIC SMG2S::smg2s)\n# for C-interface code\nadd_executable(test_c.exe test_c.c)\ntarget_link_libraries(test_c.exe PRIVATE SMG2S::smg2s2c)\n```\n\nIn case that the support of `C++14` is disabled by some compilers, please insert also the following lines into your `CMakeLists.txt` before the usage of SMG2S.\n\n```cmake\ninclude(CheckCXXCompilerFlag)\nCHECK_CXX_COMPILER_FLAG(\"-std=c++14\" COMPILER_SUPPORTS_CXX14)\nif(COMPILER_SUPPORTS_CXX14)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++14\")\nelse()\n     message([FATAL_ERROR] \"The compiler ${CMAKE_CXX_COMPILER} has no C++14 support. Please use a different C++ compiler.\")\nendif()\n```\n\n### Usage\n\n#### Parallel vector and sparse matrix\n\nIn SMG2S, the parallelisation is supported through that both vectors and sparse matrices are naturally distributed across a 1D MPI grid of processes. SMG2S grants the freedom to the user to decide the way to distribute the vector and sparse matrices across a group of processes, e.g, for a parallel vector, user can decide the range of global indices dedicated to each process. \n\n##### parVectorMap class\n\n`parVectorMap` is a class which determines the way to distribute a vector or sparse matrix across multiple MPI processes:\n\n- This class is to create a mapping from a fixed-size vector to multiple MPI procs in 1D grid.\n\n- This class can also be used to create more distributed vectors and sparse matrices following the same way.\n\n- For each MPI proc, a piece of vector with indexing `[lower_bound, upper_bound)` is allocated.\n\n- This class is templated such that different `integer` can be used to describes the dimension of vector and matrices.\n\n- This class provides a series of member funtions for querying, please refer to [parVectorMap full API](https://smg2s.github.io/SMG2S/classpar_vector_map.html) for more details.\n\nHere is an example:\n\n```cpp\nMPI_Init(&argc, &argv);\n\nint world_size;\nint world_rank;\nint probSize = 7;\nMPI_Comm_size(MPI_COMM_WORLD, &world_size);\nMPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\nint span, lower_b, upper_b;\n\nspan = int(ceil(double(probSize)/double(world_size)));\n\nif(world_rank == world_size - 1){\n    lower_b = world_rank * span;\n    upper_b = probSize - 1 + 1;\n}else{\n    lower_b = world_rank * span;\n    upper_b = (world_rank + 1) * span - 1 + 1;\n}\nauto parVecMap = parVectorMap<int>(MPI_COMM_WORLD, lower_b, upper_b);\n```\n\n##### parVector class\n\n`parVector` class construts a dense vector across a group of MPI processes. \n\n- It is able to be initialized by a `parVectorMap` object, and following the distribution scheme determined by this `parVectorMap` object.\n\n- It is also able to be directly initialized by the range of global indices of a vector owned by each MPI process, the same as the construction of a `parVectorMap` object.\n\n- This class provides a series of member funtions for querying and manuplating of a distributed vector, please refer to [parVector full API](https://smg2s.github.io/SMG2S/classpar_vector.html) for more details.\n\n- This class is also templated which allows to build a vector with different scalar types, either real or complex, either double precision or single precision....\n\n##### parMatrixSparse class\n\n`parMatrixSparse`class constructs a sparse matrix across a group of MPI processes.\n\n- The sparse matrix is distributed on a 1D MPI process grid by row.\n  \n  - a `parMatrixSparse` object can be constructed with a `parVectorMap` obejct, such that the distribution of rows of a sparse matrix follows the way determined by this `paraVectorMap` object\n  \n  - a `parMatrixSparse`object can be also constributed with a `parVector`object, what makes this sparse matrix share the same distribution scheme with this vector.\n  \n  - For any operations, which takes both sparse matrix and vector, they should also share the same distribution scheme\n\n- This class provides a series of member funtions for querying, manuplating and mathematical operations of a distributed sparse matrices,  please refer to [parMatrixSparse full API](https://smg2s.github.io/SMG2S/classpar_matrix_sparse.html) for more details.\n\n \n\n#### Building blocks of SMG2S\n\nIn order to generate a sparse matrix with user-provided spectrum, SMG2S requires the customization of three building blocks by the users:\n\n1. user-provided spectrum\n\n2. a nilpotent matrix\n\n3. initial matrix\n\nRoughly, the workflow of SMG2S to generate a sparse matrix is that:\n\n1. a strict lower-triangular matrix is generated, which is of the same size as the matrices to be generated. This matrix can be any shape, \n   \n   - for generating non-Symmetric matrices of real eigenvalues or non-Hermtian matrices, the only constraint is to be strict lower-triangluar. \n   \n   - for generating non-Synmmetric matrices of conjugated eigenvalues, this matrix can be any strict lower-triangluar and the diagonal next to the main diagonal to be empty.\n\n   - In SMG2S, a simple struct `initMat` is provided which stores 4 parameters determining a initial matrix: `diag_l`, `diag_u`, `scale` and `sparisty`. It means that the between diagonal with offset `diag_l` and `diag_u` of lower-triangular part is filled with non-zeros elements randomly generated between `0` and `1`. The values of these elements can also be scaled with the parameter `scale`. The parameter `sparisty` determines that sparsity of inital matrix, not the final generated matrices.\n\n   - Here is the details of [`initMat`](https://smg2s.github.io/SMG2S/structinit_mat.html)\n\n2. the user-provided spectrum is stored in a `parVector` object, which shares the same distribution scheme as initial matrix. \n   \n   The spectrum can be generated:\n   \n   - inplace through the manuplating member functions of the `parVector` class\n   \n   - by loading from local text files following a specific formats, [click](#format-of-given-spectrum-files) for more details.\n\n   - parallel I/Os are provided which loads the spectrums from local, for more details, please visit [I/O for loading spectrum](https://smg2s.github.io/SMG2S/group__group1.html).\n\n   The spectrum vector is to set on the initial matrix in a way that:\n   \n   - for non-symmetric matrices with real eigenvalues or non-Hermtian matrices, the spectrum will be set directly on the main diagonal.\n   \n   - for non-symmetric matrices with conjugated eigenvalues, the real parts of eigenvalues are set on the main diagonal, and their imaginary parts are set either on the lower or upper diagonal next to the diagonal following a built-in mechanism in SMG2S. (That's why the lower diagonal next to the main diagonal of initial matrix is expected to be empty for generating non-Symmetric matrices with conjugated eigenvalues).\n\n3. the initial matrix is either right or left multiplied by a nilpotent which manages to more its entries around and keeps the spectrum at the same time. For more details, please see the algorithm shown in our paper: [[PDF]](https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cpe.5710?casa_token=UUntHdbHvo4AAAAA:CHJa3O1_B-15_eHKY09LuWdh5TNs_trh_IXa_qDuNZLeTKcxa4CQt9WzrNsU1XSWxunknU8GeXP9Ihv9).\n\n    - a class named `Nilpotent` is implemented in SMG2S, which determines the nilpotent matrix used in SMG2S.\n\n    - this class provides multiple constructors of a nilpotent matrix, either with some simple parameters, or a user-provided vector. please visit [Nilpotent class](https://smg2s.github.io/SMG2S/group__group1.html) for more details.\n\n\n#### Assembling the building blocks\n\nSMG2S provides the generation of matrices in three different categories:\n\n1. non-Hermtian matrices with complex eigenvalues\n\n2. non-Symmetric matrices with real eigenvalues\n\n3. non-Symmetric matrices with conjugated eigenvalues\n\nFor each categories, SMG2S provides three functions which allows the users having different levels of freedom to control and customize the properties of generated matrices.\n\n- 1st level: users need to provide multiple simple parameters (for inital matrix and nilpotent) and a local text file containing the eigenvalues. The distribution of matrix over MPI processes is established by using the built-in scheme in SMG2S.\n\n- 2nd level: users need to provide multiple simple parameters (for inital matrix and nilpotent). The spectrum is generated by the user on the fly and stored in a `parVector` object. The generated matrix shares the same distribution scheme as the spectrum vector.\n\n- 3rd level: users need to provide multiple simple parameters for the nilpotent. The initial matrix is provided by the users with the manuplating operations provided by SMG2S. The spectrum is also generated by the user and stored in a `parVector` object which shares the same distribution with the initial matrix.\n\nFor more details about the APIs, please visit [here](https://smg2s.github.io/SMG2S/group__group2.html).\n\n\n#### Mini-app\n\nHere is an mini-app of SMG2S which generates non-Hermitian and non-Symmetric matrices with different types of input spectrum.\n\n\n```cpp\n#include <mpi.h>\n#include <smg2s-interface.hpp>\n\nint main(int argc, char** argv) \n{\n    MPI_Init(&argc, &argv);\n    \n    int world_size;\n    int world_rank;\n    int probSize = 7;\n    int l_diag = -7;\n    int u_diag = -3;\n    int nbOne = 2;\n    int offset = 1;\n    double sparsity = 0.5;\n\n    /* construct a nilpotent object for generation */\n    Nilpotent<int> nilp = Nilpotent<int>(nbOne, offset, probSize);\n    \n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n    int span, lower_b, upper_b;\n    span = int(floor(double(probSize)/double(world_size)));\n\n    if(world_rank == world_size - 1){\n        lower_b = world_rank * span;\n        upper_b = probSize - 1 + 1;\n    }else{\n        lower_b = world_rank * span;\n        upper_b = (world_rank + 1) * span - 1 + 1;\n    }\n\n    /* construct a parVecMap object which determines the distribution scheme of vectors and matrices*/\n    auto parVecMap = parVectorMap<int>(MPI_COMM_WORLD, lower_b, upper_b);\n    \n    /* example 1, generation of a non-Hermtian matrix */\n    // 1. generate the spectrum on the fly\n    parVector<std::complex<double>, int> spec1 = parVector<std::complex<double>, int>(parVecMap);\n    for(int i = lower_b; i < upper_b; i++){\n        std::complex<double> v(i+1, i+2);\n        spec1.SetValueGlobal(i, v);\n    }\n    // 2. generation \n    auto mat = nonherm<std::complex<double>, int>(probSize, nilp, initMat<int>(l_diag, u_diag, sparsity), spec1);\n\n    /* example 2, generation of a non-Symmetric matrix with real eigenvalues */\n    // 1. generate the spectrum on the fly\n    parVector<double, int> spec2 = parVector<double, int>(parVecMap);\n    for(int i = lower_b; i < upper_b; i++){\n        spec2.SetValueGlobal(i, i+1);\n    }\n    // 2. generation \n    auto mat2 = nonsymm<double , int>(probSize, nilp, initMat<int>(l_diag, u_diag, sparsity), spec2);\n\n    /* example 3, generation of a non-Symmetric matrix with conjugated eigenvalues */\n    // 1. generate the spectrum on the fly\n    parVector<std::complex<double>, int> spec3 = parVector<std::complex<double>, int>(parVecMap);\n\n    for(int i = lower_b; i < upper_b; i++){\n        if(i % 2 == 0){\n            std::complex<double> v(i/2 + 1, i/2 + 2);\n            spec3.SetValueGlobal(i, v);\n        }else{\n            std::complex<double> v(i/2 + 1, -i/2 - 2);\n            spec3.SetValueGlobal(i, v);\n        }\n        if(i == probSize - 1){\n            std::complex<double> v(i + 1, 0);\n            spec3.SetValueGlobal(i, v);\n        }\n    }\n    // 2. generation \n    auto mat3 = nonsymmconj<double , int>(probSize, nilp, initMat<int>(l_diag, u_diag, sparsity), spec3);\n\n    MPI_Finalize();\n}\n\n```\n\n\n### Format of Given Spectrum Files\n\nSMG2S is able to load user-provided spectrum in parallel from local text files. However, the provided files should conform into a specific format.\n\n1. The first line is the comment part which includes the scalar types of given spectrum. This line should be: `%%SMG2S vector in complex scalar` and `%%SMG2S vector in real scalar` for the eigenvalues in complex or real scalar type, respectively. **Attention**, for this line, the keyword `complex` or `real` should always be there and conform with the type of user-provided spectrum. The parallel IO of SMG2S queries at first this line to check if the provided eigenvalues are complex or real.\n\n2. The second line indicates the number of given eigenvaues in the files. For the ones with `3` complex values, it is `3 3 3`, and for the ones with `3` real eigenvalues, it should be `3 3`.\n\n3. Starting from the `3rd` line, it is the main content of this file. It can have either `2` or `3` columns, which depends on the scalar types of eigenvalues. For the case with complex values, the first column indicates the coordinates for each eigenvalue, the second column contains the real part of eigenvalues, and the third column is for the imaginary part of eigenvalues. For the case with real values, the two columns contain the indexing and values of eigenvalues, respectively. **Attention**, the indexing is `1`-based, rather than `0`-based.  \n\n#### Real eigenvalues for non-Symmetric matrices\n\nFor the case with real eigenvalues for non-Symmetric matrices, the given spectrum file format should be as follows:\n\n```\n%%SMG2S vector in real scalar\n3 3 \n1 10\n2 3.4790\n3 5.0540\n```\n\n#### Complex eigenvalues for non-Hermtian matrices\n\nFor the complex values for non-Hermitian matrices which are not supposed to be conjugated, the given spectrum is stored in three columns, the first column is the coordinates, the second column is the real part of complex values, and the third column is the imaginary part of complex values. Here is an example with `3` eigenvalues:\n\n    %%SMG2S vector in complex scalar\n    3 3 3\n    1 10 6.5154\n    2 10.6288 3.4790\n    3 10.7621 5.0540\n\n#### Conjugate eigenvalues for non-Symmetric matrices\n\nFor the non-Symmetric matrices whose entries are all in real scalar, they can have conjugate eigenvalues which are in complex scalar. So in order to generate non-Symmetric test matrices with given conjugated eigenvalues, the give spectrum are always stored in complex form, with three columns.\n\n**Attention**\n\nFor the non-Symmetric matrices, if one eigenvalue is complex, there is another value that they two are symmetric to the real axis in the real-imaginary plain, this is their conjugated eigenvalue. So when setting up the spectral file, one eigenvalue `a+bi` with `b != 0` should be closely followed by another eigenvalue `a-bi`. For the eigenvalues with their imaginary part to be `0`, they are stored with their imaginary part being 0. Here is an example\n\n    %%SMG2S vector in complex scalar\n    9 9 9\n    1 10.6288 -3.4790\n    2 10.6288 3.4790\n    3 2.332 0\n    4 10.7621 5.0540\n    5 10.7621 -5.0540\n    6 -2.332 0\n    7 -11.02 0\n    8 21.21 4.4\n    9 21.21 -4.4\n\n### Parallel I/O\n\n#### I/O for parallel vector\n\n- SMG2S provides the input funtionalities which is able to load spectrum from local in parameters. For more details, please visit [I/O for loading spectrum](https://smg2s.github.io/SMG2S/group__group1.html).\n\n- SMG2S provides also the output functions as member functions of  `parVector` class which saves a `parVector` object into local text files (the same format as [Format of Given Spectrum Files](#format-of-given-spectrum-files)):\n\n    - [writeToTxt](https://smg2s.github.io/SMG2S/classpar_vector.html#ae52e90a3105c377140f432251e2a3a8b) saves a vector with real scalar types.\n\n    - [writeToTxtCmplx](https://smg2s.github.io/SMG2S/classpar_vector.html#aab9f38beb4a793bf20c43431eb665d36) saves a vector with complex scalar types.\n\n#### I/O for parallel sparse matrix\n\n- SMG2S provides the writing functions which saves a `parMatrixSparse` in parallel into a local files with MatrixMarket format.\n\n    - [writeToMatrixMarket](https://smg2s.github.io/SMG2S/classpar_matrix_sparse.html#ae0bb25445d859997c267d01028de2457) saves a sparse matrix with real scalar types.\n\n    - [writeToMatrixMarketCmplx](https://smg2s.github.io/SMG2S/classpar_matrix_sparse.html#ae2106220d853b165ff53a4a643fc47d9) saves a sparse with complex scalar types.\n\n\n### Interface\n\n#### Interface to C\n\nSMG2S provides a interface to `C` for the cases with double precision scalar and both `int` and `long` for integer. In summary:\n\n- For the scalars, only `double precision` are supported.\n\n- For the integer, both `int` and `long` are supported.\n\n- Namings for C-intefaces:\n\n    - for `Nilpotent`, `initMat` and `parVectorMap`, the interfaces for the case with `long` integer has a letter `L` in some part of related function names.\n\n    - for `parVector` and `parMatrixSparse` and other independant functions which don't belong to any classes and structs, their function names starts with one of the four prefix `ds_`, `dl_`, `zs_` and `zl_`. Here, `d` refers to `double`, `s` refers to `int`, `z` refers to `dcomplex_t` and `l` refers to `long`.\n\n    - for the meaning of each function, please refer to the coresponding `C++` functions for more details.\n\n    - Here's a full [list](https://smg2s.github.io/SMG2S/group__group5.html) of APIs for the `C` interface.\n\nA basic example of usage, which is equivalent to the previous `C++` [Mini-app](#mini-app):\n\n```c\n#include <C/c-smg2s.h>\n#include <mpi.h>\n#include <math.h>\n\nint main(int argc, char* argv[]) {\n\n    MPI_Init(&argc, &argv);\n\n    int world_size;\n    int world_rank;\n\n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n\n    int probSize = 7;\n    int span, lower_b, upper_b;\n\n    int diagl = -5;\n    int diagu = -3;\n    int offset = 1;\n    int nbOne = 2;\n    double sparsity = 0.5;\n    /* construct a nilpotent object for generation */\n    nilp_t *nilp = newNilp_2(nbOne, offset, probSize);\n\n    span = (int)ceil((double)probSize/(double)world_size);\n\n    if(world_rank == world_size - 1){\n        lower_b = world_rank * span;\n        upper_b = probSize - 1 + 1;\n    }else{\n        lower_b = world_rank * span;\n        upper_b = (world_rank + 1) * span - 1 + 1;\n    }\n\n    /* construct a initMat object for SMG2S*/\n    initMatrix_t *initMat = newInitMatrix_3(diagl, diagu, sparsity);  \n    /* construct a parVecMap object which determines the distribution scheme of vectors and matrices*/\n    parVecMap_t *p = newParVecMap(MPI_COMM_WORLD, lower_b, upper_b);\n\n    /* example 1, generation of a non-Hermtian matrix */\n    // 1. generate the spectrum on the fly\n    zs_parVec_t *spec1 = new_zs_ParVec_2(p);\n    for(int i = lower_b; i < upper_b; i++){\n        dcomplex_t v = {i+1, i+2};\n        zs_parVecSetVal(spec1, i, v);\n    }\n    // 2. generation \n    zs_parMatSparse_t *mat1 = zs_nonherm_2(probSize, nilp, initMat, spec1);    \n    zs_parMatSparse_destory(mat1);\n\n    /* example 2, generation of a non-Symmetric matrix with real eigenvalues */\n    // 1. generate the spectrum on the fly\n    ds_parVec_t *spec2 = new_ds_ParVec_2(p);\n    for(int i = lower_b; i < upper_b; i++){\n        ds_parVecSetVal(spec2, i, i + 1);\n    }\n    // 2. generation \n    ds_parMatSparse_t *mat2 = ds_nonsymm_2(probSize, nilp, initMat, spec2);    \n    ds_parMatSparse_destory(mat2);\n\n    /* example 3, generation of a non-Symmetric matrix with conjugated eigenvalues */\n    // 1. generate the spectrum on the fly\n    zs_parVec_t *spec3 = new_zs_ParVec_2(p);\n    for(int i = lower_b; i < upper_b; i++){\n        if(i % 2 == 0){\n            dcomplex_t v = {i/2 + 1, i/2 + 2};\n            zs_parVecSetVal(spec3, i, v);\n        }else{\n            dcomplex_t v = {i/2 + 1, -i/2 - 2};\n            zs_parVecSetVal(spec3, i, v);\n        }\n        if(i == probSize - 1){\n            dcomplex_t v = {i + 1, 0};\n            zs_parVecSetVal(spec3, i, v);\n        }\n    }\n    // 2. generation \n    ds_parMatSparse_t *mat3 = ds_nonsymmconj_2(probSize, nilp, initMat, spec3);    \n    ds_parMatSparse_destory(mat3);\n\n    initMatrix_destory(initMat);\n    zs_parVec_destory(spec1);\n    ds_parVec_destory(spec2);\n    zs_parVec_destory(spec3);\n    nilp_destory (nilp);\n\n    MPI_Finalize();\n}\n```\n\n### Plotting and Validation\n\nSMG2S provides also a simple `python` script in [scripts/verification.py](scripts/verification.py), which provides a `spy` plotting function for the structure of a sparse matrix, and a verification function which compares the difference between the input spectrum and the spectrum of generated matrices.\n\n**Attention**, the spectrum of generated matrices are computed by the direct solver `eig` of `Python` package `numpy.linalg`, so this script is supposed to use for small size of matrices.\n\n```bash\nusage: verification.py [-h] [--matpath MATPATH] [--specpath SPECPATH] [--verify]\n\nverification of matrices generated matrices to keep given spectra\n\noptional arguments:\n  -h, --help           show this help message and exit\n  --matpath MATPATH    path of matrix to be plotted or verified. Matrix should be in MatrixMarket format\n  --specpath SPECPATH  path of spectrum to be verified which is used to generate the related matrix. Vector should be in SMG2S vector file format\n  --verify             if only plotting patterns or also verifying the spectrum: default false\n```\n\nThe [example 1](examples/ex1.cpp) provided by SMG2S can be a good starting point for the verification, since it provies multiple types of spectrums, and the spectrums and related matrices are all saved to local files through the parallel I/O of SMG2S.\n\nBelow are examples of the outputs of `verification.py` with two different sparse matrices generated with a same given spectrum. For more examples, please visit [docs/figure](docs/figure).\n\n![](docs/figure/verification_4.png)\n\n![](docs/figure/verification_5.png)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/somesy",
            "repo_link": "https://github.com/Materials-Data-Science-and-Informatics/somesy",
            "readme": "[\n![Docs](https://img.shields.io/badge/read-docs-success)\n](https://materials-data-science-and-informatics.github.io/somesy)\n[\n![CI](https://img.shields.io/github/actions/workflow/status/Materials-Data-Science-and-Informatics/somesy/ci.yml?branch=main&label=ci)\n](https://github.com/Materials-Data-Science-and-Informatics/somesy/actions/workflows/ci.yml)\n[\n![Test Coverage](https://materials-data-science-and-informatics.github.io/somesy/main/coverage_badge.svg)\n](https://materials-data-science-and-informatics.github.io/somesy/main/coverage)\n[\n![Docs Coverage](https://materials-data-science-and-informatics.github.io/somesy/main/interrogate_badge.svg)\n](https://materials-data-science-and-informatics.github.io/somesy)\n[\n![PyPIPkgVersion](https://img.shields.io/pypi/v/somesy)\n](https://pypi.org/project/somesy/)\n[\n![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/7701/badge)\n](https://bestpractices.coreinfrastructure.org/projects/7701)\n[\n![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F-green)\n](https://fair-software.eu)\n\n<!-- --8<-- [start:abstract] -->\n\n<div style=\"text-align: center;\">\n    <img alt=\"HMC Logo\" src=\"https://github.com/Materials-Data-Science-and-Informatics/Logos/raw/main/Somesy/Somesy_Logo_Text.png\" style=\"width: 50%; height: 50%;\" />\n</div>\n\n# somesy\n\nSomesy (**so**ftware **me**tadata **sy**nc) is a CLI tool to avoid messy software project metadata by keeping it in sync.\n\n## Description\n\nMany development tools either declare or need information about the software project they are used in, such as: the project name, description, version, repository url, license or project authors.\nMost such tools come with configuration files and conventions that are specific to the programming language or chosen technology.\nEmerging best practices for [FAIR](https://www.go-fair.org/fair-principles/) software metadata require to add even _more_ files where such metadata must be stated.\n\nIf good project metadata was a fire-and-forget issue, this would be acceptable, but software is never standing still - maintainers change, contributors come and go, the version number is regularly increased, the project might be moved to a different location.\nProperly maintaining this kind of information in various files scattered around the project is usually _tedious, error-prone and time consuming manual labor_.\n\n**Somesy automates the synchronization of software project metadata and frees your time to focus on your _actual_ work**.\n\n<!-- --8<-- [end:abstract] -->\n\n**You can find more information on configuring, using and contributing to `somesy` in the\n[documentation](https://materials-data-science-and-informatics.github.io/somesy/main).**\n\n<!-- --8<-- [start:quickstart] -->\n\n## Getting Started\n\n### Platform Support\n\nStarting with version **0.3.0**, `somesy` supports Linux, MacOS and Windows.\n\nMake sure that you use the latest version in order to avoid any problems.\n\n### Installing somesy\n\nSomesy requires Python `>=3.8`. To get a first impression, you can install the\nlatest stable version of somesy from PyPI using `pip`:\n\n```bash\npip install somesy\n```\n\n### Configuring somesy\n\nYes, somesy is _another_ tool with its own configuration. However, for your\nproject metadata it is hopefully the last file you need, and the only one you\nhave to think about, `somesy` will take care of the others for you!\n\nTo get started, create a file named `somesy.toml`:\n\n<!-- --8<-- [start:somesytoml] -->\n\n```toml\n[project]\nname = \"my-amazing-project\"\nversion = \"0.1.0\"\ndescription = \"Brief description of my amazing software.\"\n\nkeywords = [\"some\", \"descriptive\", \"keywords\"]\nlicense = \"MIT\"\nrepository = \"https://github.com/username/my-amazing-project\"\n\n# This is you, the proud author of your project:\n[[project.people]]\ngiven-names = \"Jane\"\nfamily-names = \"Doe\"\nemail = \"j.doe@example.com\"\norcid = \"https://orcid.org/0000-0000-0000-0001\"\nauthor = true      # is a full author of the project (i.e. appears in citations)\nmaintainer = true  # currently maintains the project (i.e. is a contact person)\n\n# this person is an acknowledged contributor, but not author or maintainer:\n[[project.people]]\ngiven-names = \"Another\"\nfamily-names = \"Contributor\"\nemail = \"a.contributor@example.com\"\norcid = \"https://orcid.org/0000-0000-0000-0002\"\n# ... but for scientific publications, this contributor should be listed as author:\npublication_author = true\n\n[config]\nverbose = true     # show detailed information about what somesy is doing\n```\n\n<!-- --8<-- [end:somesytoml] -->\n\nAlternatively, you can also add the somesy configuration to an existing\n`pyproject.toml`, `package.json`, `Project.toml`, or `fpm.toml` file. The somesy [manual](https://materials-data-science-and-informatics.github.io/somesy/main/manual/#somesy-input-file) contains examples showing how to do that.\n\n### Using somesy\n\nOnce somesy is installed and configured, somesy can take over and manage your project metadata.\nNow you can run `somesy` simply by using\n\n```bash\nsomesy sync\n```\n\nThe information in your `somesy.toml` is used as the **primary and\nauthoritative** source for project metadata, which is used to update all\nsupported (and enabled) _target files_. You can find an overview of supported\nformats further below.\n\nBy default, `somesy` will create (if they did not exist) or update `CITATION.cff` and `codemeta.json` files in your repository.\nIf you happen to use\n\n- `pyproject.toml` (in Python projects),\n- `package.json` (in JavaScript projects),\n- `Project.toml` (in Julia projects),\n- `fpm.toml` (in Fortran projects),\n- `pom.xml` (in Java projects),\n- `mkdocs.yml` (in projects using MkDocs),\n- `Cargo.toml` (in Rust projects)\n\nthen somesy would also update the respective information there.\n\nYou can see call available options with `somesy --help`,\nall of these can also be conveniently set in your `somesy.toml` file.\n\n### Somesy as a pre-commit hook\n\n<!-- --8<-- [start:precommit] -->\n\nWe highly recommend to use `somesy` as a [pre-commit hook](https://pre-commit.com/).\nA pre-commit hook runs on every commit to automatically point out issues or fix them on the spot,\nso if you do not use pre-commit in your project yet, you should start today!\nWhen used this way, `somesy` can fix most typical issues with your project\nmetadata even before your changes can leave your computer.\n\nTo add `somesy` as a pre-commit hook, add it to your `.pre-commit-config.yaml`\nfile in the root folder of your repository:\n\n```yaml\nrepos:\n  # ... (your other hooks) ...\n  - repo: https://github.com/Materials-Data-Science-and-Informatics/somesy\n    rev: \"v0.4.3\"\n    hooks:\n      - id: somesy\n```\n\nNote that `pre-commit` gives `somesy` the [staged](https://git-scm.com/book/en/v2/Getting-Started-What-is-Git%3F) version of files,\nso when using `somesy` with pre-commit, keep in mind that\n\n- if `somesy` changed some files, you need to `git add` them again (and rerun pre-commit)\n- if you explicitly run `pre-commit`, make sure to `git add` all changed files (just like before a commit)\n\n<!-- --8<-- [end:precommit] -->\n\n## Supported File Formats\n\nHere is an overview of all the currently supported files and formats.\n\n| Input Formats  | Status |     | Target Formats                | Status |\n| -------------- | ------ | --- | ----------------------------- | ------ |\n| (.)somesy.toml | ✓      |     | pyproject.toml _(poetry)_     | ✓      |\n| pyproject.toml | ✓      |     | pyproject.toml _(setuptools)_ | ✓(1.)  |\n| package.json   | ✓      |     | package.json _(JavaScript)_   | ✓(2.)  |\n| Project.toml   | ✓      |     | Project.toml _(Julia)_        | ✓      |\n| fpm.toml       | ✓      |     | fpm.toml _(Fortran)_          | ✓(3.)  |\n|                | ✓      |     | pom.toml _(Java)_             | ✓(4.)  |\n| Cargo.toml     | ✓      |     | Cargo.toml _(Rust)_           | ✓      |\n|                |        |     | mkdocs.yml                    | ✓(5.)  |\n|                |        |     | CITATION.cff                  | ✓      |\n|                |        |     | codemeta.json                 | ✓(6.)  |\n\n**Notes:**\n\n1. note that `somesy` does not support setuptools _dynamic fields_\n2. `package.json` only supports one author, so `somesy` will pick the _first_ listed author\n3. `fpm.toml` only supports one author and maintainer, so `somesy` will pick the _first_ listed author and maintainer\n4. `pom.xml` has no concept of `maintainers`, but it can have multiple licenses (somesy only supports one main project license)\n5. `mkdocs.yml` is a bit special, as it is not a project file, but a documentation file. `somesy` will only update it if it exists and is enabled in the configuration\n6. unlike other targets, `somesy` will _re-create_ the `codemeta.json` (i.e. do not edit it by hand!)\n\n<!-- --8<-- [end:quickstart] -->\n\n<!-- --8<-- [start:citation] -->\n\n## How to Cite\n\nIf you want to cite this project in your scientific work,\nplease use the [citation file](https://citation-file-format.github.io/)\nin the [repository](https://github.com/Materials-Data-Science-and-Informatics/somesy/blob/main/CITATION.cff).\n\n<!-- --8<-- [end:citation] -->\n<!-- --8<-- [start:acknowledgements] -->\n\n## Acknowledgements\n\nWe kindly thank all\n[authors and contributors](https://materials-data-science-and-informatics.github.io/somesy/latest/credits).\n\n<div>\n<img style=\"vertical-align: middle;\" alt=\"HMC Logo\" src=\"https://github.com/Materials-Data-Science-and-Informatics/Logos/raw/main/HMC/HMC_Logo_M.png\" width=50% height=50% />\n&nbsp;&nbsp;\n<img style=\"vertical-align: middle;\" alt=\"FZJ Logo\" src=\"https://github.com/Materials-Data-Science-and-Informatics/Logos/raw/main/FZJ/FZJ.png\" width=30% height=30% />\n</div>\n<br />\n\nThis project was developed at the Institute for Materials Data Science and Informatics\n(IAS-9) of the Jülich Research Center and funded by the Helmholtz Metadata Collaboration\n(HMC), an incubator-platform of the Helmholtz Association within the framework of the\nInformation and Data Science strategic initiative.\n\n<!-- --8<-- [end:acknowledgements] -->\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/spatialdata-framework",
            "repo_link": "https://github.com/scverse/spatialdata/",
            "readme": "![SpatialData banner](https://github.com/scverse/spatialdata/blob/main/docs/_static/img/spatialdata_horizontal.png?raw=true)\n\n# SpatialData: an open and universal framework for processing spatial omics data.\n\n[![Tests][badge-tests]][link-tests]\n[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/scverse/spatialdata/main.svg)](https://results.pre-commit.ci/latest/github/scverse/spatialdata/main)\n[![codecov](https://codecov.io/gh/scverse/spatialdata/branch/main/graph/badge.svg?token=X19DRSIMCU)](https://codecov.io/gh/scverse/spatialdata)\n[![documentation badge](https://readthedocs.org/projects/scverse-spatialdata/badge/?version=latest)](https://spatialdata.scverse.org/en/latest/)\n[![DOI](https://zenodo.org/badge/487366481.svg)](https://zenodo.org/badge/latestdoi/487366481)\n[![Downloads](https://static.pepy.tech/badge/spatialdata)](https://pepy.tech/project/spatialdata)\n\nSpatialData is a data framework that comprises a FAIR storage format and a collection of python libraries for performant access, alignment, and processing of uni- and multi-modal spatial omics datasets. This repository contains the core spatialdata library. See the links below to learn more about other packages in the SpatialData ecosystem.\n\n-   [spatialdata-io](https://github.com/scverse/spatialdata-io): load data from common spatial omics technologies into spatialdata.\n-   [spatialdata-plot](https://github.com/scverse/spatialdata-plot): Static plotting library for spatialdata.\n-   [napari-spatialdata](https://github.com/scverse/napari-spatialdata): napari plugin for interactive exploration and annotation of spatial data.\n\n[//]: # \"numfocus-fiscal-sponsor-attribution\"\n\nThe spatialdata project uses a [consensus based governance model](https://scverse.org/about/roles/) and is fiscally sponsored by [NumFOCUS](https://numfocus.org/). Consider making a [tax-deductible donation](https://numfocus.org/donate-to-scverse) to help the project pay for developer time, professional services, travel, workshops, and a variety of other needs.\n\nThe spatialdata project also received support by the Chan Zuckerberg Initiative.\n\n<div align=\"center\">\n  <a href=\"https://numfocus.org/project/scverse\">\n    <img height=\"60px\" \n         src=\"https://raw.githubusercontent.com/numfocus/templates/master/images/numfocus-logo.png\" \n         align=\"center\">\n  </a>\n</div>\n<br>\n\n![SpatialDataOverview](https://github.com/scverse/spatialdata/assets/1120672/cb91071f-12a7-4b8e-9430-2b3a0f65e52f)\n\n-   **The library is currently under review.** We expect there to be changes as the community provides feedback. We have an announcement channel for communicating these changes, please see the contact section below.\n-   The SpatialData storage format is built on top of the [OME-NGFF](https://ngff.openmicroscopy.org/latest/) specification.\n\n## Getting started\n\nPlease refer to the [documentation][link-docs]. In particular:\n\n-   [API documentation][link-api].\n-   [Design doc][link-design-doc].\n-   [Example notebooks][link-notebooks].\n\nAnother useful resource to get started is the source code of the [`spatialdata-io`](https://github.com/scverse/spatialdata-io) package, which shows example of how to read data from common technologies.\n\n## Installation\n\nCheck out the docs for more complete [installation instructions](https://spatialdata.scverse.org/en/stable/installation.html). To get started with the \"batteries included\" installation, you can install via pip:\n\n```bash\npip install \"spatialdata[extra]\"\n```\n\nor via conda:\n\n```bash\nmamba install -c conda-forge spatialdata napari-spatialdata spatialdata-io spatialdata-plot\n```\n\n## Limitations\n\n-   Code only manually tested for Windows machines. Currently the framework is being developed using Linux, macOS and Windows machines, but it is automatically tested only for Linux and macOS machines.\n\n## Contact\n\nTo get involved in the discussion, or if you need help to get started, you are welcome to use the following options.\n\n-   <ins>Chat</ins> via [`scverse` Zulip](https://scverse.zulipchat.com/#narrow/stream/315824-spatial) (public or 1 to 1).\n-   <ins>Forum post</ins> in the [scverse discourse forum](https://discourse.scverse.org/).\n-   <ins>Bug report/feature request</ins> via the [GitHub issue tracker][issue-tracker].\n-   <ins>Zoom call</ins> as part of the SpatialData Community Meetings, held every 2 weeks on Thursday, [schedule here](https://hackmd.io/enWU826vRai-JYaL7TZaSw).\n\nFinally, especially relevant for for developers that are building a library upon `spatialdata`, please follow this channel for:\n\n-   <ins>Announcements</ins> on new features and important changes [Zulip](https://imagesc.zulipchat.com/#narrow/stream/329057-scverse/topic/spatialdata.20announcements).\n\n## Citation\n\nMarconato, L., Palla, G., Yamauchi, K.A. et al. SpatialData: an open and universal data framework for spatial omics. Nat Methods (2024). https://doi.org/10.1038/s41592-024-02212-x\n\n<!-- Links -->\n\n[scverse-discourse]: https://discourse.scverse.org/\n[issue-tracker]: https://github.com/scverse/spatialdata/issues\n[changelog]: https://spatialdata.readthedocs.io/latest/changelog.html\n[design doc]: https://scverse-spatialdata.readthedocs.io/en/latest/design_doc.html\n[link-docs]: https://spatialdata.scverse.org/en/latest/\n[link-api]: https://spatialdata.scverse.org/en/latest/api.html\n[link-design-doc]: https://spatialdata.scverse.org/en/latest/design_doc.html\n[link-notebooks]: https://spatialdata.scverse.org/en/latest/tutorials/notebooks/notebooks.html\n[badge-tests]: https://github.com/scverse/spatialdata/actions/workflows/test.yaml/badge.svg\n[link-tests]: https://github.com/scverse/spatialdata/actions/workflows/test.yaml\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/spatialio",
            "repo_link": "https://codebase.helmholtz.cloud/ufz-sdi/spatialio",
            "readme": "<img src=\"img/spatial-io-logo.jpg\" alt=\"Spatial.IO-Logo\" height=\"55px\" style=\"margin-top: 15px;\" />\n\n<a href=\"https://www.ufz.de/index.php?en=45348\" target=\"_blank\">\n<img src=\"backend/main/static/RDM_logo.png\" alt=\"Spatial.IO-Logo\" align=\"right\" height=\"60px\" style=\"margin-top: 15px; margin-right: 10px\" />\n</a>\n<a href=\"https://www.ufz.de/\" target=\"_blank\">\n<img src=\"backend/main/static/UFZ_Logo_en.png\" alt=\"Spatial.IO-Logo\" align=\"right\" height=\"60px\" style=\"margin-top: 15px; margin-right: 30px\" />\n</a>\n\n\n# spatial.IO - An integrated cloud-ready geospatial data management system of the Helmholtz Center for Environmental Research (UFZ)\n\nA Spatial Data Infrastructure (SDI) is a combination of policies, standards and software to manage and deliver geospatial data ([Simmons, 2018](https://doi.org/10.1016/B978-0-12-409548-9.09611-1)). \nA good SDI follows policies and standards that are (widely) accepted in the communities (e.g.[FAIR](https://www.go-fair.org/fair-principles/), [OGC](https://www.ogc.org/)). \nAlthough often providing new functionality, the main advantage of an SDI is the connection of different tools and software products to build (mostly) automated workflows. \nThis allows for less manual processing (and therefore fewer errors) as well as standardised data products due to fixed workflows. For this to work flawlessly, extensive documentation and user instructions are key. \nAn SDI can contain (but is not limited to) data storage, metadata catalogue, tools for data processing, WebGIS and a form of data access (e.g. download, web service).\n\nClimate modelling and research increasingly produce and share the data standard of [netCDF](https://www.unidata.ucar.edu/software/netcdf/) files, leading to an increasing demand in automated management of netCDF data. \nThis application aims to provide automated workflows to manage standardized netCDF data and display them in an interactive WebGIS. The standard specifications follow the [Binding Regulations for Storing Data as netCDF Files](https://hereon-netcdf.readthedocs.io/en/latest/). \nOther vector and raster data formats ((Cloud optimized) GeoTIFF, sensor data) can be included in the workflows with manual work-steps and will be automated in the next versions. \nThe application will be expanded continuously into a self-service platform to create custom WebGIS, automated workflows and various (meta-)data provision interfaces for a wide range of spatial data formats.\n\n## Requirements\n\n- Simply [FAIR](https://www.go-fair.org/fair-principles/)\n- Science- and Management friendly: Provide interoperable and reliable netCDF data enriched by metadata and with provenance information.\n- User friendly: Easy to use user interface for people that manage netCDF data or create WebGIS for netCDF data, without requiring knowledge about underlying technologies like databases.\n- Admin friendly: A scalable and transferable container based solution that will smoothly integrate into typical scientific IT landscapes.\n- Developer friendly: Common open source solutions structured by microservice architecture to keep it open and simple to extend for developers.\n\n## Features\n\n- S3 cloud-storage with [MinIO](https://min.io/)\n- Creation of custom interactive WebGIS components for netCDF, STA and GeoTIFF data\n- Extendable processes to get spatially aggregated values for netCDF and GeoTIFF data\n- Use of django framework to make configuration of data and WebGIS user-friendly\n- Workflow for automated creation of OGC web services with [GeoServer](https://geoserver.org/) of new netCDF data\n- Workflow for automated creation of metadata entries in [GeoNetwork](https://geonetwork-opensource.org/)\n- [FROST®-Server](https://www.iosb.fraunhofer.de/de/projekte-produkte/frostserver.html) to store and access point data via OGC STA\n- [THREDDS Data Server (TDS)](https://www.unidata.ucar.edu/software/tds/) to provide netCDF data with [OPeNDAP](https://www.opendap.org/)\n\n## Getting Started\n\nStart all containers by running:\n\n\n    docker compose up -d\n\n\nIf you want to load test-data, run:\n\n\n    ./bin/load-testdata.sh\n\n\nTo try out the viewer, go to: [http://localhost:3000/gdi/](http://localhost:3000/gdi/)\n<br>\nFor modifying the content, go to [http://localhost:5001/gdi-backend/admin/](http://localhost:5001/gdi-backend/admin/) and log in with: _admin/admin_.\n<br>\n\n\n## Tech Stack, dependencies and third party open source products\n\n- [MinIO](https://min.io/)\n- [FROST®-Server](https://www.iosb.fraunhofer.de/de/projekte-produkte/frostserver.html)\n- [GeoServer](https://geoserver.org/)\n- [GeoNetwork](https://geonetwork-opensource.org/)\n- [THREDDS Data Server (TDS)](https://www.unidata.ucar.edu/software/tds/)\n- [django](https://www.djangoproject.com/)\n- [PostgreSQL](https://www.postgresql.org/)\n- [Vue](https://vuejs.org/)\n- [Bulma](https://bulma.io/)\n- [pygeoapi](https://pygeoapi.io/)\n\n## License\n\nAll software and components written within the spatial.IO project is currently licensed under the [EUPL](https://joinup.ec.europa.eu/sites/default/files/custom-page/attachment/eupl_v1.2_en.pdf).\n\n## How to cite spatial.IO\n\nIf spatial.IO is advancing your research, please cite as:\n\n> Schulz, Christian, Lange, Rebekka, & Bumberger, Jan (2023). spatial.IO - An integrated cloud-ready geospatial data management system. Zenodo. [https://zenodo.org/doi/10.5281/zenodo.10391523](https://zenodo.org/doi/10.5281/zenodo.10391523)\n\n## Technical implementation\n\n### Project Members\n\nspatial.IO is realized by:\n- Jan Bumberger (RDM at UFZ) (ORCID: [0000-0003-3780-8663](https://orcid.org/0000-0003-3780-8663))\n- Christian Schulz (RDM at UFZ) (ORCID: [0009-0003-7941-6059](https://orcid.org/0009-0003-7941-6059))\n- Rebekka Lange (RDM at UFZ) (ORCID: [0009-0000-1301-1372](https://orcid.org/0009-0000-1301-1372))\n\n### Software Developers\n\nspatial.IO is developed by:\n- Christian Schulz (RDM at UFZ) (ORCID: [0009-0003-7941-6059](https://orcid.org/0009-0003-7941-6059))\n- Rebekka Lange (RDM at UFZ) (ORCID: [0009-0000-1301-1372](https://orcid.org/0009-0000-1301-1372))\n\n### RDM\n\nThe technical implementation of this project was realised by the [Research Data Management Team (RDM)](https://www.ufz.de/index.php?en=45348) at the Helmholtz Center for Environmental Research. RDM at the UFZ is part of of the [Helmholtz Earth and Environment DataHub](https://datahub.erde-und-umwelt.de/en/) initiative.\n\n## Acknowledgements\n\nWe thank the [Helmholtz Association](https://www.helmholtz.de/en/) and the [Federal Ministry of Education and Research (BMBF)](https://www.bmbf.de/bmbf/en/home/home_node.html) \nfor supporting the [DataHub Initiative of the Research Field Earth and Environment](https://datahub.erde-und-umwelt.de/en/). \nThe DataHub enables an overarching and comprehensive research data management, following [FAIR](https://www.nature.com/articles/sdata201618) principles, \nfor all Topics in the Program [Changing Earth – Sustaining our Future](https://www.helmholtz.de/en/research/research-fields/earth-and-environment/).\n\n## Contact\n\nFeel free to contact [Christian Schulz](mailto:christian.schulz@ufz.de) and [Rebekka Lange](mailto:rebekka.lange@ufz.de) or the [UFZ RDM team](https://www.ufz.de/index.php?en=45348) in general with every question you may have.\n\n[Imprint](https://www.ufz.de/index.php?en=36683)",
            "project_id": "10821"
        },
        {
            "software_organization": "https://helmholtz.software/software/spechomo",
            "repo_link": "https://git.gfz-potsdam.de/geomultisens/spechomo",
            "readme": "==================================================================\nSpecHomo - Spectral homogenization of multispectral satellite data\n==================================================================\n\n* Free software: Apache-2.0\n* **Documentation:** https://geomultisens.git-pages.gfz-potsdam.de/spechomo/doc/\n* The **paper** corresponding to this software repository can be found here:\n  `Scheffler et al. 2020 <https://doi.org/10.1016/j.rse.2020.111723>`__ (cite as:\n  Scheffler D., Frantz D., Segl K. (2020). Spectral harmonization and red edge prediction of Landsat-8 to Sentinel-2\n  using land cover optimized multivariate regressors. Remote Sens. Environ. 241, 111723.\n  https://doi.org/10.1016/j.rse.2020.111723)\n* Information on how to **cite the SpecHomo Python package** can be found in the\n  `CITATION <https://git.gfz-potsdam.de/geomultisens/spechomo/-/blob/main/CITATION>`__ file.\n* Submit feedback by filing an issue `here <https://git.gfz-potsdam.de/geomultisens/spechomo/issues>`__\n  or join our chat here: |Gitter|\n\n.. |Gitter| image:: https://badges.gitter.im/Join%20Chat.svg\n    :target: https://gitter.im/spechomo/community#\n    :alt: https://gitter.im/spechomo/community#\n\nStatus\n------\n\n.. image:: https://git.gfz-potsdam.de/geomultisens/spechomo/badges/main/pipeline.svg\n        :target: https://git.gfz-potsdam.de/geomultisens/spechomo/commits/main\n.. image:: https://git.gfz-potsdam.de/geomultisens/spechomo/badges/main/coverage.svg\n        :target: https://geomultisens.git-pages.gfz-potsdam.de/spechomo/coverage/\n.. image:: https://img.shields.io/static/v1?label=Documentation&message=GitLab%20Pages&color=orange\n        :target: https://geomultisens.git-pages.gfz-potsdam.de/spechomo/doc/\n.. image:: https://img.shields.io/pypi/v/spechomo.svg\n        :target: https://pypi.python.org/pypi/spechomo\n.. image:: https://img.shields.io/conda/vn/conda-forge/spechomo.svg\n        :target: https://anaconda.org/conda-forge/spechomo\n.. image:: https://img.shields.io/pypi/l/spechomo.svg\n        :target: https://git.gfz-potsdam.de/geomultisens/spechomo/blob/main/LICENSE\n.. image:: https://img.shields.io/pypi/pyversions/spechomo.svg\n        :target: https://img.shields.io/pypi/pyversions/spechomo.svg\n.. image:: https://img.shields.io/pypi/dm/spechomo.svg\n        :target: https://pypi.python.org/pypi/spechomo\n.. image:: https://zenodo.org/badge/241405333.svg\n   :target: https://zenodo.org/badge/latestdoi/241405333\n\nSee also the latest coverage_ report and the pytest_ HTML report.\n\n\nFeature overview\n----------------\n\nSpecHomo is a **Python package for spectral homogenization of multispectral satellite data**, i.e., for the transformation\nof the spectral information of one sensor into the spectral domain of another one. This simplifies workflows, increases\nthe reliability of subsequently derived multi-sensor products and may also enable the generation of new products that\nare not possible with the initial spectral definition.\n\nSpecHomo offers **different machine learning techniques** for the prediction of the target sensor spectral information. So\nfar, multivariate linear regression, multivariate quadratic regression and random forest regression are implemented. To\nallow easy comparisons to the most simple homogenization approach, we also implemented linear spectral interpolation.\n\nIn contrast to previous spectral homogenization techniques, SpecHomo not only allows to apply a global (band-wise)\ntransformation with the same prediction coefficients for all gray values of a spectral band. It also **distinguishes**\n**between individual spectral characteristics of different land-cover types** by using specifically trained prediction\ncoefficients for various spectral clusters. This increases the accuracy of the predicted spectral information.\nApart from that, SpecHomo can not only be used to homogenize already similar spectral definitions - it also **allows to**\n**predict unilaterally missing bands** such as the red edge bands that are not present in Landsat-8 data.\n\n**Prediction accuracies and effects to subsequent products** such as spectral indices or classifications have been\nevaluated in the above mentioned paper at the example of Sentinel-2 spectral information predicted from Landsat-8.\nAlgorithm details may also be found there.\n\nSatellite data (surface reflectance) acquired by **following sensors may be used** as source or target sensor:\n\n* Landsat-5 TM\n* Landsat-7 ETM+\n* Landsat-8 OLI\n* Sentinel-2A MSI\n* Sentinel-2B MSI\n* RapidEye-5 MSI\n* SPOT-4\n* SPOT-5\n\nSpecHomo features **classifiers for homogenization** that we trained in the context of the GeoMultiSens project (see the\ncredits section) and for our evaluations related with the above mentioned paper. The initial spectral information for\nclassifier training has been derived from hyperspectral airborne data, spectrally convolved to different sensors. You\nmay also train your own homogenization classifiers specifically optimized to your area of interest. SpecHomo provides\nthe needed functionality for that.\n\nFor further details on how to use SpecHomo check out the\n`documentation <https://geomultisens.git-pages.gfz-potsdam.de/spechomo/doc/>`__!\n\nCredits\n-------\n\nThe spechomo package was developed within the context of the GeoMultiSens project funded\nby the German Federal Ministry of Education and Research (project grant code: 01 IS 14 010 A-C).\n\nThis package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage\n.. _coverage: https://geomultisens.git-pages.gfz-potsdam.de/spechomo/coverage/\n.. _pytest: https://geomultisens.git-pages.gfz-potsdam.de/spechomo/test_reports/report.html\n",
            "project_id": "591"
        },
        {
            "software_organization": "https://helmholtz.software/software/spex",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/spiralize",
            "repo_link": "https://github.com/jokergoo/spiralize",
            "readme": "# Visualize Data on Spirals <img width=\"150\" src=\"https://user-images.githubusercontent.com/449218/121876090-723e0900-cd09-11eb-8d0d-82fbeeb83997.png\" align=\"right\">\n\n\n[![R-CMD-check](https://github.com/jokergoo/spiral/workflows/R-CMD-check/badge.svg)](https://github.com/jokergoo/spiral/actions)\n[![CRAN](https://www.r-pkg.org/badges/version/spiralize)](https://cran.r-project.org/web/packages/spiralize/index.html)\n[![CRAN](https://cranlogs.r-pkg.org/badges/grand-total/spiralize)](https://cran.r-project.org/web/packages/spiralize/index.html)\n\n\n## Features\n\nThe package **spiralize** visualizes data along an [Archimedean spiral](https://en.wikipedia.org/wiki/Archimedean_spiral).\nIt has two major advantages for visualization:\n\n1. It is able to visualize data with very long axis with high resolution.\n2. It is efficient for time series data to reveal periodic patterns.\n\n## Documentation\n\nhttps://jokergoo.github.io/spiralize/\n\n## Citation\n\nZuguang Gu, et al., spiralize: an R package for Visualizing Data on Spirals, Bioinformatics, 2021. https://doi.org/10.1093/bioinformatics/btab778\n\n## Install\n\nThe package is available on CRAN and can be installed by:\n\n```r\ninstall.packages(\"spiralize\")\n```\n\nIf you want the latest version, install it directly from GitHub:\n\n```r\nlibrary(devtools)\ninstall_github(\"jokergoo/spiralize\")\n```\n\n## Usage\n\nIt includes three steps:\n\n1. initialize the spiral,\n2. add a track,\n3. add graphics to the track.\n\nStep 2 and 3 can be applied multiple times to allow multiple-track visualization along the spiral.\n\nThe code for making spiral plot looks likes follows:\n\n```r\nlibrary(spiralize)\nspiral_initialize(...)\nspiral_track(...)\nspiral_points(...)\n...\n```\n\n## Graphics\n\nComplex plots are baiscally constructed from simple graphics. Here there are following low-level graphics functions:\n\n- `spiral_points()`\n- `spiral_lines()`\n- `spiral_rect()`\n- `spiral_segments()`\n- `spiral_polygon()`\n- `spiral_bars()`\n- `spiral_text()`\n- `spiral_axis()`\n- `spiral_yaxis()`\n- `spiral_raster()`\n\nParticularlly, horizon chart is very suitable to put on the spiral, thus there is one function for this:\n\n- `spiral_horizon()`\n\nSpiral plot can also visualize dendrograms with large number of leaves, thus there are following two functions:\n\n- `spiral_dendrogram()`\n- `spiral_phylo()` \n\n\n## Examples\n\n1. Difference of **ggplot2** daily downloads to the mean of the current year (2015-2021). Each loop contains 52 weeks so that same weeks in different years locate at the same angle in the polar coordinates.\n\n![](https://user-images.githubusercontent.com/449218/122206221-671de100-cea1-11eb-823e-6c48de851667.png)\n\n\n2. A phylogenetic life tree with 50645 species. \n\n![](https://user-images.githubusercontent.com/449218/123804978-fbe6fc80-d8ed-11eb-93d8-d3f83d552dde.png)\n\n3. The spiral COVID-19 Shiny app\n\n![](https://user-images.githubusercontent.com/449218/154753102-d66b3588-eca1-471b-bdfe-2c147ed257f5.gif)\n\n\n## License\n\nMIT @ Zuguang Gu\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/spirit",
            "repo_link": "https://github.com/spirit-code/spirit",
            "readme": "SPIRIT\n=============================\n**SPIN SIMULATION FRAMEWORK**<br />\n\n\n![Logo](https://imgur.com/iWc1kuE.png \"Spirit Logo\")\n\n\n&nbsp;\n\n\n**Core Library:**\n\n| Branch   | Build Status | Python Package Coverage | Core Library Coverage |\n| :------- | :----------: | :---------------------: | :-------------------: |\n| master:  | ![CI](https://github.com/spirit-code/spirit/workflows/CI/badge.svg?branch=master) | [![Coverage Status](https://coveralls.io/repos/github/spirit-code/spirit/badge.svg?branch=master)](https://coveralls.io/github/spirit-code/spirit?branch=master) | [![Coverage Status](https://codecov.io/gh/spirit-code/spirit/branch/master/graph/badge.svg)](https://codecov.io/gh/spirit-code/spirit/branch/master) |\n| develop: | ![CI](https://github.com/spirit-code/spirit/workflows/CI/badge.svg?branch=develop) | [![Coverage Status](https://coveralls.io/repos/github/spirit-code/spirit/badge.svg?branch=develop)](https://coveralls.io/github/spirit-code/spirit?branch=develop) | [![Coverage Status](https://codecov.io/gh/spirit-code/spirit/branch/develop/graph/badge.svg)](https://codecov.io/gh/spirit-code/spirit/branch/develop) |\n\n**[Python package](https://pypi.org/project/spirit/):** [![PyPI version](https://badge.fury.io/py/spirit.svg)](https://badge.fury.io/py/spirit)\n\n\n&nbsp;\n\n\nThe code is released under [MIT License](LICENSE.txt).<br />\nIf you intend to *present and/or publish* scientific results or visualisations for which you used Spirit,\nplease cite [`G. P. Müller et al., Phys. Rev. B 99, 224414 (2019)`](https://link.aps.org/doi/10.1103/PhysRevB.99.224414) and read the [docs/REFERENCE.md](docs/REFERENCE.md).\n\n**This is an open project and contributions and collaborations are always welcome!!**\nSee [docs/CONTRIBUTING.md](docs/CONTRIBUTING.md) on how to contribute or write an email to m.sallermann@fz-juelich.de<br />\nFor contributions and affiliations, see [docs/CONTRIBUTORS.md](docs/CONTRIBUTORS.md).\n\nPlease note that a version of the *Spirit Web interface* is hosted by the Research Centre Jülich at\nhttp://juspin.de\n\n\n&nbsp;\n\n<!--\n![nur ein Beispiel](https://commons.wikimedia.org/wiki/File:Example_de.jpg \"Beispielbild\")\n-->\n\n![Skyrmions](http://imgur.com/JgPj8t5.jpg \"Skyrmions on a 2D grid\")\n\n&nbsp;\n\n\n\nContents\n--------\n\n1. [Introduction](#Introduction)\n2. [Getting started with the Desktop User Interface](#Desktop)\n3. [Getting started with the Python Package](#Python)\n\n---------------------------------------------\n\n\n\n&nbsp;\n\n\n\nIntroduction <a name=\"Introduction\"></a>\n---------------------------------------------\n\n#### A modern framework for magnetism science on clusters, desktops & laptops and even your Phone\n\n**Spirit** is a **platform-independent** framework for spin dynamics, written in C++14.\nIt combines the traditional cluster work, using using the command-line, with modern\nvisualisation capabilites in order to maximize scientists' productivity.\n\n> \"It is unworthy of excellent men to lose hours like slaves in\n>  the labour of calculation which could safely be relegated to\n>  anyone else if machines were used.\"\n> - Gottfried Wilhelm Leibniz\n\n*Our goal is to build such machines*. The core library of the *Spirit* framework provides an\n**easy to use API**, which can be used from almost any programming language,\nand includes ready-to-use python bindings.\nA **powerful desktop user interface** is available, providing real-time visualisation and\ncontrol of parameters.\n\n### *Physics Features*\n\n- Atomistic Spin Lattice Heisenberg Model including also DMI and dipole-dipole\n- **Spin Dynamics simulations** obeying the\n  [Landau-Lifschitz-Gilbert equation](https://en.wikipedia.org/wiki/Landau%E2%80%93Lifshitz%E2%80%93Gilbert_equation)\n- Direct **Energy minimisation** with different solvers\n- **Minimum Energy Path calculations** for transitions between different\n  spin configurations, using the GNEB method\n\n### *Highlights of the Framework*\n\n- Cross-platform: everything can be built and run on Linux, OSX and Windows\n- Standalone core library with C API which can be used from almost any programming language\n- **Python package** making complex simulation workflows easy\n- Desktop UI with powerful, live **3D visualisations** and direct control of most system parameters\n- Modular backends including **parallelisation on GPU** (CUDA) and **CPU** (OpenMP)\n\n### *Documentation*\n\nMore details may be found at [spirit-docs.readthedocs.io](http://spirit-docs.readthedocs.io)\nor in the [Reference section](docs/README.md) including\n\n- [Unix/OSX build instructions](docs/Build_Unix_OSX.md)\n- [Windows build instructions](docs/Build_Windows.md)\n- [Input File Reference](core/docs/Input.md)\n\nThere is also a [Wiki](https://iffwiki.fz-juelich.de/index.php/Spirit \"Click me...\"),\nhosted by the Research Centre Jülich.\n\n---------------------------------------------\n\n\n\n&nbsp;\n\n\n\nGetting started with the Desktop Interface <a name=\"Desktop\"></a>\n---------------------------------------------\n\nSee the build instructions for [Unix/OSX](docs/Build_Unix_OSX.md) or\n[Windows](docs/Build_Windows.md) on how to get the desktop user interface.\n\n![Desktop UI with Isosurfaces in a thin layer](http://imgur.com/QUcN4aG.jpg \"Isosurfaces in a thin layer\")\n\nThe user interface provides a powerful OpenGL visualisation window\nusing the [VFRendering](https://github.com/FlorianRhiem/VFRendering) library.\nIt provides functionality to\n\n- Control Calculations\n- Locally insert Configurations (homogeneous, skyrmions, spin spiral, ... )\n- Generate homogeneous Transition Paths\n- Change parameters of the Hamiltonian\n- Change parameters of the Method and Solver\n- Configure the Visualization (arrows, isosurfaces, lighting, ...)\n\nSee the [UI-QT Reference](docs/UI-Qt.md) for the key bindings of the various features.\n\n*Unfortunately, distribution of binaries for the Desktop UI is not possible due\nto the restrictive license on QT-Charts.*\n\n---------------------------------------------\n\n\n\n&nbsp;\n\n\n\nGetting started with the Python Package <a name=\"Python\"></a>\n---------------------------------------------\n\nTo install the *Spirit python package*, either build and install from source\n([Unix/OSX](docs/Build_Unix_OSX.md), [Windows](docs/Build_Windows.md)) or\nsimply use\n\n    pip install spirit\n\nWith this package you have access to powerful Python APIs to run and control\ndynamics simulations or optimizations.\nThis is especially useful for work on clusters, where you can now script your\nworkflow, never having to re-compile when testing, debugging or adding features.\n\nThe most simple example of a **spin dynamics simulation** would be\n``` python\nfrom spirit import state, simulation\nwith state.State(\"input/input.cfg\") as p_state:\n    simulation.start(p_state, simulation.METHOD_LLG, simulation.SOLVER_SIB)\n```\nWhere `SOLVER_SIB` denotes the semi-implicit method B and the starting configuration\nwill be random.\n\nTo add some meaningful content, we can change the **initial configuration** by\ninserting a Skyrmion into a homogeneous background:\n``` python\ndef skyrmion_on_homogeneous(p_state):\n    from spirit import configuration\n    configuration.plus_z(p_state)\n    configuration.skyrmion(p_state, 5.0, phase=-90.0)\n```\n\nIf we want to calculate a **minimum energy path** for a transition, we need to generate\na sensible initial guess for the path and use the **GNEB method**. Let us consider\nthe collapse of a skyrmion to the homogeneous state:\n``` python\nfrom spirit import state, chain, configuration, transition, simulation\n\n### Copy the system and set chain length\nchain.image_to_clipboard(p_state)\nnoi = 7\nchain.set_length(p_state, noi)\n\n### First image is homogeneous with a Skyrmion in the center\nconfiguration.plus_z(p_state, idx_image=0)\nconfiguration.skyrmion(p_state, 5.0, phase=-90.0, idx_image=0)\nsimulation.start(p_state, simulation.METHOD_LLG, simulation.SOLVER_VP, idx_image=0)\n### Last image is homogeneous\nconfiguration.plus_z(p_state, idx_image=noi-1)\nsimulation.start(p_state, simulation.METHOD_LLG, simulation.SOLVER_VP, idx_image=noi-1)\n\n### Create transition of images between first and last\ntransition.homogeneous(p_state, 0, noi-1)\n\n### GNEB calculation\nsimulation.start(p_state, simulation.METHOD_GNEB, simulation.SOLVER_VP)\n```\nwhere `SOLVER_VP` denotes a direct minimization with the velocity projection algorithm.\n\nYou may also use *Spirit* order to **extract quantitative data**, such as the energy.\n``` python\ndef evaluate(p_state):\n    from spirit import system, quantities\n    M = quantities.get_magnetization(p_state)\n    E = system.get_energy(p_state)\n    return M, E\n```\n\nObviously you may easily create significantly more complex workflows and use Python\nto e.g. pre- or post-process data or to distribute your work on a cluster and much more!"
        },
        {
            "software_organization": "https://helmholtz.software/software/stable-baselines3",
            "repo_link": "https://github.com/DLR-RM/stable-baselines3",
            "readme": "<!-- [![pipeline status](https://gitlab.com/araffin/stable-baselines3/badges/master/pipeline.svg)](https://gitlab.com/araffin/stable-baselines3/-/commits/master) -->\n[![CI](https://github.com/DLR-RM/stable-baselines3/workflows/CI/badge.svg)](https://github.com/DLR-RM/stable-baselines3/actions/workflows/ci.yml)\n[![Documentation Status](https://readthedocs.org/projects/stable-baselines/badge/?version=master)](https://stable-baselines3.readthedocs.io/en/master/?badge=master) [![coverage report](https://gitlab.com/araffin/stable-baselines3/badges/master/coverage.svg)](https://github.com/DLR-RM/stable-baselines3/actions/workflows/ci.yml)\n[![codestyle](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n\n# Stable Baselines3\n\n<img src=\"docs/\\_static/img/logo.png\" align=\"right\" width=\"40%\"/>\n\nStable Baselines3 (SB3) is a set of reliable implementations of reinforcement learning algorithms in PyTorch. It is the next major version of [Stable Baselines](https://github.com/hill-a/stable-baselines).\n\nYou can read a detailed presentation of Stable Baselines3 in the [v1.0 blog post](https://araffin.github.io/post/sb3/) or our [JMLR paper](https://jmlr.org/papers/volume22/20-1364/20-1364.pdf).\n\n\nThese algorithms will make it easier for the research community and industry to replicate, refine, and identify new ideas, and will create good baselines to build projects on top of. We expect these tools will be used as a base around which new ideas can be added, and as a tool for comparing a new approach against existing ones. We also hope that the simplicity of these tools will allow beginners to experiment with a more advanced toolset, without being buried in implementation details.\n\n**Note: Despite its simplicity of use, Stable Baselines3 (SB3) assumes you have some knowledge about Reinforcement Learning (RL).** You should not utilize this library without some practice. To that extent, we provide good resources in the [documentation](https://stable-baselines3.readthedocs.io/en/master/guide/rl.html) to get started with RL.\n\n## Main Features\n\n**The performance of each algorithm was tested** (see *Results* section in their respective page),\nyou can take a look at the issues [#48](https://github.com/DLR-RM/stable-baselines3/issues/48) and [#49](https://github.com/DLR-RM/stable-baselines3/issues/49) for more details.\n\nWe also provide detailed logs and reports on the [OpenRL Benchmark](https://wandb.ai/openrlbenchmark/sb3) platform.\n\n\n| **Features**                | **Stable-Baselines3** |\n| --------------------------- | ----------------------|\n| State of the art RL methods | :heavy_check_mark: |\n| Documentation               | :heavy_check_mark: |\n| Custom environments         | :heavy_check_mark: |\n| Custom policies             | :heavy_check_mark: |\n| Common interface            | :heavy_check_mark: |\n| `Dict` observation space support  | :heavy_check_mark: |\n| Ipython / Notebook friendly | :heavy_check_mark: |\n| Tensorboard support         | :heavy_check_mark: |\n| PEP8 code style             | :heavy_check_mark: |\n| Custom callback             | :heavy_check_mark: |\n| High code coverage          | :heavy_check_mark: |\n| Type hints                  | :heavy_check_mark: |\n\n\n### Planned features\n\nSince most of the features from the [original roadmap](https://github.com/DLR-RM/stable-baselines3/issues/1) have been implemented, there are no major changes planned for SB3, it is now *stable*.\nIf you want to contribute, you can search in the issues for the ones where [help is welcomed](https://github.com/DLR-RM/stable-baselines3/labels/help%20wanted) and the other [proposed enhancements](https://github.com/DLR-RM/stable-baselines3/labels/enhancement).\n\nWhile SB3 development is now focused on bug fixes and maintenance (doc update, user experience, ...), there is more active development going on in the associated repositories:\n- newer algorithms are regularly added to the [SB3 Contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib) repository\n- faster variants are developed in the [SBX (SB3 + Jax)](https://github.com/araffin/sbx) repository\n- the training framework for SB3, the RL Zoo, has an active [roadmap](https://github.com/DLR-RM/rl-baselines3-zoo/issues/299)\n\n## Migration guide: from Stable-Baselines (SB2) to Stable-Baselines3 (SB3)\n\nA migration guide from SB2 to SB3 can be found in the [documentation](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html).\n\n## Documentation\n\nDocumentation is available online: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)\n\n## Integrations\n\nStable-Baselines3 has some integration with other libraries/services like Weights & Biases for experiment tracking or Hugging Face for storing/sharing trained models. You can find out more in the [dedicated section](https://stable-baselines3.readthedocs.io/en/master/guide/integrations.html) of the documentation.\n\n\n## RL Baselines3 Zoo: A Training Framework for Stable Baselines3 Reinforcement Learning Agents\n\n[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a training framework for Reinforcement Learning (RL).\n\nIt provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n\nIn addition, it includes a collection of tuned hyperparameters for common environments and RL algorithms, and agents trained with those settings.\n\nGoals of this repository:\n\n1. Provide a simple interface to train and enjoy RL agents\n2. Benchmark the different Reinforcement Learning algorithms\n3. Provide tuned hyperparameters for each environment and RL algorithm\n4. Have fun with the trained agents!\n\nGithub repo: https://github.com/DLR-RM/rl-baselines3-zoo\n\nDocumentation: https://rl-baselines3-zoo.readthedocs.io/en/master/\n\n## SB3-Contrib: Experimental RL Features\n\nWe implement experimental features in a separate contrib repository: [SB3-Contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib)\n\nThis allows SB3 to maintain a stable and compact core, while still providing the latest features, like Recurrent PPO (PPO LSTM), CrossQ, Truncated Quantile Critics (TQC), Quantile Regression DQN (QR-DQN) or PPO with invalid action masking (Maskable PPO).\n\nDocumentation is available online: [https://sb3-contrib.readthedocs.io/](https://sb3-contrib.readthedocs.io/)\n\n## Stable-Baselines Jax (SBX)\n\n[Stable Baselines Jax (SBX)](https://github.com/araffin/sbx) is a proof of concept version of Stable-Baselines3 in Jax, with recent algorithms like DroQ or CrossQ.\n\nIt provides a minimal number of features compared to SB3 but can be much faster (up to 20x times!): https://twitter.com/araffin2/status/1590714558628253698\n\n\n## Installation\n\n**Note:** Stable-Baselines3 supports PyTorch >= 2.3\n\n### Prerequisites\nStable Baselines3 requires Python 3.9+.\n\n#### Windows\n\nTo install stable-baselines on Windows, please look at the [documentation](https://stable-baselines3.readthedocs.io/en/master/guide/install.html#prerequisites).\n\n\n### Install using pip\nInstall the Stable Baselines3 package:\n```sh\npip install 'stable-baselines3[extra]'\n```\n\nThis includes an optional dependencies like Tensorboard, OpenCV or `ale-py` to train on atari games. If you do not need those, you can use:\n```sh\npip install stable-baselines3\n```\n\nPlease read the [documentation](https://stable-baselines3.readthedocs.io/) for more details and alternatives (from source, using docker).\n\n\n## Example\n\nMost of the code in the library tries to follow a sklearn-like syntax for the Reinforcement Learning algorithms.\n\nHere is a quick example of how to train and run PPO on a cartpole environment:\n```python\nimport gymnasium as gym\n\nfrom stable_baselines3 import PPO\n\nenv = gym.make(\"CartPole-v1\", render_mode=\"human\")\n\nmodel = PPO(\"MlpPolicy\", env, verbose=1)\nmodel.learn(total_timesteps=10_000)\n\nvec_env = model.get_env()\nobs = vec_env.reset()\nfor i in range(1000):\n    action, _states = model.predict(obs, deterministic=True)\n    obs, reward, done, info = vec_env.step(action)\n    vec_env.render()\n    # VecEnv resets automatically\n    # if done:\n    #   obs = env.reset()\n\nenv.close()\n```\n\nOr just train a model with a one liner if [the environment is registered in Gymnasium](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#registering-envs) and if [the policy is registered](https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html):\n\n```python\nfrom stable_baselines3 import PPO\n\nmodel = PPO(\"MlpPolicy\", \"CartPole-v1\").learn(10_000)\n```\n\nPlease read the [documentation](https://stable-baselines3.readthedocs.io/) for more examples.\n\n\n## Try it online with Colab Notebooks !\n\nAll the following examples can be executed online using Google Colab notebooks:\n\n- [Full Tutorial](https://github.com/araffin/rl-tutorial-jnrr19)\n- [All Notebooks](https://github.com/Stable-Baselines-Team/rl-colab-notebooks/tree/sb3)\n- [Getting Started](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/stable_baselines_getting_started.ipynb)\n- [Training, Saving, Loading](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/saving_loading_dqn.ipynb)\n- [Multiprocessing](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/multiprocessing_rl.ipynb)\n- [Monitor Training and Plotting](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/monitor_training.ipynb)\n- [Atari Games](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/atari_games.ipynb)\n- [RL Baselines Zoo](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/rl-baselines-zoo.ipynb)\n- [PyBullet](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/pybullet.ipynb)\n\n\n## Implemented Algorithms\n\n| **Name**         | **Recurrent**      | `Box`          | `Discrete`     | `MultiDiscrete` | `MultiBinary`  | **Multi Processing**              |\n| ------------------- | ------------------ | ------------------ | ------------------ | ------------------- | ------------------ | --------------------------------- |\n| ARS<sup>[1](#f1)</sup>   | :x: | :heavy_check_mark: | :heavy_check_mark: | :x: | :x: | :heavy_check_mark: |\n| A2C   | :x: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |\n| CrossQ<sup>[1](#f1)</sup>   | :x: | :heavy_check_mark: | :x:                | :x:                 | :x:                | :heavy_check_mark: |\n| DDPG  | :x: | :heavy_check_mark: | :x:                | :x:                 | :x:                | :heavy_check_mark: |\n| DQN   | :x: | :x: | :heavy_check_mark: | :x:                 | :x:                | :heavy_check_mark: |\n| HER   | :x: | :heavy_check_mark: | :heavy_check_mark: | :x: | :x: | :heavy_check_mark: |\n| PPO   | :x: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark: | :heavy_check_mark: |\n| QR-DQN<sup>[1](#f1)</sup>  | :x: | :x: | :heavy_check_mark: | :x:                 | :x:                | :heavy_check_mark: |\n| RecurrentPPO<sup>[1](#f1)</sup>   | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark: | :heavy_check_mark: |\n| SAC   | :x: | :heavy_check_mark: | :x:                | :x:                 | :x:                | :heavy_check_mark: |\n| TD3   | :x: | :heavy_check_mark: | :x:                | :x:                 | :x:                | :heavy_check_mark: |\n| TQC<sup>[1](#f1)</sup>   | :x: | :heavy_check_mark: | :x:                | :x:                 | :x: | :heavy_check_mark: |\n| TRPO<sup>[1](#f1)</sup>  | :x: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark: | :heavy_check_mark: |\n| Maskable PPO<sup>[1](#f1)</sup>   | :x: | :x: | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark: | :heavy_check_mark:  |\n\n<b id=\"f1\">1</b>: Implemented in [SB3 Contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib) GitHub repository.\n\nActions `gymnasium.spaces`:\n * `Box`: A N-dimensional box that contains every point in the action space.\n * `Discrete`: A list of possible actions, where each timestep only one of the actions can be used.\n * `MultiDiscrete`: A list of possible actions, where each timestep only one action of each discrete set can be used.\n * `MultiBinary`: A list of possible actions, where each timestep any of the actions can be used in any combination.\n\n\n\n## Testing the installation\n### Install dependencies\n```sh\npip install -e .[docs,tests,extra]\n```\n### Run tests\nAll unit tests in stable baselines3 can be run using `pytest` runner:\n```sh\nmake pytest\n```\nTo run a single test file:\n```sh\npython3 -m pytest -v tests/test_env_checker.py\n```\nTo run a single test:\n```sh\npython3 -m pytest -v -k 'test_check_env_dict_action'\n```\n\nYou can also do a static type check using `mypy`:\n```sh\npip install mypy\nmake type\n```\n\nCodestyle check with `ruff`:\n```sh\npip install ruff\nmake lint\n```\n\n## Projects Using Stable-Baselines3\n\nWe try to maintain a list of projects using stable-baselines3 in the [documentation](https://stable-baselines3.readthedocs.io/en/master/misc/projects.html),\nplease tell us if you want your project to appear on this page ;)\n\n## Citing the Project\n\nTo cite this repository in publications:\n\n```bibtex\n@article{stable-baselines3,\n  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},\n  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},\n  journal = {Journal of Machine Learning Research},\n  year    = {2021},\n  volume  = {22},\n  number  = {268},\n  pages   = {1-8},\n  url     = {http://jmlr.org/papers/v22/20-1364.html}\n}\n```\n\nNote: If you need to refer to a specific version of SB3, you can also use the [Zenodo DOI](https://doi.org/10.5281/zenodo.8123988).\n\n## Maintainers\n\nStable-Baselines3 is currently maintained by [Ashley Hill](https://github.com/hill-a) (aka @hill-a), [Antonin Raffin](https://araffin.github.io/) (aka [@araffin](https://github.com/araffin)), [Maximilian Ernestus](https://github.com/ernestum) (aka @ernestum), [Adam Gleave](https://github.com/adamgleave) (@AdamGleave), [Anssi Kanervisto](https://github.com/Miffyli) (@Miffyli) and [Quentin Gallouédec](https://gallouedec.com/) (@qgallouedec).\n\n**Important Note: We do not provide technical support, or consulting** and do not answer personal questions via email.\nPlease post your question on the [RL Discord](https://discord.com/invite/xhfNqQv), [Reddit](https://www.reddit.com/r/reinforcementlearning/), or [Stack Overflow](https://stackoverflow.com/) in that case.\n\n\n## How To Contribute\n\nTo any interested in making the baselines better, there is still some documentation that needs to be done.\nIf you want to contribute, please read [**CONTRIBUTING.md**](./CONTRIBUTING.md) guide first.\n\n## Acknowledgments\n\nThe initial work to develop Stable Baselines3 was partially funded by the project *Reduced Complexity Models* from the *Helmholtz-Gemeinschaft Deutscher Forschungszentren*, and by the EU's Horizon 2020 Research and Innovation Programme under grant number 951992 ([VeriDream](https://www.veridream.eu/)).\n\nThe original version, Stable Baselines, was created in the [robotics lab U2IS](http://u2is.ensta-paristech.fr/index.php?lang=en) ([INRIA Flowers](https://flowers.inria.fr/) team) at [ENSTA ParisTech](http://www.ensta-paristech.fr/en).\n\n\nLogo credits: [L.M. Tenkes](https://www.instagram.com/lucillehue/)\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/stmlab",
            "repo_link": "https://gitlab.com/dlr-sy/stmlab",
            "readme": "[![PyPi](https://img.shields.io/pypi/v/stmlab?label=PyPi)](https://pypi.org/project/stmlab/)\r\n[![doi](https://img.shields.io/badge/DOI-10.5281%2Fzenodo.13844636-red.svg)](https://zenodo.org/records/13844636)\r\n\r\n# STMLab\r\n> This Python package provides an independent standard runtime environment for software projects developed by the [Department of Structural Mechanics](https://www.dlr.de/en/sy/about-us/departments/structural-mechanics) at the [Institute of Lightweight Structures](https://www.dlr.de/en/sy) of the [German Aerospace Center](https://www.dlr.de/en) It uses the [Jupyter](https://jupyter.org/) project as its graphical user interface. Two types of installation procedures are available. A community version can be installed and executed using pip. An enterprise version with yet unpublished software projects is available as an offline installer on request.\r\n\r\n## Downloading\r\nUse GIT to get the latest code base. From the command line, use\r\n```\r\ngit clone https://gitlab.dlr.de/dlr-sy/stmlab stmlab\r\n```\r\nIf you check out the repository for the first time, you have to initialize all submodule dependencies first. Execute the following from within the repository. \r\n```\r\ngit submodule update --init --recursive\r\n```\r\nTo update all refererenced submodules to the latest production level, use\r\n```\r\ngit submodule foreach --recursive 'git pull origin $(git config -f $toplevel/.gitmodules submodule.$name.branch || echo master)'\r\n```\r\n## Installation\r\nSTMLab can be installed from source using [poetry](https://python-poetry.org). If you don't have [poetry](https://python-poetry.org) installed, run\r\n```\r\npip install poetry --pre --upgrade\r\n```\r\nto install the latest version of [poetry](https://python-poetry.org) within your python environment. Use\r\n```\r\npoetry update\r\n```\r\nto update all dependencies in the lock file or directly execute\r\n```\r\npoetry install\r\n```\r\nto install all dependencies from the lock file. Last, you should be able to import STMLab as a python package.\r\n```python\r\nimport stmlab\r\n```\r\n## Contact\r\n* [Marc Garbade](mailto:marc.garbade@dlr.de)",
            "project_id": "61244582"
        },
        {
            "software_organization": "https://helmholtz.software/software/stream2segment",
            "repo_link": "https://github.com/rizac/stream2segment",
            "readme": "# <img align=\"left\" height=\"30\" src=\"https://www.gfz-potsdam.de/fileadmin/gfz/medien_kommunikation/Infothek/Mediathek/Bilder/GFZ/GFZ_Logo/GFZ-Logo_eng_RGB.svg\"> Stream2segment <img align=\"right\" height=\"50\" src=\"https://www.gfz-potsdam.de/fileadmin/gfz/GFZ_Wortmarke_SVG_klein_en_edit.svg\">\n\n|Jump to: | [Usage](#usage) | [Installation](#installation) | [Development and Maintenance](#development-and-maintenance) | [Citation](#citation) |\n| - | - | - | - | - |\n\nA Python library and command line application to download, process and visualize \nevent-based seismic waveform  segments, specifically designed to manage big \nvolumes of data.\n\nThe key aspects with respect to widely-used similar applications is the use of\na Relational database management system (RDBMS) to store downloaded data and \nmetadata. The main advantages of this approach are: \n\n* **Storage efficiency**: no huge amount of files, no complex, virtually \n  unusable directory structures. Moreover, a database prevents data and metadata \n  inconsistency by design, and allows more easily to track what has already \n  been downloaded in order to customize and improve further downloads\n\n* **Simple Python objects representing stored data and relationships**, easy \n  to work with in any kind of custom code accessing the database. For instance, a \n  segment is represented by a `Segment` object with its data, metadata and related \n  objects easily accessible through its attributes, e.g., `segment.stream()`, \n  `segment.maxgap_numsamples`, `segment.event.magnitude`, \n  `segment.station.network`, `segment.channel.orientation_code` and so on.\n  \n* **A powerful segments selection** made even easier by means of a simplified\n  syntax: map any attribute described above to a selection expression\n  (e.g. `segment.event.magnitude: \"[4, 5)\"`) and with few lines you can compose \n  complex database queries such as e.g., *\"get all downloaded segments within a \n  given magnitude range, with well-formed data and no gaps, \n  from broadband channels only and a given specific network\"*\n\n\n\n## Usage\n\nFor full details, please consult the [wiki page](https://github.com/rizac/stream2segment/wiki)\n\nStream2segment is a Python library and command line application available \nafter installation via the command `s2s` on the terminal. By typing `s2s --help` you\nwill see all available subcommands for downloading \nand managing data, launching Python processing functions, creating class labels for segments \nannotation, or producing graphical output, as shown below:\n\n![S2s GUI](https://raw.githubusercontent.com/wiki/rizac/stream2segment/images/screenshot_gui.png)\n\n<!--\n<table>\n\t<tr>\n\t\t<td align=\"center\"><img width=\"90%\" src=\"https://geofon.gfz-potsdam.de/software/stream2segment/processgui.png\"/></td>\n\t\t<td align=\"center\"><img width=\"90%\" src=\"https://geofon.gfz-potsdam.de/software/stream2segment/s2s_dinfogui.png\"/></td>\n\t</tr>\n\t<tr>\n\t\t<td>The <code>s2s show ...</code> command opens a GUI in the browser where downloaded data and customizable plots are shown</td>\n\t\t<td> The <code>s2s dl dstats ...</code> command opens an HTML page in the browser where download statistics can be shown</td>\n\t</tr>\n</table>\n\n\n<sub>Both image linked from https://geofon.gfz-potsdam.de/software/stream2segment/</sub>\n-->\n\nYou start the program via the command `init` ( \n`s2s init --help` for details) to create several fully documented\nexamples files that you can immediately start to configure and modify\n(see the **[gitHub wiki page](https://github.com/rizac/stream2segment/wiki)** for details).\nIn a nutshell: \n\n 1. **A download configuration file** in YAML syntax. Edit the file \n    (all documentation is provided in the file as block comments) and \n    start downloading by typing:\n   \n    ```console\n    s2s download -c <config_file> ...\n    ```\n   \n    > **Note** the path of the database where to store the downloaded data\n      must be input in the config file. The supported database types are SQLite \n      and Postgres: for massive downloads (as a rule of thumb: &ge; 1 million segments)\n      we suggest to use Postgres. In any case, we **strongly** suggest running the program \n      on computers with at least **16GB** of RAM.\n\n    > **Note**  massive downloads are time-consuming operations where it is likely to miss\n      some data due to any kind of temporary connection problems. Consequently, **it is advisable\n      to perform the same massive download at least twice with the same configuration**  \n      (subsequent runs will be faster as data will not be re-downloaded unnecessarily)\n\n 2. **A Jupyter notebook tutorial with examples for processing downloaded data**,\n    for user who prefer this approach instead of the processing module described\n    below (online version **[here](https://github.com/rizac/stream2segment/wiki/Using-Stream2segment-in-your-Python-code)**)\n\n 3. **Two Python modules** (with relative configuration in YAML syntax):\n \n    1. `paramtable.py`: process downloaded data and produce a tabular output (CSV, HDF) by executing the \n       module as script (see code block after `if __name__ == \"__main__\"` in the module for details):\n       ```console\n       python paramtable.py ...\n       ```\n         \n    2. `gui.py`: visualize downloaded data in the user browser via the plots defined in the module (an example in the figure above):\n       ```console\n       s2s show -d download.yaml -p gui.py -c gui.yaml ...\n       ```\n       (Type `s2s show --help` for details).\n       \n    > **Note**: the associated YAML files (`paramtable.yaml`, `gui.yaml`) are not \n      mandatory but enforce the good practice of separating configuration settings (YAML)\n      and the actual Python code. This way you can experiment \n      the same code with several settings by only creating different YAML files\n\n\n## Installation\n\nThis program has been installed and tested on Ubuntu (14 and later) and macOS\n(El Capitan and later).\n\nIn case of installation problems, we suggest you to proceed in this order:\n\n 1. Look at [Installation Notes](#installation-notes) to check if the problem\n    has already been observed and a solution proposed\n 2. Google for the solution (as always)\n 3. [Ask for help](https://github.com/rizac/stream2segment/issues)\n\n\n### 1 Requirements\n\nIn this section we assume that you already have Python (**3.5 or later**) \nand the required database software. The latter should not be needed if you use\n[SQLite](https://docs.python.org/3/library/sqlite3.html) or if the\ndatabase is already installed remotely, so basically you are concerned only if you\nneed to download data locally (on your computer) on a Postgres database.\n\n\n#### 1.1 macOS\n\nOn macOS (El Capitan and later) all required software is generally already\npreinstalled. We suggest you to go to the next step and look at the\n[Installation Notes](#installation-notes) in case of problems\n(to install software on macOS, we recommend to use [brew](https://brew.sh/)).\n\n<details>\n<summary>Details</summary>\n\nIn few cases, on some computers we needed to run one or more of the following\ncommands (it's up to you to run them now or later, only those really needed):\n\n```\nxcode-select --install\nbrew install openssl\nbrew install c-blosc\nbrew install git\n```\n\n</details>\n\n#### 1.2 Ubuntu\n\nUbuntu does not generally have all required packages pre-installed. The bare minimum\nof the necessary packages can be installed with the `apt-get` command:\n\n```\nsudo apt-get install git python3-pip python3-dev  # python 3\n```\n\n<details>\n<summary>Details</summary>\n\nIn few cases, on some computers we needed to run one or more of the following\ncommands (it's up to you to run them now or later, only those really needed):\n\nUpgrade `gcc` first:\n\t\n```\nsudo apt-get update\nsudo apt-get upgrade gcc\n```\n\nThen:\n\n```\nsudo apt-get update\nsudo apt-get install libpng-dev libfreetype6-dev \\\n\tbuild-essential gfortran libatlas-base-dev libxml2-dev libxslt-dev python-tk\n```\n\n\n</details>\n\n### 2 Clone repository\n\nGit-clone (basically: download) this repository to a specific folder of your choice:\n```\ngit clone https://github.com/rizac/stream2segment.git ./stream2segment\n```\nand move into the repository root:\n```\ncd stream2segment\n```\n\n### 3 Install and activate Python virtualenv\n\nWe strongly recommend to use Python virtual environment to avoid conflicts\nwith already installed packages on your operating system (if you already\nhave a virtual environment, just activate it and go to the next section).\n\nConda users (e.g. Anaconda, Miniconda) can skip this section and check the [Conda documentation](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) instead.\n\nMake virtual environment in a \"stream2segment/env\" directory (env is a convention,\nbut it's ignored by `git commit` so better keeping it. You can also use \".env\"\nwhich makes it usually hidden in Ubuntu. Also on Ubuntu, you might need to install\n`venv` first via `sudo apt-get install python3-venv`)\n```\npython3 -m venv ./env\n```\n\nTo activate your virtual environment, type:\n\n ```\n source env/bin/activate\n ```\nor `source env/bin/activate.csh` (depending on your shell)\n\n> <sub>Activation needs to be done __each time__ we will run the program.</sub>\n> <sub>To check you are in the right env, type: `which pip` and you should see it's\n  pointing inside the env folder</sub>\n\n\n### 4 Install Stream2segment\n\n**Important reminders before installing**: \n  - From now on you are supposed to be in the stream2segment directory,\n     (where you cloned the repository) with your Python virtualenv activated\n  - In case of errors, check the [Installation notes below](#installation-Notes)\n\nInstall the required packages with the tested versions listed in `requirements.txt` \n(if you are working on an existing environment with stuff \nalready installed in it, **please read the [first installation note](#installation-notes) below** \nbefore proceeding):\n```console\npip install --upgrade pip setuptools wheel && pip install -r ./requirements.txt\n```\n > <sub>type `requirements.dev.txt` instead of `requirements.txt` if you want to install also test packages, e.g., you want to contribute to the code and/or run tests</sub>\n\nInstall this package:\n```console\npip install -e .\n```\n\n(optional) install jupyter notebook or jupyterlab \n(see [Jupyter page for details](https://jupyter.org/install)), e.g.:\n```console\npip install jupyterlab\n```\n\nThe program is now installed. To double-check the program functionalities,\nyou can run tests (see below) and report the problem in case of failure.\nIn any case, before reporting a problem remember to check first the\n[Installation Notes](#installation-notes)\n\n\n### 5 Installation Notes\n\n- in case of a message like `ERROR: No matching distribution found for <package_name>`,\n  try to skip the requirements file:\n  ```console\n  pip install --upgrade pip setuptools wheel && pip install -e .\n  ```  \n  This will install packages satisfying a *minimum* required \n  version instead of the *exact* version passing tests: while less safe in general, this approach\n  lets `pip` handle the best versions to use, with more chance of\n  success in this case. **You can choose this strategy not only in case of mismatching distributions, \n  but also while working on a virtual environment with already installed packages, \n  because it has less chance of breaking existing code.**\n\n- In older ObsPy version, numpy needs to be installed first. If you see an error \n  like \"you need to install numpy first\", open \"requirements.txt\" and copy the \n  line which starts with numpy. Supposing it's `numpy==0.1.12`, then run \n  `pip install numpy==0.1.12` before re-running the `pip install ...` command \n  above\n\n- When installing the program (`pip install -e .`), `-e` is optional and \n  makes the package editable, meaning that you can edit the repository and make all \n  changes immediately available, without re-installing the package. This is useful \n  when, e.g., `git pull`-ing new versions frequently.\n  \n- (update January 2021) On macOS (version 11.1, with Python 3.8 and 3.9):\n\n  - if the installation fails with a lot of printout, and you spot a\n    \"Failed building wheel for psycopg2\", see  \n    <!--, try to execute:\n    ```\n    export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/opt/openssl/lib/ && pip ./installme-dev\n    ```\n    (you might need to change the path of openssl below). Credits \n    -->\n    [here](https://stackoverflow.com/a/61159643/3526777) and\n    [here](https://stackoverflow.com/a/39800677/3526777)\n \n  - If the error message is \"Failed building wheel for tables\",\n    then try to install c-blosc (on macOS,  `brew install c-blosc`) <!-- and re-run `installme-dev` installation command\n    (with the `export` command above, if needed) -->\n \n\n- If you see (we experienced this while running tests, thus we can guess you should see\n  it whenever accessing the program for the first time):\n  ```\n  This system supports the C.UTF-8 locale which is recommended.\n  You might be able to resolve your issue by exporting the\n  following environment variables:\n\n    export LC_ALL=C.UTF-8\n    export LANG=C.UTF-8\n  ```\n  Then edit your `~/.profile` (or `~/.bash_profile` on Mac) and put the two lines starting\n  with 'export', and execute `source ~/.profile` (`source ~/.bash_profile` on Mac) and\n  re-execute the program.  \n\n- On Ubuntu 12.10, there might be problems with libxml (`version libxml2_2.9.0' not found`). \n  Move the file or create a link in the proper folder. The problem has been solved looking\n  at http://phersung.blogspot.de/2013/06/how-to-compile-libxml2-for-lxml-python.html\n\nAll following issues should be solved by installing all dependencies as described in\nthe section [Prerequisites](#prerequisites). If you did not install them, here the solutions\nto common problems you might have and that we collected from several Ubuntu installations:\n\n- For numpy installation problems (such as `Cannot compile 'Python.h'`) , the fix \n  has been to update gcc and install python3-dev (python2.7-dev if you are using Python2.7,\n  discouraged): \n  ```\n  sudo apt-get update\n  sudo apt-get upgrade gcc\n  sudo apt-get install python3-dev\n  ```\n   For details see [here](http://stackoverflow.com/questions/18785063/install-numpy-in-python-virtualenv)\n \n - For scipy problems, `build-essential gfortran libatlas-base-dev` are required for scipy.\n   For details see [here](http://stackoverflow.com/questions/2213551/installing-scipy-with-pip/3865521#3865521)\n \n - For lxml problems, `libxml2-dev libxslt-dev` are required. For details see [here](http://lxml.de/installation.html)\n \n - For matplotlib problems (matplotlib is not used by the program but from imported libraries),\n   `libpng-dev libfreetype6-dev` are required. For details see\n   [here](http://stackoverflow.com/questions/25593512/cant-install-matplotlib-using-pip) and\n   [here]( http://stackoverflow.com/questions/28914202/pip-install-matplotlib-fails-cannot-build-package-freetype-python-setup-py-e)\n\n\n\n## Development and Maintenance\n\n### 1 Run tests\n\nStream2segment has been highly tested (current test coverage is above 90%)\non Python version >= 3.5+. Although automatic continuous integration (CI) systems are not\nin place, we do our best to regularly tests under new Python and package versions. \nRemember that tests are time-consuming (some minutes currently).\nHere some examples depending on your needs:\n\n```\npytest -xvvv -W ignore ./tests/\n```\n\n```\npytest -xvvv -W ignore --dburl postgresql://<user>:<password>@localhost/<dbname> ./tests/\n```\n\n<!--\n```\npytest -xvvv -W ignore --cov=./stream2segment --cov-report=html ./tests/\n```\n-->\n\n```\npytest -xvvv -W ignore --dburl postgresql://<user>:<password>@localhost/<dbname> --cov=./stream2segment --cov-report=html ./tests/\n```\n\nWhere the options denote:\n\n- `-x`: stop at first error\n- `-vvv`: increase verbosity,\n- `-W ignore`: do not print Python warnings issued during tests. You can omit the `-W`\n  option to turn warnings on and inspect them, but consider that a lot of redundant\n  messages will be printed: in case of test failure, it is hard to spot the relevant error\n  message. Alternatively, try `-W once` - warn once per process - and `-W module` -warn\n  once per calling module.\n- `--cov`: track code coverage, to know how much code has been executed during tests, and\n  `--cov-report`: type of report (if html, you will have to opened 'index.html' in the\n  project directory 'htmlcov')\n- `--dburl`: Additional database to use.\n  The default database is an in-memory sqlite database (e.g., no file will be created),\n  thus this option is basically for testing the program also on postgres. In the example,\n  the postgres is installed locally (`localhost`) but it does not need to.\n  *Remember that a database with name `<dbname>` must be created first in postgres, and\n  that the data in any given postgres database will be overwritten if not empty*\n\n\n> <sub>Note on coding: although PEP8 recommends 79 character length, the program used initially a 100\n  characters max line width, which is being reverted to 79 (you might see mixed\n  lengths in the modules). It seems that [among new features planned for Python 4 there is\n  an increment to 89.5 characters](https://charlesleifer.com/blog/new-features-planned-for-python-4-0/).\n  If true, we might stick to that in the future</sub>\n  \n  \n### 2 Updating dependencies\n\nIn the absence of Continuous Integration in place, from times to times, it is necessary\n  to update the dependencies, to make `pip install` more likely to work (at least for\n  some time). The procedure is:\n  ```\n\tpip install -e .\n\tpip freeze > ./requirements.tmp\n\tpip install -e \".[dev]\"\n\tpip freeze > ./requirements.dev.tmp\n  ```\n**Remember to comment the line of stream2segment\n  from all requirements** (as it should be installed as argument of pip:\n  `pip install <options> .`, and not inside the requirements file).\n\n  Run tests (see above) with warnings on: fix what might go wrong, and eventually you can\n  replace the old `requirements.txt` and `requirements.dev.txt` with the `.tmp` file\n  created. \n\n### 3 Updating wiki\n  \n  Requirements (to be done once):\n   - `jupyter` installed.\n   - The git repository `stream2segment.wiki` which you can clone from the \n     stream2segment/wiki URL on the GitHub page. The repository must\n     be cloned next to (on the same parent directory of) the\n     stream2segment repository\n     \n  The wiki is simply a git project composed of Markdown (.md) files, where\n  `Home.md` implements the landing page of the wiki on the browser, and thus\nusually hosts the table of contents with links to other markdown files `.md` \n  in the directory. Currently, two of those `.md` files are generated from the \n  notebooks `.ipynb` inside stream2segment:\n  \n  - ./resources/templates/\n    - Using-Stream2segment-in-your-Python-code.ipynb\n    - The-Segment-object.ipynb\n  \n#### 3.1 Update existing notebook\n\n1. Edit the notebook in stream2segment/resources/templates:\n  `jupyter notebook stream2segment/resources/templates`\n  Execute the whole notebook to update it, then `git push` as usual\n   \n2. Create `.md` versions of the notebook for the wiki. From the stream2segment \n   repository as `cwd`:\n   ```bash\n    F='Using-Stream2segment-in-your-Python-code';jupyter nbconvert --to markdown ./stream2segment/resources/templates/$F.ipynb --output-dir ../stream2segment.wiki \n   ```\n   (repeat for every notebook file, e.g. `The-Segment-object`. Note only the file name,\n   no file extension needed)\n   \n3. Commit and push to the `stream2segment.wiki` repo:\n   `cd ../stream2segment.wiki`, then as usual `git commit` and `git push`. One line command:\n   `(cd ../stream2segment.wiki && git commit -am 'updating wiki' && git push)`\n    \n#### 3.2 Add a new notebook\n  \nCreate the notebook (`jupyter notebook stream2segment/resources/templates`). \n**Choose a meaningful file name: use upper case when needed, type hyphens '-'\ninstead of spaces**: the file name will be used as title to show the page\nonline (replacing hyphens with spaces).\nOnce the notebook is created and executed:\n     \n- (optional) If you want to include the notebook also as example in the `s2s init` command,\n     look at `stream2segment/cli.py`  \n  \n- Make the notebook being executed during tests (see examples in `tests/misc/test_notebook.py`)\n     and run tests to check everything works.\n  \n- Make the notebook visible in the wiki by adding a reference to it\n     (the notebook URL is the file name with no extension, I guess case- insensitive). \n     A reference can be added in several places:\n     - In the file `_Sidebar.md` (in the wiki repository)\n       which will show it in the sidebar on GitHub\n     - In `Home.md`\n     - In some other notebook (see example in\n       `Using-stream2segment-in-you-Python-code.ipynb`). In this case, note that\n       you might need to update also the referencing notebook\n       (see points 2-3 [above](#to-update-one-of-those-existing-notebooks))\n\n- Create the markdown file and commit to the wiki (see points 2-3 above under\n     `To update one of those existing notebooks`)\n\n\n\n## Citation\n\n**Software:**\n> Zaccarelli, Riccardo (2018): Stream2segment: a tool to download, process and visualize event-based seismic waveform data. GFZ Data Services.  [http://doi.org/10.5880/GFZ.2.4.2019.002](http://doi.org/10.5880/GFZ.2.4.2019.002)\n\n\n**Research article:**\n> Riccardo Zaccarelli, Dino Bindi, Angelo Strollo, Javier Quinteros and Fabrice Cotton. Stream2segment: An Open‐Source Tool for Downloading, Processing, and Visualizing Massive Event‐Based Seismic Waveform Datasets. *Seismological Research Letters* (2019). [https://doi.org/10.1785/0220180314](https://doi.org/10.1785/0220180314)\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/sumo",
            "repo_link": "https://github.com/eclipse-sumo/sumo",
            "readme": "<a href=\"https://sumo.dlr.de/docs\"><p align=\"center\"><img width=50% src=\"https://raw.githubusercontent.com/eclipse/sumo/main/docs/web/docs/images/sumo-logo.svg\"></p></a>\n\nEclipse SUMO - Simulation of Urban MObility\n===========================================\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.13907886.svg )](https://doi.org/10.5281/zenodo.13907886  )\n[![Windows](https://github.com/eclipse-sumo/sumo/actions/workflows/build-windows.yml/badge.svg)](https://github.com/eclipse-sumo/sumo/actions/workflows/build-windows.yml)\n[![Linux](https://github.com/eclipse-sumo/sumo/actions/workflows/build-linux.yml/badge.svg)](https://github.com/eclipse-sumo/sumo/actions/workflows/build-linux.yml)\n[![macOS](https://github.com/eclipse-sumo/sumo/actions/workflows/build-macos.yml/badge.svg)](https://github.com/eclipse-sumo/sumo/actions/workflows/build-macos.yml)\n[![sonarcloud security](https://sonarcloud.io/api/project_badges/measure?project=org.eclipse.sumo&metric=security_rating)](https://sonarcloud.io/summary/overall?id=org.eclipse.sumo)\n[![Translation status](https://hosted.weblate.org/widgets/eclipse-sumo/-/svg-badge.svg)](https://hosted.weblate.org/engage/eclipse-sumo/)\n![Repo Size](https://img.shields.io/github/repo-size/eclipse/sumo.svg)\n\nWhat is SUMO\n------------\n\n[\"Simulation of Urban MObility\" (SUMO)](https://sumo.dlr.de/) is an open source,\nhighly portable, microscopic traffic simulation package designed to handle\nlarge road networks and different modes of transport.\n\n<p align=\"center\"><img width=70% src=\"https://raw.githubusercontent.com/eclipse/sumo/main/docs/web/docs/images/multiple-screenshots.png\"></p>\n\nIt is mainly developed by employees of the [Institute of Transportation Systems\nat the German Aerospace Center](https://www.dlr.de/ts/en/).\n\n\nWhere to get it\n---------------\n\nYou can download SUMO via our [downloads site](https://sumo.dlr.de/docs/Downloads.html).\n\nAs the program is still under development (and is being extended continuously), we advice you to\nuse the latest sources from our GitHub repository. Using a command line client,\nexecute the following command:\n\n```\ngit clone --recursive https://github.com/eclipse-sumo/sumo\n```\n\nContact\n-------\n\nTo stay informed, we have a mailing list for SUMO, which\n[you can subscribe](https://dev.eclipse.org/mailman/listinfo/sumo-user) to.\nMessages to the list can be sent to sumo-user@eclipse.org.\nSUMO announcements will be made through the sumo-announce@eclipse.org list;\n[you can subscribe](https://dev.eclipse.org/mailman/listinfo/sumo-announce) to it as well.\nFor further contact information, have a look at [this page](https://sumo.dlr.de/docs/Contact.html).\n\n\nBuild and Installation\n----------------------\n\nFor Windows we provide pre-compiled binaries and CMake files to generate Visual Studio projects.\nIf you want to develop under Windows, please also clone the dependent libraries using:\n\n```\ngit clone --recursive https://github.com/DLR-TS/SUMOLibraries\n```\n\nIf you're using Linux, you should have a look whether your distribution already contains sumo.\nThere is also a [ppa for ubuntu users](https://launchpad.net/~sumo) and an\n[open build service instance](https://build.opensuse.org/project/show/science:dlr).\nIf you want to build SUMO yourself, the steps for ubuntu are:\n\n```\nsudo apt-get install cmake python g++ libxerces-c-dev libfox-1.6-dev libgdal-dev libproj-dev libgl2ps-dev swig\ncd <SUMO_DIR> # please insert the correct directory name here\nexport SUMO_HOME=\"$PWD\"\ncmake -B build .\ncmake --build build -j$(nproc)\n```\n\nFor [detailed build instructions, have a look at our Documentation](https://sumo.dlr.de/docs/Developer/Main.html#build_instructions).\n\n\nGetting started\n---------------\n\nTo get started with SUMO, take a look at the docs/tutorial and examples directories,\nwhich contain some example networks with routing data and configuration files.\nThere is also user documentation provided in the docs/ directory and on the\nhomepage.\n\nDocumentation\n---------------\n\n- The main documentation is at [sumo.dlr.de/docs](https://sumo.dlr.de/docs). Note that this tracks the [development version](https://sumo.dlr.de/docs/FAQ.html#why_does_sumo_not_behave_as_documented_in_this_wiki).\n- A mirror of the main documentation is at [sumo.sourceforge.net/docs](https://sumo.sourceforge.net/docs).\n- An offline version of the documentation is part of every release and can be accessed via `docs/userdoc/index.html`.\n\nImproving SUMO\n--------------\n\nPlease use the [GitHub issue tracking tool](https://github.com/eclipse-sumo/sumo/issues) for bugs and requests,\nor file them to the sumo-user@eclipse.org list. Before\nfiling a bug, please consider to check with a current repository checkout\nwhether the problem has already been fixed.\n\nWe welcome patches, pull requests and other contributions! For details see [our contribution guidelines](CONTRIBUTING.md).\n\nWe use [Weblate for translating SUMO](https://hosted.weblate.org/projects/eclipse-sumo/). If you\nwant to add translation strings or a language, see [our contribution guidelines](CONTRIBUTING.md#translating) and\n[this page](https://sumo.dlr.de/docs/Developer/Translating.html) for more information.\n\n\nLicense\n-------\n\nSUMO is licensed under the [Eclipse Public License Version 2](https://eclipse.org/legal/epl-v20.html).\nThe licenses of the different libraries and supplementary code information are in the\nsubdirectories and in the [Documentation](https://sumo.dlr.de/docs/Libraries_Licenses.html).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/supervillain",
            "repo_link": "https://github.com/evanberkowitz/supervillain",
            "readme": "# supervillain\n\n[![DOI](https://zenodo.org/badge/679369801.svg)](https://zenodo.org/badge/latestdoi/679369801)\n\nSupervillain is a python package for studying the Villain model.\n\n# Installation + Development\n\nNavigate to the cloned repo and try\n\n```\npip install .  # for development use pip install -e . \n./test/end-to-end.py\n```\n\nIf pip installation succeeds so too should the example script, which by default samples the (φ, n) formulation of the model on a small lattice.\n\nsupervillain has documentation built with [sphinx](https://www.sphinx-doc.org/en/master/).\nTo build the documentation once you \n\n```\nsphinx-build . _build\n```\n\nand then can open `_build/index.html` in a browser.\nIf you are developing you can replace `sphinx-build` with [`sphinx-autobuild`](https://pypi.org/project/sphinx-autobuild/) to get live updates to the documentation as you go.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/swh-client",
            "repo_link": "https://github.com/Ramy-Badr-Ahmed/php-swh-client",
            "readme": "![GitHub top language](https://img.shields.io/github/languages/top/Ramy-Badr-Ahmed/swh-client)\n![GitHub](https://img.shields.io/github/license/Ramy-Badr-Ahmed/swh-client)  [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12808864.svg)](https://doi.org/10.5281/zenodo.12808864)\n\n[![SWH](https://archive.softwareheritage.org/badge/swh:1:dir:ce683dcced024cb3af1db3b01bbe86f2a9b08028/)](https://archive.softwareheritage.org/swh:1:dir:ce683dcced024cb3af1db3b01bbe86f2a9b08028;origin=https://github.com/Ramy-Badr-Ahmed/swh-client;visit=swh:1:snp:63102a06d859d7d3bcccf1bfe5ade84d8e54e2d5;anchor=swh:1:rev:fb18ecd48c6d62947316845716fc578030ccf749)\n\n# SWH API Client\n\nThis is a PHP API client/connector for [Software Heritage (SWH) web API](https://archive.softwareheritage.org/api/) - currently in Beta phase. The client is wrapped round the [`Illuminate Http package`](https://packagist.org/packages/illuminate/http) and the [`GuzzleHTTP`](https://docs.guzzlephp.org/en/stable/index.html) library.\n\n>[!Note]\n> _**Detailed documentation**_ can be found in the [wiki pages](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki) of this very repository.\n>\n>  A demonstrable version (some features) can be accessed here: <a href=\"https://1959e979-c58a-4d3c-86bb-09ec2dfcec8a.ka.bw-cloud-instance.org/\" target=\"_blank\">**Demo Version**</a>\n>> Working on new features and fixes will be gladly considered. Please feel free to report.\n\n## Installation Steps:\n\n    1) Clone this project.\n    \n    2) Open a console session and navigate to the cloned directory:\n    \n        Run \"composer install\"\n\n        This should involve installing the PHP REPL, PsySH\n\n    3) (Optional) Acquire SWH tokens for increased SWH-API Rate-Limits.\n    \n    4) Prepare .env file and add tokens:   \n    \n        4.1) Rename/Copy the cloned \".env.example\" file to .env\n                cp .env.example .env   \n                \n        4.2) (Optional) Edit these two token keys:\n        \n                SWH_TOKEN_PROD=Your_TOKEN_FROM_SWH_ACCOUNT              # step 3)                 \n                SWH_TOKEN_STAGING=Your_STAGING_TOKEN_FROM_SWH_ACCOUNT   # step 3)                 \n\n    5) (optional) Add psysh to PATH.\n\n## Quickstart:\n\nIn a console session inside the cloned directory, start the php REPL:\n\n```php\n$ psysh     // if not added to PATH replace with: vendor/bin/psysh\n\nPsy Shell v0.12.0 (PHP 8.2.0 — cli) by Justin Hileman\n```\n\nThis will open a REPL console-based session where one can test the functionality of the api classes and their methods before building a suitable workflow/use-cases.\n\n### Presets\n\nAs a one-time configuration parameter, you can set the desired returned data type by SWH (default JSON):\n\n```php\n> namespace Module\\HTTPConnector;\n> use Module\\HTTPConnector;         \n\n> HTTPClient::setOptions(responseType:'object')     // json/collect/object available\n```\n\n> * More details on the default configs: [Default Configurations](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki#default-configurations)\n> * More details on further options set: [Preset Configurations](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki).\n\n### Visits\n\nRetrieve Latest Full Visit in the SWH archive:\n\n```php\n> namespace Module\\OriginVisits;\n> use Module\\OriginVisits; \n\n> $visitObject = new SwhVisits('https://github.com/torvalds/linux/');\n\n> $visitObject->getVisit('latest', requireSnapshot: true)\n```\n\n> More details on further swh visits methods: [SwhVisits](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki#ii-swhvisits).\n\n### DAG Model:\n\nAs graph Nodes, retrieve node Contents, Edges or find a Path to other nodes (top-bottom):\n\n```php\n> namespace Module\\DAGModel;\n> use Module\\DAGModel; \n\n> $snpNode = new GraphNode('swh:1:snp:bcfd516ef0e188d20056c77b8577577ac3ca6e58')\n\n> $snpNode->nodeHopp()   // node contents\n\n> $snpNode->nodeEdges()  // node edges keyed by the respective name\n\n> $revNode = new GraphNode('swh:1:rev:9cf5bf02b583b93aa0d149cac1aa06ee4a4f655c')\n\n> $revNode->nodeTraversal('deps/nghttp2/lib/includes/nghttp2/nghttp2ver.h.in') //  traverse to a deeply nested file\n```\n\nMore details on:\n\n> * General [Node Methods](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki#iii-graphnode).\n> * The Graph methods:\n>   * [Graph contents](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki#iv-graphhopping)\n>   * [Graph edges](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki#v-graphedges)\n>   * [Graph paths](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki#vi-graphtraversal)\n\n### Archive\n\nYou can specify repositories URL w/o paths and archive to SWH using one of the two variants (`static/non-static methods`):\n\n```php\n> namespace Module\\Archival;\n> use Module\\Archival; \n    \n> $saveRequest = new Archive('https://github.com/torvalds/linux/')    // Example 1\n> $saveRequest->save2Swh()\n    \n> $newSaveRequest = Archive::repository('https://github.com/hylang/hy/tree/stable/hy/core')  // Example 2\n\n    // in both cases: the returned POST response contains the save request id and date\n```\n\nEnquire about archival status using the id/date of the archival request (available in the initial POST response)\n\n```php\n> $saveRequest->getArchivalStatus($saveRequestDateOrID)     // current status is returned \n> $saveRequest->trackArchivalStatus($saveRequestDateOrID)   // tracks until archival has succeeded\n```\n\n> More details on further archive methods: [Archive](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki#vii-archive).\n\n### EBNF Grammar\n\nValidate a given swhID. `TypeError` is thrown for non-valid swhIDs.\n\n```php\n> namespace Module\\DataType; \n> use Module\\DataType; \n         \n$snpID = new SwhcoreId('swh:1:snp:bcfd516ef0e188d20056c77b8577577ac3ca6e5Z') // throws TypeError Exception\n```\n> Full details of the SWHID persistent Identifiers: [Syntax](https://docs.softwareheritage.org/devel/swh-model/persistent-identifiers.html#syntax)\n\n>[!Note]\n> Todo: Core identifiers with qualifiers.\n\n### MetaData\n\nReturns a list of metadata authorities that provided metadata on the given target\n\n```php\n> namespace Module\\MetaData;\n> use Module\\MetaData; \n\n> SwhMetaData::getOriginMetaData('https://github.com/torvalds/linux/')\n```\n\n> More details on further metadata methods: [Metadata](https://github.com/Ramy-Badr-Ahmed/swh-client/wiki#viii-metadata).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/t8code",
            "repo_link": "https://github.com/DLR-AMR/t8code",
            "readme": "\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7034838.svg)](https://doi.org/10.5281/zenodo.7034838)\n[![t8code tests serial](https://github.com/DLR-AMR/t8code/actions/workflows/tests_t8code_serial.yml/badge.svg)](https://github.com/DLR-AMR/t8code/actions/workflows/tests_t8code_serial.yml)\n[![t8code tests parallel](https://github.com/DLR-AMR/t8code/actions/workflows/tests_t8code_parallel.yml/badge.svg)](https://github.com/DLR-AMR/t8code/actions/workflows/tests_t8code_parallel.yml)\n\n<p align=\"center\">\n  <img width=\"300px\" src=t8code_logo.png>\n</p>\n\n### Introduction\n\nt8code (spoken as \"tetcode\") is a C/C++ library to manage parallel adaptive meshes with various element types.\nt8code uses a collection (a forest) of multiple connected adaptive space-trees in parallel and scales to at least one million MPI ranks and over 1 Trillion mesh elements.\nIt is licensed under the GNU General Public License 2.0 or later. Copyright (c) 2015 the developers.\n\nt8code is intended to be used as a thirdparty library for numerical simulation codes or any other applications that require meshes.\n\n<table>\n    <tr>\n        <td><img src=\"https://github.com/DLR-AMR/t8code/blob/main/doc/pictures/cmesh_tet_holes.png?raw=true\" height=\"200\" /></td> \n        <td><img src=\"https://github.com/DLR-AMR/t8code/blob/main/doc/pictures/flow_around_circle_sim2.jpg?raw=true\" height=\"181\" /></td>\n    </tr>\n      <tr>\n        <td><img src=\"https://github.com/DLR-AMR/t8code/blob/main/doc/pictures/mesh_3d_hybrid_cutout.jpg?raw=true\" height=\"200\" /></td>\n        <td><img src=\"https://github.com/DLR-AMR/t8code/blob/main/doc/pictures/AirplaneWithTetMesh.png?raw=true\" height=\"200\" /></td>\n    </tr>\n</table>\n\nt8code, or T8 for short, supports the following element types (also different types in the same mesh):\n\n- 0D: vertices\n- 1D: lines\n- 2D: quadrilaterals and triangles\n- 3D: hexahedra, tetrahedra, prisms and pyramids\n\nAmong others, t8code offers the following functionalities:\n\n- Create distributed adaptive meshes over complex domain geometries\n- Adapt meshes according to user given refinement/coarsening criteria\n- Establish a 2:1 balance\n- (Re-)partition a mesh (and associated data) among MPI ranks\n- Manage ghost (halo) elements and data\n- Hierarchical search in the mesh\n- Curved mesh elements\n\nt8code uses space-filling curves (SFCs) to manage the adaptive refinement and efficiently store the mesh elements and associated data.\nA modular approach makes it possible to exchange the underlying SFC without changing the high-level algorithms.\nThus, we can use and compare different refinement schemes and users can implement their own refinement rules if so desired.\n\nCurrently t8code offers the following implementations by default:\n  - lines use a 1D Morton curve with 1:2 refinement\n  - quadrilateral/hexahedral elements are inherited from the p4est submodule, using the Morton curve 1:4, 1:8 refinement; \n  - triangular/tetrahedral are implemented using the Tetrahedral Morton curve, 1:4, 1:8 refinement;\n  - prisms are implemented using the triangular TM curve and a line curve, 1:8 refinement.\n  - pyramids are implemented using the Pyramidal Morton curve and the TM curve for its tetrahedral children, 1:10 (for pyramids) / 1:8 (for tetrahedra) refinement.\n  - The code supports hybrid meshes including any of the above element types (of the same dimension).\n\nYou find more information on t8code in the [t8code Wiki](https://github.com/DLR-AMR/t8code/wiki).\n\nFor a brief introduction in AMR and the algorithms used by t8code we recommend to read our [overview paper](https://elib.dlr.de/194377/1/t8code_overview_IMR2023.pdf).\n\n### Setup\n\nWe provide a short guide to install t8code in our Wiki [Installation guide](https://github.com/DLR-AMR/t8code/wiki/Installation).\n\n  \n### Getting started\n  \n  To get familiar with t8code and its algorithms and data structures we recommend executing the tutorial examples in `tutorials`\n  and read the corresponding Wiki pages starting with [Step 0 - Helloworld](https://github.com/DLR-AMR/t8code/wiki/Step-0---Hello-World).\n  \n  A sophisticated example of a complete numerical simulation is our finite volume solver of the advection equation in `example/advection`.\n\n\n### Documentation\n\nt8code uses [Doxygen](https://doxygen.nl/) to generate the code documentation. You can build the documentation with\n\n```\nmake doxygen\n```\n\nand then find the generated files in the `/doc` subfolder.\n\nYou can also find the documentation of our releases on the [t8code website](https://dlr-amr.github.io/t8code/pages/documentation.html).\n\n### License and contributing\nt8code is licensed under GPLv2 (see [COPYING](COPYING)). We appreciate\ncontributions from the community and refer to [CONTRIBUTING.md](CONTRIBUTING.md)\nfor more details.\n\nNote that we strive to be a friendly, inclusive open-source\ncommunity and ask all members of our community to adhere to our\n[`CODE_OF_CONDUCT.md`](CODE_OF_CONDUCT.md). \n\nTo get in touch, [open an issue](https://github.com/DLR-AMR/t8code/issues/new)\nor write an email to one of the principal developers.\n\n### Julia wrapper\n\nWe offer [T8code.jl](https://github.com/DLR-AMR/T8code.jl) - an official\n[Julia](https://julialang.org/) package allowing to call t8code routines from\nthe [Julia](https://julialang.org/) programming language. From within a Julia\nsession do\n```julia\njulia> import Pkg; Pkg.add([\"T8code\", \"MPI\"])\n```\nto install the package on your system.\n\n### Publications\n  \n  An (incomplete) list of publications related to t8code:\n    \n  [1] **Overview Paper**: \n  Holke, Johannes and Burstedde, Carsten and Knapp, David and Dreyer, Lukas and Elsweijer, Sandro and Ünlü, Veli and Markert, Johannes and Lilikakis, Ioannis and Böing, Niklas and Ponnusamy, Prasanna and Basermann, Achim  (2023) *t8code v. 1.0 - Modular Adaptive Mesh Refinement in the Exascale Era*. SIAM International Meshing Round Table 2023, 06.03.2023 - 09.03.2023, Amsterdam, Niederlande. \n  [Full text available](https://elib.dlr.de/194377/1/t8code_overview_IMR2023.pdf)\n  \n    \n  [2] **Original PhD thesis**: \n  Holke, Johannes *Scalable algorithms for parallel tree-based adaptive mesh refinement with general element types*, PhD thesis at University of Bonn, 2018,\n      [Full text available](https://bonndoc.ulb.uni-bonn.de/xmlui/handle/20.500.11811/7661)\n   \n      \n  [3] **Tetrahedral and triangular Space-filling curve**:\n  Burstedde, Carsten and Holke, Johannes *A Tetrahedral Space-Filling Curve for Nonconforming Adaptive Meshes*, SIAM Journal on Scientific Computing, 2016, [10.1137/15M1040049](https://epubs.siam.org/doi/10.1137/15M1040049)\n  \n  \n  [4] **Coarse mesh partitioning**:\n  Burstedde, Carsten and Holke, Johannes *Coarse mesh partitioning for tree-based AMR*, SIAM Journal on Scientific Computing, 2017, [10.1137/16M1103518](https://epubs.siam.org/doi/10.1137/16M1103518)\n  \n  \n  [5] **Ghost computation**:\n  Holke, Johannes and Knapp, David and Burstedde, Carsten *An Optimized, Parallel Computation of the Ghost Layer for Adaptive Hybrid Forest Meshes*, SIAM Journal on Scientific Computing, 2021, [10.1137/20M1383033](https://epubs.siam.org/doi/abs/10.1137/20M1383033)\n \n  \n  [6] **Geometry controlled refinement for hexahedra**:\n  Elsweijer, Sandro and Holke, Johannes and Kleinert, Jan and Reith, Dirk  (2022) *Constructing a Volume Geometry Map for Hexahedra with Curved Boundary Geometries*.   In: SIAM International Meshing Roundtable Workshop 2022.  SIAM International Meshing Roundtable Workshop 2022, 22. - 25. Feb. 2022, [Full text available](https://elib.dlr.de/186570/1/ConstructingAVolumeGeometryMapForHexahedraWithCurvedBoundaryGeometries.pdf) \n  \n### Theses with t8code relations\n\n  An (incomplete) list of theses written with or about t8code:\n  \n\n  [A] **Prism space-filling curve**: \n  Knapp, David (2017) *Adaptive Verfeinerung von Prismen*. Bachelor's thesis, Rheinische Friedrich-Wilhems-Universität Bonn.\n  \n  \n  [B] **Pyramidal space-filling curve**: \n  Knapp, David (2020) *A space-filling curve for pyramidal adaptive mesh refinement*. Master's thesis, Rheinische Friedrich-Wilhems-Universität Bonn. [Full text available](https://www.researchgate.net/publication/346789160_A_space-filling_curve_for_pyramidal_adaptive_mesh_refinement)\n  \n   \n  [C] **DG solver based on t8code**: \n  Dreyer, Lukas (2021) *The local discontinuous galerkin method for the advection-diffusion equation on adaptive meshes*.  Master's thesis, Rheinische Friedrich-Wilhems-Universität Bonn.\n  [Full text available](https://elib.dlr.de/143969/1/masterthesis_dreyer.pdf) \n  \n  \n  [D] **Geometry controlled refinement for hexahedra (Part 1)**: \n  Elsweijer, Sandro (2021) *Curved Domain Adaptive Mesh Refinement with Hexahedra*.  Tech report, Hochschule Bonn-Rhein-Sieg.\n  [Full text available](https://elib.dlr.de/186571/1/masterprojekt-2_elsweijer_ABGABEVERSION_TITEL.pdf)\n  \n\n  [E] **Subelement and resolving hanging faces in 2D**: \n  Becker, Florian (2021) *Removing hanging faces from tree-based adaptive meshes for numerical simulation*, Master's thesis, Universität zu Köln.\n  [Full text available](https://elib.dlr.de/187499/1/RemovingHangingFacesFromTreeBasedAMR.pdf)\n  \n  \n  [F] **Coarsening as post-processing to reduce simulation file size**: \n  Spataro, Luca  (2021) *Lossy data compression for atmospheric chemistry using adaptive mesh coarsening*.  Master's thesis, Technische Universität München.\n  [Full text available](https://elib.dlr.de/144997/1/master-thesis-final-spataro.pdf)\n \n  \n  [G] **Geometry controlled refinement for hexahedra (Part 2)**: \n  Elsweijer, Sandro (2022) *Evaluation and generic application scenarios for curved hexahedral adaptive mesh refinement*.  Master's thesis, Hochschule Bonn-Rhein-Sieg.  [10.13140/RG.2.2.34714.11203](<https://doi.org/10.13140/RG.2.2.34714.11203>) [Full text available](https://elib.dlr.de/186561/1/sandro_elsweijer-evaluation_and_generic_application_scenarios_for_curved_hexahedral_adaptive_mesh_refinement.pdf)\n  \n  \n  [H] **Multigrid and other preconditioners for DG**: \n  Böing, Niklas  (2022) *Evaluation of preconditioners for implicit solvers of local DG for the advection-diffusion equation* (*Untersuchung von Präkonditionierern für implizite Löser für das Local DG-Verfahren zur Lösung der Advektions-Diffusionsgleichung*).  Master's thesis, Universität zu Köln.\n[Full text available](https://elib.dlr.de/186347/1/Untersuchung%20von%20Pr%C3%A4konditionierern%20f%C3%BCr%20implizite%20L%C3%B6ser%20f%C3%BCr%20das%20Local%20DG-Verfahren%20zur%20L%C3%B6sung%20der%20Advektions-Diffusionsgleichung.pdf)\n  \n\n  [I] **Removing elements from the mesh (cutting holes)**: \n  Lilikakis, Ioannis  (2022) *Algorithms for tree-based adaptive meshes with incomplete trees*.  Master's thesis, Universität zu Köln.    \n [Full text may be available in future](https://elib.dlr.de/191968/)\n \n  [J] **Curved tetrahedra**:\n  Fussbroich Jakob (2023) *Towards high-order, hybrid adaptive mesh refinement: Implementation and evaluation of curved unstructured mesh elements*. Master's thesis. Technische Hochschule Köln.\n  [Full text available](https://elib.dlr.de/200442/)\n\n  [K] **Hanging node resolution 3D**:\n  Tabea Leistikow (2024) *Derivation and implementation of a hanging nodes resolution scheme for hexahedral non-conforming meshes in t8code*. Master's thesis, Universität zu Köln.\n  Full text currently not available.\n\n  ### Citing t8code\n  \n  If you use t8code in any of your publications, please cite the [github repository](https://doi.org/10.5281/zenodo.7034838), [1] and [2]. For publications specifically related to \n- **the tetrahedral index**, please cite [3].\n- **coarse mesh partitioning**, please cite [4].\n- **construction and handling of the ghost layer**, please cite [5].\n- **geometry controlled refinement**, please cite [6] (general) and [J] (tetrahedral).\n- **hanging node resolution and/or subelements**, please cite [E] and [K].\n\nIf you use any functionality described in the theses, we encourage you to cite them as well.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/tamarin-prover",
            "repo_link": "https://github.com/tamarin-prover/tamarin-prover",
            "readme": "The Tamarin prover repository\n=============================\n[![master branch build-status](https://travis-ci.org/tamarin-prover/tamarin-prover.svg?branch=develop)](https://travis-ci.org/tamarin-prover/tamarin-prover)\n\nThis README describes the organization of the repository of the Tamarin prover\nfor security protocol verification. Its intended audience are interested\nusers and future developers of the Tamarin prover. For installation\nand usage instructions of the Tamarin prover see chapter 2 of the manual:\nhttps://tamarin-prover.github.io/manual/master/book/002_installation.html\n\n\nDeveloping and contributing\n---------------------------\n\nSee [contributing instructions](CONTRIBUTING.md) for instructions on how to develop,\ntest and release changes to the Tamarin prover source code.\n\n\nVersion Numbering Policy\n-----------------------\n\nWe use version numbers with four components.\n\n - The first component is the major version number. It indicates complete\n   rewrites of the codebase.\n - The second component is the minor version number. We use odd minor version\n   numbers to denote development releases intended for early adopters. We use\n   even minor version numbers to denote public releases, which are also\n   published.\n - The third component indicates bugfix releases.\n - The fourth component indicates documentation and meta-data changes.\n\nWe ensure that the external interface of a version of the Tamarin prover is backwards\ncompatible with the external interface of all versions that agree on the major\nand minor version number.\n\nWe announce all releases of the Tamarin prover on:\nhttp://tamarin-prover.github.io\n\n\nManual\n------\n\nThe manual is available as PDF or HTML at https://tamarin-prover.github.io/manual/index.html\n\nExperimental improved graph output\n----------------------------------\n\nYou can use our experimental improved graph output which may be\nhelpful for very large graphs that can be created for complicated\nprotocols. To enable this feature read the instructions about\n[improved graphs](/misc/cleandot/README.md).\n\nSpthy code editors\n------------------\n\nThe project contains support for spthy syntax highlighting and support\nin the [etc](/etc/) directory. This includes support for [Sublime Text](/etc/SUBLIME_TEXT.md), [VIM](/etc/spthy.vim) and [Notepad++](/etc/notepad_plus_plus_spthy.xml).\n\nExternal tools\n------------------\n\nExternal tools may use the [Tree-sitter](https://tree-sitter.github.io/tree-sitter/) grammar\nin the [tree-sitter/](/tree-sitter/) directory.\n\n\nExample Protocol Models\n-----------------------\n\nAll example protocol models are found in the directory\n\n    ./examples/\n\nAll models that we consider stable\nare part of every installation of the Tamarin prover. See\n`tamarin-prover.cabal` for the list of installed protocols. We use the\nfollowing sub-directories to organize the models.\n\n~~~~\naccountability/ case studies using the accountability implementation presented in\n                the \"Verifying Accountability for Unbounded Sets of Participants\" paper\ncsf12/          the AKE case studies from our CSF'12 paper.\nclassic/        classic security protocols like the ones from\n                [SPORE](http://www.lsv.ens-cachan.fr/Software/spore/table.html)\nloops/          experiments for testing loop-invariants and protocols with\n                non-monotonic state\nrelated_work/   examples from related work on protocols with loops or\n                non-monotonic state\nexperiments/    all other experiments\nake/            more AKE examples including ID-based and tripartite group KE\n                protocols based on bilinear pairing\nfeatures/       (small) models that demonstrate a given feature\nccs15/\t        the observational equivalence case studies from our CCS'15 paper\ncsf-18/         the XOR case studies from the CSF'18 paper\n~~~~\n\nFeel free to add more sub-directories and describe them here.\n\nIn general, we try use descriptive names for files containing the models. We\nalso document all our findings as comments in the protocol model.  Moreover,\nwe use the following header in all files to make their context more explicit.\n\n~~~~\n/*\n   Protocol:    Example\n   Modeler:     Simon Meier, Benedikt Schmidt\n   Date:        January 2012\n\n   Status:      working\n\n   Description of protocol.\n\n*/\n~~~~\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/tbt-segmentation",
            "repo_link": "https://github.com/DLR-FT/TBT-Segmentation",
            "readme": "<!--\nSPDX-FileCopyrightText: 2023 German Aerospace Center (DLR)\n\nSPDX-License-Identifier: CC-BY-NC-ND-4.0\n-->\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.13807484.svg)](https://doi.org/10.5281/zenodo.13807484)\n\n> This tool is based on the paper [Temporal Behavior Trees: Robustness and Segmentation](https://doi.org/10.1145/3641513.3650180) and its companion poster [Temporal Behavior Trees - Segmentation](https://doi.org/10.1145/3641513.3652534), which were published at [HSCC'24](https://hscc.acm.org/2024/).\n\n> If you encounter any issues, have questions, or need assistance, feel free to reach out:  sebastian dot schirmer at dlr dot de\n\n## Table of Content\n- [Temporal Behavior Trees: Robustness and Segmentation](#temporal-behavior-trees-robustness-and-segmentation)\n  - [Getting Started](#getting-started)\n  - [Folder Structure](#folder-structure)\n  - [Brief Summary of the Supported Operators](#brief-summary-of-the-supported-operators)\n  - [Docker Environment](#docker-environment)\n  - [How to Interpret the Output Format](#how-to-interpret-the-output-format)\n  - [Contributors](#contributors)\n  - [Contributing](#contributing)\n  - [Changes](#changes)\n  - [License](#license)\n\n# Temporal Behavior Trees: Robustness and Segmentation\n\nTemporal Behavior Trees (TBT) are a specification formalism for monitoring behaviors.\nThey are inspired by behavior trees that are commonly used to program robotic applications, but allow to specify temporal properties in their leaf nodes. \nTherefore, they can be easily retrofitted to existing behavior trees.\n\nFor instance, consider the following behavior tree that specifies the landing sequence of an unmanned aircraft (1) *move to position*, (2) *stay in position*, (3) *move to touchdown*, and (4) *descend*:\n\n<p align=\"center\">\n<img src=\"https://github.com/DLR-FT/TBT-Segmentation/blob/main/figs/BehaviorTree.JPG\" width=\"400\">\n</p>\n\nGiven such a TBT specification and a trace, i.e., a sequence of events of a system, we can compute the corresponding robustness.\nRobustness provides an quantitative interpretation *how* much the TBT specification was satisfied or violated.\n\nFurther, we can use a TBT specification to segment a trace.\nThat means that we assign portions of the provided specification to segments of the given trace.\nSuch a segmentation then helps to better explain which portions of the specification were satisfied or violated.\n\nIt is also useful to visualize the resulting segmentation, as shown below for the landing maneuver:\n\n<p align=\"center\">\n<img src=\"https://github.com/DLR-FT/TBT-Segmentation/blob/main/figs/Segmentation.png\" width=\"400\">\n</p>\n\n## Getting Started\nRequires Rust to compile source code and Python for visualization.\n1. [Install Rust](https://www.rust-lang.org/)\n1. Specify a TBT, e.g., as done [here](specification/shiplanding_formula.tbt). The grammar can be found [here](src/tbt.pest)\n1. [Provide a Trace by implementing ``get_trace``](src/user_defined/get_trace.rs)\n2. [Replace the ``user_defined``-function by your own (Line 5)](src/lib.rs)\n3. Call ``cargo build`` or ``cargo build --release`` \n4. Call ``cargo run -- --help`` to get help on the command-line-usage\n5. Call ``cargo test`` to see if the tests are successful\n \nFor instance:\n\n``cargo run --release -- -u -s specification/shiplanding_formula_combined.tbt -f ./res/logs_wind_front_Lateral/`` runs segmentation using subsampling on a provided logfile. \nFor this example, ``get_trace`` is already provided.\n\nUsing the [visualization script](scripts/visualize_ship_landing.py), we can easily plot a segmentation by, e.g., ``python visualize_ship_landing.py plot -b Lateral -s 5000 10000 20000 -e 0 -l ../res/logs_wind_front_Lateral/`` where ``5000, 10000, 20000`` represent beginning of segments (omitting 0), ``-b`` states the expected behavior and is used to plot the dotted lines, and ``-e`` represents the number of skipped entries due to subsampling. There is also the option to save a plot to inspect it in a docker environment using ``-p``.\nWe can also replay the flight by, e.g.,  ``python visualize_ship_landing.py live -l ../res/logs_wind_front_Lateral/ -b Lateral -f 0.005 0.1 2.0``.\n\nFor more information call ``python visualize_ship_landing.py --help``.\n\n> Using ``--toml <FILE>`` as command-line-argument generates a .toml-file for the computed segmentations.\n\n## Folder Structure\n- [figs](figs) are resources used for this readme document\n- [res](res) contains the logfiles used in the HSCC paper\n  - The logfolder name specifies the wind direction (*front* or *side*) and the anticipated maneuver (*45Deg*, *Lateral*, *Oblique*, or *Straight*)\n  - Each flight consists of two csv-files: one for the ship and one for the aircraft\n  - The files contain the position, the velocity, and the angles for the ship and the aircraft\n- [scripts](scripts) provides auxiliary resources\n  - [Makefile](scripts/Makefile) is used for Rust profiling\n  - [clean.sh](scripts/clean.sh) is used for cleaning up the repository\n  - [infer_parameters_visualization.py](scripts/infer_parameters_visualization.py) is used for the [run.sh](scripts/run.sh) script to extract the segments from the produced output files\n  - [run.sh](scripts/run.sh) is a script that executes our segmentation tool on all the available [logfiles](res) and produces png files to further analyze ([infer_parameters_visualization.py](scripts/infer_parameters_visualization.py))\n  - [visualize_ship_landing.py](scripts/visualize_ship_landing.py) is a script that is used to produced the png files that show the flight and the computed segments\n- [specification](specification) contains some example specifications  \n- [src](src) contains the source code  \n    - [lib.rs](src/lib.rs) provides a package of TBTs functions that can be used by others \n      - It requires a user to provide two functions [get_trace()](src/lib.rs) and [get_events_per_second()](src/lib.rs)\n      - This repository provides these functions for the ship landing: [user_defined/](src/user_defined/)\n    - [main.rs](src/main.rs) is an example that uses [lib.rs](src/lib.rs) and the user-defined functions [tree/](src/tree/)\n    - [stl.rs](src/stl.rs) provides the syntax and semantics for STL formulas\n    - [behaviortree.rs](src/behaviortree.rs) provides the syntax and semantics for TBTs\n    - [command_line_parser.rs](src/command_line_parser.rs) is used to interface with the command line\n    - [functions.rs](src/functions.rs) is used to represent atomic functions that are used by the TBT parser\n    - [parser.rs](src/parser.rs) is a TBT parser that reads a .tbt-file and produces a ```Tree```\n    - [tbt.pest](src/tbt.pest) represents the grammar used by the TBT parser\n    - [toml_out.rs](src/toml_out.rs) is used to produce a .toml-file\n    - [csv_reader.rs](src/csv_reader.rs) represent auxiliary functions such as reading a csv-file\n    - [table.rs](src/table.rs) represents the main data structure for the dynamic programming\n    - [user_defined/](src/user_defined/) is an example implementation for the *UserProvidedFunctions* required by [lib.rs](src/lib.rs)\n      - [get_trace.rs](src/user_defined/get_trace.rs) reads the trace data used in the experiment (ie it reads a csv-file and provides a ``Trace``)\n- [tests](tests/) contains multiple test cases that can be executed to test whether the compilation works\n- [Dockerfile](Dockerfile) just c/p the whole repository and builds it to produce a docker container that then can run [run.sh](scripts/run.sh) to procude the HSCC artifacts\n\n> To use the TBT tool for a different use-case, a user needs to provide the *UserProvidedFunction* ([get_trace()](src/lib.rs) and [get_tree()](src/lib.rs)) similar to what has been done here for the ship landing ([tree/](src/tree/)). I.e., he/she needs to extract logdata into a *Trace* struct and needs to build the TBT.\n\n## Brief Summary of the Supported Operators\n\nTBT ``T:=``\n- ``Fallback([T_1,...,T_n])``: At least one of the subtrees must eventually be satisfied.\n- ``Sequence([T_1, T_2])``: Each subtree must be satisfied in order from left to right.\n- ``Parallel(m, [T_1,...,T_n])``: At least ``m`` of the subtrees must be simultaneously satisfied.\n- ``Timeout(t, T)``: The subtree must be satisfied by a finite prefix of length ``t``.\n- ``Kleene(n, T)``: There must be ``n`` repetitions of the subtree to be satisfied.\n- ``Leaf(S)``: STL formula ``S`` must be satisfied.\n\nSTL ``S:=``\n- ``Atomic(function)``: The function must return a positive number to be satisfied, otherwise it is violated.\n- ``Conjuntion(S_1, S_2)``: Both subformulas must be satisfied.\n- ``Disjunction(S_1, S_2)``: One of the subformulas or both must be satisfied.\n- ``Neg(S)``: The subformulas must be violated.\n- ``Next(S)``: The subformula must be satisfied in the next step.\n- ``Eventually(S)``: Eventually the subformula must be satisfied.\n- ``Globally(S)``: The subformula must always be satisfied.\n- ``Until(S_1, S_2)``: The subformula ``S_1`` must be satisfied *until* ``S_2`` is satisfied.\n- ``EventuallyInterval(l, u, S)``: Eventually within ``l`` and ``u`` steps, the subformula must be satisfied.\n- ``GloballyInterval(l, u, S)``: Always within ``l`` and ``u`` steps, the subformula must be satisfied.\n- ``UntilInterval(l, u, S_1, S_2)``: Within ``l`` and ``u`` steps, the subformula ``S_1`` must be satisfied *until* ``S_2`` is satisfied.\n\nThe TBT operators are defined [here](src/behaviortree.rs) and the STL operators are defined [here](src/stl.rs). \n\nA TBT parser is implemented that is based on this [grammar](src/tbt.pest).\n\nFor more details, we refer to the [paper](https://doi.org/10.1145/3641513.3650180).\n\n## Docker Environment\n1. Install [Docker](https://docs.docker.com/engine/install/)\n2. Builder Docker Image: ``docker build -t tbt .``\n3. Run Docker Container: ``docker run -it --rm --name tbt-container tbt bash``\n4. To test if the container is working reproduce paper results by (being in the docker bash):\n   - Run ``. scripts/run.sh`` that takes all logfiles and computes the segmentation.    \n      - The script calls the tool as defined [here](#getting-started) for each logfolder that exists in [res](res).\n      - The results for each run are stored in the respective logfolder.\n   - Check results of each logfiles that are located in the following subfolder: ``cd ./res/``\n   - The files in the folders [res/<folder>](res) are called ``subsampling_result.txt`` and ``subsamplingAndLazy_result.txt``.\n   - Besides the result-files, for each segmentation, the script produces a `.png`-plot. Every `.png`-plot that has a name that ends with `aX`, where `X` is a number, represents an alternative segmentations where the number corresponds to the alternative in the result-file.  For instance, Figure 9 of the HSCC paper can then be found [here](res/logs_wind_front_Oblique/subsampling_result_a3.png).\n   - (Optional) To display plots copy them from the docker container to your host machine; dont use the docker bash.\n     -  ``docker cp <container_id>:<location_png/results> <location_to_be_stored>`` (copy whole folder or individual files), e.g., ``docker cp e7ba94d69e94:/app/res ./docker``\n     -  to get container_id call ``docker ps``\n\n> The Dockerfile uses multiple stages. The first stage builds the executable using rust/cargo and the second stage uses a debian environment to execute it. Therefore, there are no cargo-commands available in the container while running.\n\n> Also, there is a line ending issue, when building the docker image in a Windows environment. We recommend building the image on a Linux machine to avoid this issue (WSL is an option for Windows systems).\n \n## How to Interpret the Output Format\nRunning e.g. `cargo run --release -- -l -c -u -s <your-folder>/TBT-Segmentation/specification/shiplanding_formula_combined.tbt -f <your-foulder>/TBT-Segmentation/res/logs_wind_front_Lateral/` produces an output that contains the following lines:\n\n>Constants: {\n>  \"Lateral_AngleToShip\": 90.0, ... }\n\nthat represent all read constants in the provided TBT specification.\n\n> AP(0) in_pos ([\"uas_x\", \"uas_y\", \"uas_z\", \"ship_x\", \"ship_y\", \"ship_z\", \"ship_heading\"]): (2.5 - sqrt((((((ship_x + (30 * cos((deg_to_rad(135) + ship_heading)))) - uas_x) ^ 2) + (((ship_y + (30 * sin((deg_to_rad(135) + ship_heading)))) - uas_y) ^ 2)) + (((ship_z + 20) - uas_z) ^ 2))))\n\na sequence of the parsed atomic propositions. \n\n> SETTING: <br>\n> Logfile: /root/canbedeleted/TBT-Segmentation/res/logs_wind_front_Lateral/ <br>\n\nrepresents the logfile name.\n\n> Approximations: (lazy evaluation= true, subsampling = true(delta: 100))\n\nshow which approximations are enabled.\nIn this case, lazy evauation and subsampling with a delta of 100 are enabled.\n\n> Trace length: 252\n\nprovides that the length of the trace is 252 after subsampling. \nI.e. the original file has >25.000 entries.\n\n> Temporal behavior tree: <br>\n  Sequence(22)[\n    Fallback(20)[ <...> ]]\n\nshows a pretty print of the used TBT with its node identifiers.\nHere, the root node has ID 22.\n\n> Created tree table with 733,194 entries. <br>\nCreated formula table with 828,828 entries.\n\nare information on the table used for dynamic programming.\n\n> Statistics: Robustness value is 0.05925286 with 3,277,611 total tree lookups and 1,503,504 formula lookups\n\nprovides information how effective dynamic programming was.\n\n> Get segmentation after 0 seconds.\n\nstates that it took 0 seconds to compute a segmentation.\n\n> Approximate segmentation with robustness 0.05925286 and subsampling delta of 0.5564443 is:\n\nis the beginning of the segmentation. The following lines provide information on the segments.\n\n> lower:          0   upper:         78   value:      0.31250286  segment: Leaf(0 move_to_position_lateral)\n\nrepresent one segment.\nIt states that the leaf node `move_to_position_lateral` was assigned to the segment that begins at index 0 and ends at index 78. \nFurther its robustness value is 0.31, i.e., the trace segment did satisfy this node.\n\n\n## Contributors\n- Sebastian Schirmer\n  \n## Contributing\n\nPlease see [the contribution guidelines](CONTRIBUTING.md) for further information about how to contribute.\n\n## Changes\n\nPlease see the [Changelog](CHANGELOG.md) for notable changes of the material.\n\n## License\n\nPlease see the file [LICENSE.md](LICENSE.md) for further information about how the content is licensed.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/tereno-doi",
            "repo_link": "https://jugit.fz-juelich.de/ibg-3/ibg3_data_management/software/projects/tereno-doi/tdoi",
            "readme": "# tdoi\ntdoi is a webapplication for creating DOIs.\n\n## Project setup\n```\nnpm install\n```\n[Environment Dateien](https://drive.google.com/drive/folders/1AV0bKfaz9jepHj05gtNlCnU1EcBBC6jG?usp=sharing)\n\n### Compiles and hot-reloads for development\n```\nnpm run serve\n```\n\n### Compiles and minifies for production\n```\nnpm run build\n```\n\n### Lints and fixes files\n```\nnpm run lint\n```\n\n### Customize configuration\nSee [Configuration Reference](https://cli.vuejs.org/config/).\n\n## start docker container\n`./dockerize`\n",
            "project_id": "11310"
        },
        {
            "software_organization": "https://helmholtz.software/software/tetrax",
            "repo_link": "https://codebase.helmholtz.cloud/micromagnetic-modeling/tetrax",
            "readme": "# TetraX\n\n![](logo_large.png)\n\nTetraX is a package for finite-element-method (FEM) micromagnetic modeling of magnetization statics and dynamics with\nthe aim to provide user friendly and flexible workflows. Apart from energy minimizers and an LLG solver, it provides\nimplementations of several FEM dynamic-matrix approaches to numerically calculate the normal modes and associated\nfrequencies for magnetic specimen of different geometries such as confined samples, infinitely long waveguides, or\ninfinitely extended multilayers. Next to support for ferromagnets, TetraX will also provide the first full micromagnetic\npackage for antiferromagnets.\n\nTetraX is maintained by the [Micromagnetic Modeling Group](https://www.hzdr.de/db/Cms?pOid=55944&pNid=107) of Dr. Attila\nKákay at the [Helmholtz-Zentrum Dresden - Rossendorf](https://www.hzdr.de).\n\nFor questions or feedback, please contact [Lukas Körber](mailto:l.koerber@hzdr.de).\n\n# Installation\n\nInstall this package using\n\n```bash\n   pip install git+https://gitlab.hzdr.de/micromagnetic-modeling/tetrax.git\n```\n\nTo allow for 3D visualization in Jupyter notebooks, you additionally need to activate the k3d extension in your shell\nusing\n\n```bash\n   jupyter nbextension install --py --sys-prefix k3d\n   jupyter nbextension enable --py --sys-prefix k3d\n```\n\n# Getting started\n\nTo get started, take a look into the package documentation on [Read the Docs](https://tetrax.readthedocs.io/en/latest/).\n",
            "project_id": "4372"
        },
        {
            "software_organization": "https://helmholtz.software/software/tigl",
            "repo_link": "https://github.com/DLR-SC/tigl",
            "readme": "<p><img src=\"doc/images/logo.png\" alt=\"TiGL Logo\" title=\"TiGL Logo\" style=\"background-color:white;padding:5px;\"/></p>\n\n[![CI workflow for main branch](https://github.com/DLR-SC/tigl/actions/workflows/main.yml/badge.svg)](https://github.com/DLR-SC/tigl/actions/workflows/main.yml)\n[![codecov](https://codecov.io/gh/dlr-sc/tigl/branch/master/graph/badge.svg)](https://codecov.io/gh/dlr-sc/tigl)\n[![Apache 2.0](https://img.shields.io/crates/l/k)](https://github.com/DLR-SC/tigl/blob/cpacs_3/LICENSE.txt)\n[![Install with conda](https://anaconda.org/dlr-sc/tigl3/badges/version.svg)](https://anaconda.org/dlr-sc/tigl3/badges/version.svg)\n[![Cite-us](https://img.shields.io/badge/doi-10.1007%2Fs11786--019--00401--y-blue)](https://doi.org/10.1007/s11786-019-00401-y) \n[![Documentation](https://img.shields.io/badge/docs-online-green)](https://dlr-sc.github.io/tigl/doc/latest/) \n\nThe **Ti**GL **G**eometry **L**ibrary can be used for the computation and processing of aircraft geometries \nstored inside [CPACS](https://github.com/DLR-LY/CPACS) files. TiGL offers many geometry related functions such as\n - Point retrieval functions to compute points on the aircraft surface\n - Intersection functions to compute the intersection of the aircraft with planes\n - Export functions for standard CAD file formats (STEP + IGES) or mesh formats, \n   including VTK, Collada, and STL.\n   \nThe TiGL library uses the OpenCASCADE CAD kernel to represent the airplane geometry \nby NURBS surfaces. The library provides external interfaces for C, C++, Python, Java, MATLAB, and FORTRAN.\n\nTiGL is shipped with the Qt based _TiGL Viewer_ for visualizing aircraft\ngeometries or viewing CAD files.\n\n![Screenshot of the TiGL Viewer](doc/images/tiglviewer-web.jpg)\n\n# Downloads\n\n - Pre-Compiled Releases:  https://github.com/DLR-SC/tigl/wiki/Downloads\n - Nightly Builds:    https://github.com/DLR-SC/tigl/actions?query=workflow%3A%22Continuous+Integration%22+event%3Aschedule\n\n# News\n\nPlease head over to our TiGL website: https://dlr-sc.github.io/tigl/#news\n\n# Cite us\n\nTiGL is available as Open Source and we encourage anyone to make use of it. If you are applying TiGL in a scientific environment and publish any related work, please cite the following article:\n\nSiggel, M., Kleinert, J., Stollenwerk, T. et al.:  *TiGL: An Open Source Computational Geometry Library for Parametric Aircraft Design*, Math.Comput.Sci. (2019). https://doi.org/10.1007/s11786-019-00401-y\n\nA free copy of the paper is offered here: https://rdcu.be/bIGUH \n\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/tigramite",
            "repo_link": "https://github.com/jakobrunge/tigramite",
            "readme": "# Tigramite – Causal inference for time series datasets\n![logo](docs/_images/tigramite_logo_header.png)\nVersion 5.2\n(Python Package)\n\n[Github](https://github.com/jakobrunge/tigramite.git)\n\n[Documentation](https://jakobrunge.github.io/tigramite/)\n\n[Tutorials](https://github.com/jakobrunge/tigramite/tree/master/tutorials/)\n\n## Overview\n\nIt's best to start with our [Overview/review paper: Causal inference for time series](https://github.com/jakobrunge/tigramite/blob/master/tutorials/Runge_Causal_Inference_for_Time_Series_NREE.pdf)\n\n__Update:__ Tigramite now has a new CausalEffects class that allows to estimate (conditional) causal effects and mediation based on assuming a causal graph. Have a look at the tutorial.\n\nFurther, Tigramite provides several causal discovery methods that can be used under different sets of assumptions. An application always consists of a method and a chosen conditional independence test, e.g. PCMCIplus together with ParCorr. The following two tables give an overview of the assumptions involved:\n\n| Method | Assumptions         | Output |\n| :-- | :-- | :-- |\n|         |   (in addition to Causal Markov Condition and Faithfulness)   |    |\n| PCMCI  | Causal stationarity, no contemporaneous causal links, no hidden variables |  Directed lagged links, undirected contemporaneous links (for tau_min=0)  |\n| PCMCIplus | Causal stationarity, no hidden variables    | Directed lagged links, directed and undirected contemp. links (Time series CPDAG) |\n| LPCMCI | Causal stationarity    | Time series PAG |\n| RPCMCI  | No contemporaneous causal links, no hidden variables |  Regime-variable and causal graphs for each regime with directed lagged links, undirected contemporaneous links (for tau_min=0)  |\n| J-PCMCI+ | Multiple datasets, causal stationarity, no hidden system confounding, except if context-related   | Directed lagged links, directed and undirected contemp. links (Joint time series CPDAG) |\n\n\n| Conditional independence test | Assumptions                                                                                            |\n| :-- | :-- | \n| ParCorr                       | univariate, continuous variables with linear dependencies and Gaussian noise                           |\n| RobustParCorr                 | univariate, continuous variables with linear dependencies, robust for different marginal distributions |\n| ParCorrWLS                    | univariate, continuous variables with linear dependencies, can account for heteroskedastic data        |\n| GPDC / GPDCtorch              | univariate, continuous variables with additive dependencies                                            |\n| CMIknn                        | multivariate, continuous variables with more general dependencies (permutation-based test)             |\n| Gsquared                      | univariate discrete/categorical variables                                                              |\n| CMIsymb                       | multivariate discrete/categorical variables (permutation-based test)                                   |\n| RegressionCI                  | mixed datasets with univariate discrete/categorical and (linear) continuous variables                  |\n\nRemark: With the conditional independence test wrapper class PairwiseMultCI you can turn every univariate test into a multivariate test.\n\n## General Notes\n\nTigramite is a causal inference for time series python package. It allows to efficiently estimate causal graphs from high-dimensional time series datasets (causal discovery) and to use graphs for robust forecasting and the estimation and prediction of direct, total, and mediated effects. Causal discovery is based on linear as well as non-parametric conditional independence tests applicable to discrete or continuously-valued time series. Also includes functions for high-quality plots of the results. Please cite the following papers depending on which method you use:\n\n- Overview: Runge, J., Gerhardus, A., Varando, G. et al. Causal inference for time series. Nat Rev Earth Environ (2023). https://doi.org/10.1038/s43017-023-00431-y\n\n- PCMCI: J. Runge, P. Nowack, M. Kretschmer, S. Flaxman, D. Sejdinovic, Detecting and quantifying causal associations in large nonlinear time series datasets. Sci. Adv. 5, eaau4996 (2019). https://advances.sciencemag.org/content/5/11/eaau4996\n- PCMCI+: J. Runge (2020): Discovering contemporaneous and lagged causal relations in autocorrelated nonlinear time series datasets. Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence, UAI 2020,Toronto, Canada, 2019, AUAI Press, 2020. http://auai.org/uai2020/proceedings/579_main_paper.pdf\n- LPCMCI: Gerhardus, A. & Runge, J. High-recall causal discovery for autocorrelated time series with latent confounders Advances in Neural Information Processing Systems, 2020, 33. https://proceedings.neurips.cc/paper/2020/hash/94e70705efae423efda1088614128d0b-Abstract.html\n- RPCMCI: Elena Saggioro, Jana de Wiljes, Marlene Kretschmer, Jakob Runge; Reconstructing regime-dependent causal relationships from observational time series. Chaos 1 November 2020; 30 (11): 113115. https://doi.org/10.1063/5.0020538\n- Generally: J. Runge (2018): Causal Network Reconstruction from Time Series: From Theoretical Assumptions to Practical Estimation. Chaos: An Interdisciplinary Journal of Nonlinear Science 28 (7): 075310. https://aip.scitation.org/doi/10.1063/1.5025050\n- Nature Communications Perspective paper: https://www.nature.com/articles/s41467-019-10105-3\n- Mediation class: J. Runge et al. (2015): Identifying causal gateways and mediators in complex spatio-temporal systems. Nature Communications, 6, 8502. http://doi.org/10.1038/ncomms9502\n- Mediation class: J. Runge (2015): Quantifying information transfer and mediation along causal pathways in complex systems. Phys. Rev. E, 92(6), 62829. http://doi.org/10.1103/PhysRevE.92.062829\n- CMIknn: J. Runge (2018): Conditional Independence Testing Based on a Nearest-Neighbor Estimator of Conditional Mutual Information. In Proceedings of the 21st International Conference on Artificial Intelligence and Statistics. http://proceedings.mlr.press/v84/runge18a.html\n- CausalEffects: J. Runge, Necessary and sufficient graphical conditions for optimal adjustment sets in causal graphical models with hidden variables, Advances in Neural Information Processing Systems, 2021, 34. https://proceedings.neurips.cc/paper/2021/hash/8485ae387a981d783f8764e508151cd9-Abstract.html\n\n## Features\n\n- flexible conditional independence test statistics adapted to\n  continuously-valued, discrete and mixed data, and different assumptions about\n  linear or nonlinear dependencies\n- handling of missing values and masks\n- p-value correction and (bootstrap) confidence interval estimation\n- causal effect class to  non-parametrically estimate (conditional) causal effects and also linear mediated causal effects\n- prediction class based on sklearn models including causal feature selection\n\n## Required python packages\n\n- python=3.7/3.8/3.9/3.10\n- numpy <1.24,>=1.18\n- scipy>=1.10.0\n- numba==0.56.4\n\n## Optional packages depending on used functions\n- scikit-learn>=1.2   # Gaussian Process (GP) Regression\n- matplotlib>=3.7.0   # Plotting\n- seaborn>=0.12.2     # Plotting\n- networkx>=3.0       # Plotting\n- torch>=1.13.1       # GPDC pytorch version (in conda install pytorch)\n- gpytorch>=1.9.1     # GPDC gpytorch version\n- dcor>=0.6           # GPDC distance correlation version\n- joblib>=1.2.0       # CMIsymb shuffle parallelization\n- ortools>=9.2        # RPCMCI\n\n## Installation\n\npython setup.py install\n\nThis will install tigramite in your path.\n\nTo use just the ParCorr, CMIknn, and CMIsymb independence tests, only numpy/numba and scipy are required. For other independence tests more packages are required:\n\n- GPDC: scikit-learn is required for Gaussian Process regression and dcor for distance correlation\n\n- GPDCtorch: gpytorch is required for Gaussian Process regression\n\nNote: Due to incompatibility issues between numba and numpy, we currently enforce soft dependencies on the versions.\n\n## User Agreement\n\nBy downloading TIGRAMITE you agree with the following points: TIGRAMITE is provided without any warranty or conditions of any kind. We assume no responsibility for errors or omissions in the results and interpretations following from application of TIGRAMITE.\n\nYou commit to cite above papers in your reports or publications.\n\n\n## License\n\nCopyright (C) 2014-2025 Jakob Runge\n\nSee license.txt for full text.\n\nGNU General Public License v3.0\n\nTIGRAMITE is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version. TIGRAMITE is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/timeio",
            "repo_link": "https://codebase.helmholtz.cloud/ufz-tsm/tsm-orchestration",
            "readme": "",
            "project_id": "7159"
        },
        {
            "software_organization": "https://helmholtz.software/software/timeseries-management",
            "repo_link": "https://git.gfz-potsdam.de/id2/tsm/tsm.docker-compose",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/tixi",
            "repo_link": "https://github.com/DLR-SC/tixi",
            "readme": "# TIXI #\r\n\r\n[![CI](https://github.com/DLR-SC/tixi/actions/workflows/main.yml/badge.svg)](https://github.com/DLR-SC/tixi/actions/workflows/main.yml)\r\n\r\n - Binary Downloads:  https://github.com/DLR-SC/tixi/wiki/Downloads\r\n - API Documentation: http://dlr-sc.github.io/tixi/\r\n - Issue Tracker:     https://github.com/DLR-SC/tixi/issues\r\n - Wiki:              https://github.com/DLR-SC/tixi/wiki\r\n\r\n## Installation ##\r\n - with Conda: [![Anaconda-Server Badge](https://anaconda.org/dlr-sc/tixi3/badges/installer/conda.svg)](https://anaconda.org/DLR-SC/tixi3)\r\n - with Linux package manager: [OpenBuildService](https://software.opensuse.org/download.html?project=science:dlr&package=tixi3)\r\n\r\n\r\n## Description ##\r\nTiXI is a fast and simple XML interface library and could be used from applications written in C, C++, Fortran, JAVA and Python. The library can be directly integrated into a code by third party software or can be used by users who don't want to deal with the complexity of XML when creating a new application. Although simplified and somewhat restricted compared to a full-fledged XML processing library the user can, for example, create documents, create and delete nodes, and add and remove element attributes. Routines to read and write simple text nodes and additionally specialized nodes holding integer and floating point numbers are part of this API. Furthermore, routines to process aggregates of these simple types have been implemented. For the processing of geometric data, reading and writing of multidimensional arrays or arrays of vectors, i.e. coordinates of points are supported. The library has been designed to hide the implementation details so that the underlying XML library, currently libxml2, can be replaced by another one without changing the XML processing API in the applications.\r\n\r\nReading a text attribute could be as easy as:\r\n\r\n```\r\ntixiGetTextAttribute( handle, elementPath, attributeName, &attributeValue );\r\n```\r\n\r\nGetting a double value would look like this:\r\n```\r\ntixiGetDoubleElement( handle, elementPath, &x );\r\n```\r\n\r\n## Multi Language Support ##\r\nThe TIXI library is written in C, but there are interfaces and wrappers for C++, Fortran, Python, JAVA and Matlab. Take a look at our examples for [C](https://github.com/DLR-SC/tixi/wiki/CExamples) and [Fortran](https://github.com/DLR-SC/tixi/wiki/Fortran%20Examples).\r\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/tomato-tools",
            "repo_link": "https://git.geomar.de/open-source/tomato-toolboxes/tomato",
            "readme": "# TOMATO - TOlles MAster TOol\nWritten for GEOMAR\n\n## Synopsis\nTomato is a launcher gui that offers easy access to several tools along the workflows of image and data correction.  \nMore info on tomato and the various tomato tools an be found [here](https://git.geomar.de/open-source/tomato-toolboxes/tomato-tools-info).\n\n## Installation\n`$TOMATO` = cloned tomato repository\n### Download binaries\nYou can download pre-built binaries of tomato and the tomato-tools [here](https://git.geomar.de/open-source/tomato-toolboxes/tool-binaries).\n### Build executable\n\nYou can use QtCreator (1) or build manually (2)\n\n#### 1 build with QtCreator\n  1. Start QtCreator\n  2. `File -> Open File or Project`\n  3. Choose `$TOMATO/src/CMakeLists.txt`\n  4. Let QtCreator configure everything and build with `Ctrl + B`. On Windows, you may have to change the compiler to MinGW.\n\n#### 2 build manually\n\n$BUILDDIR = whereever you want to build\n  1. Create a build directory\n  2. cd to the build directory\n  3. `cmake /path/to/tomatocode/src`\n  4. `make` (-j4 or more if you are in a hurry)\n\n### Create environment\n  1. Create, in your home folder (usually `/home/$USER` or `C:/Users/$USER`), a folder `tomato`\n  2. Copy $TOMATO/tools.json to $HOMEFOLDER/tomato/tools.json\n\n### Build documentation\n  1. Install doxygen if not available\n  2. in `$TOMATO/src`, run `doxygen Doxyfile`\n\n## Dependencies\n  * CMake 3.5\n  * C++ 17\n  * Qt 5\n\n## Tomato data\nTomato saves it's information on tools, profiles and workflows in [json files](https://www.json.org/json-de.html). Parts of the data can be edited via the tomato UI or directly in the json with every text editor.\n\n### Storage location\n\nThe json files must be in the same folder whose path is saved in a config file at `$HOMEFOLDER/.tomato`. Per default, Tomato will assume this folder to be `$HOMEFOLDER/tomato/`. It can be changed in the config file directly or through the UI with `Help -> Settings`.\n\n### JSON specifications\nThis section shows the structure of the files and explains some of the values.\n\n#### Tools and their parameters\nA tool represents the information on a program that's installed on the computer. This is **general** information and not user specific. It is stored in `tools.json` in structures like the one shown in the following example.\n\n##### Example 1\n\n``` json\n{\n    \"defaultExecutable\": \"Geopredictor\",\n    \"defaultPathLinux\": \"/home/lppetersen/src/build-regionfind-gui-Desktop-Debug/Geopredictor\",\n    \"defaultPathWindows\": \"C:\\Programs\\Geopredictor\\Geopredictor.exe\",\n    \"interactive\": false,\n    \"isTomatoTool\": false,\n    \"name\": \"Geopredictor\",\n    \"toolbox\": 0,\n    \"params\": [\n        {\n            \"description\": \"Sound Velocity Profile in folder with raw mb data files\",\n            \"format\": 2,\n            \"multipleAllowed\": 0,\n            \"optional\": true,\n            \"paramName\": \"-SVP\",\n            \"type\": 5\n        },\n        {\n            \"description\": \"XYZ file to process\",\n            \"format\": 2,\n            \"multipleAllowed\": 0,\n            \"optional\": true,\n            \"paramName\": \"-XYZ\",\n            \"type\": 5\n        }\n    ]\n}\n```\nFor the **tools**:\n\n * `name`: The displayed name of the tool\n * `defaultExecutable` The name of the tool's executable (.exe file on Windows), without a path or file ending (like .exe)\n * `defaultPathWindows` [optional] The path where the executable would be expected on Windows\n * `defaultPathLinux` [optional] The path where the executable would be expected on Linux\n * `params` An array of parameters, see below\n * `toolbox` The toolbox to which the tool belongs (tools will be ordered accordingly in the UI) [This will be replaced at some point and is thus not further specified]\n * `interactive` [optional] Whether the tool runs straight until termination or needs user input\n * `isTomatoTool` [optional] Whether tool is an explicit Tomato Tool which allows to report its current settings back to TOMATO\n\n For the **parameters** in the tools:\n\n * `description`: A brief description of the parameter\n * `format`: The index of the Format in which the parameter is expected, see table below.\n * `multipleAllowed`: Whether the parameter can be passed several arguments, and if yes, how they should be separated.\n * `optional`: Whether the parameter is necessary\n * `paramName`: E.g. `--outputDirectory`, including possible leading `--` or `-`\n * `type`: The type of how the value should be added to the parameter, e.g. with a `=`\n\n\n| Format | Type | Multiple values |\n| --- | --- | --- |\n|  0 STRING <br> 1 PATH_FOLDER <br> 2 PATH_FILE <br> 3 INT <br> 4 BOOL <br> 5 FLOAT <br> 6 NONE |  0 FLAG <br> 1 INPUT <br> 2 INPUT_NO_PARAM <br> 3 VALUE_EQUALS <br> 4 VALUE_COLON <br> 5 VALUE_BLANK | 0 NO_MULTIPLES <br> 1 MULTIPLES_SEMICOLON <br> 2 MULTIPLES_COLON <br> 3 MULTIPLES_COMMA |\n\n#### Profiles\nA profiles holds information for a (1) specific tool, mostly where exactly it is installed and which parameters should be passed with which values. There can be none or many profiles for every tool. If there's no profile, an empty `default` profile will be created on Tomato's launch. They are stored in `profiles.json` or directly in Workflows (see paragraph Workflows). For the structure, see the example below.\n\n##### Example 1\n\n``` json\n{\n  \"localPath\": \"/home/lppetersen/src/tomatools/videosplit/build/VideoSplit\",\n  \"name\": \"video split example workflow\",\n  \"savedParams\": [\n      {\n          \"param\": \"--ffmpegPath\",\n          \"value\": \"ffmpeg\"\n      },\n      {\n          \"param\": \"--inputVideo\",\n          \"value\": \"/home/lppetersen/sampleData/tomato-example-workflow/acmw-testdata/Data/MSM96/MSM96_10-1_OFOS/GMR_CAM-18_Video_Sony-4K/raw/MSM96_10-1_OFOS_GMR-CAM-18_20201015_110918.mp4\"\n      },\n      {\n          \"param\": \"--outputDir\",\n          \"value\": \"/home/lppetersen/sampleData/tomato-example-workflow/acmw-testdata/TomatoIntermediate\"\n      },\n      {\n          \"param\": \"--chunkLengthSecs\",\n          \"value\": \"10\"\n      }\n  ],\n  \"tool\": \"VideoSplit\",\n  \"version\": \"\"\n}\n```\n\n* `localPath`: The path to the executable file on this computer\n* `name`: The name of the profile. Will be used to group profiles to workflows and shown in the UI.\n* `tool`: The tool to which the profiles belongs. This must not be the name but the `defaultExecutable`. A tool with this `defaultExecutable` must exist in `tools.json`.\n* `version`: [optional] Can be useful if there are different versions of a tool installed on the computer.\n* `savedParams`: Both the parameter name and the saved value that's supposed to be passed to the tool.\n\n#### Workflows\nA Workflow is a collection of profiles and metadata. It stores general information on how to use a toolchain to get a specific result with specific starting data. A Workflow usually belongs to a station of a cruise. They are either stored in the `Workflows` folder in the tomato directory or directly in the folders of the station they belong to. They are stored in the structure shown in the shortened examples below.\n\n##### Example 1\n\n``` json\n{\n    \"name\": \"Survey Overview (Geotiff)\",\n    \"nodes\": [\n        {\n            \"profile\": \"video split ex wf\",\n            \"requiredDatasets\": [\n                {\n                    \"datasetTypeId\": 1\n                }\n            ],\n            \"tool\": \"VideoSplit\"\n        },\n        {\n            \"profile\": \"default\",\n            \"requiredDatasets\": [\n                {\n                    \"datasetTypeId\": 1\n                }\n            ],\n            \"tool\": \"Filerenaming\"\n        }\n    ],\n    \"sensors\": [\n    {\n        \"sensorname\": \"$Camera\",\n        \"sensorpath\": \"/home/lppetersen/sampleData/tomato-example-workflow/acmw-testdata/Data/MSM96/MSM96_10-1_OFOS/GMR_CAM-18_Video_Sony-4K\"\n    },\n    {\n        \"sensorname\": \"$NavSensor\",\n        \"sensorpath\": \"/home/lppetersen/sampleData/tomato-example-workflow/acmw-testdata/Data/MSM96/MSM96_10-1_OFOS/MSM_NAV-2_USBL_Sonardyne\"\n    }\n    ],\n    \"template\": \"Image Survey Overview (Geotiff)\"\n} \n```\n * `name` The displayed name of the workflow\n * `nodes` An array of workflow nodes\n * `sensors` An array of sensors resp. their folders\n * `template` The name of the workflow template that the workflow is based on\n\n**Workflow nodes**\n\n * `profile` the name of the profile (must exist in `profiles.json`)\n * `requiredDatasets` the type of the datasets necessry. This will be further extended later, currently it is an array the index of the dataset, see below.\n * `tool`\n\nThese are rather exemplaric than functional in the current state.\n\n |Dataset Type|\n |---|\n |  0 SENSOR_INFORMATION <br> 1 RAW_IMAGE_VIDEO |\n\n##### Example 2\n\n\n``` json\n{\n    \"workflow\": {\n        \"description\": \"The Image Survey Overview workflow turns a video and its raw navigation data into a geotiff file to explore in your favourite GIS software.\\nThe workflow QA/QCs the navigation data, extracts frames from the video, georeferences the individual frames and assembles everything in a single, easy-to-use file.\",\n        \"name\": \"Station86\",\n        \"nodes\": [\n            {\n                \"profile\": {\n                    \"localPath\": \"VideoSplit\",\n                    \"name\": \"Video Split_2021-03-29T18:25:02_Station86\",\n                    \"savedParams\": [\n                        {\n                            \"param\": \"--ffmpegPath\",\n                            \"value\": \"ffmpeg\"\n                        },\n                        {\n                            \"param\": \"--inputVideo\",\n                            \"value\": \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/Station86/cam/raw\"\n                        },\n                        {\n                            \"param\": \"--outputDir\",\n                            \"value\": \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/Station86/cam/raw\"\n                        },\n                        {\n                            \"param\": \"--chunkLengthSecs\",\n                            \"value\": \"1\"\n                        }\n                    ],\n                    \"tool\": \"VideoSplit\",\n                    \"version\": \"\"\n                },\n                \"requiredDatasets\": [\n                ],\n                \"tool\": \"VideoSplit\"\n            },\n            {\n                \"profile\": {\n                    \"localPath\": \"FrameExtract\",\n                    \"name\": \"Frame Extract_2021-03-29T18:25:02_Station86\",\n                    \"savedParams\": [\n                        {\n                            \"param\": \"--targetDirectory\",\n                            \"value\": \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/Station86/cam/processed\"\n                        },\n                        {\n                            \"param\": \"--sourceFiles\",\n                            \"value\": \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/Station86/cam/raw\"\n                        }\n                    ],\n                    \"tool\": \"FrameExtract\",\n                    \"version\": \"\"\n                },\n                \"requiredDatasets\": [\n                ],\n                \"tool\": \"FrameExtract\"\n            }\n        ],\n        \"sensors\": [\n            {\n                \"sensorname\": \"$Camera\",\n                \"sensorpath\": \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/Station86/cam\"\n            },\n            {\n                \"sensorname\": \"$NavSensor\",\n                \"sensorpath\": \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/Station86/nav\"\n            }\n        ],\n        \"template\": \"Image Survey Overview (Geotiff)\"\n    }\n}\n```\nSimilar to example 1, but the profiles are embedded directly and not linked\n\n\n#### Workflow Templates\nWorkflow Templates are the blueprints that the workflows are built on. They contain the information on which sensors are necessary to create a reasonable Workflow and which parameters can be automatically filled based on the sensors' directories. They are stored in `wf_templates.json`.\n\n##### Example 1\n``` json\n{\n  \"workflow_templates\": [\n    {\n            \"name\": \"Image Survey Overview (Geotiff)\",\n            \"description\": \"The Image Survey Overview workflow turns a video and its raw navigation data into a geotiff file to explore in your favourite GIS software.\\nThe workflow QA/QCs the navigation data, extracts frames from the video, georeferences the individual frames and assembles everything in a single, easy-to-use file.\",\n            \"params\": [\n            {\n                \"param\": \"--outputDir\",\n                \"tool\": \"VideoSplit\",\n                \"sensor\": \"$Camera\",\n                \"subfolder\": \"raw\"\n            },\n            {\n                \"param\": \"--inputVideo\",\n                \"tool\": \"VideoSplit\",\n                \"sensor\": \"$Camera\",\n                \"subfolder\": \"raw\"\n            },\n            {\n                \"param\": \"--targetDirectory\",\n                \"tool\": \"FrameExtract\",\n                \"sensor\": \"$Camera\",\n                \"subfolder\": \"processed\"\n            },\n            {\n                \"param\": \"--sourceFiles\",\n                \"tool\": \"FrameExtract\",\n                \"sensor\": \"$Camera\",\n                \"subfolder\": \"raw\"\n            },\n            {\n                \"param\": \"--workingDir\",\n                \"tool\": \"ImageGeoreference\",\n                \"sensor\": \"$Camera\",\n                \"subfolder\": \"processed\"\n            },\n            {\n                \"param\": \"--navigationDataFile\",\n                \"tool\": \"ImageGeoreference\",\n                \"sensor\": \"$NavSensor\",\n                \"subfolder\": \"processed\"\n            },\n            {\n                \"param\": \"--inputImages\",\n                \"tool\": \"ImageSurveyOverview\",\n                \"sensor\": \"$Camera\",\n                \"subfolder\": \"processed\"\n            },\n            {\n                \"param\": \"--outputImage\",\n                \"tool\": \"ImageSurveyOverview\",\n                \"sensor\": \"$Camera\",\n                \"subfolder\": \"data_products\"\n            }\n        ],\n        \"tools\": [\n            \"VideoSplit\",\n            \"FrameExtract\",\n            \"ImageGeoreference\",\n            \"ImageSurveyOverview\"\n        ],\n        \"sensorFolders\": [\n            \"$Camera\",\n            \"$NavSensor\"\n        ]\n    }\n  ]\n}\n```\n  * `params`: A list of default parameters that can be applied to the newly created Profiles when a new Workflow is instantiated from a Workflow Template. On instantiation, the parameters will be built from the folder that's specified e.g. for the `$Camera` sensor and the corresponding subfolder.\n  * `tools`: A list of all tools that are used in this Workflow (Template).\n  * `sensorFolders`: A list of the sensors for which there should be directories. In this case, a folder with Camera data and Navigation data is needed.\n\n#### Projects\nA project is the structure that holds Workflows for the stations of a cruise. Projects are stored in the cruises' folder as `tomato_project.json`.\n\n##### Example 1\n\n``` json\n{\n    \"name\": \"SO1337\",\n    \"projectFolder\": \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/\",\n    \"workflows\": [\n        \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/Station87/Workflow_Image Survey Overview Example.json\",\n        \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/Station86/Workflow_Station86.json\",\n        \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/Station85/Station85.json\"\n    ]\n}\n```\n  * `name`: The name of the cruise.\n  * `projectFolder`: The directory with all the cruise data.\n  * `workflows`: A list of paths where the workflows from the cruise's stations are stored.\n\n#### Recent Projects\nA list in which tomato stores the projects that were opened recently. It's stored in `recent_projects.json` as shown in the following example:\n\n##### Example 1\n``` json\n{\n    \"recentProjects\": [\n        {\n            \"name\": \"TomatoIntermediate\",\n            \"path\": \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/TomatoIntermediate/tomato_project.json\"\n        },\n        {\n            \"name\": \"SO1337\",\n            \"path\": \"/home/lppetersen/src/tomato/build-src-Desktop-Debug/SO1337/tomato_project.json\"\n        }\n    ]\n}\n```\n## License\n\nTomato is released under LGPLv3.\n\n© 2020 GEOMAR Helmholtz Centre for Ocean Research Kiel.\n",
            "project_id": "1684"
        },
        {
            "software_organization": "https://helmholtz.software/software/tomobear",
            "repo_link": "https://github.com/KudryashevLab/TomoBEAR",
            "readme": "# TomoBEAR\n\n[![DOI](https://zenodo.org/badge/675692608.svg)](https://zenodo.org/badge/latestdoi/675692608)\n\n**TomoBEAR** is a configurable and customizable modular pipeline for streamlined processing of cryo-electron tomographic data and preliminary subtomogram averaging (StA) based on best practices in the scientific research group of Dr. Misha Kudryashev[^1][^2].\n\n![TomoBEAR Social Media Logo Image](images/TomoBEAR_gitlogo.png)\n\nImplementation details and benchmarks you can find in our publication:\n</br> Balyschew N, Yushkevich A, Mikirtumov V, Sanchez RM, Sprink T, Kudryashev M. Streamlined Structure Determination by Cryo-Electron Tomography and Subtomogram Averaging using TomoBEAR. *Nat Commun* **14**, 6543 (2023). doi: [10.1038/s41467-023-42085-w](https://www.nature.com/articles/s41467-023-42085-w)\n\n> **Warning**\n> <br/> This software is currently in pre-release state. New features may still appear and refactoring may still take place between all the current and future 0.x.y versions until 1.0.0 will be ready to be released. Binaries are not currently shipped.\n\n## Contents\n\n- [Quick start](#quick-start)\n- [Documentation and licensing](#documentation-and-licensing)\n- [Changes and releases](#changes-and-releases)\n- [Feedback and contribution](#feedback-and-contribution)\n- [Citation](#citation)\n- [Acknowledgements](#acknowledgements)\n- [Contacts](#contacts)\n\n## Quick start\n\n### Video-tutorials\n\nWe have prepared a range of short (8-12 min) video-tutorials explaining setup, usage and example output of the ```TomoBEAR``` to help you get started with ```TomoBEAR``` based on the [ribosome tutorial](https://github.com/KudryashevLab/TomoBEAR/wiki/Tutorials):\n* [Video 1](https://youtu.be/2uizkE616tE): how to get the latest ```TomoBEAR``` version and configure ```TomoBEAR``` and its dependencies;\n* [Video 2](https://youtu.be/N93tfAXp990): description of the project configuration file and the pipeline execution;\n* [Video 3](https://youtu.be/qbkRtMJp0eI): additional configuration file parameters description, ```TomoBEAR```-```IMOD```-```TomoBEAR``` loop for checking tilt series alignment results and fiducials refinement (if needed);\n* [Video 4](https://youtu.be/BP2T_Y7BiDo): checking on further intermediate results (alignment, CTF-correction, reconstruction, template matching).\n\n### Pipeline structure\n\nIn the following picture you can see a flow chart of the main `TomoBEAR` processing steps. As the basic input data you can use raw frame movies or already assembled tilt stacks. More on input formats you [can read here](https://github.com/KudryashevLab/TomoBEAR/wiki/Usage.md#input-data-file-formats).\n\n![Schematic Pipeline Image](images/pipeline_upd.png)\n\nBlue boxes outline the steps that are performed fully automatically, green boxes may require human intervention. The steps encapsulated in the red frame represent the functionality of live data processing. More detailed diagram [is located on wiki](https://github.com/KudryashevLab/TomoBEAR/wiki).\n\n> **Note**\n> <br/> Full MATLAB (source code) version of `TomoBEAR` supports workstations and single interactive nodes with GPUs on the computing clusters at the moment. We are also working towards enabling the support of binaries on the mentioned systems as well as support of both source code and binary versions of the `TomoBEAR` on HPC clusters.\n\n## Documentation and licensing\n\nDetailed information on the installation, setup and usage as well as tutorials and example results can be found in the corresponding [wiki](https://github.com/KudryashevLab/TomoBEAR/wiki).\n\nPlease, see the [LICENSE file](LICENSE.md) for the information about how the content of this repository is licensed.\n\n## Changes and releases\n\nThe [CHANGELOG file](CHANGELOG.md) contains all notable changes corresponding to the different `TomoBEAR` releases, which are available at the [Releases page](https://github.com/KudryashevLab/TomoBEAR/releases).\n\nIf you want to clone a specific ```TomoBEAR``` version, please refer to the **Setup > Get source code and binary > Clone specific version** section on the wiki page [Installation and Setup](https://github.com/KudryashevLab/TomoBEAR/wiki/Installation-and-Setup.md).\n\n## Feedback and contribution\n\nIn case of any questions, issues or suggestions you may interact with us by one of the following ways:\n* open an issue/bug report, feature request or post a question using [Issue Tracker](https://github.com/KudryashevLab/TomoBEAR/issues);\n* write an e-mail to [Misha Kudryashev](mailto:misha.kudryashev@gmail.com) or [Artsemi Yushkevich](mailto:Artsemi.Yushkevich@mdc-berlin.de);\n* start a discussion in [Discussions](https://github.com/KudryashevLab/TomoBEAR/discussions);\n\nIf you wish to contribute, please, fork this repository and make a pull request back with your changes and a short description. For further details on contribution plase read our [contribution guidelines](CONTRIBUTING.md). \n\n## Citation\n\nIf you use `TomoBEAR` or its parts in your research, please **cite both** `TomoBEAR` and **all external software packages** which you have used under `TomoBEAR`.\n\nThe `TomoBEAR` modules dependencies on third-party software are listed on the page [Modules](https://github.com/KudryashevLab/TomoBEAR/wiki/Modules.md) and the list of the corresponding references to cite is located on the page [External Software](https://github.com/KudryashevLab/TomoBEAR/wiki/External-Software.md).\n\n## Acknowledgements\n\nWe are grateful to the following organizations:\n- Buchmann family and [BMLS (Buchmann Institute for Molecular Life Sciences)](https://www.bmls.de) for supporting this project with their starters stipendia for PhD students;\n- [DFG (Deutsche Forschungsgesellschaft)](https://www.dfg.de) for funding the project.\n\nAs well we are grateful to the [structural biology scientific research group of Werner Kühlbrandt](https://www.biophys.mpg.de/2207989/werner_kuehlbrandt) at the [MPIBP (Max Planck Institute of Biophysics)](https://www.biophys.mpg.de) and the [MPIBP](https://www.biophys.mpg.de) in Frankfurt (Hesse), Germany for support.\n\nThe authors thank as well the following people:\n* Dr. Daniel Castano-Diez, Dr. Kendra Leigh and Dr. Christoph Diebolder and Dr. Wolfgang Lugmayr for useful discussions;\n* Uljana Kravchenko, Xiaofeng Chu, Giulia Glorani for testing the developmental versions and providing feedback,\n* Ricardo Sanchez for producing MATLAB version of the [SUSAN framework](https://github.com/rkms86/SUSAN) in order to be compatible with TomoBEAR;\n* Juan Castillo from the Max Planck Institute for Biophysics for the IT support at the Max Planck for Biophysics,\n* the high-performance computing team at the MDC for supporting our operation at the Max-Cluster.\n\nWe would like to acknowledge as well that TomoBEAR contains modified pieces of MATLAB source code of the Dynamo package developed by Dr. Daniel Castaño-Díez et al.: https://www.dynamo-em.org.\n\n## Contacts\n* Prof. Dr. Misha Kudryashev[^1][^2] ([e-mail](mailto:misha.kudryashev@gmail.com?subject=[GitHub]%20TomoBEAR)) - `TomoBEAR` project leader, Principal Investigator;\n\n* Nikita Balyschew[^2] - `TomoBEAR` core version developer, alumni Ph.D. student.\n\n* Artsemi Yushkevich[^1] ([e-mail](mailto:Artsemi.Yushkevich@mdc-berlin.de?subject=[GitHub]%20TomoBEAR)) - `TomoBEAR` contributing developer, Ph.D. student.\n\n* Vasilii Mikirtumov[^1] ([e-mail](mailto:mikivasia@gmail.com?subject=[GitHub]%20TomoBEAR)) - `TomoBEAR` application engineer, Ph.D. student.\n\n\n[^1]: [In situ Structural Biology Group](https://www.mdc-berlin.de/kudryashev) at the [MDCMM (Max Delbrück Center of Molecular Medicine)](https://www.mdc-berlin.de) in Berlin, Germany.\n\n[^2]: [Independent Research Group (Sofja Kovaleskaja)](https://www.biophys.mpg.de/2149775/members) at the Department of Structural Biology at [MPIBP (Max Planck Institute of Biophysics)](https://www.biophys.mpg.de/en) in Frankfurt (Hesse), Germany;\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/treams",
            "repo_link": "https://github.com/tfp-photonics/treams",
            "readme": "![Version](https://img.shields.io/github/v/tag/tfp-photonics/treams)\n[![PyPI](https://img.shields.io/pypi/v/treams)](https://pypi.org/project/treams)\n![License](https://img.shields.io/github/license/tfp-photonics/treams)\n![build](https://github.com/tfp-photonics/treams/actions/workflows/build.yml/badge.svg)\n[![docs](https://github.com/tfp-photonics/treams/actions/workflows/docs.yml/badge.svg)](https://tfp-photonics.github.io/treams)\n![doctests](https://github.com/tfp-photonics/treams/actions/workflows/doctests.yml/badge.svg)\n![tests](https://github.com/tfp-photonics/treams/actions/workflows/tests.yml/badge.svg)\n[![coverage](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Ftfp-photonics%2Ftreams%2Fhtmlcov%2Fendpoint.json)](https://htmlpreview.github.io/?https://github.com/tfp-photonics/treams/blob/htmlcov/index.html)\n\n# treams\n\nThe package `treams` provides a framework to simplify computations of the\nelectromagnetic scattering of waves at finite and at periodic arrangements of particles\nbased on the T-matrix method.\n\n## Installation\n\n### Installation using pip\n\nTo install the package with pip, use\n\n```sh\npip install treams\n```\n\nIf you're using the system wide installed version of python, you might consider the\n``--user`` option.\n\n## Documentation\n\nThe documentation can be found at https://tfp-photonics.github.io/treams.\n\n## Publications\n\nWhen using this code please cite:\n\n[D. Beutel, I. Fernandez-Corbaton, and C. Rockstuhl, treams - A T-matrix scattering code for nanophotonic computations, arXiv (preprint), 2309.03182 (2023).](https://doi.org/10.48550/arXiv.2309.03182)\n\nOther relevant publications are\n* [D. Beutel, I. Fernandez-Corbaton, and C. Rockstuhl, Unified Lattice Sums Accommodating Multiple Sublattices for Solutions of the Helmholtz Equation in Two and Three Dimensions, Phys. Rev. A 107, 013508 (2023).](https://doi.org/10.1103/PhysRevA.107.013508)\n* [D. Beutel, P. Scott, M. Wegener, C. Rockstuhl, and I. Fernandez-Corbaton, Enhancing the Optical Rotation of Chiral Molecules Using Helicity Preserving All-Dielectric Metasurfaces, Appl. Phys. Lett. 118, 221108 (2021).](https://doi.org/10.1063/5.0050411)\n* [D. Beutel, A. Groner, C. Rockstuhl, C. Rockstuhl, and I. Fernandez-Corbaton, Efficient Simulation of Biperiodic, Layered Structures Based on the T-Matrix Method, J. Opt. Soc. Am. B, JOSAB 38, 1782 (2021).](https://doi.org/10.1364/JOSAB.419645)\n\n\n## Features\n\n* [x] T-matrix calculations using a spherical or cylindrical wave basis set\n* [x] Calculations in helicity and parity (TE/TM) basis\n* [x] Scattering from clusters of particles\n* [x] Scattering from particles and clusters arranged in 3d-, 2d-, and 1d-lattices\n* [x] Calculation of light propagation in stratified media\n* [x] Band calculation in crystal structures\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/tridec-cloud",
            "repo_link": "https://github.com/locationtech-archived/geoperil",
            "readme": "<!--\nGeoPeril - A platform for the computation and web-mapping of hazard\nspecific geospatial data, as well as for serving functionality to handle,\nshare, and communicate threat specific information in a collaborative\nenvironment.\n\nCopyright (C) 2021 GFZ German Research Centre for Geosciences\n\nSPDX-License-Identifier: Apache-2.0\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  http://apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the Licence is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the Licence for the specific language governing permissions and\nlimitations under the Licence.\n\nContributors:\n  Johannes Spazier (GFZ)\n  Sven Reissland (GFZ)\n  Martin Hammitzsch (GFZ)\n  Matthias Rüster (GFZ)\n  Hannes Fuchs (GFZ)\n-->\n\n# GeoPeril\n\nThis project is a prototype implementation of an early warning system for\ntsunamis, including:\n\n* harvesting of earthquake events from catalogs or APIs\n* automatic execution of simulations for events with given thresholds\n* remote execution of simulations with EasyWave as the simulation processing backend\n* queuing of simulation processes with support for multiple remote processing servers\n* individual accounts with different permission levels\n* modifying earthquake parameters or creating fictional earthquakes to simulate a scenario\n\n## Development environment\n\nTo start up a development environment use the `docker-compose-dev.yml` file:\n\n```shell\ncd docker\ndocker-compose -f docker-compose-dev.yml up --build\n```\n\nYou can then visit `http://localhost:8080` to see the frontend.\nDefault login credentials for an administrative account are `admin`/`admin` and\nfor a less privileged user `test`/`test`.\n\nChanges for the source code of the frontend component are then hot reloaded and\nwill be rebuild on the fly.\n\nData for world seas were downloaded from:\nhttps://catalog.data.gov/dataset/world-water-body-limits-detailed-2017mar30\n\n## License\n\nCopyright © 2021 Helmholtz Centre Potsdam - GFZ German Research Centre for Geosciences, Germany (https://www.gfz-potsdam.de)\n\nThis work is licensed under the following license(s):\n* Software files are licensed under [Apache-2.0](LICENSES/Apache-2.0.txt)\n* Everything else is licensed under [Apache-2.0](LICENSES/Apache-2.0.txt)\n\nPlease see the individual files for more accurate information.\n\n> **Hint:** We provided the copyright and license information in accordance to the [REUSE Specification 3.0](https://reuse.software/spec/).\n\n## FAQ\n\n### apt error: not signed on build\n\nThe following error may appear:\n\n```bash\nW: GPG error: http://security.debian.org/debian-security buster/updates InRelease: At least one invalid signature was encountered.\nE: The repository 'http://security.debian.org/debian-security buster/updates InRelease' is not signed.\nW: GPG error: http://deb.debian.org/debian buster InRelease: At least one invalid signature was encountered.\nE: The repository 'http://deb.debian.org/debian buster InRelease' is not signed.\nW: GPG error: http://deb.debian.org/debian buster-updates InRelease: At least one invalid signature was encountered.\nE: The repository 'http://deb.debian.org/debian buster-updates InRelease' is not signed.\nERROR: Service '...' failed to build : ... \n```\n\nThis could happen if you have an older base image cached. To solve this remove\nthe local images with: `docker image prune -a`\n\n**NOTE:** This deletes all images on your machine. Save any image you can not\ndownload from a registry!\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/trimmomatic",
            "repo_link": "https://github.com/usadellab/Trimmomatic",
            "readme": "# Trimmomatic\n# Note \nwhile the software is licensed under the GPL, the adapter sequences are *not* included in the GPL part, but owned by and used with permission of Illumina. Oligonucleotide sequences © 2023 Illumina, Inc. All rights reserved.\n# Quick start\n## Installation\nThe easiest option is to download a binary release zip, and unpack it somewhere convenient. You'll need to modify the example command lines below to reference the trimmomatic JAR file and the location of the adapter fasta files. \n\n## Build from Source\nThe current version can be built by cloning the repository, change into the top level directory and build using 'ant'.\n\nTo build from a source release, download the source zip or tar.gz, unpack it, change into top level directory (Trimmomatic-x.xx), and build using 'ant'. \n\n## Paired End:\n\nWith most new data sets you can use gentle quality trimming and adapter clipping.\n\nYou often don't need leading and traling clipping. Also in general setting the keepBothReads to True can be useful when working with paired end data, you will keep even redunfant information but this likely makes your pipelines more manageable. Note the additional :2 in front of the True (for keepBothReads) - this is the minimum adapter length in palindrome mode, you can even set this to 1. (Default is a very conservative 8)\n\nIf you have questions please don't hesitate to contact us, this is not necessarily one size fits all. (e.g. RNAseq expression analysis vs DNA assembly).\n\njava -jar trimmomatic-0.39.jar PE input_forward.fq.gz input_reverse.fq.gz output_forward_paired.fq.gz output_forward_unpaired.fq.gz output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:True LEADING:3 TRAILING:3 MINLEN:36\n \n\nfor reference only (less sensitive for adapters)\n\njava -jar trimmomatic-0.35.jar PE -phred33 input_forward.fq.gz input_reverse.fq.gz output_forward_paired.fq.gz output_forward_unpaired.fq.gz output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\n\nThis will perform the following:\n\n* Remove adapters (ILLUMINACLIP:TruSeq3-PE.fa:2:30:10)\n* Remove leading low quality or N bases (below quality 3) (LEADING:3)\n* Remove trailing low quality or N bases (below quality 3) (TRAILING:3)\n* Scan the read with a 4-base wide sliding window, cutting when the average quality per base drops below 15 (SLIDINGWINDOW:4:15)\n* Drop reads below the 36 bases long (MINLEN:36)\n\n## Single End:\n\njava -jar trimmomatic-0.35.jar SE -phred33 input.fq.gz output.fq.gz ILLUMINACLIP:TruSeq3-SE:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\n\nThis will perform the same steps, using the single-ended adapter file\n\n \n# Description\n\nTrimmomatic performs a variety of useful trimming tasks for illumina paired-end and single ended data.The selection of trimming steps and their associated parameters are supplied on the command line.\n\nThe current trimming steps are:\n\n* ILLUMINACLIP: Cut adapter and other illumina-specific sequences from the read.\n* SLIDINGWINDOW: Perform a sliding window trimming, cutting once the average quality within the window falls below a threshold.\n* LEADING: Cut bases off the start of a read, if below a threshold quality\n* TRAILING: Cut bases off the end of a read, if below a threshold quality\n* CROP: Cut the read to a specified length\n* HEADCROP: Cut the specified number of bases from the start of the read\n* MINLEN: Drop the read if it is below a specified length\n* TOPHRED33: Convert quality scores to Phred-33\n* TOPHRED64: Convert quality scores to Phred-64\n\nIt works with FASTQ (using phred + 33 or phred + 64 quality scores, depending on the Illumina pipeline used), either uncompressed or gzipp'ed FASTQ. Use of gzip format is determined based on the .gz extension.\n\nFor single-ended data, one input and one output file are specified, plus the processing steps. For paired-end data, two input files are specified, and 4 output files, 2 for the 'paired' output where both reads survived the processing, and 2 for corresponding 'unpaired' output where a read survived, but the partner read did not.\n \n# Running Trimmomatic\n\nSince version 0.27, trimmomatic can be executed using -jar. The 'old' method, using the explicit class, continues to work.\nPaired End Mode:\n\njava -jar <path to trimmomatic.jar> PE [-threads <threads] [-phred33 | -phred64] [-trimlog <logFile>] <input 1> <input 2> <paired output 1> <unpaired output 1> <paired output 2> <unpaired output 2> <step 1> ...\n\nor\n\njava -classpath <path to trimmomatic jar> org.usadellab.trimmomatic.TrimmomaticPE [-threads <threads>] [-phred33 | -phred64] [-trimlog <logFile>] <input 1> <input 2> <paired output 1> <unpaired output 1> <paired output 2> <unpaired output 2> <step 1> ...\nSingle End Mode:\n\njava -jar <path to trimmomatic jar> SE [-threads <threads>] [-phred33 | -phred64] [-trimlog <logFile>] <input> <output> <step 1> ...\n\nor\n\njava -classpath <path to trimmomatic jar> org.usadellab.trimmomatic.TrimmomaticSE [-threads <threads>] [-phred33 | -phred64] [-trimlog <logFile>] <input> <output> <step 1> ...\n\nIf no quality score is specified, phred-64 is the default. This will be changed to an 'autodetected' quality score in a future version.\n\nSpecifying a trimlog file creates a log of all read trimmings, indicating the following details:\n\n* the read name\n* the surviving sequence length\n* the location of the first surviving base, aka. the amount trimmed from the start\n* the location of the last surviving base in the original read\n* the amount trimmed from the end\n\nMultiple steps can be specified as required, by using additional arguments at the end.\n\nMost steps take one or more settings, delimited by ':' (a colon)\n\nStep options:\n\n* ILLUMINACLIP:&lt;fastaWithAdaptersEtc>:&lt;seed mismatches>:&lt;palindrome clip threshold>:&lt;simple clip threshold>\n    * fastaWithAdaptersEtc: specifies the path to a fasta file containing all the adapters, PCR sequences etc. The naming of the various sequences within this file determines how they are used. See below.\n    * seedMismatches: specifies the maximum mismatch count which will still allow a full match to be performed\n    * palindromeClipThreshold: specifies how accurate the match between the two 'adapter ligated' reads must be for PE palindrome read alignment.\n    * simpleClipThreshold: specifies how accurate the match between any adapter etc. sequence must be against a read.\n \n* SLIDINGWINDOW:&lt;windowSize>:&lt;requiredQuality>\n    * windowSize: specifies the number of bases to average across\n    * requiredQuality: specifies the average quality required.\n\n* LEADING:&lt;quality>\n    * quality: Specifies the minimum quality required to keep a base.\n\n* TRAILING:&lt;quality>\n    * quality: Specifies the minimum quality required to keep a base.\n\n* CROP:&lt;length>\n    * length: The number of bases to keep, from the start of the read.\n\n*   HEADCROP:&lt;length>\n    * length: The number of bases to remove from the start of the read.\n\n* MINLEN:&lt;length>\n    * length: Specifies the minimum length of reads to be kept.\n\n# Trimming Order\n\nTrimming occurs in the order which the steps are specified on the command line. It is recommended in most cases that adapter clipping, if required, is done as early as possible.\n \n# The Adapter Fasta\n\nIllumina adapter and other technical sequences are copyrighted by Illumina,but we have been granted permission to distribute them with Trimmomatic. Suggested adapter sequences are provided for TruSeq2 (as used in GAII machines) and TruSeq3 (as used by HiSeq and MiSeq machines), for both single-end and paired-end mode. These sequences have not been extensively tested, and depending on specific issues which may occur in library preparation, other sequences may work better for a given dataset.\n\nTo make a custom version of fasta, you must first understand how it will be used. Trimmomatic uses two strategies for adapter trimming: Palindrome and Simple\n\nWith 'simple' trimming, each adapter sequence is tested against the reads, and if a sufficiently accurate match is detected, the read is clipped appropriately.\n\n'Palindrome' trimming is specifically designed for the case of 'reading through' a short fragment into the adapter sequence on the other end. In this approach, the appropriate adapter sequences are 'in silico ligated' onto the start of the reads, and the combined adapter+read sequences, forward and reverse are aligned. If they align in a manner which indicates 'read-through', the forward read is clipped and the reverse read dropped (since it contains no new data).\n\nNaming of the sequences indicates how they should be used. For 'Palindrome' clipping, the sequence names should both start with 'Prefix', and end in '/1' for the forward adapter and '/2' for the reverse adapter. All other sequences are checked using 'simple' mode. Sequences with names ending in '/1' or '/2' will be checked only against the forward or reverse read. Sequences not ending in '/1' or '/2' will be checked against both the forward and reverse read. If you want to check for the reverse-complement of a specific sequence, you need to specifically include the reverse-complemented form of the sequence as well, with another name.\n\nThe thresholds used are a simplified log-likelihood approach. Each matching base adds just over 0.6, while each mismatch reduces the alignment score by Q/10. Therefore, a perfect match of a 12 base sequence will score just over 7, while 25 bases are needed to score 15. As such we recommend values between 7 - 15 for this parameter. For palindromic matches, a longer alignment is possible - therefore this threshold can be higher, in the range of 30. The 'seed mismatch' parameter is used to make alignments more efficient, specifying the maximum base mismatch count in the 'seed' (16 bases). Typical values here are 1 or 2.\n \n"
        },
        {
            "software_organization": "https://helmholtz.software/software/trixiparticlesjl",
            "repo_link": "https://github.com/trixi-framework/TrixiParticles.jl",
            "readme": "# TrixiParticles.jl\n\n[![Docs-stable](https://img.shields.io/badge/docs-stable-blue.svg)](https://trixi-framework.github.io/TrixiParticles.jl/stable)\n[![Docs-dev](https://img.shields.io/badge/docs-dev-blue.svg)](https://trixi-framework.github.io/TrixiParticles.jl/dev)\n[![Slack](https://img.shields.io/badge/chat-slack-e01e5a)](https://join.slack.com/t/trixi-framework/shared_invite/zt-sgkc6ppw-6OXJqZAD5SPjBYqLd8MU~g)\n[![Youtube](https://img.shields.io/youtube/channel/views/UCpd92vU2HjjTPup-AIN0pkg?style=social)](https://www.youtube.com/@trixi-framework)\n[![CI](https://github.com/trixi-framework/TrixiParticles.jl/actions/workflows/ci.yml/badge.svg)](https://github.com/trixi-framework/TrixiParticles.jl/actions/workflows/ci.yml)\n[![codecov](https://codecov.io/github/trixi-framework/TrixiParticles.jl/branch/main/graph/badge.svg?token=RDZXYbij0b)](https://codecov.io/github/trixi-framework/TrixiParticles.jl)\n[![SciML Code Style](https://img.shields.io/static/v1?label=code%20style&message=SciML&color=9558b2&labelColor=389826)](https://github.com/SciML/SciMLStyle)\n[![License: MIT](https://img.shields.io/badge/License-MIT-success.svg)](https://opensource.org/licenses/MIT)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10797541.svg)](https://zenodo.org/doi/10.5281/zenodo.10797541)\n\n<p align=\"center\">\n  <img src=\"https://github.com/trixi-framework/TrixiParticles.jl/assets/10238714/479ff0c6-3c65-44fe-b3e0-2ed653e7e3a5\" alt=\"TrixiP_logo\" width=\"40%\"/>\n</p>\n\n**TrixiParticles.jl** is a high-performance numerical simulation framework for particle-based methods, focused on the simulation of complex multiphysics problems, and written in [Julia](https://julialang.org).\n\nTrixiParticles.jl focuses on the following use cases:\n- Accurate and efficient physics-based modelling of complex multiphysics problems.\n- Development of new particle-based methods and models.\n- Easy setup of accessible simulations for educational purposes, including student projects, coursework, and thesis work.\n\nIt offers intuitive configuration, robust pre- and post-processing, and vendor-agnostic GPU-support based on the Julia package [KernelAbstractions.jl](https://github.com/JuliaGPU/KernelAbstractions.jl). \n\n[![YouTube](https://github.com/user-attachments/assets/dc2be627-a799-4bfd-9226-2077f737c4b0)](https://www.youtube.com/watch?v=V7FWl4YumcA&t=4667s)\n\n## Features\n- Incompressible Navier-Stokes\n  - Methods: Weakly Compressible Smoothed Particle Hydrodynamics (WCSPH), Entropically Damped Artificial Compressibility (EDAC)\n  - Models: Surface Tension, Open Boundaries\n- Solid-body mechanics\n  - Methods:  Total Lagrangian SPH (TLSPH), Discrete Element Method (DEM)\n- Fluid-Structure Interaction\n- Particle sampling of complex geometries from `.stl` and `.asc` files.\n- Output formats:\n  - VTK\n\n## Examples\nWe provide several example simulation setups in the `examples` folder (which can be accessed from Julia via `examples_dir()`).\n\n<table align=\"center\" border=\"0\">\n  <tr>\n  </tr>\n  <tr>\n    <td align=\"center\">\n      <img src=\"https://github.com/trixi-framework/TrixiParticles.jl/assets/10238714/683e9363-5705-49cc-9a5c-3b47d73ea4b8\" style=\"width: 80% !important;\"/><br><figcaption>2D Dam Break</figcaption>\n    </td>\n    <td align=\"center\">\n      <img src=\"https://github.com/trixi-framework/TrixiParticles.jl/assets/10238714/c10faddf-0400-47c9-b225-f5d286a8ecb8\" style=\"width: 80% !important;\"/><br><figcaption>Moving Wall</figcaption>\n    </td>\n  </tr>\n  <tr>\n  </tr>\n  <tr>\n    <td align=\"center\">\n      <img src=\"https://github.com/trixi-framework/TrixiParticles.jl/assets/10238714/e05ace63-e330-441a-a391-eda3d2764074\" style=\"width: 80% !important;\"/><br><figcaption>Oscillating Beam</figcaption>\n    </td>\n    <td align=\"center\">\n      <img src=\"https://github.com/trixi-framework/TrixiParticles.jl/assets/10238714/ada0d554-e0ba-44ed-923d-2b77ef252258\" style=\"width: 80% !important;\"/><br><figcaption>Dam Break with Elastic Plate</figcaption>\n    </td>\n  </tr>\n</table>\n\n\n## Installation\nIf you have not yet installed Julia, please [follow the instructions for your\noperating system](https://julialang.org/downloads/platform/). TrixiParticles.jl works\nwith Julia v1.9 and newer. We recommend using the latest stable release of Julia.\n\n### For users\nTrixiParticles.jl is a registered Julia package.\nYou can install TrixiParticles.jl,\n[OrdinaryDiffEq.jl](https://github.com/SciML/OrdinaryDiffEq.jl) (used for time integration)\nand [Plots.jl](https://github.com/JuliaPlots/Plots.jl) by executing the following commands\nin the Julia REPL:\n```julia\njulia> using Pkg\n\njulia> Pkg.add([\"TrixiParticles\", \"OrdinaryDiffEq\", \"Plots\"])\n```\n\n### For developers\nIf you plan on editing TrixiParticles.jl itself, you can download TrixiParticles.jl\nto a local folder and use the code from the cloned directory:\n```bash\ngit clone git@github.com:trixi-framework/TrixiParticles.jl.git\ncd TrixiParticles.jl\nmkdir run\njulia --project=run -e 'using Pkg; Pkg.develop(PackageSpec(path=\".\"))' # Add TrixiParticles.jl to `run` project\njulia --project=run -e 'using Pkg; Pkg.add([\"OrdinaryDiffEq\", \"Plots\"])' # Add additional packages\n```\n\nIf you installed TrixiParticles.jl this way, you always have to start Julia with the\n`--project` flag set to your `run` directory, e.g.,\n```bash\njulia --project=run\n```\nfrom the TrixiParticles.jl root directory.\nFurther details can be found in the [documentation](https://trixi-framework.github.io/TrixiParticles.jl/stable).\n\n## Usage\n\nIn the Julia REPL, first load the package TrixiParticles.jl.\n```jldoctest getting_started\njulia> using TrixiParticles\n```\n\nThen start the simulation by executing\n```jldoctest getting_started; filter = r\".*\"s\njulia> trixi_include(joinpath(examples_dir(), \"fluid\", \"hydrostatic_water_column_2d.jl\"))\n```\n\nThis will open a new window with a 2D visualization of the final solution:\n<img src=\"https://github.com/trixi-framework/TrixiParticles.jl/assets/44124897/95821154-577d-4323-ba57-16ef02ea24e0\" width=\"400\">\n\nFurther details can be found in the [documentation](https://trixi-framework.github.io/TrixiParticles.jl/stable).\n\n## Documentation\n\nYou can find the documentation for the latest release\n[here](https://trixi-framework.github.io/TrixiParticles.jl/stable).\n\n## Publications\n\n## Cite Us\n\nIf you use TrixiParticles.jl in your own research or write a paper using results obtained\nwith the help of TrixiParticles.jl, please cite it as\n```bibtex\n@misc{trixiparticles,\n  title={{T}rixi{P}articles.jl: {P}article-based multiphysics simulations in {J}ulia},\n  author={Erik Faulhaber and Niklas Neher and Sven Berger and\n          Michael Schlottke-Lakemper and Gregor Gassner},\n  year={2024},\n  howpublished={\\url{https://github.com/trixi-framework/TrixiParticles.jl}},\n  doi={10.5281/zenodo.10797541}\n}\n```\n\n## Authors\nErik Faulhaber (University of Cologne) and Niklas Neher (HLRS) implemented the foundations\nfor TrixiParticles.jl and are principal developers along with Sven Berger (hereon).\nThe project was started by Michael Schlottke-Lakemper (University of Augsburg)\nand Gregor Gassner (University of Cologne), who provide scientific direction and technical advice.\nThe full list of contributors can be found in [AUTHORS.md](AUTHORS.md).\n\n## License and contributing\nTrixiParticles.jl is licensed under the MIT license (see [LICENSE.md](LICENSE.md)). Since TrixiParticles.jl is\nan open-source project, we are very happy to accept contributions from the\ncommunity. Please refer to [CONTRIBUTING.md](CONTRIBUTING.md) for more details.\nNote that we strive to be a friendly, inclusive open-source community and ask all members\nof our community to adhere to our [`CODE_OF_CONDUCT.md`](CODE_OF_CONDUCT.md).\nTo get in touch with the developers,\n[join us on Slack](https://join.slack.com/t/trixi-framework/shared_invite/zt-sgkc6ppw-6OXJqZAD5SPjBYqLd8MU~g)\nor [create an issue](https://github.com/trixi-framework/TrixiParticles.jl/issues/new).\n\n## Acknowledgments\n<p align=\"center\">\n  <img align=\"middle\" src=\"https://github.com/trixi-framework/TrixiParticles.jl/assets/44124897/05132bf1-180f-4228-b30a-37dfb6e36ed5\" width=20%/>&nbsp;&nbsp;&nbsp;\n  <img align=\"middle\" src=\"https://github.com/trixi-framework/TrixiParticles.jl/assets/44124897/ae2a91d1-7c10-4e0f-8b92-6ed1c43ddc28\" width=20%/>&nbsp;&nbsp;&nbsp;\n</p>\n\nThe project has benefited from funding from [hereon](https://www.hereon.de/) and [HiRSE](https://www.helmholtz-hirse.de/).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/tsmp",
            "repo_link": "https://github.com/HPSCTerrSys/TSMP",
            "readme": "\n# Terrestrial System Modeling Platform - TSMP\n\n[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/HPSCTerrSys/TSMP/RenderMasterSphinxDocumentation.yml?label=documentation)](https://hpscterrsys.github.io/TSMP/index.html)\n[![Latest release](https://img.shields.io/github/v/tag/HPSCTerrSys/TSMP.svg?color=brightgreen&label=latest%20release&sort=semver)](https://github.com/HPSCTerrSys/TSMP/tags) \n[![GitHub last commit](https://img.shields.io/github/last-commit/HPSCTerrSys/TSMP)](https://github.com/HPSCTerrSys/TSMP/commits/master)\n[![Twitter Follow](https://img.shields.io/twitter/follow/HPSCTerrSys?style=social)](https://twitter.com/HPSCTerrSys)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.8283715.svg)](https://doi.org/10.5281/zenodo.8283715)\n\n\n## Introduction \n\nThe Terrestrial System Modeling Platform (TSMP or TerrSysMP, https://www.terrsysmp.org) is an open source scale-consistent, highly modular, massively parallel regional Earth system model. TSMP essentially consists of an interface which couples dedicated versions of the Consortium for Small-scale Modeling ([COSMO](http://www.cosmo-model.org)) or ICOsahedral Nonhydrostatic ([ICON](https://code.mpimet.mpg.de/projects/iconpublic)) atmospheric model in NWP or climate mode, the Community Land Model ([CLM](http://www.cesm.ucar.edu/models/clm/)), and the hydrologic model [ParFlow](https://www.parflow.org) through the [OASIS3](https://oasis.cerfacs.fr/en/)-[MCT](https://www.mcs.anl.gov/research/projects/mct/) coupler.\n\nTSMP allows for a physically-based representation of transport processes of mass, energy and momentum and interactions between the different compartments of the geo-ecosystem across scales, explicitly reproducing feedbacks in the hydrological cycle from the groundwater into the atmosphere.\n\nTSMP is extensively used for idealized and real data process and sensitivity studies in water cycle research, for climate change simulations, data assimilation studies including reanalyses, as well as experimental real time forecasting and monitoring simulations, ranging from individual catchments to continental model domains. TSMP runs on notebooks as well on latest supercomputers using a range of compilers.\n\nTSMP development has been driven by groups within the [Center for High-Performance Scientific Computing in Terrestrial Systems](http://www.hpsc-terrsys.de) (HPSC-TerrSys), as part of the [Geoverbund ABC/J](http://www.geoverbund-abcj.de/geoverbund/EN/Home/home_node.html), the geoscientific network of the University of Cologne, Bonn University, RWTH Aachen University, and the Research Centre Jülich. The current team is anchored in Jülich and Bonn in Germany.\n\n**Visit**\n\n**https://www.terrsysmp.org**\n\n**for information on the features of TSMP, ongoing developments, citation, usage examples, links to documentation, the team, contact information and publications.**\n\n## Quick Start on Linux\n\nPlease see [getting started section](https://hpscterrsys.github.io/TSMP/content/gettingstarted.html) for guided steps on how the model can be setup and configured for *one* specific experiment, which we use as one of the default test cases. To get an overview on possible TSMP applications refer to the [TSMP website](https://www.terrsysmp.org) and the [TSMP documention](https://hpscterrsys.github.io/TSMP/index.html).\n\n## TSMP version history\nThe model components used in TSMP are OASIS3-MCT v2, COSMO v5.01, CLM v3.5, ParFlow 3.2 for TSMP versions v1.2.1, v1.2.2 and v1.2.3, ParFlow 3.9 for version v1.3.3 and ParFlow 3.12 for version v1.4.0. TSMP supports ParFlow 3.7 onwards from version v1.3.3 onward. \n\n## Citing TSMP\n\nIf you use TSMP in a publication, please cite the these papers that describe the model's basic functionalities:\n\n* Shrestha, P., Sulis, M., Masbou, M., Kollet, S., and Simmer, C. (2014). A Scale-Consistent Terrestrial Systems Modeling Platform Based on COSMO, CLM, and ParFlow. Monthly Weather Review, 142(9), 3466–3483. doi:[10.1175/MWR-D-14-00029.1](https://dx.doi.org/10.1175/MWR-D-14-00029.1).\n* Gasper, F., Goergen, K., Kollet, S., Shrestha, P., Sulis, M., Rihani, J., and Geimer, M. (2014). Implementation and scaling of the fully coupled Terrestrial Systems Modeling Platform (TerrSysMP) in a massively parallel supercomputing environment &ndash; a case study on JUQUEEN (IBM Blue Gene/Q). Geoscientific Model Development, 7(5), 2531-2543. doi:[10.5194/gmd-7-2531-2014](https://dx.doi.org/10.5194/gmd-7-2531-2014).\n\n## License\nTSMP is open source software and is licensed under the [MIT-License](https://github.com/HPSCTerrSys/TSMP/blob/master/LICENSE).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ukis-csmask",
            "repo_link": "https://github.com/dlr-eoc/ukis-csmask",
            "readme": "# [![UKIS](img/ukis-logo.png)](https://www.dlr.de/eoc/en/desktopdefault.aspx/tabid-5413/10560_read-21914/) ukis-csmask\n\n![ukis-csmask](https://github.com/dlr-eoc/ukis-csmask/workflows/ukis-csmask/badge.svg)\n[![codecov](https://codecov.io/gh/dlr-eoc/ukis-csmask/branch/main/graph/badge.svg)](https://codecov.io/gh/dlr-eoc/ukis-csmask)\n![Upload Python Package](https://github.com/dlr-eoc/ukis-csmask/workflows/Upload%20Python%20Package/badge.svg)\n[![PyPI version](https://img.shields.io/pypi/v/ukis-csmask)](https://pypi.python.org/pypi/ukis-csmask/)\n[![GitHub license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)\n[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://black.readthedocs.io/en/stable/)\n[![DOI](https://zenodo.org/badge/328616234.svg)](https://zenodo.org/badge/latestdoi/328616234)\n\nUKIS Cloud Shadow MASK (ukis-csmask) package masks clouds and cloud shadows in Sentinel-2, Landsat-9, Landsat-8, Landsat-7 and Landsat-5 images. Masking is performed with a pre-trained convolution neural network. It is fast and works directly on Level-1C data (no atmospheric correction required). Images just need to be in Top Of Atmosphere (TOA) reflectance and include at least the \"blue\", \"green\", \"red\" and \"nir\" spectral bands. Best performance (in terms of accuracy and speed) is achieved when images also include \"swir16\" and \"swir22\" spectral bands and are resampled to approximately 30 m spatial resolution.\n\nThis [publication](https://doi.org/10.1016/j.rse.2019.05.022) provides further insight into the underlying algorithm and compares it to the widely used [Fmask](http://www.pythonfmask.org/en/latest/) algorithm across a heterogeneous test dataset.\n\n> Wieland, M.; Li, Y.; Martinis, S. Multi-sensor cloud and cloud shadow segmentation with a convolutional\nneural network. *Remote Sensing of Environment*, 2019, 230, 1-12. [https://doi.org/10.1016/j.rse.2019.05.022](https://doi.org/10.1016/j.rse.2019.05.022)\n\nThis [publication](https://doi.org/10.5194/isprs-archives-XLIII-B3-2022-217-2022) introduces the Python package, performs additional evaluation on recent cloud and cloud shadow benchmark datasets and tests the applicability of ukis-csmask on Landsat-9 imagery.\n\n> Wieland, M.; Fichtner, F.; Martinis, S. UKIS-CSMASK: A Python package for multi-sensor cloud and cloud shadow segmentation. *Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.*, 2022, XLIII-B3-2022, 217–222. [https://doi.org/10.5194/isprs-archives-XLIII-B3-2022-217-2022](https://doi.org/10.5194/isprs-archives-XLIII-B3-2022-217-2022)\n\nIf you use ukis-csmask in your work, please consider citing one of the above publications.\n\n![Examples](img/examples.png)\n\n## Example (Sentinel 2)\nHere's an example on how to compute a cloud and cloud shadow mask from an image. Please note that here we use [ukis-pysat](https://github.com/dlr-eoc/ukis-pysat) for convencience image handling, but you can also work directly with [numpy](https://numpy.org/) arrays.\n\n````python\nfrom ukis_csmask.mask import CSmask\nfrom ukis_pysat.raster import Image, Platform\n\n# read Level-1C image from file, convert digital numbers to TOA reflectance\n# and make sure resolution is 30 m to get best performance\nimg = Image(data=\"sentinel2.tif\", dimorder=\"last\")\nimg.dn2toa(platform=Platform.Sentinel2)\nimg.warp(\n    resampling_method=0,\n    resolution=30,\n    dst_crs=img.dataset.crs\n)\n\n# compute cloud and cloud shadow mask\n# NOTE: band_order must match the order of bands in the input image. it does not have to be in this explicit order.\n# make sure to use these six spectral bands to get best performance\ncsmask = CSmask(\n    img=img.arr,\n    band_order=[\"blue\", \"green\", \"red\", \"nir\", \"swir16\", \"swir22\"],\n    nodata_value=0,\n)\n\n# access cloud and cloud shadow mask\ncsmask_csm = csmask.csm\n\n# access valid mask\ncsmask_valid = csmask.valid\n\n# convert results to UKIS-pysat Image\ncsmask_csm = Image(csmask.csm, transform=img.dataset.transform, crs=img.dataset.crs, dimorder=\"last\")\ncsmask_valid = Image(csmask.valid, transform=img.dataset.transform, crs=img.dataset.crs, dimorder=\"last\")\n\n# write results back to file\ncsmask_csm.write_to_file(\"sentinel2_csm.tif\", dtype=\"uint8\", compress=\"PACKBITS\")\ncsmask_valid.write_to_file(\"sentinel2_valid.tif\", dtype=\"uint8\", compress=\"PACKBITS\", kwargs={\"nbits\":2})\n````\n\n## Example (Landsat 8)\nHere's a similar example based on Landsat 8.\n\n````python\nimport rasterio\nimport numpy as np\nfrom ukis_csmask.mask import CSmask\nfrom ukis_pysat.raster import Image, Platform\n\n# set Landsat 8 source path and prefix (example)\ndata_path = \"/your_data_path/\"\nL8_file_prefix = \"LC08_L1TP_191015_20210428_20210507_02_T1\"\n\ndata_path = data_path+L8_file_prefix+\"/\"\nmtl_file  = data_path+L8_file_prefix+\"_MTL.txt\"\n\n# stack [B2:'Blue', B3:'Green', B4:'Red', B5:'NIR', B6:'SWIR1', B7:'SWIR2'] as numpy array\nL8_band_files  = [data_path+L8_file_prefix+'_B'+ x + '.TIF' for x in [str(x+2) for x in range(6)]]\n\n# >> adopted from https://gis.stackexchange.com/questions/223910/using-rasterio-or-gdal-to-stack-multiple-bands-without-using-subprocess-commands\n# read metadata of first file\nwith rasterio.open(L8_band_files[0]) as src0:\n    meta = src0.meta\n# update meta to reflect the number of layers\nmeta.update(count = len(L8_band_files))\n# read each layer and append it to numpy array\nL8_bands = []\nfor id, layer in enumerate(L8_band_files, start=1):\n    with rasterio.open(layer) as src1:\n        L8_bands.append(src1.read(1))\nL8_bands = np.stack(L8_bands,axis=2)\n# <<\n\nimg = Image(data=L8_bands, crs = meta['crs'], transform = meta['transform'], dimorder=\"last\")\n\nimg.dn2toa(\n        platform=Platform.Landsat8,\n        mtl_file=mtl_file,\n        wavelengths = [\"blue\", \"green\", \"red\", \"nir\", \"swir16\", \"swir22\"]\n)\n# >> proceed by analogy with Sentinel 2 example\n````\n\n## Installation\nThe easiest way to install ukis-csmask is through pip. To install ukis-csmask with [default CPU provider](https://onnxruntime.ai/docs/execution-providers/) run the following.\n\n```shell\npip install ukis-csmask[cpu]\n```\n\nTo install ukis-csmask with [OpenVino support](https://onnxruntime.ai/docs/execution-providers/OpenVINO-ExecutionProvider.html) for enhanced CPU inference run the following instead.\n\n```shell\npip install ukis-csmask[openvino]\n```\n\nTo install ukis-csmask with [GPU support](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html) run the following instead. This requires that you have a GPU with CUDA runtime libraries installed on the system.\n\n```shell\npip install ukis-csmask[gpu]\n```\n\nukis-csmask depends on [onnxruntime](https://onnxruntime.ai/). For a list of additional dependencies check the [requirements](https://github.com/dlr-eoc/ukis-csmask/blob/main/requirements.txt).\n\n## Contributors\nThe UKIS team creates and adapts libraries which simplify the usage of satellite data. Our team includes (in alphabetical order):\n* Boehnke, Christian\n* Fichtner, Florian\n* Mandery, Nico\n* Martinis, Sandro\n* Riedlinger, Torsten\n* Wieland, Marc\n\nGerman Aerospace Center (DLR)\n\n## Licenses\nThis software is licensed under the [Apache 2.0 License](https://github.com/dlr-eoc/ukis-csmask/blob/main/LICENSE).\n\nCopyright (c) 2020 German Aerospace Center (DLR) * German Remote Sensing Data Center * Department: Geo-Risks and Civil Security\n\n## Changelog\nSee [changelog](https://github.com/dlr-eoc/ukis-csmask/blob/main/CHANGELOG.rst).\n\n## Contributing\nThe UKIS team welcomes contributions from the community.\nFor more detailed information, see our guide on [contributing](https://github.com/dlr-eoc/ukis-csmask/blob/main/CONTRIBUTING.md) if you're interested in getting involved.\n\n## What is UKIS?\nThe DLR project Environmental and Crisis Information System (the German abbreviation is UKIS, standing for [Umwelt- und Kriseninformationssysteme](https://www.dlr.de/eoc/en/desktopdefault.aspx/tabid-5413/10560_read-21914/) aims at harmonizing the development of information systems at the German Remote Sensing Data Center (DFD) and setting up a framework of modularized and generalized software components.\n\nUKIS is intended to ease and standardize the process of setting up specific information systems and thus bridging the gap from EO product generation and information fusion to the delivery of products and information to end users.\n\nFurthermore the intention is to save and broaden know-how that was and is invested and earned in the development of information systems and components in several ongoing and future DFD projects.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ultimodel",
            "repo_link": "https://github.com/DLR-VF/ULTImodel",
            "readme": "# ULTImodel\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/DLR-VF/ULTImodel/blob/master/LICENSE)\n[![PyPI version](https://badge.fury.io/py/ultimodel.svg)](https://pypi.python.org/pypi/ultimodel)\n[![Documentation Status](https://readthedocs.org/projects/ultimodel/badge/?version=latest)](https://ultimodel.readthedocs.io/en/latest/?badge=latest)\n[![Cite-us](https://img.shields.io/badge/doi-10.5281%2Fzenodo.7826486-blue)](https://doi.org/10.5281/zenodo.7826486)\n \n**ULTImodel** &mdash; A universal transport distribution model written in Python.\n\n## Description\n**ULTImodel** is a distribution model that helps to spatially distribute road-based transport for countries, including border-crossing travel. It is set up using open data like [OSM](https://openstreetmap.org).\nThe software includes modules for network generation, trip generation and trip distribution based on two main inputs:\n\n* Georeferenced traffic analysis zones (TAZ) for the respective region\n* Target value for national transport volume (i.e. person-kilometres or tonne-kilometres)\n\n![Prim_Sec](ultimodel-mkdocs/docs/images/readme_visual_fr.png \"Results of distribution and secondary model\")\n\n## Installation\n\nThe __current version__ is [ultimodel-1.0.0](https://github.com/DLR-VF/ULTImodel/releases/tag/1.0.0).\n\nYou may __install ULTImodel__ by executing the following\n\n__pip__\n```console\npython -m pip install ultimodel\n```\n\nYou may __download a copy or fork the code__ at [ULTImodel&apos;s github page]([link-to-github](https://github.com/DLR-VF/ULTImodel)).\n\nBesides, you may __download the current release__ here:\n\n* [ultimodel-1.0.1.zip](https://github.com/DLR-VF/ULTImodel/archive/refs/tags/1.0.1.zip)\n* [ultimodel-1.0.1.tar.gz](https://github.com/DLR-VF/ULTImodel/archive/refs/tags/1.0.1.tar.gz)\n\n\n## Usage\nExamples of using **ULTImodel** can be found in the [tutorials repository](https://github.com/DLR-VF/ULTImodel-tutorials).\n\nAdditional documentation can be found at <https://ultimodel.readthedocs.io/>.\n\n\n## Authors and acknowledgment\n**ULTImodel** was developed by Nina Thomsen.\n\nWe want to thank the following persons for the help during **ULTImodel's** development: Lars Hedemann, Simon Metzler, Gernot Liedtke, Christian Winkler, Tudor Mocanu, and Daniel Krajzewicz.\n\n## License\n**ULTImodel** is licensed under the [MIT license](https://github.com/DLR-VF/ULTImodel/blob/master/LICENSE).\n\n## Links\nPlease find further information on the web:\n\n* The complete documentation is located at <https://ultimodel.readthedocs.io/>\n* The github repository is located at <https://github.com/DLR-VF/ULTImodel>\n* The issue tracker is located at <https://github.com/DLR-VF/ULTImodel/issues>\n\n## Legal\n\nPlease find the legal information here: <https://github.com/DLR-VF/ULTImodel/blob/master/ultimodel-mkdocs/docs/legal.md>\n\n\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/ultramassexplorer-ume",
            "repo_link": "https://gitlab.awi.de/bkoch/ume",
            "readme": "![Package Icon](../inst/figures/ume_package_icon.png)\n\n# An R package for UltraMassExplorer (UME)\n***\n## Installation\n***\n### In case you already loaded a previous version of ume:\n  detach(\"package:ume\", unload = TRUE)\n\n### Install ume package\n  install.packages(\"remotes\")\n  remotes::install_git(url = \"https://gitlab.awi.de/bkoch/ume.git\")\n                           \n### Optional: Install package containing pre-build molecular formula libraries and a test peak list (cf. Leefmann et al. 2019):\n  remotes::install_git(url = \"https://gitlab.awi.de/bkoch/ume.formulas.git\")\n  \n***\n\n## Usage - quick tour\n***\n### Ressources\n***\n#### Vignette: All you need to know about the ume package\n  vignette(\"ume\")\n\n#### Molecular formula library (data.table)\n  library(ume.formulas)\n  ume.formulas::lib_02\n  \n#### Test peak list (data.table)\n  ume.formulas::ume_test_fjords\n\n#### Known molecular formulas (such as standards, surfactants, CRAM, Ideg, Iterr, ...) (data.table)\n  library(ume)\n  ume::known_mf\n  ume::known_mf[, unique(category)]\n***\n### Molecular formula assignment\n***\n  mfd <- ume::ume_assign_formulas(pl = ume.formulas::ume_test_fjords\n                           , formula_library = ume.formulas::lib_02\n                           , pol = \"neg\"\n                           , ma_dev = 0.5\n                           , msg = FALSE)\n  \n#### Formula filter process\n  mfd_filt <- ume::ume_filter_formulas(mfd = mfd\n                                       , remove_blank_list = c(\"Blank\")\n                                       , normalization = \"none\"\n                                       , exclude_category = c(\"surfactant\")\n                                       , c_iso_check = T\n                                       , dbe_o_max = 10\n                                       , p_min = 0, p_max = 0\n                                       , s_min = 0, s_max = 1\n                                       , n_min = 0, n_max = 2\n                                       , msg = TRUE\n  )\n\n#### Data summary\n  ume::calc.data_summary(mfd_filt)\n\n#### Visualization examples\n\nMass spectrum:\n  ume::uplot.ms(pl = ume.formulas::ume_test_fjords)\n  ?uplot.ms\n  \nvan Krevelen diagram:\n  ume::uplot.vk(mfd_filt)\n  ?uplot.vk\n  \nEvaluation of carbon istope abundance\n  ume::uplot.isotope_precision(mfd_filt)\n  ?uplot.isotope_precision\n\n***\n  \n\n",
            "project_id": "707"
        },
        {
            "software_organization": "https://helmholtz.software/software/unicore",
            "repo_link": "https://github.com/UNICORE-EU/",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/uqtestfuns",
            "repo_link": "https://github.com/casus/uqtestfuns",
            "readme": "# UQTestFuns\n[![JOSS](https://img.shields.io/badge/JOSS-10.21105/joss.05671-brightgreen?style=flat-square)](https://doi.org/10.21105/joss.05671)\n[![DOI](http://img.shields.io/badge/DOI-10.5281/zenodo.14181563-blue.svg?style=flat-square)](https://doi.org/10.5281/zenodo.14181563)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/psf/black)\n[![Python 3.7](https://img.shields.io/badge/python-3.7-blue.svg?style=flat-square)](https://www.python.org/downloads/release/python-370/)\n[![License](https://img.shields.io/github/license/damar-wicaksono/uqtestfuns?style=flat-square)](https://choosealicense.com/licenses/mit/)\n[![PyPI](https://img.shields.io/pypi/v/uqtestfuns?style=flat-square)](https://pypi.org/project/uqtestfuns/)\n\n|                                  Branches                                  | Status                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n|:--------------------------------------------------------------------------:|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [`main`](https://github.com/damar-wicaksono/uqtestfuns/tree/main) (stable) | ![build](https://img.shields.io/github/actions/workflow/status/damar-wicaksono/uqtestfuns/main.yml?branch=main&style=flat-square) [![codecov](https://img.shields.io/codecov/c/github/damar-wicaksono/uqtestfuns/main?logo=CodeCov&style=flat-square&token=Y6YQEPJ1TT)](https://app.codecov.io/gh/damar-wicaksono/uqtestfuns/tree/main) [![Docs](https://readthedocs.org/projects/uqtestfuns/badge/?version=stable&style=flat-square)](https://uqtestfuns.readthedocs.io/en/stable/?badge=stable) |\n|  [`dev`](https://github.com/damar-wicaksono/uqtestfuns/tree/dev) (latest)  | ![build](https://img.shields.io/github/actions/workflow/status/damar-wicaksono/uqtestfuns/main.yml?branch=dev&style=flat-square) [![codecov](https://img.shields.io/codecov/c/github/damar-wicaksono/uqtestfuns/dev?logo=CodeCov&style=flat-square&token=Y6YQEPJ1TT)](https://app.codecov.io/gh/damar-wicaksono/uqtestfuns/tree/dev) [![Docs](https://readthedocs.org/projects/uqtestfuns/badge/?version=latest&style=flat-square)](https://uqtestfuns.readthedocs.io/en/latest/?badge=latest)    |\n\n<!--One paragraph description-->\nUQTestFuns is an open-source Python3 library of test functions commonly used\nwithin the applied uncertainty quantification (UQ) community.\nSpecifically, the package provides:\n\n- an implementation _with minimal dependencies_ (i.e., NumPy and SciPy) and\n  _a common interface_ of many test functions available in the UQ literature\n- a _single entry point_ collecting test functions _and_ their probabilistic\n  input specifications in a single Python package\n- an _opportunity for an open-source contribution_, supporting\n  the implementation of new test functions or posting reference results.\n\nIn short, UQTestFuns is an homage\nto the [Virtual Library of Simulation Experiments (VLSE)](https://www.sfu.ca/~ssurjano/).\n\n## Usage\n\nUQTestFuns includes several commonly used test functions in the UQ community.\nTo list the available functions:\n\n```python-repl\n>>> import uqtestfuns as uqtf\n>>> uqtf.list_functions()\n+-------+-------------------------------+-----------+------------+----------+---------------+--------------------------------+\n|  No.  |          Constructor          |  # Input  |  # Output  |  Param.  |  Application  | Description                    |\n+=======+===============================+===========+============+==========+===============+================================+\n|   1   |           Ackley()            |     M     |     1      |   True   | optimization, | Optimization test function     |\n|       |                               |           |            |          | metamodeling  | from Ackley (1987)             |\n+-------+-------------------------------+-----------+------------+----------+---------------+--------------------------------+\n|   2   |        Alemazkoor20D()        |    20     |     1      |  False   | metamodeling  | High-dimensional low-degree    |\n|       |                               |           |            |          |               | polynomial from Alemazkoor &   |\n|       |                               |           |            |          |               | Meidani (2018)                 |\n+-------+-------------------------------+-----------+------------+----------+---------------+--------------------------------+\n|   3   |        Alemazkoor2D()         |     2     |     1      |  False   | metamodeling  | Low-dimensional high-degree    |\n|       |                               |           |            |          |               | polynomial from Alemazkoor &   |\n|       |                               |           |            |          |               | Meidani (2018)                 |\n+-------+-------------------------------+-----------+------------+----------+---------------+--------------------------------+\n|   4   |          Borehole()           |     8     |     1      |  False   | metamodeling, | Borehole function from Harper  |\n|       |                               |           |            |          |  sensitivity  | and Gupta (1983)               |\n+-------+-------------------------------+-----------+------------+----------+---------------+--------------------------------+\n...\n```\n\nConsider the Borehole function, a test function commonly used for metamodeling\nand sensitivity analysis purposes; to create an instance of this test function:\n\n```python-repl\n>>> my_testfun = uqtf.Borehole()\n>>> print(my_testfun)\nFunction ID      : Borehole\nInput Dimension  : 8 (fixed)\nOutput Dimension : 1\nParameterized    : False\nDescription      : Borehole function from Harper and Gupta (1983)\nApplications     : metamodeling, sensitivity\n```\n\nThe probabilistic input specification of this test function is built-in:\n\n```python-repl\n>>> print(my_testfun.prob_input)\nFunction ID     : Borehole\nInput ID        : Harper1983\nInput Dimension : 8\nDescription     : Probabilistic input model of the Borehole model from\n                  Harper and Gupta (1983)\nMarginals       :\n\n No.    Name    Distribution        Parameters                          Description\n-----  ------  --------------  ---------------------  -----------------------------------------------\n  1      rw        normal      [0.1       0.0161812]            radius of the borehole [m]\n  2      r       lognormal        [7.71   1.0056]                 radius of influence [m]\n  3      Tu       uniform        [ 63070. 115600.]      transmissivity of upper aquifer [m^2/year]\n  4      Hu       uniform          [ 990. 1100.]         potentiometric head of upper aquifer [m]\n  5      Tl       uniform          [ 63.1 116. ]        transmissivity of lower aquifer [m^2/year]\n  6      Hl       uniform           [700. 820.]          potentiometric head of lower aquifer [m]\n  7      L        uniform          [1120. 1680.]                length of the borehole [m]\n  8      Kw       uniform         [ 9985. 12045.]     hydraulic conductivity of the borehole [m/year]\n\nCopulas         : Independence\n```\n\nA sample of input values can be generated from the input model:\n\n```python-repl\n>>> xx = my_testfun.prob_input.get_sample(10)\narray([[8.40623544e-02, 2.43926544e+03, 8.12290909e+04, 1.06612711e+03,\n        7.24216436e+01, 7.78916695e+02, 1.13125867e+03, 1.02170796e+04],\n       [1.27235295e-01, 3.28026293e+03, 6.36463631e+04, 1.05132831e+03,\n        6.81653728e+01, 8.17868370e+02, 1.16603931e+03, 1.09370944e+04],\n       [8.72711602e-02, 7.22496512e+02, 9.18506063e+04, 1.06436843e+03,\n        6.44306474e+01, 7.74700231e+02, 1.46266808e+03, 1.12531788e+04],\n       [1.22301709e-01, 2.29922122e+02, 8.00390345e+04, 1.05290108e+03,\n        1.10852262e+02, 7.94709283e+02, 1.28026313e+03, 1.01879077e+04],\n...\n```\n\n...and used to evaluate the test function:\n\n```python-repl\n>>> yy = my_testfun(xx)\narray([ 57.32635774, 110.12229548,  53.10585812,  96.15822154,\n        58.51714875,  89.40068404,  52.61710076,  61.47419171,\n        64.18005235,  79.00454634])\n```\n\n## Installation\n\nYou can obtain UQTestFuns directly from PyPI using `pip`:\n\n```bash\n$ pip install uqtestfuns\n```\n\nAlternatively, you can also install the latest version from the source:\n\n```bash\npip install git+https://github.com/damar-wicaksono/uqtestfuns.git\n```\n\n> **NOTE**: UQTestFuns is currently work in progress,\n> therefore interfaces are subject to change.\n\nIt's a good idea to install the package in an isolated virtual environment.\n\n## Getting help\n\n<!--Getting help-->\nFor a getting-started guide on UQTestFuns,\nplease refer to the [Documentation](https://uqtestfuns.readthedocs.io/en/latest/).\nThe documentation also includes details on each of the available test functions.\n\nFor any other questions related to the package,\npost your questions on the GitHub Issue page.\n\n## Package development and contribution\n\n<!--Package Development-->\nUQTestFuns is under ongoing development;\nany contribution to the code (for example, a new test function)\nand the documentation (including new reference results) are welcomed!\n\nPlease consider the [Contribution Guidelines](CONTRIBUTING.MD) first,\nbefore making a pull request. \n\n## Citing UQTestFuns\n\nIf you use this package in your research or projects, please consider citing\nboth the associated paper and the Zenodo archive (for the specific version\nused).\n\n### Citing the paper (JOSS)\n\nThe citation of the paper associated with this package is:\n\n```bibtex\n@article{Wicaksono2023,\n  author    = {Wicaksono, Damar and Hecht, Michael},\n  title     = {{UQTestFuns}: A {Python3} library of uncertainty quantification ({UQ}) test functions},\n  journal   = {Journal of Open Source Software},\n  year      = {2023},\n  volume    = {8},\n  number    = {90},\n  doi       = {10.21105/joss.05671},\n}\n```\n\n### Citing a specific version (Zenodo)\n\nTo ensure reproducibility, cite the exact version of the package you used.\nEach release is archived on Zenodo with a unique DOI; find and use the DOI\nfor the version you used at [Zenodo].\n\nThe citation for the current public version is:\n\n```bibtex\n@software{UQTestFuns_0_5_0,\n  author       = {Wicaksono, Damar and Hecht, Michael},\n  title        = {{UQTestFuns: A Python3 Library of Uncertainty Quantification (UQ) Test Functions}},\n  month        = nov,\n  year         = 2024,\n  publisher    = {Zenodo},\n  version      = {v0.5.0},\n  doi          = {10.5281/zenodo.14181563},\n  url          = {https://doi.org/10.5281/zenodo.14181563}\n}\n```\n\n## Credits and contributors\n\n<!--Credits and contributors-->\nThis work was partly funded\nby the [Center for Advanced Systems Understanding (CASUS)](https://www.casus.science/)\nwhich is financed by Germany's Federal Ministry of Education and Research (BMBF)\nand by the Saxony Ministry for Science, Culture and Tourism (SMWK)\nwith tax funds on the basis of the budget approved\nby the Saxony State Parliament.\n\nUQTestFuns is currently maintained by:\n\n- Damar Wicaksono ([HZDR/CASUS](https://www.casus.science/))\n\nunder the Mathematical Foundations of Complex System Science Group\nled by Michael Hecht ([HZDR/CASUS](https://www.casus.science/)) at CASUS.\n\n## License\n\n<!--License-->\nUQTestFuns is released under the [MIT License](LICENSE).\n\n[Zenodo]: https://zenodo.org/search?q=parent.id%3A7701903&f=allversions%3Atrue&l=list&p=1&s=10&sort=version\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/urbem-urban-emission-downscaling-for-air-quality-modeling",
            "repo_link": "https://github.com/martinottopaul/UrbEm",
            "readme": "# UrbEm v1.0.0\nThe Urban Emission downscaling model (UrbEm)for air quality modeling\n\n0. Introduction\n\nThe use of regional emission inventories can be challenging for urban-scale AQ applications and air quality management in cities. Nevertheless, their exploitation through disaggregation by utilizing spatial proxies is a credible solution for European cities that lack bottom-up emission inventories. \n\nTo this end, we developed the UrbEm approach, which enables in a modular manner downscaling of gridded regional emissions with specific spatial proxies based on a variety of open access, robust, sustainable and frequently updated sources. UrbEm can be applied to any urban area in Europe and provides methodological homogeneity between different cities.\n\nTo demonstrate the general applicability and performance of the developed method and tool, we introduced the method, and compared the spatial distribution of uniformly disaggregated regional emissions with emissions downscaled with the UrbEm approach for the differing cities of Athens and Hamburg (manuscript submitted for publication, pre-print accessible on request). \n\nThe UrbEm downscaling approach is completely free of cost and open source. Its application is realized in (1) a series of R scripts and (2) as Pyhton script. Both applications rely on e.g. CAMS-REG emission inventories as well as a set (maps) of spatial proxies, which need to be downloaded before using UrbEm.\n\n1. Access necessary input data\n\n1.1. Emission datasets\n\nUrbEm v1.0 is configured to read CAMS-REG-AP v3.1 regional emissions. After registration, these can be downloaded free of cost at: https://eccad.aeris-data.fr\nAfter registration in the \"Access Data\" section, the CAMS-REG-AP dataset should be selected and downloaded for all pollutants and sectors.\n\nThe second emission database applied is the European Pollutant Release and Transfer Register E-PRTR, which can be downloaded without registration at: https://www.eea.europa.eu/data-and-maps/data/member-states-reporting-art-7-under-the-european-pollutant-release-and-transfer-register-e-prtr-regulation-23/european-pollutant-release-and-transfer-register-e-prtr-data-base\n\nBoth datasets should be placed in separate folders.\n\n1.2. Spatial proxies\nBesides a collection of spatial proxies (download here: https://doi.org/10.5281/zenodo.5508739), which have been specifically prepared for application in UrbEm, the Global Human Settlement Layer (download here: https://ghsl.jrc.ec.europa.eu/ghs_pop2019.php) Population density product \"GHS_POP_E2015_GLOBE_R2019A_4326_30SS_V1_0\" needs to be downloaded.\n\nMake sure all proxies are placed in one folder.\n\n\n2. Apply UrbEm v1.0\n\nBoth solutions (R and Python) are configured to \n(1) read CAMS-REG-AP v3.1 and E-PRTR emission input files, \n(2) downscale these gridded and point emissions with the downloaded set of spatial proxies,\n(3) to arrive at annual total emissions for a selected year and a selected urban domain,\n(4) and write these as area, line and/or point source emission files,\n(5) in a *.csv file format for the EPISODE-CityChem preprocessor UECT (Karl et al. 2019).\n\nAlthough UrbEm v1.0 delivers only UECT/EPISODE-CityChem file format as output, it is generally possible to change to the desired output format by code modification. Nevertheless, we promote to use the EPISODE-CityChem air quality model for urban-scales due to its efficiency, performance and ongoing development. EPISODE-CityChem can be downloaded free of cost at https://doi.org/10.5281/zenodo.1116173.\n\n2.1. UrbEm Rscripts\n\nThe UrbEm v1.0 Rscripts are separated in three main scripts:\n1_UrbEm_pointsources_v1.R\n2_UrbEm_areasources_v2.R\n3_UrbEm_linesources_v3.\n\nThese scripts need to be run sequentially to create point, area and line emission files. \n\nBefore running the scripts, make sure the R libraries raster, sf, rgdal, osmdata and lwgeom are installed in your R environment. \n\nAddtionally the following auxiliary functions (scripts distributed with UrbEm v1.0) are necessary and will be sourced at the beginning of some main scripts:\nareasources_e-prtr_pointsource_correction.R\nareasources_to_osm_linesources.R\nproxy_distribution.R\nproxy_preparation.R\n\nWhile there are no changes in the auxiliary scripts necessary to run UrbEm, there need to be changes made in the main scripts. Each of the main scripts has an input section at the beginning, which needs to be adjusted, for e.g.:\n- setting input folders of emission files and proxies\n- setting output folders and output text strings\n- setting a domain definition\n- setting downscaling options\n\nThe input section of each main script, as well as the code itself delivers a documentation of each step made in the script.\n\nFeel free to adjust the code for your purposes.\n\n\n\n2.2. UrbEm Python scripts\n\nThe UrbEm v1.0 Python scripts are separated in two main scripts: \n- 1_UrbEM_proxies_v1.py \n- 2_UrbEM_emissions_v1.py\n\nThese scripts need to be run sequentially to 1. create proxy, point, area and line emission files.\n\nBefore running the scripts, make sure the python libraries pandas, numpy, gdal, geopandas, os, sys, fnmatch, inspect, rasterio, rasterio.mask, earthpy.spatial, shapely.geometry, earthpy, fiona, osgeo, gc, geotable, pyproj, shapely, time, shutil, OSMPythonTools.nominatim, OSMPythonTools.overpass, OSMPythonTools.data, collections and shapefile are installed in your Python v3 environment.\n\nSpatial datasets: In order to be able to run the python scripts the user should also download:\n- Population density data (Global dataset/ 2015 / WGS84 / 30 arcsec): https://ghsl.jrc.ec.europa.eu/download.php?ds=pop \n- CORINE raster and GDB files: https://land.copernicus.eu/pan-european/corine-land-cover/clc2018 \n- E-PRTR kmz data: \nhttps://www.eea.europa.eu/data-and-maps/data/member-states-reporting-art-7-under-the-european-pollutant-release-and-transfer-register-e-prtr-regulation-23/e-prtr-facilities-kmz-format/eprtr_facilities_v9.kmz \n- E-PRTR csv data: \nhttps://www.eea.europa.eu/data-and-maps/data/member-states-reporting-art-7-under-the-european-pollutant-release-and-transfer-register-e-prtr-regulation-23/european-pollutant-release-and-transfer-register-e-prtr-data-base/eprtr_v9_csv.zip \n- Urban Center data: https://ghsl.jrc.ec.europa.eu/ghs_stat_ucdb2015mt_r2019a.php \n- Eurostat countries: https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/countries \n- Shipping Routes\n\nEach of the main scripts has an input section at the beginning, which needs to be adjusted, for e.g.:\n- setting input folders of emission files and proxies\n- setting a domain definition\n- setting downscaling options\n\nThe input section of each script, as well as the code itself delivers a documentation of each step made in the script.\n\nFeel free to adjust the code for your purposes.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/urmoac",
            "repo_link": "https://github.com/DLR-VF/UrMoAC",
            "readme": "# UrMoAC\n\n# ![logo.png](https://raw.githubusercontent.com/DLR-VF/UrMoAC/master/logo.png) UrMoAC\n[![License: EPL2](https://img.shields.io/badge/license-EPL2-green)](https://github.com/DLR-VF/UrMoAC/blob/master/LICENSE.md)\n[![DOI](https://img.shields.io/badge/doi-10.5281%2Fzenodo.13234444-blue)](https://doi.org/10.5281/zenodo.13234444)\n[![Documentation Status](https://readthedocs.org/projects/urmoac/badge/?version=latest)](https://urmoac.readthedocs.io/en/latest/?badge=latest)\n![Build Status](https://github.com/DLR-VF/UrMoAC/actions/workflows/maven_build.yml/badge.svg)\n\n&ldquo;Urban Mobility Accessibility Computer&rdquo; or &ldquo;UrMoAC&rdquo; is a tool for computing accessibility measures, supporting aggregation, variable limits, and intermodal paths. It is a scientific tool.\n\nThis version of the documentation describes the current development version. You should use one of the available [releases](https://github.com/DLR-VF/UrMoAC/releases). The according documentation can be found at [readthedocs](http://urmoac.readthedocs.io) or within the release itself.\n\nWhat the tool basically does is to load a set of origin locations and a set of destination locations as well as a road network and optionally a description of the public transport offer. Then, it iterates over all loaded origins and computes the respective accessibility measure for each of them by routing to all destinations within the defined limit. Optionally, areas by which the origins and destinations shall be aggregated may be loaded.\n\nSome features:\n\n* input is read from databases or files;\n* variable origins / destinations;\n* variable aggregation options;\n* weights for origins and destinations;\n* flexible limits for search: max. time, max. distance, max. number, max. seen value, nearest only;\n* support for different transport modes, as well as intermodal accessibilities;\n* GTFS-based public transport accessibility computation;\n* possibility to read time-dependent travel times (for motorised individual traffic);\n* support for data preparation and visualisation.\n\n## Documentation\n\nThe complete documentation is located at <http://urmoac.readthedocs.io>. It should cover different versions.\n\nWhen using one of the releases, you should consult the included documentation as the information below describes the current state of the development.\n\nPlease consult the section *Links* below for further information sources.\n\n## Installation\n\n**UrMoAC** is written in the [Java](https://www.java.com/) programming language. You need [Java](https://www.java.com/) to run it. The easiest way to install it is to download the .jar-file from the latest [release](https://github.com/DLR-VF/UrMoAC/releases). Further possibilities to run it are given at [Installation](https://github.com/DLR-VF/UrMoAC/blob/master/docs/mkdocs/Installation.md).\n\n## Usage examples\n\nA most basic call may look as following:\n\n```console\njava -jar UrMoAC.jar --from origins.csv --to destinations.csv --net network.csv --od-output nm_output.csv --mode bike --time 0 --epsg 0\n```\n\nWhich would compute the accessibility of the destinations stored in ```destinations.csv``` starting at the origins stored in ```origins.csv``` along the road network stored in ```network.csv``` for the transport mode bike. Information about the used file formats are given at [Input Data Formats](https://github.com/DLR-VF/UrMoAC/blob/master/docs/mkdocs/InputDataFormats.md).\n\n## License\n\n**UrMoAC** is licensed under the [Eclipse Public License 2.0](LICENSE.md).\n\n**When using it, please cite it as:**\n\nDaniel Krajzewicz, Dirk Heinrichs and Rita Cyganski (2017) [_Intermodal Contour Accessibility Measures Computation Using the 'UrMo Accessibility Computer'_](https://elib.dlr.de/118235/). International Journal On Advances in Systems and Measurements, 10 (3&4), Seiten 111-123. IARIA.\n\nAnd / or use the DOI: [![DOI](https://img.shields.io/badge/doi-10.5281%2Fzenodo.13234444-blue)](https://doi.org/10.5281/zenodo.13234444) (v0.8.2)\n\n## Support and Contribution\n\n**UrMoAC** is under active development and we are happy about any interaction with users or dvelopers.\n\n## Authors\n\n**UrMoAC** has been developed at the [Institute of Transport Research](http://www.dlr.de/vf) of the [German Aerospace Center](http://www.dlr.de).\n\n## Links\n\nYou may find further information about **UrMoAC** at the following pages:\n* a complete documentation is located at <http://urmoac.readthedocs.io>;\n* the recent as well as the previous releases can be found at <https://github.com/DLR-VF/UrMoAC/releases>;\n* the source code repository is located at <https://github.com/DLR-VF/UrMoAC>;\n* the issue tracker is located at <https://github.com/DLR-VF/UrMoAC/issues>;\n* you may start a discussion or join an existing one at <https://github.com/DLR-VF/UrMoAC/discussions>.\n\n## Legal\n\nPlease find additional legal information at [Legal](https://github.com/DLR-VF/UrMoAC/blob/master/docs/mkdocs/Legal.md).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/utile-oxy",
            "repo_link": "https://github.com/andyco98/UTILE-Oxy/",
            "readme": "# *UTILE-Oxy* - Deep Learning to Automate Video Analysis of Bubble Dynamics in Proton Exchange Membrane Electrolyzers\n\n![](https://github.com/andyco98/UTILE-Oxy/blob/main/images/workflow.png)\n\n\nWe present  an automated workflow using deep learning for the analysis of videos containing oxygen bubbles in PEM electrolyzers by 1. preparing an annotated dataset and training models in order to conduct semantic segmentation of bubbles and 2. automating the extraction of bubble properties for further distribution analysis.\n\nThe publication [UTILE-Oxy - Deep Learning to Automate Video Analysis of Bubble Dynamics in Proton Exchange Membrane Electrolyzers](https://pubs.rsc.org/en/content/articlelanding/2024/cp/d3cp05869g) is available in an open access fashion on the journal PCCP for further information!\n\n\n## Description\nThis project focuses on the deep learning-based automatic analysis of polymer electrolyte membrane water electrolyzers (PEMWE) oxygen evolution videos. \nThis repository contains the Python implementation of the UTILE-Oxy software for automatic video analysis, feature extraction, and plotting.\n\nThe models we present in this work are trained on a specific use-case scenario of interest in oxygen bubble evolution videos of transparent cells. It is possible to fine-tune, re-train or employ another model suitable for your individual case if your data has a strong visual deviation from the presented data here, which was recorded and shown as follows:\n\n![](https://github.com/andyco98/UTILE-Oxy/blob/main/images/figexperiment.png)\n\n## Model's benchmark\nIn our study, we trained several models to compare their prediction performance on unseen data. We trained specifically three different models on the same dataset composed by :\n- Standard U-Net 2D\n- U-Net 2D with a ResNeXt 101 backbone \n- Attention U-Net\n\nWe obtained the following performance results:\n\n| Model                           | Precision [%] | Recall [%] | F1-Score [%] |\n|---------------------------------|----------------|------------|--------------|\n| U-Net 2D                        | 81             | 89         | 85           |\n| U-Net with ResNeXt101 backbone  | 95             | 78         | 86           |\n| Attention U-Net                 | 95             | 75         | 84           |\n\n\nSince the F1-Scores are similar a visual inspection was carried out to find the best-performing model :\n\n![](https://github.com/andyco98/UTILE-Oxy/blob/main/images/benchmark.png)\n\nBut even clearer is the visual comparison of the running videos:\n\n![](https://github.com/andyco98/UTILE-Oxy/blob/main/images/video_results.gif)\n\n## Extracted features\n\n### Time-resolved bubble ratio computation and bubble coverage distribution\n\n![](https://github.com/andyco98/UTILE-Oxy/blob/main/images/timeresolved.png)\n\n### Bubble position probability density map\n\n![](https://github.com/andyco98/UTILE-Oxy/blob/main/images/heatmaps.png)\n\n### Individual bubble shape analysis\n\n![](https://github.com/andyco98/UTILE-Oxy/blob/main/images/individualcorrect.png)\n\n## Installation\nIn order to run the actual version of the code, the following steps need to be done:\n- Clone the repository\n- Create a new environment using Anaconda using Python 3.8 or superior\n- Pip install the jupyter notebook library\n\n    ```\n    pip install notebook\n    ```\n- From your Anaconda console open jupyter notebook (just tip \"jupyter notebook\" and a window will pop up)\n- Open the /UTILE-Oxy/UTILE-Oxy_prediction.ipynb file from the jupyter notebook directory\n- Further instructions on how to use the tool are attached to the code with examples in the juypter notebook\n\n## Dependencies\nThe following libraries are needed to run the program:\n\n  ```\n   pip install opencv-python, numpy, patchify, pillow, segmentation_models, keras, tensorflow, matplotlib, scikit-learn, pandas\n\n   ```\n### Notes\n\nThe datasets used for training and the trained model are available at Zenodo: https://doi.org/10.5281/zenodo.10184579."
        },
        {
            "software_organization": "https://helmholtz.software/software/varfish",
            "repo_link": "https://github.com/bihealth/varfish-server",
            "readme": "[![Documentation Status](https://readthedocs.org/projects/varfish-server/badge/?version=latest)](https://varfish-server.readthedocs.io/en/latest/?badge=latest)\n[![Code Coverage](https://codecov.io/gh/varfish-org/varfish-server/branch/main/graph/badge.svg?token=5ZACSH5MZZ)](https://codecov.io/gh/varfish-org/varfish-server)\n[![image](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)\n\n# VarFish\n\n**Comprehensive DNA variant analysis for diagnostics and research.**\n\nThis is the repository for the web server component.\n\nHoltgrewe, M.; Stolpe, O.; Nieminen, M.; Mundlos, S.; Knaus, A.; Kornak, U.; Seelow, D.; Segebrecht, L.; Spielmann, M.; Fischer-Zirnsak, B.; Boschann, F.; Scholl, U.; Ehmke, N.; Beule, D. *VarFish: Comprehensive DNA Variant Analysis for Diagnostics and Research*. Nucleic Acids Research 2020, gkaa241. <https://doi.org/10.1093/nar/gkaa241>.\n\n## Getting Started\n\n- [VarFish Homepage](https://www.cubi.bihealth.org/software/varfish/)\n- [Manual](https://varfish-server.readthedocs.io/en/latest/)\n  - [Installation Instructions](https://varfish-server.readthedocs.io/en/latest/admin_install.html).\n- [Docker Compose Installer](https://github.com/varfish-org/varfish-docker-compose#run-varfish-server-using-docker-compose).\n\n## VarFish Repositories\n\n- [varfish-server](https://github.com/varfish-org/varfish-server) The VarFish Server is the web frontend used by the end users / data analysts.\n- [varfish-annotator](https://github.com/varfish-org/varfish-annotator) The VarFish Annotator is a command line utility used for annotating VCF files and converting them to files that can be imported into VarFish Server.\n- [varfish-cli](https://github.com/varfish-org/varfish-cli) The VarFish Command Line Interface allows to import data through the VarFish REST API.\n- [varfish-db-downloader](https://github.com/varfish-org/varfish-db-downloader) The VarFish DB Downloader is a command line tool for downloading the background database.\n- [varfish-docker-compose](https://github.com/varfish-org/varfish-docker-compose) Quickly get started running a VarFish server by using Docker Compose. We provide a prebuilt data set with some already imported data.\n\n## At a Glance\n\n- License: MIT\n- Dependencies / Tech Stack\n  - Python \\>=3.8\n  - Django 3\n  - PostgreSQL \\>=12\n\nGitHub is used for public issue tracking. Currently, development happens\non internal infrastructure.\n\n## VarFish Component Compatibility Table\n\nThe following combinations have been validated / are supported to work.\n\n| VarFish Server | VarFish CLI | VarFish Annotator |\n| -------------- | ----------- | ----------------- |\n| v1.2.2         | v0.3.0      | v0.21             |\n| v1.2.1         | v0.3.0      | v0.21             |\n| v1.2.0         | v0.3.0      | v0.21             |\n\n## VarFish Data Release Compatibility Table\n\nThe following combinations have been validated / are supported to work.\n\n| VarFish Server | Data Release | VarFish DB Downloader |\n| -------------- | ------------ | --------------------- |\n| v1.2.2         | 20210728c    | v0.3.\\*               |\n| v1.2.1         | 20210728     | v0.3.\\*               |\n| v1.2.1         | 20210728b    | v0.3.\\*               |\n| v1.2.0         | 20210728     | v0.3.\\*               |\n| v1.2.0         | 20210728b    | v0.3.\\*               |\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/vasca",
            "repo_link": "https://github.com/rbuehler/vasca",
            "readme": "\n![VASCA icon](docs/images/VASCA_icon.png)\n[![🧪 pytest](https://github.com/rbuehler/vasca/actions/workflows/ci.yml/badge.svg)](https://github.com/rbuehler/vasca/actions/workflows/ci.yml)\n[![📚 docs](https://github.com/rbuehler/vasca/actions/workflows/docs.yml/badge.svg)](https://rbuehler.github.io/vasca/)\n[![🚀 pypi](https://github.com/rbuehler/vasca/actions/workflows/pypi.yml/badge.svg)](https://pypi.org/project/vasca/)\n\n\n# Variable Source Cluster Analysis (VASCA)\n\n1. [Motivation](#motivation)\n2. [Pipeline Overview](#pipeline-overview)\n3. [Key Features](#key-features)\n4. [Proof-of-Principle Study](#proof-of-principle-study)\n5. [Documentation and Installation](#documentation-and-installation)\n6. [Getting Started](docs/getting_started.md#getting-started)\n\n## Motivation\nVASCA (Italian for \"bathtub\" 🛁) is a high-performance software package developed to\naddress the challenges of time-domain astronomy, especially given the increasing volume\nof data from large-scale surveys such as [ZTF](https://en.wikipedia.org/wiki/Zwicky_Transient_Facility),\n[LSST](https://en.wikipedia.org/wiki/Vera_C._Rubin_Observatory), and [ULTRASAT](https://www.weizmann.ac.il/ultrasat/).\nDesigned to analyze time-variable cosmic sources like active galactic nuclei, stars, and\ntransient events, VASCA provides a modular, scalable solution for integrating data from\nmultiple instruments and conducting a cohesive analysis.\n\n## Pipeline Overview\n\nThe VASCA analysis pipeline consists of three primary steps:\n1. **Spatial Clustering**: Associate detections from repeated observations to unique\ncosmic sources using [mean-shift](https://en.wikipedia.org/wiki/Mean_shift) clustering.\n2. **Statistical Variability Detection**: Identify time-variable sources by testing flux\nvariations against a constant hypothesis at a 5-σ significance level.\n3. **Source Classification**: Classify detected sources, including cross-matching with\nexternal catalogs (e.g., SIMBAD, Gaia).\n\nThe main output of the pipeline is a catalog of time-variable cosmic\nsources, including detailed classifications and cross-matches with existing astronomical\ndatabases.\n\n## Key Features\n\n- **Simplicity and Modularity**: The software uses a hierarchical data model and modular\nprocessing to ensure scalability and ease of use. It supports data from multiple\ninstruments seamlessly.\n- **Proven Algorithms**: VASCA relies on established algorithms and statistical methods,\nensuring robustness and reducing the maintenance burden.\n- **Focus on Specific Use Case**: Optimized for analyzing time-domain astronomical data,\nVASCA keeps complexity low, simplifying auditing and debugging.\n- **Standards Compliance**: Outputs are designed for publication readiness by adhering to\nIAU and CDS standards, using widely-accepted, non-proprietary data formats. \n- **Customization and Extensibility**: VASCA allows flexible configuration, making it\nadaptable to different datasets and instrument-specific requirements.\n\n## Proof-of-Principle Study\n\nVASCA was applied to a proof-of-principle study  using the Galaxy Evolution Explorer\n(GALEX) archive (2003-2013). This study produced a catalog of over 4,000 UV-variable\nsources, revealing UV variability across all classes of stars. Notably, a massive,\npulsating white dwarf exhibited unique long-term variability in the UV. The full article\nincluding a description of VASCA's pipeline can be found here:\n[The time-variable ultraviolet sky: Active galactic nuclei, stars, and white dwarfs](https://ui.adsabs.harvard.edu/abs/2024A%26A...687A.313B/abstract).\n\n## Documentation and Installation\n\nVASCA is distributed as an open-source package. Comprehensive documentation is available\n[here](https://rbuehler.github.io/vasca/), including example notebooks and an API reference to help users get started.\nFor quick installation, VASCA can be installed via [PyPI](https://pypi.org/project/vasca/) using:\n```shell\npip install vasca\n```\nFor more info see the [installation guide](docs/getting_started.md#installation)."
        },
        {
            "software_organization": "https://helmholtz.software/software/velocityconversion",
            "repo_link": "https://github.com/cmeessen/VelocityConversion",
            "readme": "# VelocityConversion\n\n[![DOI](https://zenodo.org/badge/87794116.svg)](https://zenodo.org/badge/latestdoi/87794116) [![PyPI version](https://badge.fury.io/py/velocityconversion.svg)](https://badge.fury.io/py/velocityconversion)\n\n- [VelocityConversion](#velocityconversion)\n  - [Introduction](#introduction)\n  - [Getting started](#getting-started)\n    - [Use the latest version not on PyPI](#use-the-latest-version-not-on-pypi)\n  - [Usage as command line tool](#usage-as-command-line-tool)\n  - [Usage as a Python module](#usage-as-a-python-module)\n  - [Modifying physical properties of the minerals](#modifying-physical-properties-of-the-minerals)\n  - [Contributing](#contributing)\n  - [Citing](#citing)\n  - [References](#references)\n  - [Licence](#licence)\n\n## Introduction\n\nThis code is a python implementation of the p- and s-wave velocity to density\nconversion approach after Goes et al. (2000). The implementation was optimised\nfor regular 3D grids using lookup tables instead of Newton iterations.\n\nGoes et al. (2000) regard the expansion coefficient as temperature dependent\nusing the relation by Saxena and Shen (1992). In `VelocityConversion`, the user\ncan additionally choose between a constant expansion coefficient or a pressure-\nand temperature dependent coefficient that was derived from Hacker and Abers\n(2004).\n\nFor detailed information on the physics behind the approach have a look at the\noriginal paper by Goes et al. (2000).\n\n## Getting started\n\n`VelocityConversion` requires Python 3 and numpy. Install `numpy` and\n`VelocityConversion` by running\n\n```bash\npip install numpy velocityconversion\n```\n\nTo uninstall `VelocityConversion`, run\n\n```bash\npip uninstall velocityconversion\n```\n\n### Use the latest version not on PyPI\n\nIf you want to use the very latest version, or want to\n[contribute](#contributing), clone the repository to you local hard drive:\n\n```bash\ngit clone https://github.com/cmeessen/VelocityConversion.git\n```\n\nor, if you haven an [SSH key](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent)\nassociated to your account:\n\n```bash\ngit clone git@github.com:cmeessen/VelocityConversion.git\n```\n\nTo check whether everything is working run the tests\n\n```bash\npython test.py\n```\n\nIf the output looks like this, everything is working fine:\n\n```\ntest_vp_AlphaConst (__main__.TestVelocityConversion) ... ok\ntest_vs_AlphaConst (__main__.TestVelocityConversion) ... ok\ntest_vs_AlphaPT (__main__.TestVelocityConversion) ... ok\ntest_vs_AlphaT (__main__.TestVelocityConversion) ... ok\n\n----------------------------------------------------------------------\nRan 4 tests in 1.633s\n\nOK\n```\n\n## Usage as command line tool\n\nIn order to use the code as command line tool, add the `./Examples` directory\nto your `PATH`, e.g. in your bash profile:\n\n```bash\nexport PATH=/path/to/VelocityConversion/Examples:$PATH\n```\n\nAlternatively you can move the bash script\n[VelocityConversion](./Examples/VelocityConversion) to a place that is within\nyour `PATH`. Now the bash script `VelocityConversion` can be executed:\n\n```\nVelocityConversion\n\nUsage: VelocityConversion FileIn -type <P|S> [optional args]\n    Optional arguments:\n        -AlphaT\n        -AlphaPT\n        -dT <val>\n        -comp <Filename>\n        -h | --help\n        -NN\n        -out <FileOut>\n        -scaleV <value>\n        -setQ <1|2>\n        -v | -verbose\n        -XFe <val>\n        --version\n```\n\nThe steps to prepare a conversion are\n\n- definition of mantle rock composition in a `*.csv` file using the mineral\n  terminology of [MinDB.csv](./VelocityConversion/MinDB.csv)\n- provide a velocity distribution on a regular 3D grid where columns are `x y z\n  v`\n- run `VelocityConversion` specifying the velocity type with `-type P` or\n  `-type S`\n\nWorking examples for the usage as command line tool are provided in the script\n[RunExamples.sh](./Examples/RunExamples.sh).\n\n## Usage as a Python module\n\nVelocityConversion can also be imported as a Python module. Therefore, navigate\nto the folder that contains your clone of the repository (and\n[setup.py](./setup.py)) and execute\n\n```bash\npip install -e .\n```\n\nNow, the module can be imported to Python:\n\n```python\nfrom VelocityConversion import MantleConversion\nMC = MantleConversion()\n```\n\nA short working example for a conversion is:\n\n```python\nfrom VelocityConversion import MantleConversion\nMC = MantleConversion()\nMC.LoadFile(\"./Examples/VsSL2013.dat\")\nMC.SetVelType(\"S\")\nMC.DefaultMineralogy()\nMC.FillTables()\nMC.CalcPT()\nMC.SaveFile(\"./Examples/VsSL2013_out.dat\")\n```\n\nFor a more complete documentation on how to use `VelocityConversion` as a Python\nmodule please visit the\n[documentation](https://cmeessen.github.io/VelocityConversion/).\n\n## Modifying physical properties of the minerals\n\nThe database that contains the physical properties of the individual mineral\nphases is stored in [MinDB.csv](./VelocityConversion/MinDB.csv).\nMineral parameters can be edited, or new minerals added. A new mineral phase\nshould then be referred to in the code or the assemblage file using the name\nthat was assigned in the `phase` column of `MinDB.csv`.\n\n## Contributing\n\nPlease see [CONTRIBUTING.md](./CONTRIBUTING.md) if you want to contribute to\n`VelocityConversion`.\n\n## Citing\n\nIf you use this code, please consider citing it as\n\n> Meeßen, Christian (2019): \"VelocityConversion (v1.1.2)\". Zenodo,\n> http://doi.org/10.5281/zenodo.5897455.\n\nor refer to [CITATION.cff](./CITATION.cff).\n\n## References\n\nBerckhemer, H., W. Kampfmann, E. Aulbach, and H. Schmeling. “Shear Modulus and\nQ of Forsterite and Dunite near Partial Melting from Forced-Oscillation\nExperiments.” Physics of the Earth and Planetary Interiors, Special Issue\nProperties of Materials at High Pressures and High Temperatures, 29, no. 1\n(July 1, 1982): 30–41. doi:10.1016/0031-9201(82)90135-2.\n\nGoes, S., R. Govers, and P. Vacher. “Shallow Mantle Temperatures under Europe\nfrom P and S Wave Tomography.” Journal of Geophysical Research 105, no. 11\n(2000): 153–11. doi:10.1029/1999jb900300.\n\nHacker, Bradley R., and Geoffrey A. Abers. “Subduction Factory 3: An Excel\nWorksheet and Macro for Calculating the Densities, Seismic Wave Speeds, and H2O\nContents of Minerals and Rocks at Pressure and Temperature.” Geochemistry,\nGeophysics, Geosystems 5, no. 1 (January 1, 2004): Q01005.\ndoi:10.1029/2003GC000614.\n\nKennett, B. L. N., E. R. Engdahl, and R. Buland. “Constraints on Seismic\nVelocities in the Earth from Traveltimes.” Geophysical Journal International\n122, no. 1 (July 1, 1995): 108–24. doi:10.1111/j.1365-246X.1995.tb03540.x.\n\nSaxena, Surendra K., and Guoyin Shen. “Assessed Data on Heat Capacity, Thermal\nExpansion, and Compressibility for Some Oxides and Silicates.” Journal of\nGeophysical Research: Solid Earth 97, no. B13 (Dezember 1992): 19813–25.\ndoi:10.1029/92JB01555.\n\nSchaeffer, A. J., and S. Lebedev. “Global Shear Speed Structure of the Upper\nMantle and Transition Zone.” Geophysical Journal International 194, no. 1 (July\n1, 2013): 417–49. doi:10.1093/gji/ggt095.\n\nSobolev, Stephan V., Hermann Zeyen, Gerald Stoll, Friederike Werling, Rainer\nAltherr, and Karl Fuchs. “Upper Mantle Temperatures from Teleseismic Tomography\nof French Massif Central Including Effects of Composition, Mineral Reactions,\nAnharmonicity, Anelasticity and Partial Melt.” Earth and Planetary Science\nLetters 139, no. 1–2 (März 1996): 147–63. doi:10.1016/0012-821X(95)00238-8.\n\n## Licence\n\nLicence: GNU General Public Licence, Version 3, 29 June 2007\n\nCopyright (2017): Christian Meeßen, Potsdam, Germany\n\nVelocityConversion is free software: you can redistribute it and/or modify it\nunder the terms of the GNU General Public License as published by the Free\nSoftware Foundation, either version 3 of the License, or (at your option) any\nlater version. VelocityConversion is distributed in the hope that it will be\nuseful, but WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public\nLicense for more details. You should have received a cop y of the GNU General\nPublic License along with this program. If not, see\nhttp://www.gnu.org/licenses/.\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/vencopy",
            "repo_link": "https://gitlab.com/dlr-ve/esy/vencopy/vencopy",
            "readme": "# Welcome to venco.py!\n\n- Authors: Niklas Wulff, Fabia Miorelli\n- Contact: vencopy@dlr.de\n\n# Contents\n\n- [Description](#description)\n- [Installation](#installation)\n- [Codestyle](#codestyle)\n- [Documentation](#documentation)\n- [Useful Links](#useful-links)\n- [Want to contribute?](#want-to-contribute)\n\n## Description\n\nA data processing tool estimating hourly electric demand and flexibility profiles for future \nelectric vehicle fleets. Profiles are targeted to be scalable for the use in large-scale\nenergy system models. \n\n## Installation\n\nDepending on if you want to use venco.py or if you want to contribute, there are\ntwo different installation procedures described in venco.py's documentation:\n\n[I want to apply the tool](https://dlr-ve.gitlab.io/esy/vencopy/vencopy/gettingstarted/installation.html#installation-for-users)\n\n[I want to contribute to the codebase, the documentation or the tutorials](https://dlr-ve.gitlab.io/esy/vencopy/vencopy/gettingstarted/installation.html#installation-for-developers)\n\nIn order to start using venco.py, check out our [tutorials](https://dlr-ve.gitlab.io/esy/vencopy/vencopy/gettingstarted/start.html). For this you won't need any additional data.\n\nTo run venco.py in full mode, you will need the data set Mobilität in Deutschland (German for \"mobility in Germany\"). You\ncan request it here from the clearingboard transport: https://daten.clearingstelle-verkehr.de/order-form.html \nAlternatively you can use venco.py with any National Travel Survey or mobility pattern dataset.\n\n\n## Codestyle\n\nWe use PEP-8, with the exception of UpperCamelCase for class names.\n\n## Documentation\n\nThe documentation can be found here: https://dlr-ve.gitlab.io/esy/vencopy/vencopy/\nTo be able to build the documentation locally on your machine you should additionally install the following three packages in your vencopy environment : sphinx, sphinx_rtd_theme and rst2pdf.\nAfter that you can build the documentation locally from a conda bash with the following command:\n\n```python\nsphinx-build -b html ./docs/ ./build/\n```\n\n## Useful Links\n\n- Documentation: https://dlr-ve.gitlab.io/esy/vencopy/vencopy/\n- Source code: https://gitlab.com/dlr-ve/esy/vencopy/vencopy\n- PyPI release: https://pypi.org/project/vencopy/\n- Licence: https://opensource.org/licenses/BSD-3-Clause\n\n## Want to contribute?\n\nPlease read our contribute section in the documentation and reach out to Fabia\n(fabia.miorelli@dlr.de). If you experience difficulties on set up or have other technical questions, join our\n[gitter community](https://gitter.im/vencopy/community)\n",
            "project_id": "50526856"
        },
        {
            "software_organization": "https://helmholtz.software/software/vinos",
            "repo_link": "https://codebase.helmholtz.cloud/mussel/netlogo-northsea-species.git",
            "readme": "",
            "project_id": "4399"
        },
        {
            "software_organization": "https://helmholtz.software/software/vitess",
            "repo_link": "https://iffgit.fz-juelich.de/vitess/vitess/-/releases",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/vitruvius",
            "repo_link": "https://github.com/vitruv-tools/Vitruv",
            "readme": "# Vitruv\n[![GitHub Action CI](https://github.com/vitruv-tools/Vitruv/actions/workflows/ci.yml/badge.svg)](https://github.com/vitruv-tools/Vitruv/actions/workflows/ci.yml)\n[![Latest Release](https://img.shields.io/github/release/vitruv-tools/Vitruv.svg)](https://github.com/vitruv-tools/Vitruv/releases/latest)\n[![Issues](https://img.shields.io/github/issues/vitruv-tools/Vitruv.svg)](https://github.com/vitruv-tools/Vitruv/issues)\n[![License](https://img.shields.io/github/license/vitruv-tools/Vitruv.svg)](https://raw.githubusercontent.com/vitruv-tools/Vitruv/main/LICENSE)\n\n[Vitruvius](https://vitruv.tools) is a framework for view-based (software) development.\nIt assumes different models to be used for describing a system, which are automatically kept consistent by the framework executing (semi-)automated rules that preserve consistency.\nThese models are modified only via views, which are projections from the underlying models.\nFor general information on Vitruvius, see our [GitHub Organisation](https://github.com/vitruv-tools) and our [Wiki](https://github.com/vitruv-tools/.github/wiki).\n\nThis project contains the central Vitruvius framework, providing the definition of a V-SUM (Virtual Single Underlying Model) containing development artifacts to be kept consistent and to be accessed and modified via views.\nIn the implementation, a V-SUM is called `VirtualModel`, which is instantiated with a set of `ChangePropagationSpecifications` (no matter whether they are developed with the [Vitruv-DSLs](https://github.com/vitruv-tools/Vitruv-DSLs) or just as an implementation of the interface defined in the [Vitruv-Change](https://github.com/vitruv-tools/Vitruv-Change) repository).\nThe `VirtualModel` then provides functionality to derive and modify views and to propagate the changes in these views back to the `VirtualModel`, which then executes the `ChangePropagationSpecifications` to preserve consistency.\n\n## Framework-internal Dependencies\n\nThis project depends on the following other projects from the Vitruvius framework:\n- [Vitruv-Change](https://github.com/vitruv-tools/Vitruv-Change)\n\n## Module Overview\n\n| Name         | Description                                                                                  |\n|--------------|----------------------------------------------------------------------------------------------|\n| views        | Definition of view types on the underlying models.                                           |\n| vsum         | Definition of V-SUMs with consistency preservation rules between meta-models and view types. |\n| remote       | Client-server infrastructure for working with V-SUMs.                                        |\n| applications | Definition of and registry for V-SUMs.                                                       |\n| *testutils*  | *Utilities for testing in Vitruvius or V-SUM projects.*                                      |\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/voltron",
            "repo_link": "https://github.com/BIMSBbioinfo/VoltRon",
            "readme": "![](https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/voltron_framework_box_io.png)\n\n<br>\n\n**Website and Tutorials**: <a href=\"https://bioinformatics.mdc-berlin.de/VoltRon\">https://bioinformatics.mdc-berlin.de/VoltRon</a>\n\n**VoltRon**  is a spatial omic analysis toolbox for multi-omics integration using spatial image registration. VoltRon is also capable of analyzing multiple types of spatially-aware data modalities.\n   \n   <ul class=\"maintext2\">\n    <li style=\"padding-bottom: 10px\">\n      <strong> Unique data structure </strong> of VoltRon allows users to seamlessly define tissue blocks, layers and multiple assay types in one R object.\n    </li>\n    <li style=\"padding-bottom: 10px\">\n      <strong> End-to-end downstream data analysis </strong> for distinct spatial biology technologies are supported. VoltRon visualizes and analyzes regions of interests (ROIs), spots, cells, molecules and tiles **(under development)**.\n    </li>\n    <li style=\"padding-bottom: 10px\">\n      <strong> Automated Image Registration </strong> incorporates <a href=\"https://opencv.org/\">OpenCV</a> (fully embedded into the package using <a href=\"https://www.rcpp.org/\">Rcpp</a>) to detect common features across images and achieves registration. Users may interact with built-in mini shiny apps to change alignment parameters and validate alignment accuracy.\n    </li>\n    <li style=\"padding-bottom: 10px\">\n      <strong> Manual Image Registration </strong> helps users to select common features across spatial datasets using reference images stored in VoltRon objects. In case automated image registration doesn't work, you can still align images by manually picking landmark points.\n    </li>\n    <li style=\"padding-bottom: 10px\">\n    <p style=\"padding-bottom: 3px\"> <strong> Spatially Aware Analysis </strong> allows detecting spatial patterns across cells, spots, molecules and other entities. </p>\n    <ul class=\"maintext3\">\n      <li style=\"padding-bottom: 10px padding-top: 12px\">\n      <strong>(Niche Clustering: Spots)</strong> VoltRon allows integration to single cell RNA datasets using <a href=\"https://satijalab.org/seurat/\">Seurat</a>, <a href=\"https://www.bioconductor.org/packages/release/bioc/vignettes/SingleCellExperiment/inst/doc/intro.html\">SingleCellExperiment</a> and <a href=\"https://github.com/dmcable/spacexr\">spacexr</a> for spot deconvolution. Estimated cell type abundances are then used to cluster spots into groups of cell type niches which are defined as spots with distinct composition of cell types.\n      </li>\n      <li style=\"padding-bottom: 2px\">\n      <strong>(Niche Clustering: Cells)</strong> VoltRon creates spatial neighborhoods around cells to cluster local cellular compositions around all cells which in turn informs users on cell types that are likely within proximity to each other.\n      </li>\n      <li style=\"padding-bottom: 10px\">\n      <strong>(Hot Spot Detection)</strong> VoltRon detects region of locally spatial patterns of cells/molecules/spots that are abundant in biological events and/or features.\n      </li>\n    </ul>  \n    </li>\n    <li style=\"padding-bottom: 10px\">\n    <p> <strong> Support for Big Data </strong> for VoltRon objects enables storing large feature data matrices and large microscopic images of tissues on disk without overloading memory, thus allowing analysis on large datasets with ease. VoltRon stores large images as pyramid structures to speed up visualization and data retrieval. </p>\n    </li>\n    <li style=\"padding-bottom: 10px\">\n    <p> <strong> Interoperability across R/Python frameworks </strong> allows users to convert VoltRon objects to a large number of objects used by other spatial omic platforms such as Seurat, Squidpy (AnnData), SpatialExperiment (BioConductor) and Giotto. </p>\n    </li>\n  </ul>\n\n## Staying up-to-date\n\nTo ask questions please use VoltRon discussion forum on google groups.\n\n- https://groups.google.com/forum/#!forum/voltron_discussion\n\n## Installation\n\nInstall from the GitHub repository using devtools (with R version 4.3.0 or higher):\n\n``` r\nif (!require(\"devtools\", quietly = TRUE))\n    install.packages(\"devtools\")\ndevtools::install_github(\"BIMSBbioinfo/VoltRon\")\n```\n\nDepending on the number of required dependencies, installation may be completed under a minute or may take a few minutes. \n\nOn **Windows** and **MacOS**, OpenCV will be downloaded automatically upon installation. However, [Rtools](https://cran.r-project.org/bin/windows/Rtools/rtools43/rtools.html) may be required to be downloaded too, hence this may take some time!\n\nOn **Ubuntu** we provide a set of instructions that may help users to build OpenCV with necessary headers [here](inst/extdata/install_ubuntu.md).\n\nOn **Fedora** you may need [`opencv-devel`](https://src.fedoraproject.org/rpms/opencv):\n\n```sh\nyum install opencv-devel\n```\n\n## Tutorials\n\nPlease see the [Explore](https://artur-man.github.io/VoltRon/tutorials.html) section in the VoltRon website for tutorials, example scripts and analysis found in the [preprint](https://www.biorxiv.org/content/10.1101/2023.12.15.571667v1). Tutorials include links for accessing necessary data to run scripts across all tutorials. \n\n## References\n\nManukyan, A., Bahry, E., Wyler, E., Becher, E., Pascual-Reguant, A., Plumbom, I., ... & Akalin, A. (2023). [VoltRon: A Spatial Omics Analysis Platform for Multi-Resolution and Multi-omics Integration using Image Registration](https://www.biorxiv.org/content/10.1101/2023.12.15.571667v1). bioRxiv, 2023-12.\n\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/weskit",
            "repo_link": "https://gitlab.com/one-touch-pipeline/weskit",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/wombat",
            "repo_link": "https://git.gsi.de/phelix/lv/wombat_ce",
            "readme": "# Wavefront optics measurement and beam analysis tool\n![alt text](Logos/WombatLogo.svg \"WOMBAT Logo\")\n\nThis LabVIEW project contains the WOMBAT application. It's a modular software for the acquisition of image data (both real and simulated cameras available) as well as image data analysis. Its main focus is the analysis of images delivered by a Shack-Hartmann sensor for wavefront measurement.\n\n**Cloning the software**\n\nYou can clone this repository and its submodule with the following command\n```\n    git clone https://git.gsi.de/phelix/lv/wombat.git\n    git submodule init\n    git submodule update\n```\n",
            "project_id": "2084"
        },
        {
            "software_organization": "https://helmholtz.software/software/wps-command-line-tool-repository",
            "repo_link": "https://github.com/riesgos/gfz-command-line-tool-repository",
            "readme": "# gfz-riesgos-wps-repository\n\n[![pipeline status](https://gitext.gfz-potsdam.de/riesgos/gfz-riesgos-wps-repository/badges/master/pipeline.svg)](https://gitext.gfz-potsdam.de/riesgos/gfz-riesgos-wps-repository/commits/master)\n\n## Description\n\nThis is the java source code for the wps-repository for the riesgos project.\n\nIt aims to be an framework for easy integration of command line programs\nas web processing services and provide a bunch of services within the scope\nof the [RIESGOS project](http://www.riesgos.de/en/). This focus here is\nmainly on those processes provided by the [GFZ](https://www.gfz-potsdam.de/en/home/).\n\n## How it works\n\nThe processes that are integrated here are command line programs.\nMost processes integrated so far use python3 but any executable command line\nprogram can be integrated.\n\nEach process must be wrapped in a docker image to provide fully independent\nexecution of the processes (also in case of some hard coded temporary files)\nand to manage the dependencies (programs, libraries, python packages,\ninternal configuration files, ...).\n\nFor each processes a json configuration file must be provided, so that\nthe basic process skeleton - which is the same for all processes -\nknows how to provide the input data, how to\nstart the process and how to read the output of the programs. It is\nalso used to specify the way of error handling in the process skeleton.\n\nFor more information about dockerfiles you can take a look at\nthe [official docker documentation](https://docs.docker.com/engine/reference/builder/).\nThe role of docker for the overall framework here is explained on [its\nown documentation page](doc/RoleOfDocker.md).\n\nThe json configuration is explained in more detail\n[here](doc/JsonConfigurationExplaned.md).\n\n## Requirements\n\nAll of the code here runs on top of the WPS Server provided by\n[52° North](https://github.com/52North/WPS).\n\nFor other details please refer to the [installation guide](doc/Installationguide.md).\n\n## Currently implemented processes\n\nPlease refer to the following [sub page](doc/IncludedProcesses.md)\nfor an overview of the\nprocesses that are already on board.\n\nAdditionally to the main processes there are also some [format conversion\nprocesses](doc/FormatConversionProcesses.md) in the repository.\n\n## How to add a service\n\nIf you want to know how to add your own service, we provide a\nstep-by-step guide to add a service [here](doc/HowToAddOwnProcess.md).\n"
        },
        {
            "software_organization": "https://helmholtz.software/software/wrainfo",
            "repo_link": "https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo",
            "readme": ".. figure:: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo/-/raw/main/docs/images/wrainfo_logo.png\n    :target: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo\n    :align: center\n\n\n==============================================================\nWRaINfo - An Open Source Library for Weather Radar Information\n==============================================================\n\nis a software for real-time weather radar data processing. It is specifically designed for X-band weather radars of FURUNO.\n\n.. image:: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo/badges/main/pipeline.svg\n        :target: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo/pipelines\n.. image:: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo/badges/main/coverage.svg\n        :target: https://fernlab.git-pages.gfz-potsdam.de/products/furuno/wrainfo/coverage/\n.. image:: https://img.shields.io/static/v1?label=Documentation&message=GitLab%20Pages&color=orange\n        :target: https://fernlab.git-pages.gfz-potsdam.de/products/furuno/wrainfo/doc/\n.. image:: https://zenodo.org/badge/DOI/10.5281/zenodo.7220833.svg\n        :target: https://doi.org/10.5281/zenodo.7220833\n\nFor detailed information, refer to the `documentation <https://fernlab.git-pages.gfz-potsdam.de/products/furuno/wrainfo/doc/>`_.\nFor more background information on the individual functions, see the `software metapaper <https://openresearchsoftware.metajnl.com/articles/10.5334/jors.453>`_-.\nSee also the latest coverage_ report and the pytest_ HTML report.\n\n* **Contact**: Alice Künzel (alicek@gfz-potsdam.de)\n* Information on how to **cite the WRaINfo Python package** can be found in the `CITATION <CITATION.rst>`__ file.\n* Please **cite also the Wradlib Python package** as follows:\n\tAn Open Source Library for Weather Radar Data Processing\n\tHeistermann, M., Jacobi, S., and Pfaff, T.: Technical Note: An open source library for processing weather\n\tradar data (wradlib), Hydrol. Earth Syst. Sci., 17, 863-871, doi:10.5194/hess-17-863-2013, 2013\n\n\n.. contents:: Table of Contents\n   :depth: 2\n\n=================\nFeatures overview\n=================\n\nThe FURUNO raw data can already provide useful visual information about the\nspatial distribution of precipitation events. But in order to use the FURUNO\ndata for quantitatvie studies, the raw data has to be processed in order to account\nfor typical error sources such as ground clutter, uncertainities in polarimetric\nvariables and in the z-R relationship as well as attenuation of the radar signal.\nTherefore this python package has been developed for processing FURUNO weather radar\ndata.\n\n\nRemove ground clutter\n---------------------\n\nTo remove ground clutter from raw data exists a function from wradlib based on all\npolarimetric variables and on a static clutter map, which is generated over a long time period.\nPixel which are identified as clutter were exclude from further processing by set the pixels to NaN.\nFor processing a clutter map, the package includes a function to read only the values from raw data sequentially to not overload the memory.\nHere is an example before and after removing ground clutter using WRaINfo.\n\n.. figure:: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo/-/raw/main/docs/images/wr_furuno_comparison_of_raw_reflectivity_and_clutter_corrected_reflectivity.png\n    :target: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo\n\t:width: 80 %\n\n\nAttenuation correction\n----------------------\n\nRainfall-induced attenuation is a major source of underestimation for radar-based precipitation estimation at X-band.\nAfter phase processing, the attenuation correction is used with the approach of `Testud et al. (2001) <https://www.sciencedirect.com/science/article/pii/S1464190900001155?via%3Dihub>`__ is used.\nHere is an example before and after attenuation correction using WRaINfo.\n\n.. figure:: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo/-/raw/main/docs/images/wr_furuno_reflectivity_before_and_after_attenaution_correction.png\n    :target: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo\n    :width: 80 %\n\n\nPrecipitation Estimation\n------------------------\n\nThere are several methods for deriving the amount of precipitation from reflectivity. In general, the z - R conversion is used.\nThe precipitation amount is determined with an integration interval of seconds based on the scan interval.\n\n.. figure:: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo/-/raw/main/docs/images/wr_furuno_reflectivity_attenaution_corrected_and_estimated_precipitation.png\n    :target: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo\n    :width: 80 %\n\n\nGeoreferencing and gridding\n---------------------------\n\nAfter clutter and attenuation correction and precipitation estimation, the polar data are georeferenced using the specified EPSG code\nand saved as a NetCDF file. Here is an example of a georeferenced dataset.\n\n.. figure:: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo/-/raw/main/docs/images/wr_furuno_georeferenced_and_gridded_precipitation_data_with_WRaINfo.png\n    :target: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo\n    :width: 80 %\n\n\n============\nInstallation\n============\n\n`Install <https://fernlab.git-pages.gfz-potsdam.de/products/furuno/wrainfo/doc/installation.html>`_ wrainfo\n\n===================\nHistory / Changelog\n===================\n\nYou can find the protocol of recent changes in the WRaINfo package\n`here <HISTORY.rst>`__.\n\n=======\nLicense\n=======\n\nThe software is available under the `Apache 2.0 <LICENSE/>`_.\n\n============\nContribution\n============\n\n`Contributions <https://fernlab.git-pages.gfz-potsdam.de/products/furuno/wrainfo/doc/contributing.html>`__ are always welcome.\n\n=================\nData availability\n=================\n\nPreprocessed FURUNO weather radar data (level 2a) for the Neubrandenburg site are made available in the `TERENO Data DiscoveryPortal <https://ddp.tereno.net/ddp/>`__\nunder the `CC BY-NC 4.0 license <https://creativecommons.org/licenses/by-nc/4.0/>`__.\nPlease contact us (fernlab@gfz-potsdam.de), if you wish to use the data under another license (e.g. commercially).\n\n========\nCredits\n========\n\n.. |FERNLOGO| image:: https://git.gfz-potsdam.de/fernlab/products/furuno/wrainfo/-/raw/main/docs/images/fernlab_logo.png\n    :width: 10 %\n\n.. list-table::\n    :class: borderless\n\n    * - |FERNLOGO|\n\n      - WRaINfo has been developed by `FERN.Lab <https://fernlab.gfz-potsdam.de/>`_, the Helmholtz Innovation Lab \"Remote sensing for sustainable use of resources\", located at the `Helmholtz Centre Potsdam, GFZ German Research Centre for Geosciences <https://www.gfz-potsdam.de/en/>`_. FERN.Lab is funded by the `Initiative and Networking Fund of the Helmholtz Association <https://www.helmholtz.de/en/about-us/structure-and-governance/initiating-and-networking/>`_.\n\n\nDevelopment Team:\n - Alice Künzel, researcher\n   *Helmholtz Centre Potsdam German Research Centre for Geosciences GFZ, Section 1.4 - Remote Sensing and Geoinformatics*\n - Kai Mühlbauer, researcher\n   *University of Bonn, Institute of Geosciences - Meteorology Section*\n - Julia Neelmeijer, supervisor\n   *Helmholtz Centre Potsdam German Research Centre for Geosciences GFZ, Section 1.4 - Remote Sensing and Geoinformatics*\n - Daniel Spengler, supervisor\n   *Helmholtz Centre Potsdam German Research Centre for Geosciences GFZ, Section 1.4 - Remote Sensing and Geoinformatics*\n\nThis package was created with Cookiecutter_ and the `fernlab/cookiecutter-pypackage`_ project template.\nThe test data represent raw data of the weather radar FURUNO and files which are created with the WRaINfo package.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`fernlab/cookiecutter-pypackage`: https://github.com/fernlab/cookiecutter-pypackage\n.. _coverage: https://fernlab.git-pages.gfz-potsdam.de/products/furuno/wrainfo/coverage/\n.. _pytest: https://fernlab.git-pages.gfz-potsdam.de/products/furuno/wrainfo/test_reports/report.html\n",
            "project_id": "2462"
        },
        {
            "software_organization": "https://helmholtz.software/software/xcascade",
            "repo_link": "",
            "readme": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/xdibias",
            "repo_link": "https://gitlab.dlr.de/xdibias/xdibias",
            "readme": "",
            "project_id": ""
        },
        {
            "software_organization": "https://helmholtz.software/software/xraypac",
            "repo_link": "https://gitlab.desy.de/cdt/xraypac",
            "readme": "# License Information\n\nCopyright © 2024-2025 Deutsches Elektronen-Synchrotron DESY, a research center of the Helmholtz Association.\n\nContact person: Malik Muhammad Abdullah\n\nAuthors: Ludger Inhester, Zoltan Jurek, Sang-Kil Son, Malik M. Abdullah, and Robin Santra\n\nXRAYPAC is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n\nXRAYPAC is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License along with XRAYPAC. If not, see http://www.gnu.org/licenses/.\n\n\n# XRAYPAC\n\nXRAYPAC is a toolkit for modelling x-ray matter interaction.\nIt consists of XATOM, XMOLECULE, CDTK, and XMDYN.\nPlease go to https://www.desy.de/~xraypac to learn more about XRAYPAC.\n\n\nInstallation:\n=============\n\nInstallation instruction are found in the respective subfolder.\nBecause of dependencies, the tools have to be installed in the right order:\n\n1. XATOM\n2. XMOLECULE\n3. CDTK\n\n\n\n",
            "project_id": "8131"
        }
    ]
}